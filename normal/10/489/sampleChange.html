<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        &#47&#47 initialize weights
        if init_weights:
            <a id="change">self._init_weights(shape=1 + X.shape[1])</a>

        self.cost_ = []

        if self.minibatches is None:
            self.w_ = self._normal_equation(X, y)

        &#47&#47 Gradient descent or stochastic gradient descent learning
        else:
            n_idx = list(range(y.shape[0]))
            self.init_time_ = time()
            for i in range(self.epochs):
                if self.minibatches &gt; 1:
                    X, y = self._shuffle(X, y)

                minis = np.array_split(n_idx, self.minibatches)
                for idx in minis:
                    y_val = self.activation(X[idx])
                    errors = (y[idx] - y_val)
                    <a id="change">self.w_[1:]</a> += self.eta * X[idx].T.dot(errors)
                    <a id="change">self.w_[0]</a> += self.eta * errors.sum()

                cost = self._sum_squared_error_cost(y, self.activation(X))
                self.cost_.append(cost)</code></pre><h3>After Change</h3><pre><code class='java'>
            self.thres_ = 0.5

        if init_weights:
            <a id="change">self.w_</a> = <a id="change">self._init_weights(shape=1 + X.shape[1],
                                         zero_init_weight=self.zero_init_weight,
                                         seed=self.random_seed)</a>

        self.cost_ = []

        if self.minibatches is None:
            self.w_ = self._normal_equation(X, y)

        &#47&#47 Gradient descent or stochastic gradient descent learning
        else:
            n_idx = list(range(y.shape[0]))
            self.init_time_ = time()
            for i in range(self.epochs):
                if self.minibatches &gt; 1:
                    X, y = self._shuffle(X, y)

                minis = np.array_split(n_idx, self.minibatches)
                for idx in minis:
                    y_val = self.activation(X[idx])
                    errors = (y[idx] - y_val)
                    <a id="change">self.w_[1:]</a> += self.eta * X[idx].T.dot(errors)
                    <a id="change">self.w_[0]</a> += self.eta * errors.sum()

                cost = self._sum_squared_error_cost(y, self.activation(X))
                self.cost_.append(cost)</code></pre>