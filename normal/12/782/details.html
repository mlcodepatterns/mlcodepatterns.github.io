<html><h3>78a367e150f625f1b138c847d49ea51498d5263a,official/nlp/modeling/models/bert_pretrainer_test.py,BertPretrainerTest,test_bert_pretrainerv2,#BertPretrainerTest#,118
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        encoder_network=test_network, customized_masked_lm=customized_masked_lm)
    num_token_predictions = 20
    &#47&#47 Create a set of 2-dimensional inputs (the first dimension is implicit).
    word_ids = <a id="change">tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)</a>
    mask = <a id="change">tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)</a>
    type_ids = <a id="change">tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)</a>
    lm_mask = <a id="change">tf.keras.Input(shape=(num_token_predictions,), dtype=tf.int32)</a>

    &#47&#47 Invoke the trainer model on the inputs. This causes the layer to be built.
    outputs = <a id="change">bert_trainer_model([word_ids, mask, type_ids, lm_mask])</a>

    has_encoder_outputs = dict_outputs or return_all_encoder_outputs
    if has_encoder_outputs:
      self.assertSameElements(</code></pre><h3>After Change</h3><pre><code class='java'>
        encoder_network=test_network, customized_masked_lm=customized_masked_lm)
    num_token_predictions = 20
    &#47&#47 Create a set of 2-dimensional inputs (the first dimension is implicit).
    <a id="change">inputs</a> = dict(
        input_word_ids=<a id="change">tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)</a>,
        input_mask=<a id="change">tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)</a>,
        input_type_ids=<a id="change">tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)</a>,
        masked_lm_positions=<a id="change">tf.keras.Input(
            shape=(num_token_predictions,), dtype=tf.int32)</a>)

    &#47&#47 Invoke the trainer model on the inputs. This causes the layer to be built.
    outputs = <a id="change">bert_trainer_model(inputs)</a>

    has_encoder_outputs = dict_outputs or return_all_encoder_outputs
    if has_encoder_outputs:
      self.assertSameElements(</code></pre><img src="3793721.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 10</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/tensorflow/models/commit/78a367e150f625f1b138c847d49ea51498d5263a#diff-02f502cd3c44259e82caa76a9c17eaeb637de913ff270aaa3fb01caae1c84054L145' target='_blank'>Link</a></div><div id='project'> Project Name: tensorflow/models</div><div id='commit'> Commit Name: 78a367e150f625f1b138c847d49ea51498d5263a</div><div id='time'> Time: 2020-11-18</div><div id='author'> Author: hongkuny@google.com</div><div id='file'> File Name: official/nlp/modeling/models/bert_pretrainer_test.py</div><div id='class'> Class Name: BertPretrainerTest</div><div id='method'> Method Name: test_bert_pretrainerv2</div><BR><BR><div id='link'><a href='https://github.com/tensorflow/models/commit/7bfdae1a85924bed872200163d40cbae4c4b4bcf#diff-02f502cd3c44259e82caa76a9c17eaeb637de913ff270aaa3fb01caae1c84054L145' target='_blank'>Link</a></div><div id='project'> Project Name: tensorflow/models</div><div id='commit'> Commit Name: 7bfdae1a85924bed872200163d40cbae4c4b4bcf</div><div id='time'> Time: 2020-11-17</div><div id='author'> Author: hongkuny@google.com</div><div id='file'> File Name: official/nlp/modeling/models/bert_pretrainer_test.py</div><div id='class'> Class Name: BertPretrainerTest</div><div id='method'> Method Name: test_bert_pretrainerv2</div><BR><BR><div id='link'><a href='https://github.com/tensorflow/models/commit/78a367e150f625f1b138c847d49ea51498d5263a#diff-02f502cd3c44259e82caa76a9c17eaeb637de913ff270aaa3fb01caae1c84054L145' target='_blank'>Link</a></div><div id='project'> Project Name: tensorflow/models</div><div id='commit'> Commit Name: 78a367e150f625f1b138c847d49ea51498d5263a</div><div id='time'> Time: 2020-11-18</div><div id='author'> Author: hongkuny@google.com</div><div id='file'> File Name: official/nlp/modeling/models/bert_pretrainer_test.py</div><div id='class'> Class Name: BertPretrainerTest</div><div id='method'> Method Name: test_bert_pretrainerv2</div><BR><BR><div id='link'><a href='https://github.com/tensorflow/models/commit/8cd8b2295024b21e7ee8db6cf871df824f20ab42#diff-02f502cd3c44259e82caa76a9c17eaeb637de913ff270aaa3fb01caae1c84054L145' target='_blank'>Link</a></div><div id='project'> Project Name: tensorflow/models</div><div id='commit'> Commit Name: 8cd8b2295024b21e7ee8db6cf871df824f20ab42</div><div id='time'> Time: 2020-11-17</div><div id='author'> Author: hongkuny@google.com</div><div id='file'> File Name: official/nlp/modeling/models/bert_pretrainer_test.py</div><div id='class'> Class Name: BertPretrainerTest</div><div id='method'> Method Name: test_bert_pretrainerv2</div><BR>