<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

&#47&#47 Setup results directory ----------------------------------------------------

<a id="change">save_dir</a> = os.path.join(results_dir, <a id="change">os.path.splitext(__file__)[0] + &quot_&quot + datetime.now().strftime(&quot%Y%m%dT%H%M%S&quot)</a>)
<a id="change">if not os.path.exists(save_dir):
    os.makedirs(save_dir)

&#47&#47 Set reconstruction options -------------------------------------------------

</a>opts = {
    &#47&#47 The loss function type: {&quotl2&quot,&quotl1&quot,&quotinner&quot,&quotgram&quot}
    &quotloss_type&quot: &quotl2&quot,

    &#47&#47 The maximum number of iterations
    &quotmaxiter&quot: max_iteration,

    &#47&#47 The initial image for the optimization (setting to None will use random noise as initial image)
    &quotinitial_image&quot: initial_image,

    &#47&#47 Display the information on the terminal or not
    &quotdisp&quot: True
}

&#47&#47 Save the optional parameters
with <a id="change">open(os.path.join(save_dir, &quotoptions.pkl&quot), &quotw&quot)</a> as f:
    pickle.dump(opts, f)

&#47&#47 Reconstrucion --------------------------------------------------------------

for subject, roi, image_label in product(subjects_list, rois_list, image_label_list):

    print(&quot&quot)
    print(&quotSubject:     &quot + subject)
    print(&quotROI:         &quot + roi)
    print(&quotImage label: &quot + image_label)
    print(&quot&quot)

    &#47&#47 Load the decoded CNN features
    features = {}
    for layer in layers:
        &#47&#47 The file full name depends on the data structure for decoded CNN features
        file_name = decode_feature_filename(network, layer, subject, roi, image_type, image_label)
        feat = sio.loadmat(file_name)[&quotfeat&quot]
        if &quotfc&quot in layer:
            feat = feat.reshape(feat.size)

        &#47&#47 Correct the norm of the decoded CNN features
        feat_std = estimate_cnn_feat_std(feat)
        feat = (feat / feat_std) * feat_std0[layer]

        features.update({layer: feat})

    &#47&#47 Weight of each layer in the total loss function

    &#47&#47 Norm of the CNN features for each layer
    feat_norm = np.array([np.linalg.norm(features[layer]) for layer in layers], dtype=&quotfloat32&quot)

    &#47&#47 Use the inverse of the squared norm of the CNN features as the weight for each layer
    weights = 1. / (feat_norm ** 2)

    &#47&#47 Normalise the weights such that the sum of the weights = 1
    weights = weights / weights.sum()
    layer_weight = dict(zip(layers, weights))

    opts.update({&quotlayer_weight&quot: layer_weight})

    &#47&#47 Reconstruction
    <a id="change">snapshots_dir</a> = <a id="change">os.path.join(save_dir, &quotsnapshots_%s-%s&quot % (subject, roi), &quotimage-%s&quot % image_label)</a>
    recon_img, loss_list = reconstruct_image(features, net,
                                             save_intermediate=True,
                                             save_intermediate_path=snapshots_dir,
                                             **opts)

    &#47&#47 Save the results

    &#47&#47 Save the raw reconstructed image
    <a id="change">save_name</a> = <a id="change">&quotrecon_img&quot + &quot-&quot + subject + &quot-&quot + roi + &quot-&quot + image_label + &quot.mat&quot</a>
    <a id="change">sio.savemat(os.path.join(save_dir, save_name), {&quotrecon_img&quot: recon_img})</a>

    &#47&#47 To better display the image, clip pixels with extreme values (0.02% of
    &#47&#47 pixels with extreme low values and 0.02% of the pixels with extreme high
    &#47&#47 values). And then normalise the image by mapping the pixel value to be</code></pre><h3>After Change</h3><pre><code class='java'>

&#47&#47 Setup results directory ----------------------------------------------------

save_dir_root = os.path.join(results_dir, <a id="change">os.path.splitext(__file__)[0]</a>)
<a id="change">if not os.path.exists(save_dir_root):
    os.makedirs(save_dir_root)

&#47&#47 Set reconstruction options -------------------------------------------------

</a>opts = {
    &#47&#47 The loss function type: {&quotl2&quot,&quotl1&quot,&quotinner&quot,&quotgram&quot}
    &quotloss_type&quot: &quotl2&quot,

    &#47&#47 The maximum number of iterations
    &quotmaxiter&quot: max_iteration,

    &#47&#47 The initial image for the optimization (setting to None will use random noise as initial image)
    &quotinitial_image&quot: initial_image,

    &#47&#47 Display the information on the terminal or not
    &quotdisp&quot: True
}

&#47&#47 Save the optional parameters
with <a id="change">open(os.path.join(save_dir_root, &quotoptions.pkl&quot), &quotw&quot)</a> as f:
    pickle.dump(opts, f)

&#47&#47 Reconstrucion --------------------------------------------------------------

for subject, roi, image_label in product(subjects_list, rois_list, image_label_list):

    print(&quot&quot)
    print(&quotSubject:     &quot + subject)
    print(&quotROI:         &quot + roi)
    print(&quotImage label: &quot + image_label)
    print(&quot&quot)

    <a id="change">save_dir</a> = <a id="change">os.path.join(save_dir_root, subject, roi)</a>
    <a id="change">if not os.path.exists(save_dir):
        os.makedirs(save_dir)

    &#47&#47 Load the decoded CNN features
   </a> features = {}
    for layer in layers:
        &#47&#47 The file full name depends on the data structure for decoded CNN features
        file_name = decode_feature_filename(network, layer, subject, roi, image_type, image_label)
        feat = sio.loadmat(file_name)[&quotfeat&quot]
        if &quotfc&quot in layer:
            feat = feat.reshape(feat.size)

        &#47&#47 Correct the norm of the decoded CNN features
        feat_std = estimate_cnn_feat_std(feat)
        feat = (feat / feat_std) * feat_std0[layer]

        features.update({layer: feat})

    &#47&#47 Weight of each layer in the total loss function

    &#47&#47 Norm of the CNN features for each layer
    feat_norm = np.array([np.linalg.norm(features[layer]) for layer in layers], dtype=&quotfloat32&quot)

    &#47&#47 Use the inverse of the squared norm of the CNN features as the weight for each layer
    weights = 1. / (feat_norm ** 2)

    &#47&#47 Normalise the weights such that the sum of the weights = 1
    weights = weights / weights.sum()
    layer_weight = dict(zip(layers, weights))

    opts.update({&quotlayer_weight&quot: layer_weight})

    &#47&#47 Reconstruction
    <a id="change">snapshots_dir</a> = <a id="change">os.path.join(save_dir, &quotsnapshots&quot, &quotimage-%s&quot % image_label)</a>
    recon_img, loss_list = reconstruct_image(features, net,
                                             save_intermediate=True,
                                             save_intermediate_path=snapshots_dir,
                                             **opts)

    &#47&#47 Save the results

    &#47&#47 Save the raw reconstructed image
    save_name = &quotrecon_img&quot + &quot-&quot + image_label + &quot.mat&quot
    <a id="change">sio.savemat(os.path.join(save_dir, save_name), {&quotrecon_img&quot: recon_img})</a>

    &#47&#47 To better display the image, clip pixels with extreme values (0.02% of
    &#47&#47 pixels with extreme low values and 0.02% of the pixels with extreme high
    &#47&#47 values). And then normalise the image by mapping the pixel value to be
    &#47&#47 within [0,255].
    <a id="change">save_name</a> = &quotrecon_img_normalized&quot + &quot-&quot + image_label + &quot.jpg&quot
    PIL.Image.fromarray(normalise_img(clip_extreme_value(recon_img, pct=0.04))).save(os.path.join(save_dir, save_name))

print(&quotDone&quot)</code></pre>