<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            y_true = K.clip(y_true, K.epsilon(), 1)

            &#47&#47 make sure pred is a probability
            y_pred /= <a id="change">K.sum(y_pred, axis=-1, keepdims=True)</a>
            <a id="change">y_pred</a> = K.clip(y_pred, K.epsilon(), 1)

        &#47&#47 Prepare the volumes to operate on
        &#47&#47 If we&quotre doing &quothard&quot Dice, then we will prepare one-hot-based matrices of size
        &#47&#47 [batch_size, nb_voxels, nb_labels], where for each voxel in each batch entry,
        &#47&#47 the entries are either 0 or 1
        if self.dice_type == &quothard&quot:

            &#47&#47 if given predicted probability, transform to "hard max""
            if self.input_type == &quotprob&quot:
                if self.approx_hard_max:
                    <a id="change">y_pred_op</a> = _hard_max(y_pred, axis=-1)
                    y_true_op = _hard_max(y_true, axis=-1)
                else:
                    y_pred_op = _label_to_one_hot(K.argmax(y_pred, axis=-1), self.nb_labels)
                    y_true_op = _label_to_one_hot(K.argmax(y_true, axis=-1), self.nb_labels)

            &#47&#47 if given predicted label, transform to one hot notation
            else:
                assert self.input_type == &quotmax_label&quot
                <a id="change">y_pred_op</a> = _label_to_one_hot(y_pred, self.nb_labels)
                y_true_op = _label_to_one_hot(y_true, self.nb_labels)

        &#47&#47 If we&quotre doing soft Dice, require prob output, and the data already is as we need it
        &#47&#47 [batch_size, nb_voxels, nb_labels]
        else:
            assert self.input_type == &quotprob&quot, "cannot do soft dice with max_label input"
            <a id="change">y_pred_op</a> = y_pred
            y_true_op = y_true

        &#47&#47 reshape to [batch_size, nb_voxels, nb_labels]
        batch_size = K.shape(y_true)[0]
        <a id="change">y_pred_op</a> = K.reshape(y_pred_op, [batch_size, -1, K.shape(y_true)[-1]])
        y_true_op = K.reshape(y_true_op, [batch_size, -1, K.shape(y_true)[-1]])

        &#47&#47 compute dice for each entry in batch.
        &#47&#47 dice will now be [batch_size, nb_labels]
        <a id="change">top</a> = 2 * K.sum(y_true_op * y_pred_op, 1)
        <a id="change">bottom</a> = K.sum(K.square(y_true_op), 1) + K.sum(K.square(y_pred_op), 1)
        &#47&#47 make sure we have no 0s on the bottom. K.epsilon()
        bottom = K.maximum(bottom, self.area_reg)
        return top / bottom</code></pre><h3>After Change</h3><pre><code class='java'>

            &#47&#47 make sure pred is a probability
            if self.re_norm:
                y_pred = tf.div_no_nan(y_pred, <a id="change">K.sum(y_pred, axis=-1, keepdims=True)</a>)
            <a id="change">y_pred</a> = K.clip(y_pred, K.epsilon(), 1)

        &#47&#47 Prepare the volumes to operate on
        &#47&#47 If we&quotre doing &quothard&quot Dice, then we will prepare one-hot-based matrices of size
        &#47&#47 [batch_size, nb_voxels, nb_labels], where for each voxel in each batch entry,
        &#47&#47 the entries are either 0 or 1
        if self.dice_type == &quothard&quot:

            &#47&#47 if given predicted probability, transform to "hard max""
            if self.input_type == &quotprob&quot:
                if self.approx_hard_max:
                    <a id="change">y_pred_op</a> = _hard_max(y_pred, axis=-1)
                    y_true_op = _hard_max(y_true, axis=-1)
                else:
                    y_pred_op = _label_to_one_hot(K.argmax(y_pred, axis=-1), self.nb_labels)
                    y_true_op = _label_to_one_hot(K.argmax(y_true, axis=-1), self.nb_labels)

            &#47&#47 if given predicted label, transform to one hot notation
            else:
                assert self.input_type == &quotmax_label&quot
                <a id="change">y_pred_op</a> = _label_to_one_hot(y_pred, self.nb_labels)
                y_true_op = _label_to_one_hot(y_true, self.nb_labels)

        &#47&#47 If we&quotre doing soft Dice, require prob output, and the data already is as we need it
        &#47&#47 [batch_size, nb_voxels, nb_labels]
        else:
            assert self.input_type == &quotprob&quot, "cannot do soft dice with max_label input"
            <a id="change">y_pred_op</a> = y_pred
            y_true_op = y_true

        &#47&#47 reshape to [batch_size, nb_voxels, nb_labels]
        batch_size = K.shape(y_true)[0]
        <a id="change">y_pred_op</a> = K.reshape(y_pred_op, [batch_size, -1, K.shape(y_true)[-1]])
        y_true_op = K.reshape(y_true_op, [batch_size, -1, K.shape(y_true)[-1]])

        &#47&#47 compute dice for each entry in batch.
        &#47&#47 dice will now be [batch_size, nb_labels]
        <a id="change">top</a> = 2 * K.sum(y_true_op * y_pred_op, 1)
        <a id="change">bottom</a> = K.sum(K.square(y_true_op), 1) + K.sum(K.square(y_pred_op), 1)
        &#47&#47 make sure we have no 0s on the bottom. K.epsilon()
        bottom = K.maximum(bottom, self.area_reg)
        return top / bottom</code></pre>