<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    network.to(device)
    network.train()
    network.zero_grad()
    <a id="change">optim</a> = torch.optim.RMSprop(network.parameters())
    optim.zero_grad()
    mem_start = 0 if not device == &quotcuda&quot else \
        torch.cuda.memory_allocated() / float(1024 ** 2)

    y = network(xx)
    gc.collect()
    mem_after_forward = mem_reporter.collect_stats() / float(1024 ** 2) if not device == &quotcuda&quot else \
        torch.cuda.memory_allocated() / float(1024 ** 2)
    loss = torch.nn.MSELoss()(y, ytarget)
    <a id="change">optim.zero_grad()</a>
    loss.backward()
    <a id="change">optim.step()</a>
    gc.collect()
    &#47&#47 mem_after_backward = mem_reporter.collect_stats() / float(1024 ** 2) if not device == &quotcuda&quot else \
    &#47&#47     torch.cuda.memory_allocated() / float(1024 ** 2)
    gc.enable()</code></pre><h3>After Change</h3><pre><code class='java'>
        network.to(device)
        network.train()
        network.zero_grad()
        <a id="change">optim</a> = torch.optim.RMSprop(network.parameters())
        optim.zero_grad()
        mem_start = 0 if not device == &quotcuda&quot else \
            torch.cuda.memory_allocated() / float(1024 ** 2)

        y = network(xx)
        gc.collect()
        mem_after_forward = mem_reporter.collect_stats() / float(1024 ** 2) if not device == &quotcuda&quot else \
            torch.cuda.memory_allocated() / float(1024 ** 2)
        loss = torch.nn.MSELoss()(y, ytarget)
        <a id="change">optim.zero_grad()</a>
        loss.backward()
        <a id="change">optim.step()</a>
        gc.collect()
        &#47&#47 mem_after_backward = mem_reporter.collect_stats() / float(1024 ** 2) if not device == &quotcuda&quot else \
        &#47&#47     torch.cuda.memory_allocated() / float(1024 ** 2)
        gc.enable()</code></pre>