<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        return data_provider

    def __call__(self):
        <a id="change">data</a> = self._data_provider.get(<a id="change">self._data_provider.list_items()</a>)
        data = dict(zip(self._data_provider.list_items(), data))

        num_threads = 1
        &#47&#47 Recommended capacity =
        &#47&#47 (num_threads + a small safety margin) * batch_size + margin
        capacity = (num_threads + 32) * self._hparams.batch_size + 1024

        allow_smaller_final_batch = self._hparams.allow_smaller_final_batch

        if len(self._hparams.bucket_boundaries) == 0:
            <a id="change">data_batch</a> = tf.train.batch(
                tensors=data,
                batch_size=self._hparams.batch_size,
                num_threads=num_threads,
                capacity=capacity,
                enqueue_many=False,
                dynamic_pad=True,
                allow_smaller_final_batch=allow_smaller_final_batch,
                name="%s/batch" % self.name)
        else:
            <a id="change">input_length</a> = data[self._src_dataset.decoder.length_tensor_name]
            _, data_batch = tf.contrib.training.bucket_by_sequence_length(
                input_length=input_length,
                tensors=data,</code></pre><h3>After Change</h3><pre><code class='java'>
        return data_provider

    def __call__(self):
        <a id="change">data</a> = self._data_provider.get(<a id="change">list(self._data_provider.list_items())</a>)
        data = dict(zip(list(self._data_provider.list_items()), data))

        num_threads = 1
        &#47&#47 Recommended capacity =
        &#47&#47 (num_threads + a small safety margin) * batch_size + margin
        capacity = (num_threads + 32) * self._hparams.batch_size + 1024

        allow_smaller_final_batch = self._hparams.allow_smaller_final_batch

        if len(self._hparams.bucket_boundaries) == 0:
            <a id="change">data_batch</a> = tf.train.batch(
                tensors=data,
                batch_size=self._hparams.batch_size,
                num_threads=num_threads,
                capacity=capacity,
                enqueue_many=False,
                dynamic_pad=True,
                allow_smaller_final_batch=allow_smaller_final_batch,
                name="%s/batch" % self.name)
        else:
            <a id="change">input_length</a> = data[self._src_dataset.decoder.length_tensor_name]
            _, data_batch = tf.contrib.training.bucket_by_sequence_length(
                input_length=input_length,
                tensors=data,</code></pre>