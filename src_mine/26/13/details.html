<html><h3>e3e937cc41ed031d7971947d17f359a562414168,extract_features.py,,main,#,307
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    tokenizer = tokenization.FullTokenizer(
        vocab_file=FLAGS.vocab_file, do_lower_case=FLAGS.do_lower_case)

    examples = <a id="change">read_examples(FLAGS.input_file)</a>

    features = convert_examples_to_features(
        examples=examples, seq_length=FLAGS.max_seq_length, tokenizer=tokenizer)

    unique_id_to_feature = {}
    for feature in features:
        unique_id_to_feature[feature.unique_id] = feature

    model_fn = model_fn_builder(
        bert_config=bert_config,
        init_checkpoint=FLAGS.init_checkpoint,
        layer_indexes=layer_indexes,
        use_one_hot_embeddings=FLAGS.use_one_hot_embeddings)

    estimator = Estimator(model_fn=model_fn)

    <a id="change">input_fn</a> = input_fn_builder(
        features=features, seq_length=FLAGS.max_seq_length)

    with codecs.getwriter("utf-8")(tf.gfile.Open(FLAGS.output_file,
                                                 "w")) as writer:
        for result in estimator.predict(input_fn):
            <a id="change">unique_id</a> = int(result["unique_id"])
            <a id="change">feature</a> = unique_id_to_feature[unique_id]
            output_json = collections.OrderedDict()
            output_json["linex_index"] = unique_id
            all_features = []
            for (i, token) in enumerate(feature.tokens):
                all_layers = []
                for (j, layer_index) in enumerate(layer_indexes):
                    layer_output = result["layer_output_%d" % j]
                    layers = collections.OrderedDict()
                    layers["index"] = layer_index
                    layers["values"] = [
                        round(float(x), 6) for <a id="change">x</a> in layer_output[i:(i + 1)].flat
                    ]
                    all_layers.append(layers)
                features = collections.OrderedDict()</code></pre><h3>After Change</h3><pre><code class='java'>
    bert_config = modeling.BertConfig.from_json_file(FLAGS.bert_config_file)

    features = convert_examples_to_features(
        examples=<a id="change">read_examples(FLAGS.input_file)</a>,
        seq_length=FLAGS.max_seq_length,
        tokenizer=tokenization.FullTokenizer(
            vocab_file=FLAGS.vocab_file, do_lower_case=FLAGS.do_lower_case))

    unique_id_to_feature = {f.unique_id: f for f in features}

    model_fn = model_fn_builder(
        bert_config=bert_config,
        init_checkpoint=FLAGS.init_checkpoint,
        layer_indexes=layer_indexes,
        use_one_hot_embeddings=FLAGS.use_one_hot_embeddings)

    estimator = Estimator(model_fn=model_fn)

    <a id="change">input_fn</a> = input_fn_builder(
        features=features, seq_length=FLAGS.max_seq_length)

    with codecs.getwriter("utf-8")(tf.gfile.Open(FLAGS.output_file,
                                                 "w")) as writer:
        for result in estimator.predict(input_fn):
            <a id="change">unique_id</a> = int(result["unique_id"])
            <a id="change">feature</a> = unique_id_to_feature[unique_id]
            output_json = collections.OrderedDict()
            output_json["linex_index"] = unique_id
            all_features = []
            for (i, token) in enumerate(feature.tokens):
                all_layers = []
                for (j, layer_index) in enumerate(layer_indexes):
                    layer_output = result["layer_output_%d" % j]
                    layers = collections.OrderedDict()
                    layers["index"] = layer_index
                    layers["values"] = [
                        round(float(x), 6) for <a id="change">x</a> in layer_output[i:(i + 1)].flat
                    ]
                    all_layers.append(layers)
                features = collections.OrderedDict()</code></pre><img src="15649.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 2</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/hanxiao/bert-as-service/commit/e3e937cc41ed031d7971947d17f359a562414168#diff-668dfa0a8b18b89d9823c3d9de3bdaa60d89c2c6b6424905cab2857cd6411493L312' target='_blank'>Link</a></div><div id='project'> Project Name: hanxiao/bert-as-service</div><div id='commit'> Commit Name: e3e937cc41ed031d7971947d17f359a562414168</div><div id='time'> Time: 2018-11-08</div><div id='author'> Author: hanhxiao@tencent.com</div><div id='file'> File Name: extract_features.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: main</div><BR><BR><div id='link'><a href='https://github.com/hanxiao/bert-as-service/commit/8fb4a9c6bdf17aad1e6e0ee89d05e3f792179965#diff-668dfa0a8b18b89d9823c3d9de3bdaa60d89c2c6b6424905cab2857cd6411493L141' target='_blank'>Link</a></div><div id='project'> Project Name: hanxiao/bert-as-service</div><div id='commit'> Commit Name: 8fb4a9c6bdf17aad1e6e0ee89d05e3f792179965</div><div id='time'> Time: 2018-11-08</div><div id='author'> Author: hanhxiao@tencent.com</div><div id='file'> File Name: extract_features.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: convert_lst_to_features</div><BR><BR><div id='link'><a href='https://github.com/hanxiao/bert-as-service/commit/5f5d6d1f30eb168d004ec7699ef8e9a2bf43bbe7#diff-c38e28907f0c6735ffe31e5c0eb1fab517bcfd322dd48d5dbedf0f737aed4702L167' target='_blank'>Link</a></div><div id='project'> Project Name: hanxiao/bert-as-service</div><div id='commit'> Commit Name: 5f5d6d1f30eb168d004ec7699ef8e9a2bf43bbe7</div><div id='time'> Time: 2018-12-13</div><div id='author'> Author: hanhxiao@tencent.com</div><div id='file'> File Name: server/bert_serving/server/bert/extract_features.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: convert_lst_to_features</div><BR>