<html><h3>c2a9e8317be6120c991082c319544a2076b87624,onmt/transforms/bart.py,BARTNoising,whole_word_mask,#BARTNoising#,117
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                    to_keep[indices] = 0
                else:
                    &#47&#47 keep index, but replace it with [MASK]
                    for i in <a id="change">indices</a>:
                        tokens[i] = self.mask_tok
                    <a id="change">random_toks</a> = <a id="change">torch.randint(
                        0, len(self.vocab), size=(mask_random.sum(),))</a>
                    for i, rand_tok in zip(<a id="change">indices[mask_random]</a>, random_toks):
                        <a id="change">tokens[i]</a> = rand_tok

                &#47&#47 assert tokens_length - 1 not in indices
</code></pre><h3>After Change</h3><pre><code class='java'>
            while indices.size(0) &gt; 0:
                &#47&#47 to cover whole token
                uncompleted = is_word_start[indices + 1] == 0
                <a id="change">indices</a> = indices[uncompleted] + 1
                mask_random = mask_random[uncompleted]
                if self.replace_length != -1:
                    &#47&#47 delete token
                    to_keep[indices] = 0
                else:
                    &#47&#47 keep index, but replace it with [MASK]
                    for i in <a id="change">indices.tolist()</a>:
                        tokens[i] = self.mask_tok
                    <a id="change">random_tok_ids</a> = <a id="change">torch.randint(
                        0, len(self.vocab), size=(mask_random.sum(),)).tolist()</a>
                    for i, rid in zip(
                            <a id="change">indices[mask_random].tolist()</a>, random_tok_ids):
                        <a id="change">tokens[i]</a> = <a id="change">self.vocab[rid]</a>

                &#47&#47 assert tokens_length - 1 not in indices

        tokens = [tok for tok, keep in zip(tokens, to_keep.tolist())</code></pre><img src="1111670.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 11</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/OpenNMT/OpenNMT-py/commit/c2a9e8317be6120c991082c319544a2076b87624#diff-922404b0f64fa2e51e53bb39b2245c6478fdb213d7bfe993314a1b6779a663a3L117' target='_blank'>Link</a></div><div id='project'> Project Name: OpenNMT/OpenNMT-py</div><div id='commit'> Commit Name: c2a9e8317be6120c991082c319544a2076b87624</div><div id='time'> Time: 2020-10-22</div><div id='author'> Author: linxiao.zeng@gmail.com</div><div id='file'> File Name: onmt/transforms/bart.py</div><div id='class'> Class Name: BARTNoising</div><div id='method'> Method Name: whole_word_mask</div><BR><BR><div id='link'><a href='https://github.com/OpenNMT/OpenNMT-py/commit/c2a9e8317be6120c991082c319544a2076b87624#diff-922404b0f64fa2e51e53bb39b2245c6478fdb213d7bfe993314a1b6779a663a3L117' target='_blank'>Link</a></div><div id='project'> Project Name: OpenNMT/OpenNMT-py</div><div id='commit'> Commit Name: c2a9e8317be6120c991082c319544a2076b87624</div><div id='time'> Time: 2020-10-22</div><div id='author'> Author: linxiao.zeng@gmail.com</div><div id='file'> File Name: onmt/transforms/bart.py</div><div id='class'> Class Name: BARTNoising</div><div id='method'> Method Name: whole_word_mask</div><BR>