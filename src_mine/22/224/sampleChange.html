<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

    if single_text:
        if word_level:
            text = <a id="change">prefix.split()</a> if prefix else [&quot&quot]
        else:
            text = list(prefix) if prefix else [&quot&quot]
        max_gen_length += maxlen
    else:
        if word_level:
            text = [meta_token] + prefix.split() if prefix else [meta_token]
        else:
            text = [meta_token] + list(prefix) if prefix else [meta_token]
    next_char = &quot&quot

    if not isinstance(temperature, list):
        temperature = [temperature]

    if model_input_count(model) &gt; 1:
        model = Model(inputs=model.input[0], outputs=model.output[1])

    while next_char != meta_token and len(text) &lt; max_gen_length:
        <a id="change">encoded_text</a> = textgenrnn_encode_sequence(text[-maxlen:],
                                                  vocab, maxlen)
        next_temperature = temperature[(len(text) - 1) % len(temperature)]
        <a id="change">next_index</a> = textgenrnn_sample(
            model.predict(encoded_text, batch_size=1)[0],
            next_temperature)
        <a id="change">next_char</a> = indices_char[next_index]
        text += [next_char]

    collapse_char = &quot &quot if word_level else &quot&quot

    &#47&#47 if single text, ignore sequences generated w/ padding
    &#47&#47 if not single text, strip the &lt;s&gt; meta_tokens
    if single_text:
        <a id="change">text</a> = text[maxlen:]
    else:
        <a id="change">text</a> = text[1:-1]

    text_joined = collapse_char.join(text)
</code></pre><h3>After Change</h3><pre><code class='java'>
    if word_level and prefix:
        punct = &quot!"&#47&#47$%&()*+,-./:;&lt;=&gt;?@[\]^_`{|}~\\n\\t\&quot‘’“”’–—&quot
        prefix = re.sub(&quot([{}])&quot.format(punct), r&quot \1 &quot, prefix)
        prefix_t = [x.lower() for x in <a id="change">prefix.split()</a>]

    if not word_level and prefix:
        prefix_t = list(prefix)

    if single_text:
        text = prefix_t if prefix else [&quot&quot]
        max_gen_length += maxlen
    else:
        text = [meta_token] + prefix_t if prefix else [meta_token]

    next_char = &quot&quot

    if not isinstance(temperature, list):
        temperature = [temperature]

    if model_input_count(model) &gt; 1:
        model = Model(inputs=model.input[0], outputs=model.output[1])

    while next_char != meta_token and len(text) &lt; max_gen_length:
        <a id="change">encoded_text</a> = textgenrnn_encode_sequence(text[-maxlen:],
                                                  vocab, maxlen)
        next_temperature = temperature[(len(text) - 1) % len(temperature)]
        <a id="change">next_index</a> = textgenrnn_sample(
            model.predict(encoded_text, batch_size=1)[0],
            next_temperature)
        <a id="change">next_char</a> = indices_char[next_index]
        text += [next_char]

    collapse_char = &quot &quot if word_level else &quot&quot

    &#47&#47 if single text, ignore sequences generated w/ padding
    &#47&#47 if not single text, strip the &lt;s&gt; meta_tokens
    if single_text:
        <a id="change">text</a> = text[maxlen:]
    else:
        <a id="change">text</a> = text[1:-1]

    text_joined = collapse_char.join(text)
</code></pre>