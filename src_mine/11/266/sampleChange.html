<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
      save_audio(predicted_final_spectrogram_sample, self.params["logdir"], step)
    elif "mel" in self.get_data_layer().params[&quotoutput_type&quot]:
      predicted_final_spectrogram_sample = inverse_mel(predicted_final_spectrogram_sample)
      <a id="change">save_audio(predicted_final_spectrogram_sample, self.params["logdir"], step)</a>
    
    return {}

  def finalize_evaluation(self, results_per_batch, step):</code></pre><h3>After Change</h3><pre><code class='java'>
      return loss, [decoder_out, final_spectrogram, attention_mask, target_output, final_sequence_lengths]

  def maybe_print_logs(self, input_values, output_values):
    <a id="change">self.train_steps</a> += 1
    dict_to_log = {}
    <a id="change">step</a> = <a id="change">self.train_steps * self.params["print_samples_steps"]</a>
    spec, target, _ = input_values[&quottarget_tensors&quot]
    predicted_decoder_spectrograms = output_values[0]
    predicted_final_spectrograms = output_values[1]
    attention_mask = output_values[2]
    target_output = output_values[3]
    y_sample = spec[0]
    target = target[0]
    &#47&#47 y_length_sample = y_length[0]
    predicted_spectrogram_sample = predicted_decoder_spectrograms[0]
    predicted_final_spectrogram_sample = predicted_final_spectrograms[0]
    attention_mask_sample = attention_mask[0]
    target_output_sample = target_output[0]
    audio_length = output_values[4][0]

    im_summary = plot_spectrogram_w_target(y_sample, predicted_spectrogram_sample,
                     predicted_final_spectrogram_sample,
                     attention_mask_sample,
                     target_output_sample,
                     target,
                     audio_length,
                     self.params["logdir"], step,
                     append="train", 
                     save_to_tensorboard = self.save_to_tensorboard)
    dict_to_log[&quotimage&quot] = im_summary

    predicted_final_spectrogram_sample = predicted_final_spectrogram_sample[:audio_length-1,:]
    if "magnitude" in self.get_data_layer().params[&quotoutput_type&quot]:
      predicted_final_spectrogram_sample = np.exp(predicted_final_spectrogram_sample)
      wav_summary = save_audio(predicted_final_spectrogram_sample, self.params["logdir"], step,
        save_to_tensorboard = self.save_to_tensorboard)
      dict_to_log[&quotaudio&quot] = wav_summary
    elif "mel" in self.get_data_layer().params[&quotoutput_type&quot]:
      predicted_final_spectrogram_sample = inverse_mel(predicted_final_spectrogram_sample)
      <a id="change">wav_summary</a> = <a id="change">save_audio(predicted_final_spectrogram_sample, self.params["logdir"], step,
        save_to_tensorboard = self.save_to_tensorboard)</a>
      <a id="change">dict_to_log[&quotaudio&quot]</a> = <a id="change">wav_summary</a>
    
    if self.save_to_tensorboard:
      return dict_to_log
    else:</code></pre>