<html><h3>8fae3aef46180186d420db3ec88fc747261f0d5c,models/ShowTellModel.py,ShowTellModel,_sample,#ShowTellModel#Any#Any#Any#Any#,120
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            output, state = self.core(xt.unsqueeze(0), state)
            logprobs = F.log_softmax(self.logit(self.dropout(output.squeeze(0))), dim=1)

        return torch.cat(<a id="change">[_.unsqueeze(1) for _ in seq]</a>, 1), torch.cat([_.unsqueeze(1) for _ in seqLogprobs], 1)</code></pre><h3>After Change</h3><pre><code class='java'>

        batch_size = fc_feats.size(0)
        state = self.init_hidden(batch_size)
        <a id="change">seq = fc_feats.new_zeros(batch_size, self.seq_length, dtype=torch.long)</a>
        seqLogprobs = fc_feats.new_zeros(batch_size, self.seq_length)
        for t in range(self.seq_length + 2):
            if t == 0:
                xt = self.img_embed(fc_feats)
            else:
                if t == 1: &#47&#47 input &lt;bos&gt;
                    it = fc_feats.data.new(batch_size).long().zero_()
                xt = self.embed(it)

            output, state = self.core(xt.unsqueeze(0), state)
            logprobs = F.log_softmax(self.logit(self.dropout(output.squeeze(0))), dim=1)

            &#47&#47 sample the next word
            if t == self.seq_length + 1: &#47&#47 skip if we achieve maximum length
                break
            if sample_max:
                sampleLogprobs, it = torch.max(logprobs.data, 1)
                it = it.view(-1).long()
            else:
                if temperature == 1.0:
                    prob_prev = torch.exp(logprobs.data).cpu() &#47&#47 fetch prev distribution: shape Nx(M+1)
                else:
                    &#47&#47 scale logprobs by temperature
                    prob_prev = torch.exp(torch.div(logprobs.data, temperature)).cpu()
                it = torch.multinomial(prob_prev, 1).cuda()
                sampleLogprobs = logprobs.gather(1, it) &#47&#47 gather the logprobs at sampled positions
                it = it.view(-1).long() &#47&#47 and flatten indices for downstream processing

            if t &gt;= 1:
                &#47&#47 stop when all finished
                if t == 1:
                    unfinished = it &gt; 0
                else:
                    unfinished = unfinished * (it &gt; 0)
                it = it * unfinished.type_as(it)
                <a id="change">seq[:,t-1]</a> = it &#47&#47seq[t] the input of t+2 time step
                seqLogprobs[:,t-1] = sampleLogprobs.view(-1)
                if unfinished.sum() == 0:
                    break</code></pre><img src="324402037.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 8</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/ruotianluo/ImageCaptioning.pytorch/commit/8fae3aef46180186d420db3ec88fc747261f0d5c#diff-eae75c2309aabbe47eeda73d20e6b7289e1224f02d5308a6a7c91ca7c1b39f62L120' target='_blank'>Link</a></div><div id='project'> Project Name: ruotianluo/ImageCaptioning.pytorch</div><div id='commit'> Commit Name: 8fae3aef46180186d420db3ec88fc747261f0d5c</div><div id='time'> Time: 2018-05-30</div><div id='author'> Author: rluo@ttic.edu</div><div id='file'> File Name: models/ShowTellModel.py</div><div id='class'> Class Name: ShowTellModel</div><div id='method'> Method Name: _sample</div><BR><BR><div id='link'><a href='https://github.com/facebookresearch/pytext/commit/8f54218a8ed67dc6c3df585ff89777b1e2bb2c26#diff-73d1ca7fa5cd634e175e83c60ec748c19d3c540d992eea4f5f5ddb9bb9d0e9c6L91' target='_blank'>Link</a></div><div id='project'> Project Name: facebookresearch/pytext</div><div id='commit'> Commit Name: 8f54218a8ed67dc6c3df585ff89777b1e2bb2c26</div><div id='time'> Time: 2019-12-06</div><div id='author'> Author: hyzhan@fb.com</div><div id='file'> File Name: pytext/optimizer/sparsifiers/tests/sparsifier_test.py</div><div id='class'> Class Name: TestSparsifier</div><div id='method'> Method Name: test_param_mask_with_pre_mask</div><BR>