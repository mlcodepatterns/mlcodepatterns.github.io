<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    if probability_fn is None:
      probability_fn = nn_ops.softmax
    if dtype is None:
      <a id="change">dtype = dtypes.float32</a>
    wrapped_probability_fn = lambda score, _: probability_fn(score)
    <a id="change">super(LocationSensitiveAttention, self).__init__(
        query_layer=layers_core.Dense(
            num_units, name="query_layer", use_bias=False, dtype=dtype
        ),
        memory_layer=layers_core.Dense(
            num_units, name="memory_layer", use_bias=False, dtype=dtype
        ),
        memory=memory,
        probability_fn=wrapped_probability_fn,
        memory_sequence_length=memory_sequence_length,
        score_mask_value=score_mask_value,
        name=name
    )</a>
    self.location_layer = LocationLayer(32, 32, num_units)
    <a id="change">self._num_units</a> = num_units
    self._name = name
    self.use_bias = use_bias
    self._use_state = use_state
    <a id="change">self.cumulative_location</a> = self.initial_state(
        self._batch_size, dtype
    )
</code></pre><h3>After Change</h3><pre><code class='java'>
      `memory.shape[2:].is_fully_defined()`.
  
  memory = nest.map_structure(
      lambda m: ops.convert_to_tens<a id="change">or(m, name="memory"), memory
  )
  if memory_sequence_length is not None:
    memory_sequence_length = ops.convert_to_tensor(
        memory_sequence_length, name="memory_sequence_length"
    )
  if check_in</a>ner_dims_defined:

    def _check_dims(m):
      if not m.get_shape()[2:].is_fully_defined():
        raise ValueError(
 <a id="change">           "Expe</a>cted memory %s to <a id="change">have fully defined inner dims, "
        </a>    "<a id="change">but saw shape: %s" %</a> (m.name, m.get_shape())
        )

    nest.m<a id="change">ap_structure(_check_d</a>ims, memory)
  if memo<a id="change">ry_sequence_leng</a>th is None:
    seq_len_mask = None
  else:
    seq_len_mask = array_ops.sequence_mask(</code></pre>