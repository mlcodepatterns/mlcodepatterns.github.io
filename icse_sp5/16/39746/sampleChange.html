<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            nn.Conv2d(1, 1, 1),
            nn.Conv2d(1, 1, 1),
        ).eval()
        <a id="change">mp = prepare_fx(m, {&quot&quot: torch.quantization.default_qconfig})</a>
        mp(torch.randn(2, 1, 2, 2))
        &#47&#47 TODO(future PR): prevent the need for copying here, we can copy the
        &#47&#47 modules but should reuse the underlying tensors
        mp_copy = copy.deepcopy(mp)
        mq = convert_fx(mp_copy)

        <a id="change">mp_ns, mq_ns = add_loggers(
            &quotfp32_prepared&quot, mp, &quotint8&quot, mq, OutputLogger)</a>

        expected_occurrence = {
            ns.call_module(OutputLogger): 2,
        }
        self.checkGraphModuleNodes(
            mp_ns, expected_node_occurrence=expected_occurrence)
        self.checkGraphModuleNodes(
            mq_ns, expected_node_occurrence=expected_occurrence)

        &#47&#47 TODO(before land): test both scripted and non-scripted
        mp_ns = torch.jit.script(mp_ns)
        mq_ns = torch.jit.script(mq_ns)

        &#47&#47 calibrate
        input_fp32 = torch.randn(2, 1, 2, 2)
        mp_ns(input_fp32)
        mq_ns(input_fp32)

        &#47&#47 check activation result correctness
        <a id="change">act_compare_dict = extract_logger_info(mp_ns, mq_ns, OutputLogger)</a>
        self.assertTrue(len(act_compare_dict) == 2)
        self.assert_ns_compare_dict_valid(act_compare_dict)

    @override_qengines</code></pre><h3>After Change</h3><pre><code class='java'>
        expected_occurrence = {
            ns.call_module(OutputLogger): 2,
        }
        <a id="change">self._test_match_activations(
            m, (torch.randn(2, 1, 2, 2),),
            prepared_expected_node_occurrence=expected_occurrence,
            results_len=2)</a>

    @override_qengines
    def test_match_activations_fun(self):
        class M(nn.Module):</code></pre>