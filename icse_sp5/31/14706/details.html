<html><h3>1d4823c0ec446e93d00df8ca654db4b45b63b3d4,rllib/policy/tests/test_compute_log_likelihoods.py,,do_test_log_likelihood,#Any#Any#Any#Any#Any#Any#,18
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        if run in [dqn.DQNTrainer, sac.SACTrainer] and fw == "torch":
            continue
        print("Testing {} with framework={}".format(run, fw))
        <a id="change">config["eager"] = fw == "eager"</a>
        <a id="change">config["use_pytorch"] = fw == "torch"</a>

        <a id="change">eager_ctx = None</a>
        <a id="change">if fw == "tf":
            assert not tf.executing_eagerly()
        elif fw == "eager":
            eager_ctx = eager_mode()
            eager_ctx.__enter__()
            assert tf.executing_eagerly()

       </a> trainer = run(config=config, env=env)

        policy = trainer.get_policy()
        vars = policy.get_weights()
        &#47&#47 Sample n actions, then roughly check their logp against their
        &#47&#47 counts.
        num_actions = 1000 if not continuous else 50
        actions = []
        for _ in range(num_actions):
            &#47&#47 Single action from single obs.
            actions.append(
                trainer.compute_action(
                    obs_batch[0],
                    prev_action=prev_a,
                    prev_reward=prev_r,
                    explore=True))

        &#47&#47 Test all taken actions for their log-likelihoods vs expected values.
        if continuous:
            for idx in range(num_actions):
                a = actions[idx]
                if fw == "tf" or fw == "eager":
                    if isinstance(vars, list):
                        expected_mean_logstd = fc(
                            fc(obs_batch, vars[layer_key[1][0]]),
                            vars[layer_key[1][1]])
                    else:
                        expected_mean_logstd = fc(
                            fc(
                                obs_batch,
                                vars["default_policy/{}_1/kernel".format(
                                    layer_key[0])]),
                            vars["default_policy/{}_out/kernel".format(
                                layer_key[0])])
                else:
                    expected_mean_logstd = fc(
                        fc(obs_batch,
                           vars["_hidden_layers.0._model.0.weight"]),
                        vars["_logits._model.0.weight"])
                mean, log_std = np.split(expected_mean_logstd, 2, axis=-1)
                if logp_func is None:
                    expected_logp = np.log(norm.pdf(a, mean, np.exp(log_std)))
                else:
                    expected_logp = logp_func(mean, log_std, a)
                logp = policy.compute_log_likelihoods(
                    np.array([a]),
                    preprocessed_obs_batch,
                    prev_action_batch=np.array([prev_a]),
                    prev_reward_batch=np.array([prev_r]))
                check(logp, expected_logp[0], rtol=0.2)
        &#47&#47 Test all available actions for their logp values.
        else:
            for a in [0, 1, 2, 3]:
                count = actions.count(a)
                expected_prob = count / num_actions
                logp = policy.compute_log_likelihoods(
                    np.array([a]),
                    preprocessed_obs_batch,
                    prev_action_batch=np.array([prev_a]),
                    prev_reward_batch=np.array([prev_r]))
                check(np.exp(logp), expected_prob, atol=0.2)

        <a id="change">if eager_ctx:
            eager_ctx.__exit__(None, None, None)


</a>class TestComputeLogLikelihood(unittest.TestCase):
    def test_dqn(self):
        Tests, whether DQN correctly computes logp in soft-q mode.
        config = dqn.DEFAULT_CONFIG.copy()</code></pre><h3>After Change</h3><pre><code class='java'>
                           continuous=False,
                           layer_key=("fc", (0, 4)),
                           logp_func=None):
    <a id="change">config</a> = config.copy()
    &#47&#47 Run locally.
    config["num_workers"] = 0
    &#47&#47 Env setup.
    if continuous:
        env = "Pendulum-v0"
        obs_batch = preprocessed_obs_batch = np.array([[0.0, 0.1, -0.1]])
    else:
        env = "FrozenLake-v0"
        config["env_config"] = {"is_slippery": False, "map_name": "4x4"}
        obs_batch = np.array([0])
        preprocessed_obs_batch = one_hot(obs_batch, depth=16)

    prev_r = None if prev_a is None else np.array(0.0)

    &#47&#47 Test against all frameworks.
    for fw in <a id="change">framework_iterator(config)</a>:
        if run in [dqn.DQNTrainer, sac.SACTrainer] and fw == "torch":
            continue
</code></pre><img src="87357812.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 17</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/ray-project/ray/commit/1d4823c0ec446e93d00df8ca654db4b45b63b3d4#diff-1129758badbb76c0b7c1ea027a5d0cfa93fbaa9711e0749a3414e5b40cbd6bebL23' target='_blank'>Link</a></div><div id='project'> Project Name: ray-project/ray</div><div id='commit'> Commit Name: 1d4823c0ec446e93d00df8ca654db4b45b63b3d4</div><div id='time'> Time: 2020-04-03</div><div id='author'> Author: sven@anyscale.io</div><div id='file'> File Name: rllib/policy/tests/test_compute_log_likelihoods.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: do_test_log_likelihood</div><BR><BR><div id='link'><a href='https://github.com/ray-project/ray/commit/1d4823c0ec446e93d00df8ca654db4b45b63b3d4#diff-882c1f1ec01a8a4f0bd1c899d7f330bb6039af1ad82362f6c66dc008921312bdL133' target='_blank'>Link</a></div><div id='project'> Project Name: ray-project/ray</div><div id='commit'> Commit Name: 1d4823c0ec446e93d00df8ca654db4b45b63b3d4</div><div id='time'> Time: 2020-04-03</div><div id='author'> Author: sven@anyscale.io</div><div id='file'> File Name: rllib/tests/test_model_imports.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: model_import_test</div><BR><BR><div id='link'><a href='https://github.com/ray-project/ray/commit/1d4823c0ec446e93d00df8ca654db4b45b63b3d4#diff-b7a68b91d11f66f41396d92f0ee928151e33514d4d9424908755e88d62c28ddfL27' target='_blank'>Link</a></div><div id='project'> Project Name: ray-project/ray</div><div id='commit'> Commit Name: 1d4823c0ec446e93d00df8ca654db4b45b63b3d4</div><div id='time'> Time: 2020-04-03</div><div id='author'> Author: sven@anyscale.io</div><div id='file'> File Name: rllib/utils/exploration/tests/test_explorations.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: do_test_explorations</div><BR><BR><div id='link'><a href='https://github.com/ray-project/ray/commit/1d4823c0ec446e93d00df8ca654db4b45b63b3d4#diff-1129758badbb76c0b7c1ea027a5d0cfa93fbaa9711e0749a3414e5b40cbd6bebL23' target='_blank'>Link</a></div><div id='project'> Project Name: ray-project/ray</div><div id='commit'> Commit Name: 1d4823c0ec446e93d00df8ca654db4b45b63b3d4</div><div id='time'> Time: 2020-04-03</div><div id='author'> Author: sven@anyscale.io</div><div id='file'> File Name: rllib/policy/tests/test_compute_log_likelihoods.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: do_test_log_likelihood</div><BR>