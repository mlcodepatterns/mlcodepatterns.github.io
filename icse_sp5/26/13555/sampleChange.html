<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    assert len(operator.inputs) == 1
    assert operator.specific_config["stateful"] is False
    assert operator.specific_config["go_backwards"] is False
    <a id="change">x = operator.inputs[0]</a>
    w_input = converter.create_constant_variable(operator, "kernel:0", OrderCN)
    w_hidden = converter.create_constant_variable(operator, "recurrent_kernel:0", OrderCN)
    if <a id="change">operator.specific_config["use_bias"]</a>:
        b = converter.create_constant_variable(operator, "bias:0", OrderC)
    else:
        b = None
    lstm_opr = LSTM(None, <a id="change">operator.specific_config["use_bias"]</a>, operator.specific_config["return_sequences"],
                    use_initial_c=False, use_initial_h=False,
                    activation=<a id="change">operator.specific_config["activation"]</a>,
                    recurrent_activation=operator.specific_config["recurrent_activation"])

    y, _ = lstm_opr(x, w_input, w_hidden, b)

    <a id="change">operator.outputs = [y]</a>
</code></pre><h3>After Change</h3><pre><code class='java'>
    assert k_op.stateful is False, "[KerasConverter] Currently, LSTM.stateful is not supported"
    assert k_op.go_backwards is False, "[KerasConverter] Currently, LSTM.go_backwards is not supported"

    <a id="change">x = converter.get_variable(converter.get_input_tensor(k_op)[0])</a>
    w_input = converter.convert_to_constant_variable(k_op.kernel, OrderCN)
    w_hidden = converter.convert_to_constant_variable(k_op.recurrent_kernel, OrderCN)

    if k_op.use_bias:
        b = converter.convert_to_constant_variable(k_op.bias, OrderC)

    else:
        b = None

    y, = LSTM(None, k_op.use_bias, k_op.return_sequences,
              use_initial_c=False, use_initial_h=False,
              activation=k_op.activation,
              recurrent_activation=k_op.recurrent_activation)(x, w_input, w_hidden, b)
    <a id="change">converter.set_variable(converter.get_output_tensor(k_op)[0], y)</a>
</code></pre>