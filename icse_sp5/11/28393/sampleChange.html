<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
streamlines = list(streamlines)

&#47&#47 Prepare the display objects.
color = <a id="change">line_colors(streamlines)</a>

if fvtk.have_vtk:
    streamlines_actor = fvtk.line(streamlines, line_colors(streamlines))
</code></pre><h3>After Change</h3><pre><code class='java'>
from dipy.viz.colormap import line_colors

&#47&#47 Enables/disables interactive visualization
<a id="change">interactive = False</a>

&#47&#47 Initialization of LocalTracking. The computation happens in the next step.
streamlines = LocalTracking(csa_peaks, classifier, seeds, affine, step_size=.5)

&#47&#47 Compute streamlines and store as a list.
streamlines = list(streamlines)

&#47&#47 Prepare the display objects.
color = line_colors(streamlines)

if window.have_vtk:
    streamlines_actor = actor.line(streamlines, line_colors(streamlines))

    &#47&#47 Create the 3d display.
    r = <a id="change">window.Renderer()</a>
    r.add(streamlines_actor)

    &#47&#47 Save still images for this static example. Or for interactivity use
    window.record(r, n_frames=1, out_path=&quotdeterministic.png&quot, size=(800, 800))
    <a id="change">if interactive:
        window.show(r)

</a>
.. figure:: deterministic.png
   :align: center

   **Corpus Callosum Deterministic**

We&quotve created a deterministic set of streamlines, so called because if you
repeat the fiber tracking (keeping all the inputs the same) you will get
exactly the same set of streamlines. We can save the streamlines as a Trackvis
file so it can be loaded into other software for visualization or further
analysis.


from dipy.io.trackvis import save_trk
save_trk("CSA_detr.trk", streamlines, affine, labels.shape)


Next let&quots try some probabilistic fiber tracking. For this, we&quotll be using the
Constrained Spherical Deconvolution (CSD) Model. This model represents each
voxel in the data set as a collection of small white matter fibers with
different orientations. The density of fibers along each orientation is known
as the Fiber Orientation Distribution (FOD). In order to perform probabilistic
fiber tracking, we pick a fiber from the FOD at random at each new location
along the streamline. Note: one could use this model to perform deterministic
fiber tracking by always tracking along the directions that have the most
fibers.

Let&quots begin probabilistic fiber tracking by fitting the data to the CSD model.


from dipy.reconst.csdeconv import (ConstrainedSphericalDeconvModel,
                                   auto_response)

response, ratio = auto_response(gtab, data, roi_radius=10, fa_thr=0.7)
csd_model = ConstrainedSphericalDeconvModel(gtab, response, sh_order=6)
csd_fit = csd_model.fit(data, mask=white_matter)


Next we&quotll need to make a ``ProbabilisticDirectionGetter``. Because the CSD
model represents the FOD using the spherical harmonic basis, we can use the
``from_shcoeff`` method to create the direction getter. This direction getter
will randomly sample directions from the FOD each time the tracking algorithm
needs to take another step.


from dipy.direction import ProbabilisticDirectionGetter

prob_dg = ProbabilisticDirectionGetter.from_shcoeff(csd_fit.shm_coeff,
                                                    max_angle=30.,
                                                    sphere=default_sphere)


As with deterministic tracking, we&quotll need to use a tissue classifier to
restrict the tracking to the white matter of the brain. One might be tempted
to use the GFA of the CSD FODs to build a tissue classifier, however the GFA
values of these FODs don&quott classify gray matter and white matter well. We will
therefore use the GFA from the CSA model which we fit for the first section of
this example. Alternatively, one could fit a ``TensorModel`` to the data and use
the fractional anisotropy (FA) to build a tissue classifier.


classifier = ThresholdTissueClassifier(csa_peaks.gfa, .25)


Next we can pass this direction getter, along with the ``classifier`` and
``seeds``, to ``LocalTracking`` to get a probabilistic model of the corpus
callosum.


streamlines = LocalTracking(prob_dg, classifier, seeds, affine,
                            step_size=.5, max_cross=1)

&#47&#47 Compute streamlines and store as a list.
streamlines = list(streamlines)

if window.have_vtk:
    streamlines_actor = actor.line(streamlines, line_colors(streamlines))

    &#47&#47 Create the 3d display.
    r = window.Renderer()
    r.add(streamlines_actor)

    &#47&#47 Save still images for this static example.
    window.record(r, n_frames=1, out_path=&quotprobabilistic.png&quot, size=(800, 800))
    <a id="change">if interactive:
        window.show(r)

</a>
.. figure:: probabilistic.png
   :align: center
</code></pre>