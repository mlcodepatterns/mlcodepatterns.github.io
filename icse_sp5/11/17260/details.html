<html><h3>64764718080b11c8fb91df34c12e0ce8ac54aa4e,art/classifiers/pytorch.py,PyTorchClassifier,fit,#PyTorchClassifier#Any#Any#Any#Any#,67
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        :return: `None`
        
        &#47&#47 Check if train and output_ph available
        if <a id="change">self._train</a> is None or self._output_ph is None:
            raise ValueError("Need the training objective and the output placeholder to train the model.")

        num_batch = int(np.ceil(len(inputs) / batch_size))
        ind = np.arange(len(inputs))

        &#47&#47 Start training
        for _ in range(nb_epochs):
            &#47&#47 Shuffle the examples
            random.shuffle(ind)

            &#47&#47 Train for one epoch
            for m in range(num_batch):
                if m &lt; num_batch - 1:
                    i_batch = inputs[ind[m * batch_size:(m + 1) * batch_size]]
                    o_batch = outputs[ind[m * batch_size:(m + 1) * batch_size]]
                else:
                    i_batch = inputs[ind[m*batch_size:]]
                    o_batch = outputs[ind[m * batch_size:]]

                &#47&#47 Run train step
                if self._learning is None:
                    <a id="change">self</a>._sess.run(self._train, feed_dict={self._input_ph: i_batch, <a id="change">self._output_ph</a>: o_batch})
                else:
                    <a id="change">self._sess.run(self._train, feed_dict={self._input_ph: i_batch, self._output_ph: o_batch,
                                                           self._learning: True})</a>

    def class_gradient(self, inputs, logits=False):
        
        Compute per-class derivatives w.r.t. `input`.</code></pre><h3>After Change</h3><pre><code class='java'>

        return preds

    def fit(<a id="change">self</a>, inputs, outputs, batch_size=128, nb_epochs=10):
        
        Fit the classifier on the training set `(inputs, outputs)`.

        :param inputs: Training data.
        :type inputs: `np.ndarray`
        :param outputs: Labels.
        :type outputs: `np.ndarray`
        :param batch_size: Size of batches.
        :type batch_size: `int`
        :param nb_epochs: Number of epochs to use for trainings.
        :type nb_epochs: `int`
        :return: `None`
        
        &#47&#47 Set train phase
        self._model.train(True)

        &#47&#47 Apply defences
        inputs, outputs = self._apply_defences_fit(inputs, outputs)

        num_batch = int(np.ceil(len(inputs) / batch_size))
        ind = np.arange(len(inputs))

        &#47&#47 Start training
        for _ in range(nb_epochs):
            &#47&#47 Shuffle the examples
            random.shuffle(ind)

            &#47&#47 Train for one epoch
            for m in range(num_batch):
                if m &lt; num_batch - 1:
                    i_batch = inputs[ind[m * batch_size:(m + 1) * batch_size]]
                    o_batch = outputs[ind[m * batch_size:(m + 1) * batch_size]]
                else:
                    i_batch = inputs[ind[m*batch_size:]]
                    o_batch = outputs[ind[m * batch_size:]]

                &#47&#47 Zero the parameter gradients
                <a id="change">self._optimizer.zero_grad()</a>

                &#47&#47 Actual training
                m_batch = self._model(i_batch)
                loss = self._loss(m_batch, o_batch)
                loss.backward()
                <a id="change">self</a>._optimizer.step()

    def class_gradient(self, inputs, logits=False):
        </code></pre><img src="97680738.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 9</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/IBM/adversarial-robustness-toolbox/commit/64764718080b11c8fb91df34c12e0ce8ac54aa4e#diff-6919a2dfe30728fa2663270e78bb7c97a68c14f9308dc2b5d31cbe6eca2e5599L67' target='_blank'>Link</a></div><div id='project'> Project Name: IBM/adversarial-robustness-toolbox</div><div id='commit'> Commit Name: 64764718080b11c8fb91df34c12e0ce8ac54aa4e</div><div id='time'> Time: 2018-05-15</div><div id='author'> Author: M.N.Tran@ibm.com</div><div id='file'> File Name: art/classifiers/pytorch.py</div><div id='class'> Class Name: PyTorchClassifier</div><div id='method'> Method Name: fit</div><BR><BR><div id='link'><a href='https://github.com/IBM/adversarial-robustness-toolbox/commit/64764718080b11c8fb91df34c12e0ce8ac54aa4e#diff-6919a2dfe30728fa2663270e78bb7c97a68c14f9308dc2b5d31cbe6eca2e5599L67' target='_blank'>Link</a></div><div id='project'> Project Name: IBM/adversarial-robustness-toolbox</div><div id='commit'> Commit Name: 64764718080b11c8fb91df34c12e0ce8ac54aa4e</div><div id='time'> Time: 2018-05-15</div><div id='author'> Author: M.N.Tran@ibm.com</div><div id='file'> File Name: art/classifiers/pytorch.py</div><div id='class'> Class Name: PyTorchClassifier</div><div id='method'> Method Name: fit</div><BR><BR><div id='link'><a href='https://github.com/dpressel/mead-baseline/commit/3d9e51d5034e89bcec3a04eff3e646c70b45edb2#diff-b59bdff654a4cc9ddb5fb950b1d26fc88cbf55ebb2d644e4196d5caf2398b984L43' target='_blank'>Link</a></div><div id='project'> Project Name: dpressel/mead-baseline</div><div id='commit'> Commit Name: 3d9e51d5034e89bcec3a04eff3e646c70b45edb2</div><div id='time'> Time: 2017-03-16</div><div id='author'> Author: dpressel@gmail.com</div><div id='file'> File Name: classify/python/tf/train.py</div><div id='class'> Class Name: Trainer</div><div id='method'> Method Name: train</div><BR><BR><div id='link'><a href='https://github.com/IBM/adversarial-robustness-toolbox/commit/9b9a42de05056b418f98e3635f2cffd747123548#diff-6919a2dfe30728fa2663270e78bb7c97a68c14f9308dc2b5d31cbe6eca2e5599L114' target='_blank'>Link</a></div><div id='project'> Project Name: IBM/adversarial-robustness-toolbox</div><div id='commit'> Commit Name: 9b9a42de05056b418f98e3635f2cffd747123548</div><div id='time'> Time: 2018-05-16</div><div id='author'> Author: M.N.Tran@ibm.com</div><div id='file'> File Name: art/classifiers/pytorch.py</div><div id='class'> Class Name: PyTorchClassifier</div><div id='method'> Method Name: class_gradient</div><BR>