<html><h3>5b48f9a9c097d26d395873044ceaa1a0b886682a,solutionbox/code_free_ml/mltoolbox/code_free_ml/analyze.py,,run_local_analysis,#Any#Any#Any#Any#,291
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        parsed_line = dict(zip(header, line))
        num_examples += 1

        <a id="change">for col_schema in schema:
          col_name = col_schema[&quotname&quot]
          col_type = col_schema[&quottype&quot].lower()
          transform = features[col_name][&quottransform&quot]

          &#47&#47 Map the target transfrom into one_hot or identity.
          if transform == constant.TARGET_TRANSFORM:
            if col_type == constant.STRING_SCHEMA:
              transform = constant.ONE_HOT_TRANSFORM
            elif col_type in constant.NUMERIC_SCHEMA:
              transform = constant.IDENTITY_TRANSFORM
            else:
              raise ValueError(&quotUnknown schema type&quot)

          if transform in constant.TEXT_TRANSFORMS:
            split_strings = parsed_line[col_name].split(&quot &quot)

            &#47&#47 If a label is in the row N times, increase it&quots vocab count by 1.
            &#47&#47 This is needed for TFIDF, but it&quots also an interesting stat.
            for one_label in set(split_strings):
              &#47&#47 Filter out empty strings
              if one_label:
                vocabs[col_name][one_label] += 1
          elif transform in constant.CATEGORICAL_TRANSFORMS:
            if parsed_line[col_name]:
              vocabs[col_name][parsed_line[col_name]] += 1
          elif transform in constant.NUMERIC_TRANSFORMS:
            if not parsed_line[col_name].strip():
              continue

            numerical_results[col_name][&quotmin&quot] = (
              min(numerical_results[col_name][&quotmin&quot],
                  float(parsed_line[col_name])))
            numerical_results[col_name][&quotmax&quot] = (
              max(numerical_results[col_name][&quotmax&quot],
                  float(parsed_line[col_name])))
            numerical_results[col_name][&quotcount&quot] += 1
            numerical_results[col_name][&quotsum&quot] += float(parsed_line[col_name])
          elif transform == constant.IMAGE_TRANSFORM:
            pass
          elif transform == constant.KEY_TRANSFORM:
            pass
          else:
            raise ValueError(&quotUnknown transform %s&quot % transform)

  &#47&#47 Write the vocab files. Each label is on its own line.
 </a> vocab_sizes = {}
  for name, label_count in six.iteritems(vocabs):
    &#47&#47 Labels is now the string:
    &#47&#47 label1,count</code></pre><h3>After Change</h3><pre><code class='java'>

  &#47&#47 Make a copy of inverted_features and update the target transform to be
  &#47&#47 identity or one hot depending on the schema.
  <a id="change">inverted_features_target = copy.deepcopy(inverted_features)</a>
  for name, transform_set in six.iteritems(inverted_features_target):
    if transform_set == set([constant.TARGET_TRANSFORM]):
      <a id="change">target_schema = next(col[&quottype&quot].lower() for col in schema if col[&quotname&quot] == name)</a>
      if target_schema in constant.NUMERIC_SCHEMA:
        inverted_features_target[name] = {constant.IDENTITY_TRANSFORM}
      else:
        inverted_features_target[name] = {constant.ONE_HOT_TRANSFORM}

  &#47&#47 initialize the results
  def _init_numerical_results():
    return {&quotmin&quot: float(&quotinf&quot),
            &quotmax&quot: float(&quot-inf&quot),
            &quotcount&quot: 0,
            &quotsum&quot: 0.0}
  numerical_results = collections.defaultdict(_init_numerical_results)
  vocabs = collections.defaultdict(lambda: collections.defaultdict(int))

  num_examples = 0
  &#47&#47 for each file, update the numerical stats from that file, and update the set
  &#47&#47 of unique labels.
  for input_file in input_files:
    with file_io.FileIO(input_file, &quotr&quot) as f:
      for line in csv.reader(f):
        if len(header) != len(line):
          raise ValueError(&quotSchema has %d columns but a csv line only has %d columns.&quot %
                           (len(header), len(line)))
        parsed_line = dict(zip(header, line))
        num_examples += 1

        for col_name, transform_set in six.iteritems(inverted_features_target):
          &#47&#47 All transforms in transform_set require the same analysis. So look
          &#47&#47 at the first transform.
          <a id="change">transform_name = next(iter(transform_set))</a>
          if transform_name in constant.TEXT_TRANSFORMS:
            split_strings = parsed_line[col_name].split(&quot &quot)

            &#47&#47 If a label is in the row N times, increase it&quots vocab count by 1.</code></pre><img src="105364596.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 11</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/googledatalab/pydatalab/commit/5b48f9a9c097d26d395873044ceaa1a0b886682a#diff-b28df4a0dbd5cb118109e04660bf7d1f3e094b526fe4b73d77c8538d24f912fdL311' target='_blank'>Link</a></div><div id='project'> Project Name: googledatalab/pydatalab</div><div id='commit'> Commit Name: 5b48f9a9c097d26d395873044ceaa1a0b886682a</div><div id='time'> Time: 2017-06-14</div><div id='author'> Author: brandondutra@google.com</div><div id='file'> File Name: solutionbox/code_free_ml/mltoolbox/code_free_ml/analyze.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: run_local_analysis</div><BR><BR><div id='link'><a href='https://github.com/facebookresearch/pytext/commit/e0afe32be948c78c8fc58b43ed013b88343f73ab#diff-ed63c4a0d4ff147d342dff6611c0bfdfb9a0ed0f8f9c981efbfb158c4c46fc3dL51' target='_blank'>Link</a></div><div id='project'> Project Name: facebookresearch/pytext</div><div id='commit'> Commit Name: e0afe32be948c78c8fc58b43ed013b88343f73ab</div><div id='time'> Time: 2019-05-24</div><div id='author'> Author: zsc@fb.com</div><div id='file'> File Name: pytext/config/serialize.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: _union_from_json</div><BR><BR><div id='link'><a href='https://github.com/googledatalab/pydatalab/commit/5b48f9a9c097d26d395873044ceaa1a0b886682a#diff-b28df4a0dbd5cb118109e04660bf7d1f3e094b526fe4b73d77c8538d24f912fdL204' target='_blank'>Link</a></div><div id='project'> Project Name: googledatalab/pydatalab</div><div id='commit'> Commit Name: 5b48f9a9c097d26d395873044ceaa1a0b886682a</div><div id='time'> Time: 2017-06-14</div><div id='author'> Author: brandondutra@google.com</div><div id='file'> File Name: solutionbox/code_free_ml/mltoolbox/code_free_ml/analyze.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: run_cloud_analysis</div><BR>