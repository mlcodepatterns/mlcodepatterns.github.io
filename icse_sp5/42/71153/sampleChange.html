<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            return op


<a id="change">model_trainer = ModelTrainer(config.get_player(&quotmodel-trainer&quot))</a>
prediction_client = PredictionClient(config.get_player(&quotprediction-client&quot))

<a id="change">server0 = config.get_player(&quotserver0&quot)</a>
<a id="change">server1 = config.get_player(&quotserver1&quot)</a>
<a id="change">crypto_producer = config.get_player(&quotcrypto-producer&quot)</a>

<a id="change">with tfe.protocol.Pond(server0, server1, crypto_producer) as prot:

    &#47&#47 get model parameters as private tensors from model owner
    params = prot.define_private_input(model_trainer.player, model_trainer.provide_input, masked=True)  &#47&#47 pylint: disable=E0632

    &#47&#47 we&quotll use the same parameters for each prediction so we cache them to avoid re-training each time
    params = prot.cache(params)

    &#47&#47 get prediction input from client
    x, = prot.define_private_input(prediction_client.player, prediction_client.provide_input, masked=True)  &#47&#47 pylint: disable=E0632

    &#47&#47 helpers
    conv = lambda x, w: prot.conv2d(x, w, 1, &quotVALID&quot)
    pool = lambda x: prot.avgpool2d(x, (2, 2), (2, 2), &quotVALID&quot)

    &#47&#47 compute prediction
    Wconv1, bconv1, Wconv2, bconv2, Wfc1, bfc1, Wfc2, bfc2 = params
    bconv1 = prot.reshape(bconv1, [-1, 1, 1])
    bconv2 = prot.reshape(bconv2, [-1, 1, 1])
    layer1 = pool(prot.relu(conv(x, Wconv1) + bconv1))
    layer2 = pool(prot.relu(conv(layer1, Wconv2) + bconv2))
    layer2 = prot.reshape(layer2, [-1, ModelTrainer.HIDDEN_FC1])
    layer3 = prot.matmul(layer2, Wfc1) + bfc1
    logits = prot.matmul(layer3, Wfc2) + bfc2

    &#47&#47 send prediction output back to client
    prediction_op = prot.define_output(prediction_client.player, [logits], prediction_client.receive_output)


</a>with tfe.Session() as sess:
    print("Init")
    sess.run(tf.global_variables_initializer(), tag=&quotinit&quot)
</code></pre><h3>After Change</h3><pre><code class='java'>
            return op


<a id="change">model_trainer = ModelTrainer()</a>
prediction_client = PredictionClient()

&#47&#47 get model parameters as private tensors from model owner
<a id="change">params</a> = tfe.define_private_input(&quotmodel-trainer&quot, model_trainer.provide_input, masked=True)  &#47&#47 pylint: disable=E0632

&#47&#47 we&quotll use the same parameters for each prediction so we cache them to avoid re-training each time
<a id="change">params</a> = tfe.cache(params)

&#47&#47 get prediction input from client
x, y = tfe.define_private_input(&quotprediction-client&quot, prediction_client.provide_input, masked=True)  &#47&#47 pylint: disable=E0632</code></pre>