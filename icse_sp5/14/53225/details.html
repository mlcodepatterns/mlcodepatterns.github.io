<html><h3>641a28fbf0daff0ad1ad0f43d2c4b545cb6f9656,examples/reinforcement_learning/tutorial_cartpole_ac.py,Critic,learn,#Critic#Any#Any#Any#,142
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            self.train_op = tf.train.AdamOptimizer(lr).minimize(self.loss)

    def learn(self, s, r, s_):
        v_ = <a id="change">self</a>.sess.run(self.v, {self.s: [s_]})
        td_error, _ = <a id="change">self.sess.run([self.td_error, self.train_op], {self.s: [s], self.v_: v_, self.r: r})</a>
        return td_error


sess = tf.Session()</code></pre><h3>After Change</h3><pre><code class='java'>
                &#47&#47 self.train_op = tf.train.AdamOptimizer(lr).minimize(self.loss)
        self.optimizer = tf.train.AdamOptimizer(lr)

    def learn(<a id="change">self</a>, s, r, s_):
            &#47&#47 v_ = self.sess.run(self.v, {self.s: [s_]})
        v_ = self.model([s_]).outputs
            &#47&#47 td_error, _ = self.sess.run([self.td_error, self.train_op], {self.s: [s], self.v_: v_, self.r: r})
        with tf.GradientTape() as tape:
            <a id="change">v = self.model([s]).outputs</a>
            &#47&#47 TD_error = r + lambd * V(newS) - V(S)
            td_error = r + LAMBDA * v_ - v
            loss = tf.square(td_error)
        <a id="change">grad = tape.gradient(loss, self.model.weights)</a>
        <a id="change">self.optimizer.apply_gradients(zip(grad, self.model.weights))</a>

        return td_error

actor = Actor(n_features=N_F, n_actions=N_A, lr=LR_A)</code></pre><img src="247215933.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 12</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/tensorlayer/tensorlayer/commit/641a28fbf0daff0ad1ad0f43d2c4b545cb6f9656#diff-1702490f9eb46e983be30c93f51fa12ca85f2bb222524f54c295abacb9691eb0L142' target='_blank'>Link</a></div><div id='project'> Project Name: tensorlayer/tensorlayer</div><div id='commit'> Commit Name: 641a28fbf0daff0ad1ad0f43d2c4b545cb6f9656</div><div id='time'> Time: 2019-02-16</div><div id='author'> Author: dhsig552@163.com</div><div id='file'> File Name: examples/reinforcement_learning/tutorial_cartpole_ac.py</div><div id='class'> Class Name: Critic</div><div id='method'> Method Name: learn</div><BR><BR><div id='link'><a href='https://github.com/deepchem/deepchem/commit/387e650e16a5405691fb18ce05b34bd90239180e#diff-f582aafccf8343587e7bd879c7191fa93da2d547f815068a0b74c88b15dc9b74L257' target='_blank'>Link</a></div><div id='project'> Project Name: deepchem/deepchem</div><div id='commit'> Commit Name: 387e650e16a5405691fb18ce05b34bd90239180e</div><div id='time'> Time: 2020-01-31</div><div id='author'> Author: peastman@stanford.edu</div><div id='file'> File Name: deepchem/metalearning/maml.py</div><div id='class'> Class Name: MAML</div><div id='method'> Method Name: train_on_current_task</div><BR><BR><div id='link'><a href='https://github.com/tensorlayer/tensorlayer/commit/641a28fbf0daff0ad1ad0f43d2c4b545cb6f9656#diff-1702490f9eb46e983be30c93f51fa12ca85f2bb222524f54c295abacb9691eb0L142' target='_blank'>Link</a></div><div id='project'> Project Name: tensorlayer/tensorlayer</div><div id='commit'> Commit Name: 641a28fbf0daff0ad1ad0f43d2c4b545cb6f9656</div><div id='time'> Time: 2019-02-16</div><div id='author'> Author: dhsig552@163.com</div><div id='file'> File Name: examples/reinforcement_learning/tutorial_cartpole_ac.py</div><div id='class'> Class Name: Critic</div><div id='method'> Method Name: learn</div><BR><BR><div id='link'><a href='https://github.com/tensorlayer/tensorlayer/commit/641a28fbf0daff0ad1ad0f43d2c4b545cb6f9656#diff-1702490f9eb46e983be30c93f51fa12ca85f2bb222524f54c295abacb9691eb0L106' target='_blank'>Link</a></div><div id='project'> Project Name: tensorlayer/tensorlayer</div><div id='commit'> Commit Name: 641a28fbf0daff0ad1ad0f43d2c4b545cb6f9656</div><div id='time'> Time: 2019-02-16</div><div id='author'> Author: dhsig552@163.com</div><div id='file'> File Name: examples/reinforcement_learning/tutorial_cartpole_ac.py</div><div id='class'> Class Name: Actor</div><div id='method'> Method Name: learn</div><BR>