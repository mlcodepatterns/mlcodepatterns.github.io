<html><h3>e12008d110acae507573b4f5feb02f94125a4463,test/quantization/test_quantized_module.py,TestDynamicQuantizedModule,test_linear_api,#TestDynamicQuantizedModule#Any#Any#Any#Any#Any#,864
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        self.checkScriptable(qlinear, [[X]], check_save_load=True)

        &#47&#47 Test from_float
        <a id="change">float_linear = torch.nn.Linear(in_features, out_features).float()</a>
        if use_default_observer:
            float_linear.qconfig = torch.quantization.default_dynamic_qconfig
        prepare_dynamic(float_linear)
        float_linear(X.float())</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 Test JIT
        self.checkScriptable(qlinear, [[X]], check_save_load=True)

        <a id="change">modules_under_test = [torch.nn.Linear, torch.nn.modules.linear._LinearWithBias]</a>
        <a id="change">for mut in modules_under_test:
            &#47&#47 Test from_float
            float_linear = mut(in_features, out_features).float()
            if use_default_observer:
                float_linear.qconfig = torch.quantization.default_dynamic_qconfig
            prepare_dynamic(float_linear)
            float_linear(X.float())
            quantized_float_linear = nnqd.Linear.from_float(float_linear)

            &#47&#47 Smoke test to make sure the module actually runs
            quantized_float_linear(X)

        &#47&#47 Smoke test extra_repr
       </a> self.assertTrue(&quotQuantizedLinear&quot in str(quantized_float_linear))

    @given(
        dtype=st.sampled_from([torch.qint8, torch.float16]),</code></pre><img src="204060905.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/pytorch/pytorch/commit/e12008d110acae507573b4f5feb02f94125a4463#diff-c91f488c8eccc72a49d4ea3d68aec1a2ae05463f97de9055d02ee16b24403b91L932' target='_blank'>Link</a></div><div id='project'> Project Name: pytorch/pytorch</div><div id='commit'> Commit Name: e12008d110acae507573b4f5feb02f94125a4463</div><div id='time'> Time: 2021-01-07</div><div id='author'> Author: cc.rafaz@zafar.cc</div><div id='file'> File Name: test/quantization/test_quantized_module.py</div><div id='class'> Class Name: TestDynamicQuantizedModule</div><div id='method'> Method Name: test_linear_api</div><BR><BR><div id='link'><a href='https://github.com/kengz/SLM-Lab/commit/d4f36c2f11e20e6d5a7499cb9f717b03f5c1e787#diff-54189061d60564151db3a95e988fca02848fed6bf25221c04ab5283d4d20e69fL56' target='_blank'>Link</a></div><div id='project'> Project Name: kengz/SLM-Lab</div><div id='commit'> Commit Name: d4f36c2f11e20e6d5a7499cb9f717b03f5c1e787</div><div id='time'> Time: 2019-04-17</div><div id='author'> Author: kengzwl@gmail.com</div><div id='file'> File Name: slm_lab/agent/net/recurrent.py</div><div id='class'> Class Name: RecurrentNet</div><div id='method'> Method Name: __init__</div><BR><BR><div id='link'><a href='https://github.com/pytorch/pytorch/commit/e12008d110acae507573b4f5feb02f94125a4463#diff-c91f488c8eccc72a49d4ea3d68aec1a2ae05463f97de9055d02ee16b24403b91L198' target='_blank'>Link</a></div><div id='project'> Project Name: pytorch/pytorch</div><div id='commit'> Commit Name: e12008d110acae507573b4f5feb02f94125a4463</div><div id='time'> Time: 2021-01-07</div><div id='author'> Author: cc.rafaz@zafar.cc</div><div id='file'> File Name: test/quantization/test_quantized_module.py</div><div id='class'> Class Name: TestStaticQuantizedModule</div><div id='method'> Method Name: _test_linear_api_impl</div><BR>