<html><h3>0093fa5762122466087782c75b698429776ad49e,open_seq2seq/models/text2speech.py,Text2Speech,finalize_inference,#Text2Speech#Any#Any#,341
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
              save_format="disk"
          )

          <a id="change">dict_to_log[&quotaudio&quot]</a> = wav_summary
</code></pre><h3>After Change</h3><pre><code class='java'>
        )

        if audio_length &gt; 2:
          <a id="change">if "both" in self.get_data_layer().params[&quotoutput_type&quot]:
            predicted_mag_spec = output_values[5][j][:audio_length - 1, :]
            wav_summary = save_audio(
                predicted_mag_spec,
                self.params["logdir"],
                0,
                n_fft=self.get_data_layer().n_fft,
                sampling_rate=self.get_data_layer().sampling_rate,
                mode="infer_mag",
                number=i * batch_size + j,
                save_format="disk",
            )
         </a> predicted_final_spec = predicted_final_spec[:audio_length - 1, :]
          predicted_final_spec = self.get_data_layer().get_magnitude_spec(predicted_final_spec, is_mel=True)
          wav_summary = save_audio(
              predicted_final_spec,</code></pre><img src="193247956.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/NVIDIA/OpenSeq2Seq/commit/0093fa5762122466087782c75b698429776ad49e#diff-fa5a5d968f70899ad0c7f6d00c3467c8f24a7d56f626a78a090a69a37aaa6f13L344' target='_blank'>Link</a></div><div id='project'> Project Name: NVIDIA/OpenSeq2Seq</div><div id='commit'> Commit Name: 0093fa5762122466087782c75b698429776ad49e</div><div id='time'> Time: 2018-09-23</div><div id='author'> Author: jasonli9@live.ca</div><div id='file'> File Name: open_seq2seq/models/text2speech.py</div><div id='class'> Class Name: Text2Speech</div><div id='method'> Method Name: finalize_inference</div><BR><BR><div id='link'><a href='https://github.com/NVIDIA/OpenSeq2Seq/commit/0093fa5762122466087782c75b698429776ad49e#diff-fa5a5d968f70899ad0c7f6d00c3467c8f24a7d56f626a78a090a69a37aaa6f13L344' target='_blank'>Link</a></div><div id='project'> Project Name: NVIDIA/OpenSeq2Seq</div><div id='commit'> Commit Name: 0093fa5762122466087782c75b698429776ad49e</div><div id='time'> Time: 2018-09-23</div><div id='author'> Author: jasonli9@live.ca</div><div id='file'> File Name: open_seq2seq/models/text2speech.py</div><div id='class'> Class Name: Text2Speech</div><div id='method'> Method Name: finalize_inference</div><BR><BR><div id='link'><a href='https://github.com/NVIDIA/OpenSeq2Seq/commit/a7b27761c6f02686135d9af83a300f23cb8d71ab#diff-bad5cf47a1e1c4e4fc80651a13828c81bcd9eaba3d69e6f5148a38d058938851L174' target='_blank'>Link</a></div><div id='project'> Project Name: NVIDIA/OpenSeq2Seq</div><div id='commit'> Commit Name: a7b27761c6f02686135d9af83a300f23cb8d71ab</div><div id='time'> Time: 2018-10-10</div><div id='author'> Author: vlavrukhin@nvidia.com</div><div id='file'> File Name: open_seq2seq/models/speech2text.py</div><div id='class'> Class Name: Speech2Text</div><div id='method'> Method Name: evaluate</div><BR><BR><div id='link'><a href='https://github.com/NVIDIA/OpenSeq2Seq/commit/a7b27761c6f02686135d9af83a300f23cb8d71ab#diff-bad5cf47a1e1c4e4fc80651a13828c81bcd9eaba3d69e6f5148a38d058938851L124' target='_blank'>Link</a></div><div id='project'> Project Name: NVIDIA/OpenSeq2Seq</div><div id='commit'> Commit Name: a7b27761c6f02686135d9af83a300f23cb8d71ab</div><div id='time'> Time: 2018-10-10</div><div id='author'> Author: vlavrukhin@nvidia.com</div><div id='file'> File Name: open_seq2seq/models/speech2text.py</div><div id='class'> Class Name: Speech2Text</div><div id='method'> Method Name: maybe_print_logs</div><BR>