<html><h3>29d7182447c4120057c116eb22c06d1d909eb3a1,fairseq/distributed_utils.py,,all_gather_list,#Any#Any#Any#,132
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    enc = pickle.dumps(data)
    enc_size = len(enc)
    if enc_size + 2 &gt; max_size:
        raise ValueError(<a id="change">&quotencoded data exceeds max_size: {}&quot.format(enc_size + 2)</a>)
    assert max_size &lt; 255*256

    cpu_buffer[0] = enc_size // 255  &#47&#47 this encoding works for max_size &lt; 65k</code></pre><h3>After Change</h3><pre><code class='java'>

    enc = pickle.dumps(data)
    enc_size = len(enc)
    <a id="change">header_size = 4</a>  &#47&#47 size of header that contains the length of the encoded data
    size = header_size + enc_size
    if size &gt; max_size:
        raise ValueError(&quotencoded data size ({}) exceeds max_size ({})&quot.format(size, max_size))

    <a id="change">header = struct.pack("&gt;I", enc_size)</a>
    cpu_buffer[:size] = torch.ByteTensor(list(header + enc))
    start = rank * max_size
    buffer[start:start + size].copy_(cpu_buffer[:size])

    all_reduce(buffer, group=group)

    try:
        result = []
        for i in range(world_size):
            out_buffer = buffer[i * max_size:(i + 1) * max_size]
            <a id="change">enc_size, = struct.unpack("&gt;I", bytes(out_buffer[:header_size].tolist()))</a>
            if enc_size &gt; 0:
                result.append(pickle.loads(bytes(out_buffer[header_size:header_size + enc_size].tolist())))
        return result
    except pickle.UnpicklingError:</code></pre><img src="12607360.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/pytorch/fairseq/commit/29d7182447c4120057c116eb22c06d1d909eb3a1#diff-d4588fc3718fca1ca01de4a78b71dea14a12c7a1ee2296e8c345277d081d3ad5L154' target='_blank'>Link</a></div><div id='project'> Project Name: pytorch/fairseq</div><div id='commit'> Commit Name: 29d7182447c4120057c116eb22c06d1d909eb3a1</div><div id='time'> Time: 2019-12-13</div><div id='author'> Author: yunwang@fb.com</div><div id='file'> File Name: fairseq/distributed_utils.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: all_gather_list</div><BR><BR><div id='link'><a href='https://github.com/sony/nnabla/commit/edd86f6318b411a42a1f287fa6359bbfd12fa71c#diff-a48b44b745e45b3d5fb6b91e5a8c9329832737d3fc79e0ee75bface396a7d079L959' target='_blank'>Link</a></div><div id='project'> Project Name: sony/nnabla</div><div id='commit'> Commit Name: edd86f6318b411a42a1f287fa6359bbfd12fa71c</div><div id='time'> Time: 2019-06-24</div><div id='author'> Author: stephen.tiedemann@sony.com</div><div id='file'> File Name: python/src/nnabla/functions.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: scatter_nd</div><BR>