<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
def monte_carlo_log_likelihood(log_probability_func, train_y,
                               variational_mean, chol_var_covar,
                               train_covar):
    <a id="change">if isinstance(train_covar, LazyVariable):
        log_likelihood = train_covar.monte_carlo_log_likelihood(log_probability_func,
                                                                train_y,
                                                                variational_mean,
                                                                chol_var_covar)
    else:
        epsilon = Variable(train_covar.data.new(len(train_covar), num_trace_samples).normal_())
        samples = chol_var_covar.t().mm(epsilon)
        samples = samples + variational_mean.unsqueeze(1)
        log_likelihood = log_probability_func(samples, train_y)

   </a> return log_likelihood


def mvn_kl_divergence(mean_1, chol_covar_1, mean_2, covar_2):</code></pre><h3>After Change</h3><pre><code class='java'>

    Args:
        - covar (matrix nxn) - Variable or LazyVariable representing the covariance matrix of the observations.
             <a id="change">                  Usually, this is K + s*I, where s is the noise variance, and K is the prior covariance.
        - target (ve</a>ctor n) - Training label vector.

    Returns:
        - scalar - The marginal log likelihood of the data.</code></pre>