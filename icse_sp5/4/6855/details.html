<html><h3>0f95d969bb87f8e6abd33473edc9a58a345dc9d4,snips_nlu/tests/test_preprocessing.py,TestPreprocessing,test_should_tokenize_symbols,#TestPreprocessing#,50
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        tokens = tokenize(text, language)

        &#47&#47 Then
        expected_tokens = <a id="change">[
            Token(value=&quot$$&quot, start=0, end=2),
            Token(value=&quot%&quot, start=3, end=4),
            Token(value=&quot!!&quot, start=5, end=7)
        ]</a>
        self.assertListEqual(tokens, expected_tokens)

    def test_space_should_by_ignored(self):
        &#47&#47 Given</code></pre><h3>After Change</h3><pre><code class='java'>
        tokens = tokenize(text, language)

        &#47&#47 Then
        expected_tokens = <a id="change">[
            Token(value=&quot$&quot, start=0, end=1),
            Token(value=&quot$&quot, start=1, end=2),
            Token(value=&quot%&quot, start=3, end=4),
            Token(value=&quot!&quot, start=5, end=6),
            Token(value=&quot!&quot, start=6, end=7)
        ]</a>
        self.assertListEqual(tokens, expected_tokens)

    def test_space_should_by_ignored(self):
        &#47&#47 Given</code></pre><img src="43075377.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/snipsco/snips-nlu/commit/0f95d969bb87f8e6abd33473edc9a58a345dc9d4#diff-b3e08251568144037b5d4c59976df544b09ba9da9a6f201d9aa34d984a515d41L59' target='_blank'>Link</a></div><div id='project'> Project Name: snipsco/snips-nlu</div><div id='commit'> Commit Name: 0f95d969bb87f8e6abd33473edc9a58a345dc9d4</div><div id='time'> Time: 2019-07-11</div><div id='author'> Author: mattgathu@gmail.com</div><div id='file'> File Name: snips_nlu/tests/test_preprocessing.py</div><div id='class'> Class Name: TestPreprocessing</div><div id='method'> Method Name: test_should_tokenize_symbols</div><BR><BR><div id='link'><a href='https://github.com/allenai/allennlp/commit/f4eef6eeb5e11cc0464d01dd812b6a869405e8d0#diff-b8c4dd4e51a06490bc09f468a586fa1bd53a5f4d8356fe18908889b92e263cffL43' target='_blank'>Link</a></div><div id='project'> Project Name: allenai/allennlp</div><div id='commit'> Commit Name: f4eef6eeb5e11cc0464d01dd812b6a869405e8d0</div><div id='time'> Time: 2018-07-17</div><div id='author'> Author: joelgrus@gmail.com</div><div id='file'> File Name: allennlp/tests/data/token_indexers/elmo_indexer_test.py</div><div id='class'> Class Name: TestELMoTokenCharactersIndexer</div><div id='method'> Method Name: test_elmo_as_array_produces_token_sequence</div><BR><BR><div id='link'><a href='https://github.com/allenai/allennlp/commit/2c4a6e537126f4123de7c97f30587310d3712c06#diff-b33fde9093dd6cd4c4ba4a32539dab47549fb93f8f125dff4c22f9a604bd2b53L25' target='_blank'>Link</a></div><div id='project'> Project Name: allenai/allennlp</div><div id='commit'> Commit Name: 2c4a6e537126f4123de7c97f30587310d3712c06</div><div id='time'> Time: 2017-09-13</div><div id='author'> Author: mattg@allenai.org</div><div id='file'> File Name: tests/data/dataset_test.py</div><div id='class'> Class Name: TestDataset</div><div id='method'> Method Name: test_instances_must_have_homogeneous_fields</div><BR>