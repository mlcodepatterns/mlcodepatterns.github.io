<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        inputImgAfterDropout = inputTrain
        inputImgAfterDropoutInference = inputInference
        inputImgAfterDropoutTesting = inputTesting
    <a id="change">return (inputImgAfterDropout, inputImgAfterDropoutInference, inputImgAfterDropoutTesting)</a>


def applyBn(rollingAverageForBatchNormalizationOverThatManyBatches, inputTrain, inputVal, inputTest, inputShapeTrain) :
    numberOfChannels = inputShapeTrain[1]</code></pre><h3>After Change</h3><pre><code class='java'>
        keep_prob = (1-dropoutRate)
        
        random_tensor = keep_prob
        random_tensor += <a id="change">tf.random_uniform(shape=inputTrainShape, minval=0., maxval=1., seed=rng.randint(999999), dtype="float32")</a>
        &#47&#47 0. if [keep_prob, 1.0) and 1. if [1.0, 1.0 + keep_prob)
        dropoutMask = tf.floor(random_tensor)
    
        &#47&#47 tf.nn.dropout(x, keep_prob) scales kept values UP, so that at inference you dont need to scale then. 
        inputImgAfterDropoutTrain = inputTrain * dropoutMask
        inputImgAfterDropoutVal = inputVal * keep_prob
        inputImgAfterDropoutTest = inputTest * keep_prob
    else :
        inputImgAfterDropoutTrain = inputTrain
        inputImgAfterDropoutVal = inputVal
        inputImgAfterDropoutTest = inputTest
    <a id="change">return (inputImgAfterDropoutTrain, inputImgAfterDropoutVal, inputImgAfterDropoutTest)</a>


def applyBn(rollingAverageForBatchNormalizationOverThatManyBatches, inputTrain, inputVal, inputTest, inputShapeTrain) :
    numOfChanns = inputShapeTrain[1]</code></pre>