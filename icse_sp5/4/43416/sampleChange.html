<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                        &#47&#47 elements in the batched case.  Fixing this in general is complicated;
                        &#47&#47 we&quotll just fix some easy cases that we actually have, for now.
                        num_tokens = single_predicted.size(0)
                        <a id="change">if batch_predicted.dim() == 1:
                            batch_predicted = batch_predicted[:num_tokens]
                        elif batch_predicted.dim() == 2:
                            batch_predicted = batch_predicted[:num_tokens, :]
                        else:
                            raise NotImplementedError
                   </a> assert_allclose(single_predicted.data.numpy(),
                                    batch_predicted.data.numpy(),
                                    atol=tolerance,
                                    err_msg=key)</code></pre><h3>After Change</h3><pre><code class='java'>
                batch_predicted = batch_predictions[key][i]
                if isinstance(single_predicted, torch.autograd.Variable):
                    if single_predicted.size() != batch_predicted.size():
                        slices = tuple(slice(0, size) <a id="change">for</a> size in <a id="change">single_predicted.size()</a>)
                        batch_predicted = batch_predicted[slices]
                    assert_allclose(single_predicted.data.numpy(),
                                    batch_predicted.data.numpy(),</code></pre>