<html><h3>6a0dda1ff86915d15cba0c9c12a9fc8a5e71a1a7,official/mnist/mnist.py,,run_mnist,#Any#,156
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
  num_gpus = flags_core.get_num_gpus(flags_obj)
  multi_gpu = num_gpus &gt; 1

  <a id="change">if multi_gpu:
    &#47&#47 Validate that the batch size can be split into devices.
    distribution_utils.per_device_batch_size(flags_obj.batch_size, num_gpus)

    &#47&#47 There are two steps required if using multi-GPU: (1) wrap the model_fn,
    &#47&#47 and (2) wrap the optimizer. The first happens here, and (2) happens
    &#47&#47 in the model_fn itself when the optimizer is defined.
    model_function = tf.contrib.estimator.replicate_model_fn(
        model_fn, loss_reduction=tf.losses.Reduction.MEAN,
        devices=["/device:GPU:%d" % d for d in range(num_gpus)])

 </a> data_format = flags_obj.data_format
  if data_format is None:
    data_format = (&quotchannels_first&quot
                   if tf.test.is_built_with_cuda() else &quotchannels_last&quot)</code></pre><h3>After Change</h3><pre><code class='java'>
  distribution_strategy = distribution_utils.get_distribution_strategy(
      flags_core.get_num_gpus(flags_obj), flags_obj.all_reduce_alg)

  run_config = <a id="change">tf.estimator.RunConfig(
      train_distribute=distribution_strategy, session_config=session_config)</a>

  data_format = flags_obj.data_format
  if data_format is None:
    data_format = (&quotchannels_first&quot</code></pre><img src="81456490.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/tensorflow/models/commit/6a0dda1ff86915d15cba0c9c12a9fc8a5e71a1a7#diff-a487aa91bc1942f0c1b12d5bbc2d5019eb4321f5a4465b10407f3433de479f45L162' target='_blank'>Link</a></div><div id='project'> Project Name: tensorflow/models</div><div id='commit'> Commit Name: 6a0dda1ff86915d15cba0c9c12a9fc8a5e71a1a7</div><div id='time'> Time: 2018-08-28</div><div id='author'> Author: jaeman1.park@gmail.com</div><div id='file'> File Name: official/mnist/mnist.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: run_mnist</div><BR><BR><div id='link'><a href='https://github.com/tensorflow/models/commit/823da3187f25593275f437ec86624b42c8395fbc#diff-1862baca89d12c1cff2054d459b268af8aaae1862a1a8c3ad852e22d5393aac4L361' target='_blank'>Link</a></div><div id='project'> Project Name: tensorflow/models</div><div id='commit'> Commit Name: 823da3187f25593275f437ec86624b42c8395fbc</div><div id='time'> Time: 2018-04-19</div><div id='author'> Author: taylorrobie@google.com</div><div id='file'> File Name: official/resnet/resnet_run_loop.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: resnet_main</div><BR><BR><div id='link'><a href='https://github.com/Qiskit/qiskit-aqua/commit/5698b1cb39cd840fb6ec58ab98ad8ab099f6e1ea#diff-6c368a56b5c91de273ac913df7b06847f3cae40bdd5a7a809d56b35e2c803d6fL184' target='_blank'>Link</a></div><div id='project'> Project Name: Qiskit/qiskit-aqua</div><div id='commit'> Commit Name: 5698b1cb39cd840fb6ec58ab98ad8ab099f6e1ea</div><div id='time'> Time: 2019-01-29</div><div id='author'> Author: dongreenberg2@gmail.com</div><div id='file'> File Name: qiskit/aqua/utils/circuit_cache.py</div><div id='class'> Class Name: CircuitCache</div><div id='method'> Method Name: load_qobj_from_cache</div><BR>