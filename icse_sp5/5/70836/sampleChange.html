<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
  step_boundaries = tf.constant(boundaries, tf.int64)
  learning_rates = tf.constant(rates, tf.float32)
  unreached_boundaries = tf.reshape(
      tf.where(tf.greater(step_boundaries, global_step)), [<a id="change">-1</a>])
  unreached_boundaries = tf.concat([unreached_boundaries, <a id="change">[len(boundaries)]</a>], 0)
  index = <a id="change">tf.reshape(tf.reduce_min(unreached_boundaries), [1])</a>
  return tf.reshape(tf.slice(learning_rates, index, [1]), [])
</code></pre><h3>After Change</h3><pre><code class='java'>
          &#47&#47 Casting global step to tf.int32 is dangerous, but necessary to be
          &#47&#47 compatible with TPU.
          tf.greater(step_boundaries, tf.cast(global_step, tf.int32)),
          <a id="change">tf.constant(range(num_boundaries), dtype=tf.int32)</a>,
          tf.constant([num_boundaries] * num_boundaries, dtype=tf.int32)))
  return tf.reduce_sum(learning_rates * tf.one_hot(index, len(rates),
                                                   dtype=tf.float32))</code></pre>