<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            fetch_dataset, cycle_length=self.num_cores, sloppy=True))
    dataset = dataset.shuffle(1024)

    <a id="change">dataset = dataset.map(
        self.dataset_parser,
        num_parallel_calls=self.num_parallel_calls)</a>
    <a id="change">dataset = dataset.prefetch(batch_size)</a>

    &#47&#47 For training, batch as usual. When evaluating, prevent accidentally
    &#47&#47 evaluating the same image twice by dropping the final batch if it is less
    &#47&#47 than a full batch size. As long as this validation is done with</code></pre><h3>After Change</h3><pre><code class='java'>
    &#47&#47 than a full batch size. As long as this validation is done with
    &#47&#47 consistent batch size, exactly the same images will be used.
    if not self.is_training:
      dataset = <a id="change">dataset.apply(batching.filter_irregular_batches(batch_size))</a>

    if self.use_transpose:
      dataset = dataset.map(
          lambda images, labels: (tf.transpose(images, [1, 2, 3, 0]), labels),</code></pre>