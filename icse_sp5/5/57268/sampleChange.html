<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        More most RL usage, we have custom, often complicated, loss functions. Compute its value and put it in a pytorch tensor then pass it in as loss
        &quot&quot&quot
        self.train()
        <a id="change">self.zero_grad()</a>
        self.optim.zero_grad()
        if loss is None:
            out = self(x)
            loss = self.loss_fn(out, y)</code></pre><h3>After Change</h3><pre><code class='java'>
        Takes a single training step: one forward and one backwards pass
        More most RL usage, we have custom, often complicated, loss functions. Compute its value and put it in a pytorch tensor then pass it in as loss
        &quot&quot&quot
        <a id="change">if hasattr(self, &quotmodel_tails&quot) and x is not None:
            raise ValueError(&quotLoss computation from x,y not supported for multitails&quot)
       </a> self.lr_scheduler.step(epoch=lr_t)
        self.train()
        self.optim.zero_grad()
        if loss is None:</code></pre>