<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        batch_outputs = np.asarray(data[:n_tasks], dtype=float)
        &#47&#47 reshape to batch_size x n_tasks x ...
        if batch_outputs.ndim == 3:
          <a id="change">batch_outputs = batch_outputs.transpose((1, 0, 2))</a>
        elif batch_outputs.ndim == 2:
          <a id="change">batch_outputs = batch_outputs.transpose((1, 0))</a>
        else:
          raise ValueError(
              &quotUnrecognized rank combination for output: %s &quot %
              (batch_outputs.shape,))

      &#47&#47 Note that softmax is already applied in construct_grpah
      outputs = batch_outputs

    <a id="change">return np.copy(outputs)</a>

class TensorflowRegressor(TensorflowGraphModel):
  Regression model.
</code></pre><h3>After Change</h3><pre><code class='java'>

      return loss 

  def fit(self, dataset, nb_epoch=10, max_checkpoints_to_k<a id="change">eep=5, 
	  log_every_N_batches=50, **kwargs):
    Fit</a> the <a id="change">model.

    Parameters
    ---------- 
    dataset: dc.data.Dataset
      Dataset ob</a>j<a id="change">ect holding tr</a>aining data 
    nb_epoch: 10
      Number of training epochs.
    max_checkpoints_to_keep: int</code></pre>