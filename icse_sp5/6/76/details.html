<html><h3>f33e7b5201494eb52360efc14dbfc7e6eeb02096,examples/mujoco_all_sac_real_nvp_hierarchy.py,,run_experiment,#Any#,191
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

    low_level_policy = load_low_level_policy(policy_path=low_level_policy_path)

    <a id="change">if variant[&quotenv_name&quot] == &quotant&quot:
        ant_env = normalize(AntEnv())
        env = HierarchyProxyEnv(wrapped_env=ant_env,
                                low_level_policy=low_level_policy)
    elif variant[&quotenv_name&quot] == &quotrandom-goal-swimmer&quot:
        random_goal_swimmer_env = normalize(RandomGoalSwimmerEnv(
            reward_type=variant[&quotenv_reward_type&quot],
            goal_reward_weight=variant[&quotenv_goal_reward_weight&quot],
            goal_radius=variant[&quotenv_goal_radius&quot],
            terminate_at_goal=variant[&quotenv_terminate_at_goal&quot],
        ))
        env = HierarchyProxyEnv(wrapped_env=random_goal_swimmer_env,
                                low_level_policy=low_level_policy)

    elif variant[&quotenv_name&quot] == &quotrandom-goal-ant&quot:
        random_goal_ant_env = normalize(RandomGoalAntEnv(
            reward_type=variant[&quotenv_reward_type&quot],
            goal_reward_weight=variant[&quotenv_goal_reward_weight&quot],
            goal_radius=variant[&quotenv_goal_radius&quot],
            terminate_at_goal=variant[&quotenv_terminate_at_goal&quot],
        ))
        env = HierarchyProxyEnv(wrapped_env=random_goal_ant_env,
                                low_level_policy=low_level_policy)

    elif variant[&quotenv_name&quot] == &quothumanoid-rllab&quot:
        humanoid_env = normalize(HumanoidEnv())
        env = HierarchyProxyEnv(wrapped_env=humanoid_env,
                                low_level_policy=low_level_policy)

   </a> pool = SimpleReplayBuffer(
        env_spec=env.spec,
        max_replay_buffer_size=variant[&quotmax_pool_size&quot],
    )</code></pre><h3>After Change</h3><pre><code class='java'>
    env_name = variant[&quotenv_name&quot]
    env_type = env_name.split(&quot-&quot)[-1]

    <a id="change">if &quotrandom-goal&quot in env_name:
        EnvClass = RANDOM_GOAL_ENVS[env_type]
        env_args = {
            name.replace(&quotenv_&quot, &quot&quot, 1): value
            for name, value in variant.items()
            if name.startswith(&quotenv_&quot) and name != &quotenv_name&quot
        }
        env = normalize(EnvClass(**env_args))
    elif &quotrllab&quot in variant[&quotenv_name&quot]:
        EnvClass = RLLAB_ENVS[variant[&quotenv_name&quot]]
        base_env = normalize(EnvClass())
        env = HierarchyProxyEnv(wrapped_env=base_env,
                                low_level_policy=low_level_policy)
    else:
        raise NotImplementedError

   </a> pool = SimpleReplayBuffer(
        env_spec=env.spec,
        max_replay_buffer_size=variant[&quotmax_pool_size&quot],
    )</code></pre><img src="804364.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/rail-berkeley/softlearning/commit/f33e7b5201494eb52360efc14dbfc7e6eeb02096#diff-53750f67d2ff4fbc0e492531ea127dd86e983493daaf001b83d4247955725475L201' target='_blank'>Link</a></div><div id='project'> Project Name: rail-berkeley/softlearning</div><div id='commit'> Commit Name: f33e7b5201494eb52360efc14dbfc7e6eeb02096</div><div id='time'> Time: 2018-05-22</div><div id='author'> Author: kristian.hartikainen@gmail.com</div><div id='file'> File Name: examples/mujoco_all_sac_real_nvp_hierarchy.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: run_experiment</div><BR><BR><div id='link'><a href='https://github.com/rail-berkeley/softlearning/commit/65878bf34c16e45b6ffaedef305fa260cf474498#diff-bedd83502fd71f123d464f3b5618532b1952cffa698d11cc76998b7778ad5f85L18' target='_blank'>Link</a></div><div id='project'> Project Name: rail-berkeley/softlearning</div><div id='commit'> Commit Name: 65878bf34c16e45b6ffaedef305fa260cf474498</div><div id='time'> Time: 2018-01-23</div><div id='author'> Author: haarnoja@users.noreply.github.com</div><div id='file'> File Name: softqlearning/misc/tf_utils.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: get_configuration</div><BR><BR><div id='link'><a href='https://github.com/rail-berkeley/softlearning/commit/cdf1e5890978ce2c487f3694dee26b9317592de2#diff-2e9889afde871b0d149e20eac94542c3e2324d749b4bc456341b83fc1122eecfL72' target='_blank'>Link</a></div><div id='project'> Project Name: rail-berkeley/softlearning</div><div id='commit'> Commit Name: cdf1e5890978ce2c487f3694dee26b9317592de2</div><div id='time'> Time: 2020-06-07</div><div id='author'> Author: kristian.hartikainen@gmail.com</div><div id='file'> File Name: softlearning/environments/adapters/dm_control_adapter.py</div><div id='class'> Class Name: DmControlAdapter</div><div id='method'> Method Name: __init__</div><BR>