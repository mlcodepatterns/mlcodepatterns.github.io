<html><h3>64171b3cdf5f0fca6bb11e48831946db63263684,tests/attacks/evasion/test_fast_gradient.py,,test_minimal_perturbations_images,#Any#Any#,99
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>


def test_minimal_perturbations_images(fix_get_mnist_subset, image_classifier_list):
    <a id="change">(x_train_mnist, y_train_mnist, x_test_mnist, y_test_mnist)</a> = fix_get_mnist_subset
    classifier_list = image_classifier_list(FastGradientMethod)
    &#47&#47 TODO this if statement must be removed once we have a classifier for both image and tabular data
    if classifier_list is None:</code></pre><h3>After Change</h3><pre><code class='java'>
        attack_params = {"minimal": True, "eps_step": 0.1, "eps": 5.0}
        attack.set_params(**attack_params)

        <a id="change">expected_values = {"x_test_mean": ExpectedValue(0.03896513, 0.01),
                           "x_test_min": ExpectedValue(-0.30000000, 0.00001),
                           "x_test_max": ExpectedValue(0.30000000, 0.00001),
                           "y_test_pred_adv_expected": ExpectedValue(np.asarray([4, 2, 4, 7, 0, 4, 7, 2, 0, 7, 0]), 2)}</a>
        utils_attack._backend_norm_images(attack, classifier, fix_get_mnist_subset, expected_values)


@pytest.mark.parametrize("norm", [np.inf, 1, 2])</code></pre><img src="191043427.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/IBM/adversarial-robustness-toolbox/commit/64171b3cdf5f0fca6bb11e48831946db63263684#diff-601b70e7da026b7b19a80fcefc8175b7e6535ac61a04736e833ac15a2ec3f589L100' target='_blank'>Link</a></div><div id='project'> Project Name: IBM/adversarial-robustness-toolbox</div><div id='commit'> Commit Name: 64171b3cdf5f0fca6bb11e48831946db63263684</div><div id='time'> Time: 2020-02-06</div><div id='author'> Author: killian.levacher@gmail.com</div><div id='file'> File Name: tests/attacks/evasion/test_fast_gradient.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: test_minimal_perturbations_images</div><BR><BR><div id='link'><a href='https://github.com/IBM/adversarial-robustness-toolbox/commit/69cdc613de1b60860f9e1017fe5e960427fe53a1#diff-601b70e7da026b7b19a80fcefc8175b7e6535ac61a04736e833ac15a2ec3f589L205' target='_blank'>Link</a></div><div id='project'> Project Name: IBM/adversarial-robustness-toolbox</div><div id='commit'> Commit Name: 69cdc613de1b60860f9e1017fe5e960427fe53a1</div><div id='time'> Time: 2020-02-06</div><div id='author'> Author: killian.levacher@gmail.com</div><div id='file'> File Name: tests/attacks/evasion/test_fast_gradient.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: test_l2_norm_images</div><BR><BR><div id='link'><a href='https://github.com/IBM/adversarial-robustness-toolbox/commit/4a7b5983d440e4c840f49f45c8bab91fc0e2966f#diff-45609ddaaeae758fa5371bf75fef8aba5ea44085ced73be74eb17ceb9b7aa768L147' target='_blank'>Link</a></div><div id='project'> Project Name: IBM/adversarial-robustness-toolbox</div><div id='commit'> Commit Name: 4a7b5983d440e4c840f49f45c8bab91fc0e2966f</div><div id='time'> Time: 2020-02-19</div><div id='author'> Author: killian.levacher@gmail.com</div><div id='file'> File Name: tests/classifiersT/test_tensorflow.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: test_loss_gradient</div><BR>