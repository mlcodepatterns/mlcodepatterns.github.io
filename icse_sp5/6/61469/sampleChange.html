<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    tf.scalar_summary(&quotsttdev/&quot + name, stddev)
    tf.scalar_summary(&quotmax/&quot + name, tf.reduce_max(var))
    tf.scalar_summary(&quotmin/&quot + name, tf.reduce_min(var))
    <a id="change">tf.histogram_summary(name, var)</a>


def add_final_training_ops(class_count, final_tensor_name, bottleneck_tensor):
  Adds a new softmax and fully-connected layer for training.</code></pre><h3>After Change</h3><pre><code class='java'>
    scalar_summary(&quotsttdev/&quot + name, stddev)
    scalar_summary(&quotmax/&quot + name, tf.reduce_max(var))
    scalar_summary(&quotmin/&quot + name, tf.reduce_min(var))
    <a id="change">if(int(tf.__version__.split(".")[0])&lt;1): &#47&#47&#47&#47&#47&#47 For tf v&lt;1.0
      tf.histogram_summary(name, var)
    else: &#47&#47&#47&#47&#47&#47 For tf v&gt;=1.0 
      tf.summary.histogram(name, var) 


</a>def add_final_training_ops(class_count, final_tensor_name, bottleneck_tensor):
  Adds a new softmax and fully-connected layer for training.

  We need to retrain the top layer to identify our new classes, so this function</code></pre>