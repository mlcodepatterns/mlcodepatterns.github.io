<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        if self.params.summary_verbosity &gt;= 2:
          &#47&#47 Histogram of log values of all non-zero gradients.
          all_grads = <a id="change">[]</a>
          for grad, var in avg_grads:
            all_grads.append(tf.reshape(grad, [-1]))
          grads = tf.abs(<a id="change">tf.concat(all_grads, 0)</a>)
          &#47&#47 exclude grads with zero values.
          indices_for_non_zero_grads = tf.where(tf.not_equal(grads, 0))
          log_grads = tf.reshape(
              tf.log(tf.gather(grads, indices_for_non_zero_grads)), [-1])
          <a id="change">tf</a>.summary.histogram(&quotlog_gradients&quot, log_grads)

        if self.params.summary_verbosity &gt;= 3:
          for grad, var in avg_grads:</code></pre><h3>After Change</h3><pre><code class='java'>
                                          self.model, examples_per_step)

        if gradient_clip is not None:
          <a id="change">with tf.name_scope(&quotclip_gradients&quot):
            clipped_grads = [(tf.clip_by_value(grad, -gradient_clip,
                                               +gradient_clip), var)
                             for grad, var in avg_grads]
       </a> else:
          clipped_grads = avg_grads

        learning_rate = tf.identity(learning_rate, name=&quotlearning_rate_tensor&quot)</code></pre>