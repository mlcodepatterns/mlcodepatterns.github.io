<html><h3>ef234844e1604d5496607fcf48886d9e556c0685,engine/training.py,,run,#Any#Any#Any#Any#,20
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        apply_grad_op = train_step.apply_gradients(ave_grads)
        &#47&#47 summary for visualisations
        &#47&#47 tracking current batch loss
        summaries = [<a id="change">tf.summary.scalar("total-miss", ave_miss)</a>,
                     tf.summary.scalar("total-loss", ave_loss)]

        &#47&#47 Track the moving averages of all trainable variables.</code></pre><h3>After Change</h3><pre><code class='java'>
                &#47&#47     current_iter, loss_value, miss_value, iter_time))
                print(&quotiter {:d}, loss={:.8f} ({:.3f}s)&quot.format(
                    current_iter, loss_value, iter_time))
                <a id="change">if (current_iter % 20) == 0:
                    writer.add_summary(sess.run(write_summary_op), current_iter)
                    &#47&#47 Plot reconstructions for the basic autoencoder
                    for p in range(0,4):
                        plt.subplot(4, 2, 2*p+1)
                        temp1 = sess.run(predictions[0])
                        temp1 = temp1[p,:,12,:,0]
                        temp1.reshape(24, 24)
                        plt.imshow(temp1, cmap=&quotgray&quot)
                        plt.subplot(4, 2, 2*p+2)
                        temp2 = sess.run(predictions[1])
                        temp2 = temp2[p, :, 12, :, 0]
                        temp2.reshape(24, 24)
                        plt.imshow(temp2, cmap=&quotgray&quot)
                    plt.pause(0.0001)
               </a> if (current_iter % param.save_every_n) == 0 and i &gt; 0:
                    saver.save(sess, ckpt_name, global_step=current_iter)
                    print(&quotIter {} model saved at {}&quot.format(
                        current_iter, ckpt_name))</code></pre><img src="124269129.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/NifTK/NiftyNet/commit/ef234844e1604d5496607fcf48886d9e556c0685#diff-e6cad2aed9da6459b6146989985d3864b326729b92ced5b5ab75cc64429f3b78L91' target='_blank'>Link</a></div><div id='project'> Project Name: NifTK/NiftyNet</div><div id='commit'> Commit Name: ef234844e1604d5496607fcf48886d9e556c0685</div><div id='time'> Time: 2017-06-21</div><div id='author'> Author: r.gray@ucl.ac.uk</div><div id='file'> File Name: engine/training.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: run</div><BR><BR><div id='link'><a href='https://github.com/PPPLDeepLearning/plasma-python/commit/ea02ec9157dc556765db8f4ab809dba76fc5efaa#diff-3f06286017055dd8ac69fffb8adc71baf3372ba787f4e569086f1ea070acd9d7L785' target='_blank'>Link</a></div><div id='project'> Project Name: PPPLDeepLearning/plasma-python</div><div id='commit'> Commit Name: ea02ec9157dc556765db8f4ab809dba76fc5efaa</div><div id='time'> Time: 2017-08-07</div><div id='author'> Author: asvyatkovskiy@gmail.com</div><div id='file'> File Name: plasma/models/mpi_runner.py</div><div id='class'> Class Name: TensorBoard</div><div id='method'> Method Name: on_epoch_end</div><BR><BR><div id='link'><a href='https://github.com/tensorflow/agents/commit/78c163f37be165673b040cff49e1ee98eb89ca0f#diff-1c4137da758ae9547ad4f336e9f2ab75ef48a858338ab8b645ac44c0d95d5fdcL150' target='_blank'>Link</a></div><div id='project'> Project Name: tensorflow/agents</div><div id='commit'> Commit Name: 78c163f37be165673b040cff49e1ee98eb89ca0f</div><div id='time'> Time: 2020-06-12</div><div id='author'> Author: kokiopou@google.com</div><div id='file'> File Name: tf_agents/bandits/agents/examples/v2/trainer.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: train</div><BR>