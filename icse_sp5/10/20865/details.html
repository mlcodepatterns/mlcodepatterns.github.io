<html><h3>d71bc3c8b533c319e49cf6b347d13c48c925ea93,gpytorch/utils/getitem.py,,_compute_getitem_size,#Any#Any#,10
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                continuous_tensor_index = False

            else:
                <a id="change">if settings.debug.on():
                    if idx.numel() != tensor_idx_shape:
                        raise IndexError(
                            "index element {} is an invalid size: expected tensor indices of size {}, got "
                            "{}.".format(i, tensor_idx_shape, idx.numel())
                        )

    &#47&#47 If we don&quott have a continuous set of tensor indices, then the tensor indexed part
    &#47&#47 goes to the front
   </a> if not continuous_tensor_index:
        del final_shape[first_tensor_idx]
        final_shape.insert(0, tensor_idx_shape)
</code></pre><h3>After Change</h3><pre><code class='java'>
            &#47&#47 If we don&quott have a continuous set of tensor indices, then the tensor indexed part
            &#47&#47 goes to the front
            else:
                <a id="change">try:
                    tensor_idx_shape = _mul_broadcast_shape(tensor_idx_shape, idx.shape)
                except RuntimeError:
                    raise IndexError("Incompatible tensor indices in index - got shapes of {} .".format(
                        [idx.shape for idx in indices if torch.is_tensor(idx)]
                    ))

               </a> if slice_after_tensor_idx:
                    tensor_idx = 0

    &#47&#47 If we don&quott have a continuous set of tensor indices, then the tensor indexed part</code></pre><img src="112309763.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 8</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/cornellius-gp/gpytorch/commit/d71bc3c8b533c319e49cf6b347d13c48c925ea93#diff-b280f574be6e0b61768206593dc10514fad27a04ebb71f2909ca837f25b52c77L17' target='_blank'>Link</a></div><div id='project'> Project Name: cornellius-gp/gpytorch</div><div id='commit'> Commit Name: d71bc3c8b533c319e49cf6b347d13c48c925ea93</div><div id='time'> Time: 2019-03-18</div><div id='author'> Author: gpleiss@gmail.com</div><div id='file'> File Name: gpytorch/utils/getitem.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: _compute_getitem_size</div><BR><BR><div id='link'><a href='https://github.com/cornellius-gp/gpytorch/commit/b2951813547426828d313a80c52de8a619e99731#diff-5a33a970d4df7e5234ae3caa389eb12a97e4534081406f8954d5661400d8a937L57' target='_blank'>Link</a></div><div id='project'> Project Name: cornellius-gp/gpytorch</div><div id='commit'> Commit Name: b2951813547426828d313a80c52de8a619e99731</div><div id='time'> Time: 2018-11-26</div><div id='author'> Author: gpleiss@gmail.com</div><div id='file'> File Name: gpytorch/lazy/constant_mul_lazy_tensor.py</div><div id='class'> Class Name: ConstantMulLazyTensor</div><div id='method'> Method Name: __init__</div><BR><BR><div id='link'><a href='https://github.com/cornellius-gp/gpytorch/commit/43c471faef2844c4d95636e888018239ab4ea6a9#diff-0a5f1b492443f1d45fea644563c842fd31a4a480824e8ed0c9f9ce825fe7f039L963' target='_blank'>Link</a></div><div id='project'> Project Name: cornellius-gp/gpytorch</div><div id='commit'> Commit Name: 43c471faef2844c4d95636e888018239ab4ea6a9</div><div id='time'> Time: 2020-07-29</div><div id='author'> Author: gardner.jake@gmail.com</div><div id='file'> File Name: gpytorch/lazy/lazy_tensor.py</div><div id='class'> Class Name: LazyTensor</div><div id='method'> Method Name: inv_quad</div><BR>