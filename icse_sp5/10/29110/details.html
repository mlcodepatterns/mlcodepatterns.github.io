<html><h3>0be455f86d595c12333541c09f2c5861dd76c2d4,eval_utils.py,,eval_split,#Any#Any#Any#Any#,97
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                with torch.no_grad():
                    _seq, _sampleLogprobs = model(fc_feats, att_feats, att_masks, opt=tmp_eval_kwargs, mode=&quotsample&quot)
                _sents = utils.decode_sequence(loader.get_vocab(), _seq)
                <a id="change">for k, sent in enumerate(_sents):
                    entry = {&quotimage_id&quot: data[&quotinfos&quot][k // sample_n][&quotid&quot], &quotcaption&quot: sent}
                    n_predictions.append(entry)
            &#47&#47 case 3 gumbel max
           </a> elif sample_n_method == &quotgumbel&quot:
                tmp_eval_kwargs.update({&quotsample_max&quot: 2, &quotbeam_size&quot: 1}) &#47&#47 randomness from sample
                with torch.no_grad():
                    _seq, _sampleLogprobs = model(fc_feats, att_feats, att_masks, opt=tmp_eval_kwargs, mode=&quotsample&quot)</code></pre><h3>After Change</h3><pre><code class='java'>
                    tmp_sample_max = 0
                elif sample_n_method == &quotgumbel&quot:
                    tmp_sample_max = 2
                elif <a id="change">sample_n_method.startswith(&quottop&quot)</a>:
                    <a id="change">tmp_sample_max = -int(sample_n_method[3:])</a>
                tmp_eval_kwargs.update({&quotsample_max&quot: tmp_sample_max, &quotbeam_size&quot: 1}) &#47&#47 randomness from sample
                with torch.no_grad():
                    _seq, _sampleLogprobs = model(fc_feats, att_feats, att_masks, opt=tmp_eval_kwargs, mode=&quotsample&quot)
                _sents = utils.decode_sequence(loader.get_vocab(), _seq)</code></pre><img src="146311946.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/ruotianluo/self-critical.pytorch/commit/0be455f86d595c12333541c09f2c5861dd76c2d4#diff-ae2a626e48c778173c824cfa192d3be5f4faa116442b6a03936ad0358eb6fe5cL106' target='_blank'>Link</a></div><div id='project'> Project Name: ruotianluo/self-critical.pytorch</div><div id='commit'> Commit Name: 0be455f86d595c12333541c09f2c5861dd76c2d4</div><div id='time'> Time: 2019-04-27</div><div id='author'> Author: rluo@ttic.edu</div><div id='file'> File Name: eval_utils.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: eval_split</div><BR><BR><div id='link'><a href='https://github.com/mynlp/ccg2lambda/commit/66a06524eba0b22d14204baeb2ca6d4c9db7d1d0#diff-37fa1888a83fa218c233a05619fe4c22640ec718b32ccc03f7bf56c2d25ffe41L258' target='_blank'>Link</a></div><div id='project'> Project Name: mynlp/ccg2lambda</div><div id='commit'> Commit Name: 66a06524eba0b22d14204baeb2ca6d4c9db7d1d0</div><div id='time'> Time: 2017-05-12</div><div id='author'> Author: pascual@nii.ac.jp</div><div id='file'> File Name: scripts/semantic_types.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: convert_coq_to_nltk_type</div><BR>