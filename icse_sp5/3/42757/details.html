<html><h3>e9aea97df1dc7878827ac193ba75cbea0b3ee351,ludwig/models/modules/sequence_decoders.py,SequenceGeneratorDecoder,__init__,#SequenceGeneratorDecoder#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#,32
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        self.embeddings_dec = Embedding(num_classes, embedding_size)
        self.decoder_cell = LSTMCell(state_size)

        <a id="change">if attention_mechanism:
            if attention_mechanism == &quotbahdanau&quot:
                pass
            elif attention_mechanism == &quotluong&quot:
                self.attention_mechanism = tfa.seq2seq.LuongAttention(
                    state_size,
                    None,  &#47&#47 todo tf2: confirm on need
                    memory_sequence_length=max_sequence_length  &#47&#47 todo tf2: confirm inputs or output seq length
                )
            else:
                raise ValueError(
                    "Attention specificaiton &quot{}&quot is invalid.  Valid values are "
                    "&quotbahdanau&quot or &quotluong&quot.".format(self.attention_mechanism))

            self.decoder_cell = tfa.seq2seq.AttentionWrapper(
                self.decoder_cell,
                self.attention_mechanism
            )

       </a> self.sampler = tfa.seq2seq.sampler.TrainingSampler()

        self.projection_layer = Dense(
            units=num_classes,</code></pre><h3>After Change</h3><pre><code class='java'>
        else:
            self.vocab_size = self.num_classes

        self.decoder_embedding = <a id="change">tf.keras.layers.Embedding(
            input_dim=output_vocab_size,
            output_dim=embedding_dims)</a>
        self.dense_layer = tf.keras.layers.Dense(output_vocab_size)
        self.decoder_rnncell = tf.keras.layers.LSTMCell(rnn_units)

        &#47&#47 Sampler</code></pre><img src="200654357.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/uber/ludwig/commit/e9aea97df1dc7878827ac193ba75cbea0b3ee351#diff-c9939725f3db666ea558a390c6beae039a2f53db3ecf738c5ca12c5ca1667094L1' target='_blank'>Link</a></div><div id='project'> Project Name: uber/ludwig</div><div id='commit'> Commit Name: e9aea97df1dc7878827ac193ba75cbea0b3ee351</div><div id='time'> Time: 2020-05-05</div><div id='author'> Author: jimthompson5802@gmail.com</div><div id='file'> File Name: ludwig/models/modules/sequence_decoders.py</div><div id='class'> Class Name: SequenceGeneratorDecoder</div><div id='method'> Method Name: __init__</div><BR><BR><div id='link'><a href='https://github.com/elbayadm/attn2d/commit/2a84f46bf0a05ae5b0caaf6724808dfe65dac638#diff-6b13c5873f1c102ec844b4853a4b2b27c1c84fe72f577d3fe20f00093f971944L99' target='_blank'>Link</a></div><div id='project'> Project Name: elbayadm/attn2d</div><div id='commit'> Commit Name: 2a84f46bf0a05ae5b0caaf6724808dfe65dac638</div><div id='time'> Time: 2018-06-15</div><div id='author'> Author: alexei.b@gmail.com</div><div id='file'> File Name: fairseq/models/fconv.py</div><div id='class'> Class Name: FConvEncoder</div><div id='method'> Method Name: __init__</div><BR>