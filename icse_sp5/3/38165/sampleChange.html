<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    writer = SummaryWriter(comment="-cartpole-es")
    env = gym.make("CartPole-v0")
    print(env)
    obs = <a id="change">env.reset()</a>
    print(obs)

    net = Net(env.observation_space.shape[0], env.action_space.n)
    print(net)</code></pre><h3>After Change</h3><pre><code class='java'>

    step_idx = 0
    while True:
        t_start = <a id="change">time.time()</a>
        batch_noise = []
        batch_reward = []
        batch_steps = 0
        for _ in range(MAX_BATCH_EPISODES):
            noise = sample_noise(net)
            batch_noise.append(noise)
            reward, steps = eval_with_noise(env, net, noise)
            batch_reward.append(reward)
            batch_steps += steps
            if batch_steps &gt; MAX_BATCH_STEPS:
                break

        step_idx += 1
        m_reward = np.mean(batch_reward)
        if m_reward &gt; 199:
            print("Solved in %d steps" % step_idx)
            print(batch_reward)
            break

        train_step(net, batch_noise, batch_reward, writer, step_idx)
        writer.add_scalar("reward_mean", m_reward, step_idx)
        writer.add_scalar("reward_std", np.std(batch_reward), step_idx)
        writer.add_scalar("reward_max", np.max(batch_reward), step_idx)
        writer.add_scalar("batch_episodes", len(batch_reward), step_idx)
        writer.add_scalar("batch_steps", batch_steps, step_idx)
        <a id="change">speed = batch_steps / (time.time() - t_start)</a>
        writer.add_scalar("speed", speed, step_idx)
        print("%d: reward=%.2f, speed=%.2f f/s" % (step_idx, m_reward, speed))

    pass</code></pre>