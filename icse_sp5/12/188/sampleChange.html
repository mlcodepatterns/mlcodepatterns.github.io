<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        self._td_loss2_t = tf.losses.mean_squared_error(
            labels=q_target, predictions=self._qf2_t, weights=0.5)

        <a id="change">qf1_train_op = tf.contrib.layers.optimize_loss(
            self._td_loss1_t,
            self.global_step,
            learning_rate=self._qf_lr,
            optimizer=tf.train.AdamOptimizer,
            variables=self._qf1.get_params_internal(),
            increment_global_step=False,
            name="td_loss_1_optimizer",
            summaries=([
                "loss", "gradients", "gradient_norm", "global_gradient_norm"
            ] if self._tf_summaries else []))</a>

        qf2_train_op = tf.contrib.layers.optimize_loss(
            self._td_loss2_t,
            self.global_step,</code></pre><h3>After Change</h3><pre><code class='java'>
                labels=q_target, predictions=q_value, weights=0.5)
            for q_value in q_values)

        q_training_ops = <a id="change">tuple(
            tf.contrib.layers.optimize_loss(
                q_loss,
                self.global_step,
                learning_rate=self._qf_lr,
                optimizer=tf.train.AdamOptimizer,
                variables=self._q_functions[i].get_params_internal(),
                increment_global_step=(i == 0),
                name="q_loss_{}_optimizer".format(i),
                summaries=((
                    "loss", "gradients", "gradient_norm", "global_gradient_norm"
                ) if self._tf_summaries else ()))
            for i, q_loss in enumerate(q_losses))</a>

        self._training_ops.update({&quotqf&quot: tf.group(q_training_ops)})

    def _init_actor_update(self):</code></pre>