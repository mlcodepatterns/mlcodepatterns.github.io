<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            init = tf.global_variables_initializer()
            sess.run(init)
            backend.set_session(sess)
        x_test = <a id="change">x_test.astype(&quotfloat32&quot) / 255</a>
        model = self.load_searcher().load_best_model().produce_model()
        return self.y_encoder.inverse_transform(model.predict(x_test, ))

    def summary(self):</code></pre><h3>After Change</h3><pre><code class='java'>
        if constant.LIMIT_MEMORY:
            &#47&#47 TODO: limit pytorch memory.
            pass
        <a id="change">test_data = self.data_transformer.transform_test(x_test)</a>
        <a id="change">test_loader = DataLoader(test_data, batch_size=constant.MAX_BATCH_SIZE, shuffle=True)</a>
        model = self.load_searcher().load_best_model().produce_model()
        model.eval()

        outputs = []
        with torch.no_grad():
            <a id="change">for index, inputs in enumerate(test_loader):
                outputs.append(model(inputs).numpy())
       </a> output = reduce(lambda x, y: np.concatenate((x, y)), outputs)
        return self.y_encoder.inverse_transform(output)

    def evaluate(self, x_test, y_test):</code></pre>