<html><h3>7ec9efd5cf6a479e8c5d85dcc950f464fd15b134,tf_agents/agents/reinforce/reinforce_agent.py,ReinforceAgent,total_loss,#ReinforceAgent#Any#Any#Any#Any#,260
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
          value_preds, returns, num_episodes, weights)
      total_loss += value_estimation_loss

    <a id="change">with tf.name_scope(&quotLosses/&quot):
      tf.compat.v2.summary.scalar(
          name=&quotpolicy_gradient_loss&quot,
          data=policy_gradient_loss,
          step=self.train_step_counter)
      tf.compat.v2.summary.scalar(
          name=&quotentropy_regularization_loss&quot,
          data=entropy_regularization_loss,
          step=self.train_step_counter)
      if self._baseline:
        tf.compat.v2.summary.scalar(
            name=&quotvalue_estimation_loss&quot,
            data=value_estimation_loss,
            step=self.train_step_counter)
      tf.compat.v2.summary.scalar(
          name=&quottotal_loss&quot, data=total_loss, step=self.train_step_counter)

   </a> return tf_agent.LossInfo(total_loss, ())

  def policy_gradient_loss(self,
                           actions_distribution,</code></pre><h3>After Change</h3><pre><code class='java'>
                  network_regularization_loss +
                  entropy_regularization_loss)

    <a id="change">losses_dict = {
        &quotpolicy_gradient_loss&quot: policy_gradient_loss,
        &quotpolicy_network_regularization_loss&quot: network_regularization_loss,
        &quotentropy_regularization_loss&quot: entropy_regularization_loss,
        &quotvalue_estimation_loss&quot: 0.0,
        &quotvalue_network_regularization_loss&quot: 0.0,
    }</a>

    value_estimation_loss = None
    if self._baseline:
      value_estimation_loss = self.value_estimation_loss(
          value_preds, returns, num_episodes, weights)
      value_network_regularization_loss = tf.nn.scale_regularization_loss(
          self._value_network.losses)
      total_loss += value_estimation_loss + value_network_regularization_loss
      losses_dict[&quotvalue_estimation_loss&quot] = value_estimation_loss
      <a id="change">losses_dict[&quotvalue_network_regularization_loss&quot]</a> = (
          value_network_regularization_loss)

    <a id="change">loss_info_extra = ReinforceAgentLossInfo._make(losses_dict)</a>

    <a id="change">losses_dict[&quottotal_loss&quot]</a> = total_loss  &#47&#47 Total loss not in loss_info_extra.

    common.summarize_scalar_dict(losses_dict,
                                 self.train_step_counter,</code></pre><img src="325975757.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/tensorflow/agents/commit/7ec9efd5cf6a479e8c5d85dcc950f464fd15b134#diff-bf755fac197dae2cc47fed2451d12ed15b4c17215eabaf0b1f8f2f3dcc62952bL260' target='_blank'>Link</a></div><div id='project'> Project Name: tensorflow/agents</div><div id='commit'> Commit Name: 7ec9efd5cf6a479e8c5d85dcc950f464fd15b134</div><div id='time'> Time: 2020-02-28</div><div id='author'> Author: no-reply@google.com</div><div id='file'> File Name: tf_agents/agents/reinforce/reinforce_agent.py</div><div id='class'> Class Name: ReinforceAgent</div><div id='method'> Method Name: total_loss</div><BR><BR><div id='link'><a href='https://github.com/tensorflow/agents/commit/452cf41746dd7c4572b6e6766185431bce7f5ee1#diff-dcfe45149b2d4267f6afb0356972f52439dfd82638cacbf5339acfe0c011976aL206' target='_blank'>Link</a></div><div id='project'> Project Name: tensorflow/agents</div><div id='commit'> Commit Name: 452cf41746dd7c4572b6e6766185431bce7f5ee1</div><div id='time'> Time: 2020-05-01</div><div id='author'> Author: no-reply@google.com</div><div id='file'> File Name: tf_agents/networks/lstm_encoding_network.py</div><div id='class'> Class Name: LSTMEncodingNetwork</div><div id='method'> Method Name: call</div><BR><BR><div id='link'><a href='https://github.com/tensorflow/agents/commit/7ec9efd5cf6a479e8c5d85dcc950f464fd15b134#diff-bf755fac197dae2cc47fed2451d12ed15b4c17215eabaf0b1f8f2f3dcc62952bL260' target='_blank'>Link</a></div><div id='project'> Project Name: tensorflow/agents</div><div id='commit'> Commit Name: 7ec9efd5cf6a479e8c5d85dcc950f464fd15b134</div><div id='time'> Time: 2020-02-28</div><div id='author'> Author: no-reply@google.com</div><div id='file'> File Name: tf_agents/agents/reinforce/reinforce_agent.py</div><div id='class'> Class Name: ReinforceAgent</div><div id='method'> Method Name: total_loss</div><BR><BR><div id='link'><a href='https://github.com/tensorflow/agents/commit/452cf41746dd7c4572b6e6766185431bce7f5ee1#diff-6b5a3c0fe459503130b0ec42d0c4d82829d7ede09d4afb71aa9075c3200feb43L181' target='_blank'>Link</a></div><div id='project'> Project Name: tensorflow/agents</div><div id='commit'> Commit Name: 452cf41746dd7c4572b6e6766185431bce7f5ee1</div><div id='time'> Time: 2020-05-01</div><div id='author'> Author: no-reply@google.com</div><div id='file'> File Name: tf_agents/agents/ddpg/critic_rnn_network.py</div><div id='class'> Class Name: CriticRnnNetwork</div><div id='method'> Method Name: call</div><BR>