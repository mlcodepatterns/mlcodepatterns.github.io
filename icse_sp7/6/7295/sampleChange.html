<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        ).detach()
        if slate_reward.ndim == 1:
            logger.warning(f"Slate reward should be 2-D tensor, unsqueezing")
            <a id="change">slate_reward = slate_reward.unsqueeze(1)</a>
        elif slate_reward.ndim != 2:
            raise RuntimeError("Expect slate reward to be 2-D tensor")
        &#47&#47 guard-rail reward prediction range
        reward_clamp = self.parameters.simulation_reward_clamp</code></pre><h3>After Change</h3><pre><code class='java'>
            )

        sim_slate_reward = torch.zeros_like(training_input.slate_reward)
        <a id="change">for name, reward_net in self.reward_name_and_net.items():
            weight = self.sim_param.reward_name_weight[name]
            sr = reward_net(
                training_input.state.float_features,
                training_input.src_seq.float_features,
                sim_tgt_out_seq.float_features,
                training_input.src_src_mask,
                sim_tgt_out_idx,
            ).detach()
            assert sr.ndim == 2, f"Slate reward {name} output should be 2-D tensor"
            sim_slate_reward += weight * sr

        &#47&#47 guard-rail reward prediction range
       </a> reward_clamp = self.sim_param.reward_clamp
        if reward_clamp is not None:
            sim_slate_reward = torch.clamp(
                sim_slate_reward, min=reward_clamp.clamp_min, max=reward_clamp.clamp_max</code></pre>