<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                preds: [batch_size, target_length]
        
        logits = None
        <a id="change">if targets is not None:
            decoder_self_attention_bias = (
                attentions.attention_bias_lower_triangle(
                    layers.shape_list(targets)[1]))
            decoder_self_attention_bias = tf.Print(decoder_self_attention_bias,
                [tf.shape(decoder_self_attention_bias), decoder_self_attention_bias],
                message=&quotdecoder self attention bias&quot,
                summarize=2048)
            target_inputs = tf.nn.embedding_lookup(self._embedding, targets)
            if self._hparams.multiply_embedding_mode == &quotsqrt_depth&quot:
                target_inputs = target_inputs * \
                    (self._embedding.shape.as_list()[-1]**0.5)
            logits = self.decode(
                target_inputs,
                encoder_output,
                encoder_decoder_attention_bias,
                decoder_self_attention_bias,
            )
       </a> preds = tf.to_int32(tf.argmax(logits, axis=-1))
        return logits, preds

    def dynamic_decode(self, encoder_output, encoder_decoder_attention_bias):</code></pre><h3>After Change</h3><pre><code class='java'>
            cache=None,
        )

        <a id="change">logits = self.output_layer(decoder_output)</a>
        preds = tf.to_int32(tf.argmax(logits, axis=-1))
        return logits, preds

    def dynamic_decode(self, encoder_output, encoder_decoder_attention_bias):</code></pre>