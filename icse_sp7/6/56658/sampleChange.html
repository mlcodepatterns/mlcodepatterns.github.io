<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
      filter_size_h = 2
      if(i==depth-1):
          filter_size_w=int(result.get_shape()[1])
          <a id="change">filter_size_h=int(result.get_shape()[2])</a>
      filter = [1,filter_size_w,filter_size_h,1]
      stride = [1,filter_size_w,filter_size_h,1]
      result = conv2d(result, int(int(result.get_shape()[3])*depth_increase), name=&quotd_expand_layer&quot+str(i), k_w=3, k_h=3, d_h=1, d_w=1)
      result = tf.nn.avg_pool(result, ksize=filter, strides=stride, padding=&quotSAME&quot)</code></pre><h3>After Change</h3><pre><code class='java'>
      &#47&#47 APPEND xs[i] and gs[i]
      if(i &lt; len(xs) and i &gt; 0):
        xg = tf.concat(0, [xs[i], gs[i]])
        xg += tf.random_normal(xg.get_shape(), mean=0, stddev=<a id="change">config[&quotdiscriminator.noise_stddev&quot]*i</a>, dtype=config[&quotdtype&quot])

        xgs.append(xg)

        mxg = conv2d(xg, 6*(i), name="d_add_xg"+str(i), k_w=3, k_h=3, d_h=1, d_w=1)
        mxg = batch_norm(config[&quotbatch_size&quot], name=&quotd_add_xg_bn_&quot+str(i))(mxg)
        mxg = activation(mxg)

        xgs_conv.append(mxg)
  
        net = tf.concat(3, [net, xg])

      filter_size_w = 2
      filter_size_h = 2
      filter = [1,filter_size_w,filter_size_h,1]
      stride = [1,filter_size_w,filter_size_h,1]
      net = conv2d(net, int(int(net.get_shape()[3])*depth_increase), name=&quotd_expand_layer&quot+str(i), k_w=3, k_h=3, d_h=1, d_w=1)
      net = tf.nn.avg_pool(net, ksize=filter, strides=stride, padding=&quotSAME&quot)

      print(&quotDiscriminator pyramid layer:&quot, net)

    k=-1
    net = batch_norm(config[&quotbatch_size&quot]*2, name=&quotd_expand_bn_end_&quot+str(i))(net)
    net = activation(net)
    net = tf.reshape(net, [batch_size, -1])
    <a id="change">net = linear(net, int(1024*1.5), scope="d_fc_end1")</a>
    net = batch_norm(config[&quotbatch_size&quot]*2, name=&quotd_bn_end1&quot)(net)
    net = activation(net)
    net = linear(net, 1024, scope="d_fc_end2")
    net = batch_norm(config[&quotbatch_size&quot]*2, name=&quotd_bn_end2&quot)(net)</code></pre>