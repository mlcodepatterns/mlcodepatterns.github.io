<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            numpy.dtype(theano.config.floatX).type(0.0)

        for name, param in network.params.items():
            <a id="change">self.param_init_values[name + &quot_gradient&quot] = \
                numpy.zeros_like(param.get_value())</a>
            <a id="change">self.param_init_values[name + &quot_mean_gradient&quot] = \
                numpy.zeros_like(param.get_value())</a>
            <a id="change">self.param_init_values[name + &quot_mean_sqr_gradient&quot] = \
                numpy.zeros_like(param.get_value())</a>

        &#47&#47 geometric rate for averaging gradients
        if not &quotgradient_decay_rate&quot in optimization_options:
            raise ValueError("Gradient decay rate is not given in training "</code></pre><h3>After Change</h3><pre><code class='java'>
        :param network: the neural network object
        

        <a id="change">self._params</a> = Parameters()

        float_type = numpy.dtype(theano.config.floatX).type
        self._params.add(&quotoptimizer/timestep&quot, float_type(0.0))

        for path, param in <a id="change">network</a>.get_variables().items():
            <a id="change">self._params.add(path + &quot_gradient&quot,
                             numpy.zeros_like(param.get_value()))</a>
            <a id="change">self._params.add(path + &quot_mean_gradient&quot,
                             numpy.zeros_like(param.get_value()))</a>
            <a id="change">self._params.add(path + &quot_mean_sqr_gradient&quot,
                             numpy.zeros_like(param.get_value()))</a>

        &#47&#47 geometric rate for averaging gradients
        if not &quotgradient_decay_rate&quot in optimization_options:
            raise ValueError("Gradient decay rate is not given in training "</code></pre>