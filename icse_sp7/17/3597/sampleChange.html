<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        np.random.seed(42)
        import tensorflow as tf
        <a id="change">tf.set_random_seed(42)</a>

        from cleverhans_tutorials import mnist_tutorial_jsma

        &#47&#47 Run the MNIST tutorial on a dataset of reduced size</code></pre><h3>After Change</h3><pre><code class='java'>
                              &quotviz_enabled&quot: False,
                              &quotsource_samples&quot: 1,
                              &quotnb_epochs&quot: 2}
        <a id="change">g = tf.Graph()</a>
        <a id="change">with g.as_default():
            np.random.seed(42)
            report = mnist_tutorial_jsma.mnist_tutorial_jsma(**jsma_tutorial_args)

        &#47&#47 Check accuracy values contained in the AccuracyReport object
        &#47&#47 We already have JSMA tests in test_attacks.py, so just sanity
        &#47&#47 check the values here.
       </a> self.assertTrue(report.clean_train_clean_eval &gt; 0.65)
        self.assertTrue(report.clean_train_adv_eval &lt; 0.25)

        &#47&#47 There is no adversarial training in the JSMA tutorial
        self.assertTrue(report.adv_train_clean_eval == 0.)
        self.assertTrue(report.adv_train_adv_eval == 0.)

        <a id="change">g = tf.Graph()</a>
        <a id="change">with g.as_default():
            np.random.seed(42)
            report_2 = mnist_tutorial_jsma.mnist_tutorial_jsma(**jsma_tutorial_args)

       </a> atol_fac = 1e-6
        self.assertClose(report.train_clean_train_clean_eval,
                         report_2.train_clean_train_clean_eval,
                         atol=atol_fac * 1)</code></pre>