<html><h3>780dcd9fd372afa8524a6515eec6a4c90b1494c9,Reinforcement_learning_TUT/8_Actor_Critic_Advantage/AC_CartPole.py,Actor,__init__,#Actor#Any#Any#Any#,22
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

class Actor(object):
    def __init__(self, n_features, n_actions, lr=0.001):
        <a id="change">with tf.name_scope(&quotinputs&quot):
            self.state = tf.placeholder(tf.float32, [n_features, ], "state")
            state = tf.expand_dims(self.state, axis=0)
            self.act_index = tf.placeholder(tf.int32, name="act")
            self.advantage = tf.placeholder(tf.float32, name="adv")  &#47&#47 TD_error

       </a> with tf.variable_scope(&quotActor&quot):
            l1 = tf.layers.dense(
                inputs=state,
                units=20,    &#47&#47 number of hidden units</code></pre><h3>After Change</h3><pre><code class='java'>
        )

        with tf.variable_scope(&quotsquared_TD_error&quot):
            self.td_error = <a id="change">tf.reduce_mean(self.r + GAMMA * self.v_next - self.v)</a>
            self.loss = tf.square(self.td_error)    &#47&#47 TD_error = (r+gamma*V_next) - V_eval
        with tf.variable_scope(&quottrain&quot):
            self.train_op = tf.train.AdamOptimizer(lr).minimize(self.loss)
</code></pre><img src="206271048.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/MorvanZhou/tutorials/commit/780dcd9fd372afa8524a6515eec6a4c90b1494c9#diff-1c91ba16911d0498f1259a5655c2ecbf955025d4db42b2913d9a7d24d318d2f2L22' target='_blank'>Link</a></div><div id='project'> Project Name: MorvanZhou/tutorials</div><div id='commit'> Commit Name: 780dcd9fd372afa8524a6515eec6a4c90b1494c9</div><div id='time'> Time: 2017-03-09</div><div id='author'> Author: morvanzhou@gmail.com</div><div id='file'> File Name: Reinforcement_learning_TUT/8_Actor_Critic_Advantage/AC_CartPole.py</div><div id='class'> Class Name: Actor</div><div id='method'> Method Name: __init__</div><BR><BR><div id='link'><a href='https://github.com/tensorlayer/tensorlayer/commit/0c361196698684acd135c3bae372c92692c1d5e0#diff-87ad50e157eb29abedfcc00e3683663fc1feb68653dc988ba2ab7a475858ec66L32' target='_blank'>Link</a></div><div id='project'> Project Name: tensorlayer/tensorlayer</div><div id='commit'> Commit Name: 0c361196698684acd135c3bae372c92692c1d5e0</div><div id='time'> Time: 2017-02-14</div><div id='author'> Author: dhsig552@163.com</div><div id='file'> File Name: tensorlayer/cost.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: cross_entropy</div><BR><BR><div id='link'><a href='https://github.com/zsdonghao/text-to-image/commit/74796ff02e9425ca336f595978fe6e7c422c0378#diff-87ad50e157eb29abedfcc00e3683663fc1feb68653dc988ba2ab7a475858ec66L32' target='_blank'>Link</a></div><div id='project'> Project Name: zsdonghao/text-to-image</div><div id='commit'> Commit Name: 74796ff02e9425ca336f595978fe6e7c422c0378</div><div id='time'> Time: 2017-04-11</div><div id='author'> Author: dhsig552@163.com</div><div id='file'> File Name: tensorlayer/cost.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: cross_entropy</div><BR>