<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        loss.requires_grad_(True)
        grads = torch.autograd.grad(loss, args, allow_unused=True)

        <a id="change">for i, arg in enumerate(args):
            if toggled[i]:
                arg.requires_grad = False

       </a> return grads

    def _preconditioner(self):
        </code></pre><h3>After Change</h3><pre><code class='java'>
            return tuple(None for _ in args)

        &#47&#47 Normal case: we&quotll use the autograd to get us a derivative
        <a id="change">with torch.autograd.enable_grad():
            loss = (left_vecs * self._matmul(right_vecs)).sum()
            loss.requires_grad_(True)
            actual_grads = deque(torch.autograd.grad(loss, args_with_grads, allow_unused=True))

        &#47&#47 Now make sure that the object we return has one entry for every item in args
       </a> grads = []
        for arg in args:
            if arg.requires_grad:
                grads.append(actual_grads.popleft())</code></pre>