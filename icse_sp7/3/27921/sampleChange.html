<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

      &#47&#47 generating index for graph features used in the inputs
      index = tf.stack(
          <a id="change">[
              tf.reshape(
                  tf.stack(
                      [tf.boolean_mask(tf.range(n_atoms), mask)] *
                      (self.max_atoms - 1),
                      axis=1), [-1]),
              tf.reshape(tf.boolean_mask(parents[:, count, 1:], mask), [-1])
          ]</a>,
          axis=1)
      &#47&#47 extracting graph features for parents of the target atoms, then flatten
      &#47&#47 shape: (batch_size*max_atoms) * [(max_atoms-1)*n_graph_features]</code></pre><h3>After Change</h3><pre><code class='java'>
              [tf.boolean_mask(tf.range(n_atoms), mask)] * (self.max_atoms - 1),
              axis=1), [-1])
      stack2 = tf.reshape(tf.boolean_mask(parents[:, count, 1:], mask), [-1])
      <a id="change">index = tf.stack([stack1, stack2], axis=1)</a>
      &#47&#47 extracting graph features for parents of the target atoms, then flatten
      &#47&#47 shape: (batch_size*max_atoms) * [(max_atoms-1)*n_graph_features]
      batch_graph_features = tf.reshape(
          tf.gather_nd(self.graph_features, index),
          [-1, (self.max_atoms - 1) * self.n_graph_feat])

      &#47&#47 concat into the input tensor: (batch_size*max_atoms) * n_inputs
      batch_inputs = tf.concat(
          axis=1, values=[batch_atom_features, batch_graph_features])
      &#47&#47 DAGgraph_step maps from batch_inputs to a batch of graph_features
      &#47&#47 of shape: (batch_size*max_atoms) * n_graph_features
      &#47&#47 representing the graph features of target atoms in each graph
      batch_outputs = _DAGgraph_step(batch_inputs, self.W_list, self.b_list,
                                     self.activation_fn, self.dropout,
                                     dropout_switch)

      &#47&#47 index for targe atoms
      target_index = tf.stack([tf.range(n_atoms), parents[:, count, 0]], axis=1)
      target_index = tf.boolean_mask(target_index, mask)
      &#47&#47 update the graph features for target atoms
      &#47&#47self.graph_features = tf.compat.v1.scatter_nd_update(
      &#47&#47    self.graph_features, target_index, batch_outputs)
      <a id="change">self.graph_features.assign_add(
          tf.compat.v1.scatter_nd_update(self.graph_features, target_index,
                                         batch_outputs))</a>
    return batch_outputs


class DAGGather(tf.keras.layers.Layer):</code></pre>