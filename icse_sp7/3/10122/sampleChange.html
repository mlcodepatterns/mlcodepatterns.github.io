<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            &#47&#47 a computational graph. We just use closures.
            backprop(yh-y, optimizer)

            <a id="change">epoch_train_acc += (yh.argmax(axis=1) == y.argmax(axis=1)).sum()</a>

            &#47&#47 Slightly useful trick: start with low batch size, accelerate.
            trainer.batch_size = min(int(batch_size), max_batch_size)
            batch_size *= 1.001</code></pre><h3>After Change</h3><pre><code class='java'>
    &#47&#47 * concatenate (|): Merge the outputs of two models into a single vector,
    &#47&#47 i.e. (f|g)(x) -&gt; hstack(f(x), g(x))
    with Model.define_operators({&quot&gt;&gt;&quot: chain, &quot**&quot: clone, &quot|&quot: concatenate,
                                 <a id="change">&quot+&quot</a>: add}):
        &#47&#47 Important trick: text isn&quott like images, and the best way to use
        &#47&#47 convolution is different. Don&quott use pooling-over-time. Instead,
        &#47&#47 use the window to compute one vector per word, and do this N deep.</code></pre>