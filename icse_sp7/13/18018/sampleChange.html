<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            for ind, pred in enumerate(prediction):
                &#47&#47 go through each scale

                <a id="change">loss_batch = []</a>
                <a id="change">for b_ind, pred_b in enumerate(tf.unstack(pred, axis=0)):
                    &#47&#47 go through each image in a batch

                    pred_b = tf.reshape(pred_b, [-1, self._num_classes])
                    &#47&#47 performs softmax if required
                    if self._softmax:
                        pred_b = tf.cast(pred_b, dtype=tf.float32)
                        pred_b = tf.nn.softmax(pred_b)

                    &#47&#47 reshape pred, ground_truth, weight_map to the same
                    &#47&#47 size: (n_voxels, num_classes)
                    &#47&#47 if the ground_truth has only one channel, the shape
                    &#47&#47 becomes: (n_voxels,)
                    if not pred_b.shape.is_fully_defined():
                        ref_shape = tf.stack(
                            [tf.shape(pred_b)[0], tf.constant(-1)], 0)
                    else:
                        ref_shape = pred_b.shape.as_list()[:-1] + [-1]

                    ground_truth_b = tf.reshape(ground_truth[b_ind], ref_shape)
                    if ground_truth_b.shape.as_list()[-1] == 1:
                        ground_truth_b = tf.squeeze(ground_truth_b, axis=-1)
                    if weight_map is not None:
                        weight_b = tf.reshape(weight_map[b_ind], ref_shape)
                        if weight_b.shape.as_list()[-1] == 1:
                            weight_b = tf.squeeze(weight_b, axis=-1)
                    else:
                        weight_b = None

                    &#47&#47 preparing loss function parameters
                    loss_params = {
                        &quotprediction&quot: pred_b,
                        &quotground_truth&quot: ground_truth_b,
                        &quotweight_map&quot: weight_b}
                    if self._loss_func_params:
                        loss_params.update(self._loss_func_params)

                    &#47&#47 loss for each batch over spatial dimensions
                    loss_batch.append(self._data_loss_func(**loss_params))
                &#47&#47 loss averaged over batch
               </a> data_loss.append(tf.reduce_mean(loss_batch))
            &#47&#47 loss averaged over multiple scales
            return tf.reduce_mean(data_loss)
</code></pre><h3>After Change</h3><pre><code class='java'>

                    return tf.to_float(self._data_loss_func(**loss_params))

                <a id="change">loss_batch = tf.map_fn(
                    fn=_batch_i_loss,
                    elems=tf.range(tf.shape(pred)[0], dtype=tf.int32),
                    dtype=tf.float32,
                    parallel_iterations=1)</a>

                &#47&#47 loss averaged over batch
                data_loss.append(tf.reduce_mean(loss_batch))
            &#47&#47 loss averaged over multiple scales</code></pre>