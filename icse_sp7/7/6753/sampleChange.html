<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    dataset = dataset.map(_map_fn, num_parallel_calls=multiprocessing.cpu_count())
    dataset = dataset.batch(batch_size)  &#47&#47 TODO: consider using tf.contrib.map_and_batch
    dataset = dataset.prefetch(1)  &#47&#47 prefetch 1 batch
    iterator = <a id="change">dataset.make_one_shot_iterator()</a>
    <a id="change">one_element = iterator.get_next()</a>
    <a id="change">sess = tf.Session()</a>
    &#47&#47 feed `one_element` into a network, for demo, we simply get the data as follows
    n_step = round(n_epoch * n_data / batch_size)
    st = time.time()
    for _ in range(n_step):
        _images, _targets = <a id="change">sess.run(one_element)</a>
    print("dataset APIs took %fs for each image" % ((time.time() - st) / batch_size / n_step))  &#47&#47 CPU ~ 100%


def example4():</code></pre><h3>After Change</h3><pre><code class='java'>

    n_step = 0
    st = time.time()
    <a id="change">for img, target in dataset:
        n_step += 1
        pass
   </a> assert n_step == n_epoch * n_data / batch_size
    print("dataset APIs took %fs for each image" % ((time.time() - st) / batch_size / n_step))  &#47&#47 CPU ~ 100%

</code></pre>