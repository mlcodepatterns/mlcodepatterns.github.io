<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        import torch

        &#47&#47 Convert the inputs to Tensors
        <a id="change">inputs_t = torch.from_numpy(self._apply_processing(x)).to(self._device)</a>
        <a id="change">inputs_t = inputs_t.float()</a>
        inputs_t.requires_grad = True

        &#47&#47 Convert the labels to Tensors
        labels_t = torch.from_numpy(np.argmax(y, axis=1)).to(self._device)

        &#47&#47 Compute the gradient and return
        model_outputs = self._model(inputs_t)
        loss = self._loss(model_outputs[-1], labels_t)

        &#47&#47 Clean gradients
        self._model.zero_grad()
        &#47&#47 inputs_t.grad.data.zero_()

        &#47&#47 Compute gradients
        loss.backward()
        grds = <a id="change">inputs_t</a>.grad.cpu().numpy().copy()
        grds = self._apply_processing_gradient(grds)
        assert grds.shape == x.shape

        <a id="change">return grds</a>

    @property
    def layer_names(self):
        </code></pre><h3>After Change</h3><pre><code class='java'>
        :return: Array of gradients of the same shape as `x`.
        :rtype: `np.ndarray`
        
        <a id="change">raise NotImplementedError</a>

    def get_activations(self, x, layer, batch_size=128):
        
        Return the output of the specified layer for input `x`. `layer` is specified by layer index (between 0 and</code></pre>