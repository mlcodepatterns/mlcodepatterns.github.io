<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        &#47&#47 Initialize loss accumulators
        if callable(self.callback):
            <a id="change">self.loss_trace</a> = list()

        &#47&#47 Iterative updates
        for t in range(0, self.max_iter):
            if self.solver == &quotbatch-gradient&quot:
                grad = _grad_L2loss(self.distr,
                                    alpha, self.Tau,
                                    reg_lambda, X, y, self.eta,
                                    beta)
                if t &gt; 1:
                    if np.linalg.norm(grad) / np.linalg.norm(beta) &lt; tol / lr:
                        msg = (&quot\tConverged in {0:d} iterations&quot.format(t))
                        logger.info(msg)
                        break
                beta = beta - self.learning_rate * grad

            elif self.solver == &quotcdfast&quot:
                beta_old = deepcopy(beta)
                beta, z = \
                    self._cdfast(X, y, z, ActiveSet, beta, reg_lambda)
                if t &gt; 1:
                    if ((np.linalg.norm(beta - beta_old) /
                         np.linalg.norm(beta_old) &lt; tol / lr)):
                        msg = (&quot\tConverged in {0:d} iterations&quot.format(t))
                        logger.info(msg)
                        break
            &#47&#47 Apply proximal operator
            beta[1:] = self._prox(beta[1:], reg_lambda * alpha)

            &#47&#47 Update active set
            if self.solver == &quotcdfast&quot:
                ActiveSet[beta == 0] = 0
                ActiveSet[0] = 1.

            &#47&#47 Compute and save loss if callbacks are requested
            <a id="change">if callable(self.callback):
                self.loss_trace.append(self.callback(self.distr, alpha,
                                                     self.Tau, reg_lambda,
                                                     X, y, self.eta,
                                                     self.group, beta))

        &#47&#47 Update the estimated variables
       </a> self.beta0_ = beta[0]
        self.beta_ = beta[1:]
        self.ynull_ = np.mean(y)
        return self</code></pre><h3>After Change</h3><pre><code class='java'>

            &#47&#47 Compute and save loss if callbacks are requested
            if callable(self.callback):
                <a id="change">self.callback(beta)</a>

        &#47&#47 Update the estimated variables
        self.beta0_ = beta[0]
        self.beta_ = beta[1:]</code></pre>