<html><h3>eee9f1bbdaa88fa4fde7c3c8096a656804baf9e1,sumy/nlp/tokenizers.py,Tokenizer,to_words,#Tokenizer#Any#,34
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        return tuple(map(unicode.strip, sentences))

    def to_words(self, sentence):
        <a id="change">return nltk.word_tokenize(to_unicode(sentence))</a>
</code></pre><h3>After Change</h3><pre><code class='java'>
        return tuple(map(unicode.strip, sentences))

    def to_words(self, sentence):
        <a id="change">words = nltk.word_tokenize(to_unicode(sentence))</a>
        <a id="change">return tuple(filter(self._is_word, words))</a>

    def _is_word(self, word):
        return bool(Tokenizer._WORD_PATTERN.search(word))
</code></pre><img src="67405448.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/miso-belica/sumy/commit/eee9f1bbdaa88fa4fde7c3c8096a656804baf9e1#diff-6b9ec1e2807910dc0d5a91194d72dacd34edf930bfcb2acb4197d3cb442eed34L35' target='_blank'>Link</a></div><div id='project'> Project Name: miso-belica/sumy</div><div id='commit'> Commit Name: eee9f1bbdaa88fa4fde7c3c8096a656804baf9e1</div><div id='time'> Time: 2013-05-21</div><div id='author'> Author: miso.belica@gmail.com</div><div id='file'> File Name: sumy/nlp/tokenizers.py</div><div id='class'> Class Name: Tokenizer</div><div id='method'> Method Name: to_words</div><BR><BR><div id='link'><a href='https://github.com/inspirehep/magpie/commit/57356fdfbb6f608da7662191e4634121cc31d117#diff-b99cbfe9ff7dcb3dd324ca165a0fbdb0353121b6e6f9df155a9e2b4421755e6aL35' target='_blank'>Link</a></div><div id='project'> Project Name: inspirehep/magpie</div><div id='commit'> Commit Name: 57356fdfbb6f608da7662191e4634121cc31d117</div><div id='time'> Time: 2016-01-12</div><div id='author'> Author: jan.stypka@cern.ch</div><div id='file'> File Name: magpie/base/document.py</div><div id='class'> Class Name: Document</div><div id='method'> Method Name: get_all_words</div><BR><BR><div id='link'><a href='https://github.com/allenai/allennlp/commit/2c4a6e537126f4123de7c97f30587310d3712c06#diff-0aaa021c65facdd973dfa3e44737169ea25eae05b1394b0a26332b5e7902863bL131' target='_blank'>Link</a></div><div id='project'> Project Name: allenai/allennlp</div><div id='commit'> Commit Name: 2c4a6e537126f4123de7c97f30587310d3712c06</div><div id='time'> Time: 2017-09-13</div><div id='author'> Author: mattg@allenai.org</div><div id='file'> File Name: allennlp/data/tokenizers/word_splitter.py</div><div id='class'> Class Name: NltkWordSplitter</div><div id='method'> Method Name: split_words</div><BR>