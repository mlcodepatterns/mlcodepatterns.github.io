<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        &#47&#47 Step 4. Compute your loss function. (Again, Torch wants the target
        &#47&#47 word wrapped in a variable)
        loss = loss_function(log_probs, <a id="change">autograd.Variable(
            torch.LongTensor([word_to_ix[target]]))</a>)

        &#47&#47 Step 5. Do the backward pass and update the gradient
        loss.backward()</code></pre><h3>After Change</h3><pre><code class='java'>

        &#47&#47 Step 4. Compute your loss function. (Again, Torch wants the target
        &#47&#47 word wrapped in a variable)
        loss = loss_function(log_probs, <a id="change">torch.tensor([word_to_ix[target]], dtype=torch.long)</a>)

        &#47&#47 Step 5. Do the backward pass and update the gradient
        loss.backward()</code></pre>