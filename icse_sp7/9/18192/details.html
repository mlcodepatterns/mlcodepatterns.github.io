<html><h3>3058bfb87edb7f12bdece2e9e454048df146490a,tensorforce/models/naf_model.py,NAFModel,create_tf_operations,#NAFModel#Any#,46
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            training_output_vars = tf.contrib.framework.get_variables(&quottraining_outputs&quot)

        with tf.variable_scope(&quottarget&quot):
            self.target_network = <a id="change">NeuralNetwork(config.network, inputs=self.state)</a>
            self.internal_inputs.extend(self.target_network.internal_inputs)
            self.internal_outputs.extend(self.target_network.internal_outputs)
            self.internal_inits.extend(self.target_network.internal_inits)
            target_value = dict()

        with tf.variable_scope(&quottarget_outputs&quot):
            &#47&#47 State-value function
            target_value_output = layers[&quotlinear&quot](x=self.target_network.output, size=1)
            for action in self.action:
                &#47&#47 Naf directly outputs V(s)
                target_value[action] = target_value_output

            target_output_vars = tf.contrib.framework.get_variables(&quottarget_outputs&quot)

        with tf.name_scope("update"):
            for action in self.action:
                q_target = self.reward[:-1] + (1.0 - tf.cast(self.terminal[:-1], tf.float32)) * config.discount * target_value[action][1:]
                delta = q_target - q_value[:-1]
                <a id="change">self.loss_per_instance</a> = tf.square(delta)

                &#47&#47 We observe issues with numerical stability in some tests, gradient clipping can help
                if config.clip_gradients &gt; 0.0:</code></pre><h3>After Change</h3><pre><code class='java'>
            training_output_vars = tf.contrib.framework.get_variables(&quottraining_outputs&quot)

        with tf.variable_scope(&quottarget&quot):
            <a id="change">network_builder = util.get_function(fct=config.network)</a>
            self.target_network = <a id="change">NeuralNetwork(network_builder=network_builder, inputs=self.state)</a>
            self.internal_inputs.extend(self.target_network.internal_inputs)
            self.internal_outputs.extend(self.target_network.internal_outputs)
            self.internal_inits.extend(self.target_network.internal_inits)
            target_value = dict()

        with tf.variable_scope(&quottarget_outputs&quot):
            &#47&#47 State-value function
            target_value_output = layers[&quotlinear&quot](x=self.target_network.output, size=1)
            for action in self.action:
                &#47&#47 Naf directly outputs V(s)
                target_value[action] = target_value_output

            target_output_vars = tf.contrib.framework.get_variables(&quottarget_outputs&quot)

        with tf.name_scope("update"):
            for action in self.action:
                q_target = self.reward[:-1] + (1.0 - tf.cast(self.terminal[:-1], tf.float32)) * config.discount * target_value[action][1:]
                delta = q_target - q_value[:-1]
                <a id="change">self.loss_per_instance</a> = tf.square(delta)

                &#47&#47 We observe issues with numerical stability in some tests, gradient clipping can help
                if config.clip_gradients &gt; 0.0:</code></pre><img src="100319706.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 9</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/reinforceio/tensorforce/commit/3058bfb87edb7f12bdece2e9e454048df146490a#diff-4b29a94af11261dd40df766cb2283937a5704ac86162f4f3c31c94a47d28018eL51' target='_blank'>Link</a></div><div id='project'> Project Name: reinforceio/tensorforce</div><div id='commit'> Commit Name: 3058bfb87edb7f12bdece2e9e454048df146490a</div><div id='time'> Time: 2017-07-22</div><div id='author'> Author: aok25@cl.cam.ac.uk</div><div id='file'> File Name: tensorforce/models/naf_model.py</div><div id='class'> Class Name: NAFModel</div><div id='method'> Method Name: create_tf_operations</div><BR><BR><div id='link'><a href='https://github.com/reinforceio/tensorforce/commit/3058bfb87edb7f12bdece2e9e454048df146490a#diff-75f561d58c661a388942b7c95b4d6dd5de8c0d05599f631a18afcbc4bb4e1565L60' target='_blank'>Link</a></div><div id='project'> Project Name: reinforceio/tensorforce</div><div id='commit'> Commit Name: 3058bfb87edb7f12bdece2e9e454048df146490a</div><div id='time'> Time: 2017-07-22</div><div id='author'> Author: aok25@cl.cam.ac.uk</div><div id='file'> File Name: tensorforce/models/dqn_model.py</div><div id='class'> Class Name: DQNModel</div><div id='method'> Method Name: create_tf_operations</div><BR><BR><div id='link'><a href='https://github.com/reinforceio/tensorforce/commit/3058bfb87edb7f12bdece2e9e454048df146490a#diff-a1bbe3d638f4f2f4a37587ba1ab0ed8a00dea66ae6af34a21a07001ec9f0e09bL93' target='_blank'>Link</a></div><div id='project'> Project Name: reinforceio/tensorforce</div><div id='commit'> Commit Name: 3058bfb87edb7f12bdece2e9e454048df146490a</div><div id='time'> Time: 2017-07-22</div><div id='author'> Author: aok25@cl.cam.ac.uk</div><div id='file'> File Name: tensorforce/models/policy_gradient_model.py</div><div id='class'> Class Name: PolicyGradientModel</div><div id='method'> Method Name: create_tf_operations</div><BR>