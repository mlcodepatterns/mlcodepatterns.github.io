<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &quotimage/format&quot: tf.FixedLenFeature((), tf.string, &quotjpeg&quot),
        &quotimage/class/label&quot: tf.FixedLenFeature([], tf.int64, -1),
        &quotimage/class/text&quot: tf.FixedLenFeature([], tf.string, &quot&quot),
        &quotimage/object/bbox/xmin&quot: <a id="change">tf.VarLenFeature(dtype=tf.float32)</a>,
        &quotimage/object/bbox/ymin&quot: <a id="change">tf.VarLenFeature(dtype=tf.float32)</a>,
        &quotimage/object/bbox/xmax&quot: <a id="change">tf.VarLenFeature(dtype=tf.float32)</a>,
        &quotimage/object/bbox/ymax&quot: <a id="change">tf.VarLenFeature(dtype=tf.float32)</a>,
        &quotimage/object/class/label&quot: tf.VarLenFeature(dtype=tf.int64),
    }
</code></pre><h3>After Change</h3><pre><code class='java'>
  def dataset_parser(self, value):
    Parse an ImageNet record from a serialized string Tensor.
    keys_to_features = {
        &quotimage/encoded&quot: <a id="change">tf.FixedLenFeature(()</a>, tf.string, &quot&quot),
        &quotimage/format&quot: <a id="change">tf.FixedLenFeature(()</a>, tf.string, &quotjpeg&quot),
        &quotimage/class/label&quot: <a id="change">tf.FixedLenFeature([]</a>, tf.int64, -1),
        &quotimage/class/text&quot: <a id="change">tf.FixedLenFeature([]</a>, tf.string, &quot&quot),
        &quotimage/object/bbox/xmin&quot: <a id="change">tf.VarLenFeature(dtype=tf.float32)</a>,
        &quotimage/object/bbox/ymin&quot: <a id="change">tf.VarLenFeature(dtype=tf.float32)</a>,
        &quotimage/object/bbox/xmax&quot: <a id="change">tf.VarLenFeature(dtype=tf.float32)</a>,
        &quotimage/object/bbox/ymax&quot: <a id="change">tf.VarLenFeature(dtype=tf.float32)</a>,
        &quotimage/object/class/label&quot: <a id="change">tf.VarLenFeature(dtyp</a>e=tf.int64),
    }

    parsed = tf.parse_single_example(value, keys_to_features)
    image = <a id="change">tf.reshape(parsed[&quotim</a>age/encoded&quot], shape=[])

    image = tf.image.decode_jpeg(image, channels=3)
    image = tf.image.convert_image_dtype(image, dtype=tf.float32)

    image = self.image_preprocessing_fn(
        image=image,
        output_height=224,
        output_width=224,
        is_training=self.is_training)

    label = <a id="change">tf.cast(
        tf.r</a><a id="change">eshape(parsed[&quotim</a>age/class/label&quot], shape=[]), dtype=tf.int32)

    return image, <a id="change">tf.one_hot(label, _LA</a>BEL_CLASSES)

  def input_fn(self):
    Input function which provides a single batch for train or eval.</code></pre>