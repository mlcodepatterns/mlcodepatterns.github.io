<html><h3>d71bc3c8b533c319e49cf6b347d13c48c925ea93,gpytorch/utils/getitem.py,,_compute_getitem_size,#Any#Any#,10
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    &#47&#47 If we don&quott have a continuous set of tensor indices, then the tensor indexed part
    &#47&#47 goes to the front
    if not continuous_tensor_index:
        del <a id="change">final_shape[first_tensor_idx]</a>
        final_shape.insert(0, tensor_idx_shape)

    return torch.Size(final_shape)
</code></pre><h3>After Change</h3><pre><code class='java'>
            &#47&#47 goes to the front
            else:
                try:
                    <a id="change">tensor_idx_shape = _mul_broadcast_shape(tensor_idx_shape, idx.shape)</a>
                except RuntimeError:
                    raise IndexError("Incompatible tensor indices in index - got shapes of {} .".format(
                        [idx.shape for idx in indices if torch.is_tensor(idx)]
                    ))

                if slice_after_tensor_idx:
                    tensor_idx = 0

    &#47&#47 If we don&quott have a continuous set of tensor indices, then the tensor indexed part
    &#47&#47 goes to the front
    if tensor_idx is not None:
        <a id="change">final_shape = final_shape[:tensor_idx] + list(tensor_idx_shape) + final_shape[tensor_idx:]</a>

    return torch.Size(final_shape)

</code></pre><img src="177869082.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/cornellius-gp/gpytorch/commit/d71bc3c8b533c319e49cf6b347d13c48c925ea93#diff-b280f574be6e0b61768206593dc10514fad27a04ebb71f2909ca837f25b52c77L17' target='_blank'>Link</a></div><div id='project'> Project Name: cornellius-gp/gpytorch</div><div id='commit'> Commit Name: d71bc3c8b533c319e49cf6b347d13c48c925ea93</div><div id='time'> Time: 2019-03-18</div><div id='author'> Author: gpleiss@gmail.com</div><div id='file'> File Name: gpytorch/utils/getitem.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: _compute_getitem_size</div><BR><BR><div id='link'><a href='https://github.com/cornellius-gp/gpytorch/commit/aa88bfddd883508af23988184c2c528f4a904447#diff-4a0a4fa6c44a189b78f1d8cf0f9843227a32d6344a5c04b75c67c0bf7edffcdbL81' target='_blank'>Link</a></div><div id='project'> Project Name: cornellius-gp/gpytorch</div><div id='commit'> Commit Name: aa88bfddd883508af23988184c2c528f4a904447</div><div id='time'> Time: 2020-03-29</div><div id='author'> Author: balandat@fb.com</div><div id='file'> File Name: gpytorch/kernels/index_kernel.py</div><div id='class'> Class Name: IndexKernel</div><div id='method'> Method Name: forward</div><BR><BR><div id='link'><a href='https://github.com/cornellius-gp/gpytorch/commit/a361f45c09f173f662141ac42d4c6c3b8c304be8#diff-c7931e13f5bbed98ade910bc79deae64fe2b98148f281cbb3a81fbe76c375e56L15' target='_blank'>Link</a></div><div id='project'> Project Name: cornellius-gp/gpytorch</div><div id='commit'> Commit Name: a361f45c09f173f662141ac42d4c6c3b8c304be8</div><div id='time'> Time: 2019-11-22</div><div id='author'> Author: wm326@cornell.edu</div><div id='file'> File Name: gpytorch/lazy/sum_lazy_tensor.py</div><div id='class'> Class Name: SumLazyTensor</div><div id='method'> Method Name: __init__</div><BR>