<html><h3>6ca60969b6893268680d4386e2f22cdc3bc3c405,src/fonduer/utils/udf.py,UDFRunner,apply_mt,#UDFRunner#Any#Any#,86
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            docs_added += 1

        while any([udf.is_alive() for udf in self.udfs]) and count_parsed &lt; total_count:
            <a id="change">if docs_added &lt; total_count:
                in_queue.put(next(xs_generator))
                docs_added += 1
           </a> if docs_added == total_count:
                in_queue.put(UDF.QUEUE_CLOSED)
                docs_added += 1
</code></pre><h3>After Change</h3><pre><code class='java'>

        &#47&#47 Create a Queue to feed documents to parsers
        manager = Manager()
        in_queue = <a id="change">manager.Queue()</a>

        &#47&#47 Use an output queue to track multiprocess progress
        out_queue = JoinableQueue()

        total_count = len(xs)

        &#47&#47 Start UDF Processes
        for i in range(parallelism):
            udf = self.udf_class(
                in_queue=in_queue,
                out_queue=out_queue,
                worker_id=i,
                **self.udf_init_kwargs
            )
            udf.apply_kwargs = kwargs
            self.udfs.append(udf)

        &#47&#47 Start the UDF processes, and then join on their completion
        for udf in self.udfs:
            udf.start()

        &#47&#47 Fill input queue with documents
        pool = Pool(parallelism)
        <a id="change">in_tuples = ((in_queue, x) for x in xs)</a>
        pool.map_async(func=async_fill_input_queue, iterable=in_tuples)

        count_parsed = 0
        while count_parsed &lt; total_count:</code></pre><img src="223235182.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/HazyResearch/fonduer/commit/6ca60969b6893268680d4386e2f22cdc3bc3c405#diff-1c7984a8cc454fc449b11f1cdf978b470e6b6f9255973e3b5cb971edaad62de5L86' target='_blank'>Link</a></div><div id='project'> Project Name: HazyResearch/fonduer</div><div id='commit'> Commit Name: 6ca60969b6893268680d4386e2f22cdc3bc3c405</div><div id='time'> Time: 2018-09-05</div><div id='author'> Author: jrausch@inf.ethz.ch</div><div id='file'> File Name: src/fonduer/utils/udf.py</div><div id='class'> Class Name: UDFRunner</div><div id='method'> Method Name: apply_mt</div><BR><BR><div id='link'><a href='https://github.com/keras-team/keras/commit/9a50d7bece2e09093f7eec251fc2be5736b131da#diff-93382e768dc2423816131bd08102e682d140cd61367c89e0bd7ca7a102c28efdL353' target='_blank'>Link</a></div><div id='project'> Project Name: keras-team/keras</div><div id='commit'> Commit Name: 9a50d7bece2e09093f7eec251fc2be5736b131da</div><div id='time'> Time: 2018-01-09</div><div id='author'> Author: myutwo150@users.noreply.github.com</div><div id='file'> File Name: tests/keras/applications/applications_test.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: test_densenet_variable_input_channels</div><BR><BR><div id='link'><a href='https://github.com/okfn-brasil/serenata-de-amor/commit/67fa4171fffad014ef7f072ef56426e52080fcb5#diff-49d401875bc61aad3fcaa51ad350226d6a588268fc06d0dc08f7910d343d9b91L145' target='_blank'>Link</a></div><div id='project'> Project Name: okfn-brasil/serenata-de-amor</div><div id='commit'> Commit Name: 67fa4171fffad014ef7f072ef56426e52080fcb5</div><div id='time'> Time: 2016-11-10</div><div id='author'> Author: cuducos@gmail.com</div><div id='file'> File Name: src/fetch_suspicious_places.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: search_suspicious_around_companies</div><BR>