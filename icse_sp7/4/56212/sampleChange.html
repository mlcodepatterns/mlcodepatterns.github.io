<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    report_every = train_config.get("save_summary_steps", 100)
    accum_count = params.get("gradients_accum", 1)

    <a id="change">for i, (source, target) in enumerate(dataset):
      loss, num_words = _step(source, target)
      if i == 0 or (i + 1) % accum_count == 0:
        _apply_gradients()

      for key, value in six.iteritems(num_words):
        value = value.numpy()
        if key not in accum_num_words:
          accum_num_words[key] = value
        else:
          accum_num_words[key] += value

      step = optimizer.iterations.numpy()
      if step % report_every == 0:
        last_report_time = _report_training_status(
            step,
            loss,
            optimizer.learning_rate,
            accum_num_words,
            last_report_time)
      if step % save_checkpoints_steps == 0 or step == train_steps:
        path = checkpoint_manager.save(checkpoint_number=step)
        tf.get_logger().info("Saved checkpoint %s", path)
      if step == train_steps:
        break

   </a> return self._maybe_average_checkpoints()

  def evaluate(self, checkpoint_path=None):
    Runs evaluation.</code></pre><h3>After Change</h3><pre><code class='java'>
      if step == train_steps:
        break

    <a id="change">_save_checkpoint(step)</a>
    return self._maybe_average_checkpoints()

  def evaluate(self, checkpoint_path=None):
    Runs evaluation.</code></pre>