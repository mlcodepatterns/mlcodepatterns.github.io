<html><h3>563207ae6bd9a8565243b04dcd92af9c33bac524,deepchem/models/keras_model.py,KerasModel,fit_generator,#KerasModel#Any#Any#Any#Any#Any#Any#Any#,246
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
          outputs = [outputs[i] for i in self._loss_outputs]
        batch_loss = loss(outputs, labels, weights)
      if variables is None:
        <a id="change">vars = self.model.trainable_variables</a>
      else:
        vars = variables
      <a id="change">grads = tape.gradient(batch_loss, vars)</a>
      self._tf_optimizer.apply_gradients(zip(grads, vars))
      self._global_step.assign_add(1)
      current_step = self._global_step.numpy()
</code></pre><h3>After Change</h3><pre><code class='java'>
    if loss is None:
      loss = self._loss_fn
    var_key = None
    <a id="change">if variables is not None:
      var_key = tuple(v.experimental_ref() for v in variables)

      &#47&#47 The optimizer creates internal variables the first time apply_gradients()
      &#47&#47 is called for a new set of variables.  If that happens inside a function
      &#47&#47 annotated with tf.function it throws an exception, so call it once here.

      zero_grads = [tf.zeros(v.shape) for v in variables]
      self._tf_optimizer.apply_gradients(zip(zero_grads, variables))
   </a> if var_key not in self._gradient_fn_for_vars:
      self._gradient_fn_for_vars[var_key] = self._create_gradient_fn(variables)
    apply_gradient_for_batch = self._gradient_fn_for_vars[var_key]
    time1 = time.time()</code></pre><img src="156302162.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/deepchem/deepchem/commit/563207ae6bd9a8565243b04dcd92af9c33bac524#diff-6959c92eed13049850ed08d423ac054a0f3781b89ba52eceaf68523bbc0cde89L246' target='_blank'>Link</a></div><div id='project'> Project Name: deepchem/deepchem</div><div id='commit'> Commit Name: 563207ae6bd9a8565243b04dcd92af9c33bac524</div><div id='time'> Time: 2020-02-12</div><div id='author'> Author: peastman@stanford.edu</div><div id='file'> File Name: deepchem/models/keras_model.py</div><div id='class'> Class Name: KerasModel</div><div id='method'> Method Name: fit_generator</div><BR><BR><div id='link'><a href='https://github.com/drckf/paysage/commit/544de8b887d171dc283ea8e5d9d7aa551fde1c95#diff-5cff79061b54d449a8bf0ebe9d794dfacbe1713a9bafb7b08f0c27b00ffa8f15L478' target='_blank'>Link</a></div><div id='project'> Project Name: drckf/paysage</div><div id='commit'> Commit Name: 544de8b887d171dc283ea8e5d9d7aa551fde1c95</div><div id='time'> Time: 2017-04-14</div><div id='author'> Author: charleskennethfisher@gmail.com</div><div id='file'> File Name: paysage/fit.py</div><div id='class'> Class Name: StochasticGradientDescent</div><div id='method'> Method Name: train</div><BR><BR><div id='link'><a href='https://github.com/scikit-image/scikit-image/commit/aa9d770505d914aea76888e5eb11b5ddad54ce77#diff-582c80400ba5b550317f8824b442019270df33a386168019f6bc248010c8d6bfL151' target='_blank'>Link</a></div><div id='project'> Project Name: scikit-image/scikit-image</div><div id='commit'> Commit Name: aa9d770505d914aea76888e5eb11b5ddad54ce77</div><div id='time'> Time: 2016-07-16</div><div id='author'> Author: juan.n@unimelb.edu.au</div><div id='file'> File Name: skimage/feature/corner.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: hessian_matrix</div><BR>