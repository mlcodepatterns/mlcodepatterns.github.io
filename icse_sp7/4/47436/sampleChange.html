<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                    p += eps * d

            self.mutator.reset()
            loss = self.loss(<a id="change">self.model(trn_X)</a>, trn_y)
            if e &gt; 0:
                dalpha_pos = torch.autograd.grad(loss, self.mutator.parameters())  &#47&#47 dalpha { L_trn(w+) }
            elif e &lt; 0:</code></pre><h3>After Change</h3><pre><code class='java'>
        if norm &lt; 1E-8:
            logger.warning("In computing hessian, norm is smaller than 1E-8, cause eps to be %.6f.", norm.item())

        <a id="change">dalphas = []</a>
        for e in [eps, -2. * eps]:
            &#47&#47 w+ = w + eps*dw`, w- = w - eps*dw`
            with torch.no_grad():
                for p, d in zip(self.model.parameters(), dw):
                    p += e * d

            _, loss = self._logits_and_loss(trn_X, trn_y)
            dalphas.append(torch.autograd.grad(loss, self.mutator.parameters()))

        <a id="change">dalpha_pos, dalpha_neg = dalphas</a>  &#47&#47 dalpha { L_trn(w+) }, &#47&#47 dalpha { L_trn(w-) }
        hessian = [(p - n) / 2. * eps for p, n in zip(dalpha_pos, dalpha_neg)]
        return hessian
</code></pre>