<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))

        x = torch.mm(x, self.weight).view(-1, self.heads, self.out_channels)
        return <a id="change">self.propagate(edge_index, x=x, num_nodes=x.size(0))</a>

    def message(self, edge_index_i, x_i, x_j, num_nodes):
        &#47&#47 Compute attention coefficients.
        alpha = (torch.cat([x_i, x_j], dim=-1) * self.att).sum(dim=-1)</code></pre><h3>After Change</h3><pre><code class='java'>
        \right)\right)}
        {\sum_{k \in \mathcal{N}(i) \cup \{ i \}}
        \exp\left(\mathrm{LeakyReLU}\left(\mathbf{a}^{\top}
        [\mathbf{\Theta}\mathbf{x}_i \, \Vert \<a id="change">, \mathbf</a>{\Theta}\mathbf{x}_k]
        \right)\right)}.

    Args:
        in_channels (int): Size of ea<a id="change">ch input sample.
  </a>      out<a id="change">_channels (int): Size of each output sample.
        </a>heads (int, optional): Number of multi-head-attentions.
            (default: :obj:`1`)
        concat (bool, optional): If set to :obj:`False`, the multi-head
            attentions are averaged instead of concatenated.</code></pre>