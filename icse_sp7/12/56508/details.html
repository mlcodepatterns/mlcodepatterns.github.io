<html><h3>489db85647d6de8a42f9fc5162e1e9ef0831800b,gluonnlp/data/dataset.py,LanguageModelDataset,bptt_batchify,#LanguageModelDataset#Any#Any#Any#Any#,174
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                                                &quotlast_batch="keep".&quot
                    padding_size = batch_size - excess_size
                    last_batch.extend([vocab.padding_token]*padding_size)
                <a id="change">batches.append(mx.nd.array(vocab[last_batch], ctx=ctx).reshape(batch_size, -1).T)</a>
        return SimpleDataset(batches).transform(lambda x: (x[:min(len(x)-1, seq_len), :], x[1:, :]))
</code></pre><h3>After Change</h3><pre><code class='java'>

            - discard: The last batch is discarded if it&quots smaller than `(seq_len, batch_size)`.
        
        <a id="change">if last_batch not in [&quotkeep&quot, &quotdiscard&quot]:
            raise ValueError(
                &quotGot invalid last_batch: "{}". Must be "keep" or "discard".&quot.
                format(last_batch))

       </a> if last_batch == &quotkeep&quot:
            <a id="change">if not vocab.padding_token:
                raise ValueError(&quotvocab.padding_token must be specified &quot
                                 &quotin vocab when last_batch="keep".&quot)
           </a> coded = vocab[self._data[0]]
            sample_len = math.ceil(float(len(coded)) / batch_size)
            <a id="change">padding_size = _slice_pad_length(sample_len, seq_len + 1, 1) * batch_size + \
                sample_len * batch_size - len(coded)</a>
            coded.extend([vocab[vocab.padding_token]] * int(padding_size))
            assert len(coded) % batch_size == 0
            assert not _slice_pad_length(len(coded) / batch_size, seq_len + 1, 1)
        else:</code></pre><img src="260358292.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 9</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/dmlc/gluon-nlp/commit/489db85647d6de8a42f9fc5162e1e9ef0831800b#diff-e65d904f83e854a287965667f5aa22a784f2cf18b5348d76831968c1b18c6164L174' target='_blank'>Link</a></div><div id='project'> Project Name: dmlc/gluon-nlp</div><div id='commit'> Commit Name: 489db85647d6de8a42f9fc5162e1e9ef0831800b</div><div id='time'> Time: 2018-08-02</div><div id='author'> Author: leonard@lausen.nl</div><div id='file'> File Name: gluonnlp/data/dataset.py</div><div id='class'> Class Name: LanguageModelDataset</div><div id='method'> Method Name: bptt_batchify</div><BR><BR><div id='link'><a href='https://github.com/stellargraph/stellargraph/commit/ce597a0b10658043b6d6d8ffed3fff4a6ebbc1ea#diff-835561991ce43087f77f2c21554f32a11de89c335dfea62f6ecb675b9f69c00cL55' target='_blank'>Link</a></div><div id='project'> Project Name: stellargraph/stellargraph</div><div id='commit'> Commit Name: ce597a0b10658043b6d6d8ffed3fff4a6ebbc1ea</div><div id='time'> Time: 2019-09-26</div><div id='author'> Author: u5824685@anu.edu.au</div><div id='file'> File Name: stellargraph/layer/appnp.py</div><div id='class'> Class Name: APPNP</div><div id='method'> Method Name: __init__</div><BR><BR><div id='link'><a href='https://github.com/theislab/scanpy/commit/81dbae9b7c584c4b7a384dec47a3375febdd1ef3#diff-21ad0490793d77ccea82cf97754c21e2d80b915002d6301e3b9ae54031fdcdf4L156' target='_blank'>Link</a></div><div id='project'> Project Name: theislab/scanpy</div><div id='commit'> Commit Name: 81dbae9b7c584c4b7a384dec47a3375febdd1ef3</div><div id='time'> Time: 2021-02-01</div><div id='author'> Author: fidel.ramirez@gmail.com</div><div id='file'> File Name: scanpy/get.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: obs_df</div><BR>