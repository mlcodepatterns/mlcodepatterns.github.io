<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        config[&quotinput_block&quot].update(dict(layout=&quotcnap&quot, filters=64, kernel_size=7, strides=2,
                                          pool_size=3, pool_strides=2))

        <a id="change">config[&quotbody&quot][&quotblock&quot]</a> = dict(post_activation=None, downsample=False,
                                       bottleneck=False, bottleneck_factor=4,
                                       width_factor=1,
                                       resnext=False, resnext_factor=32,
                                       se_block=False, se_factor=16)

        <a id="change">config[&quothead&quot].update(dict(layout=&quotVdf&quot, dropout_rate=.4))</a>

        config[&quotloss&quot] = &quotce&quot
        <a id="change">config[&quotcommon&quot]</a> = dict(conv=dict(use_bias=False))
        &#47&#47 The learning rate starts from 0.1 (no warming up), and is divided by 10 at 30 and 60 epochs
        &#47&#47 with batch size = 256 on ImageNet.
        init_lr = 1e-3 if is_best_practice() else .1
        <a id="change">config[&quotdecay&quot] = (&quotconst&quot, dict(boundaries=[117188, 234375], values=[init_lr, init_lr/10, init_lr/100]))</a>
        config[&quotoptimizer&quot] = dict(name=&quotMomentum&quot, momentum=.9)
        return config

    def build_config(self, names=None):</code></pre><h3>After Change</h3><pre><code class='java'>
    
    @classmethod
    def default_config(cls):
        <a id="change">config</a> = TFModel.default_config()
        <a id="change">config[&quotcommon/conv/use_bias&quot]</a> = False
        config[&quotinput_block&quot].update(dict(layout=&quotcnap&quot, filters=64, kernel_size=7, strides=2,
                                          pool_size=3, pool_strides=2))

        <a id="change">config[&quotbody/block&quot]</a> = dict(post_activation=None, downsample=False,
                                       bottleneck=False, bottleneck_factor=4,
                                       width_factor=1,
                                       resnext=False, resnext_factor=32,
                                       se_block=False, se_factor=16)

        <a id="change">config[&quothead&quot] = dict(layout=&quotVdf&quot, dropout_rate=.4)</a>

        config[&quotloss&quot] = &quotce&quot
        <a id="change">if is_best_practice(&quotoptimizer&quot):
            config[&quotoptimizer&quot] = &quotAdam&quot
        else:
            &#47&#47 The learning rate starts from 0.1 (no warming up), and is divided by 10 at 30 and 60 epochs
            &#47&#47 with batch size = 256 on ImageNet.
            lr = .1
            config[&quotdecay&quot] = (&quotconst&quot, dict(boundaries=[117188, 234375], values=[lr, lr/10, lr/100]))
            config[&quotoptimizer&quot] = (&quotMomentum&quot, dict(momentum=.9))
       </a> return config

    def build_config(self, names=None):
        config = super().build_config(names)</code></pre>