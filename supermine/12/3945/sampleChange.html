<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            languages=squeeze_1d(None),
        )
        &#47&#47 call model
        <a id="change">dense_feat = self.normalizer.normalize(dense_feat)</a>
        <a id="change">dense_tensor = torch.tensor(dense_feat, dtype=torch.float)</a>
        if <a id="change">self</a>.tensorizer.device != "":
            <a id="change">dense_tensor = dense_tensor.to(self.tensorizer.device)</a>

        sentence_embedding = self._forward(inputs, dense_tensor)
        if self.concat_dense:
            return torch.cat([sentence_embedding, dense_tensor], 1)</code></pre><h3>After Change</h3><pre><code class='java'>
        if max_batch &lt; 0:
            max_batch = input_len

        result = <a id="change">self.forward_impl(texts[:max_batch], dense_feat[:max_batch])</a>

        if input_len &gt; max_batch:
            texts = texts[max_batch:]
            dense_feat = dense_feat[max_batch:]

            while len(texts) &gt; 0:
                result_extension = self.forward_impl(
                    texts[:max_batch], dense_feat[:max_batch]
                )
                &#47&#47 the result of forward is either a torch.Tensor or a List[Any]
                if isinstance(result, torch.Tensor):
                    result = torch.cat([result, result_extension], dim=0)
                else:
                    result.extend(result_extension)

                texts = texts[max_batch:]
                dense_feat = dense_feat[max_batch:]

        <a id="change">return result</a>

    @torch.jit.script_method
    def make_prediction(
        self,</code></pre>