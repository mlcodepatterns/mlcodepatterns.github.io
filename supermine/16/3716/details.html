<html><h3>c5d6be170013db8975d96806084df573d87e5d26,implementations/wgan_div/wgan_div.py,,,#,86
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        "../../data/mnist",
        train=True,
        download=True,
        transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize(<a id="change">(0.5, 0.5, 0.5)</a>, <a id="change">(0.5, 0.5, 0.5)</a>)]),
    ),
    batch_size=opt.batch_size,
    shuffle=True,
)

&#47&#47 Optimizers
optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))
optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))

Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor

&#47&#47 ----------
&#47&#47  Training
&#47&#47 ----------

batches_done = 0
for epoch in range(opt.n_epochs):
    for i, (imgs, _) in enumerate(dataloader):

        &#47&#47 Configure input
        real_imgs = Variable(imgs.type(Tensor),requires_grad=True)

        &#47&#47 ---------------------
        &#47&#47  Train Discriminator
        &#47&#47 ---------------------

        optimizer_D.zero_grad()

        &#47&#47 Sample noise as generator input
        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], opt.latent_dim))))

        &#47&#47 Generate a batch of images
        fake_imgs = generator(z)

        &#47&#47 Real images
        real_validity = discriminator(real_imgs)
        &#47&#47 Fake images
        fake_validity = discriminator(fake_imgs)

        &#47&#47 Compute W-div gradient penalty
        real_grad_out = Variable(Tensor(real_imgs.size(0), 1).fill_(1.0),requires_grad=False)
        real_grad = autograd.grad(real_validity,
                                  real_imgs,
                                  real_grad_out,
                                  create_graph=True,
	 		          retain_graph=True,
				  only_inputs=True)[0]
        real_grad_norm = real_grad.view(real_grad.size(0),-1).pow(2).sum(1)**(p/2)

        fake_grad_out = Variable(Tensor(fake_imgs.size(0), 1).fill_(1.0),requires_grad=False)
        fake_grad = autograd.grad(fake_validity,
                                  fake_imgs,
                                  fake_grad_out,
                                  create_graph=True,
 				  retain_graph=True,
   				  only_inputs=True)[0]
        <a id="change">fake_grad_norm</a> = fake_grad.view(fake_grad.size(0),-1).pow(2).sum(1)**(p/2)

        div_gp = torch.mean(real_grad_norm + fake_grad_norm) * k / 2
</code></pre><h3>After Change</h3><pre><code class='java'>
        train=True,
        download=True,
        transform=transforms.Compose(
            [<a id="change">transforms.Resize(opt.img_size)</a>, transforms.ToTensor(), transforms.Normalize(<a id="change">[0.5]</a>, <a id="change">[0.5]</a>)]
        ),
    ),
    batch_size=opt.batch_size,
    shuffle=True,
)

&#47&#47 Optimizers
optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))
optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))

Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor

&#47&#47 ----------
&#47&#47  Training
&#47&#47 ----------

batches_done = 0
for epoch in range(opt.n_epochs):
    for i, (imgs, _) in enumerate(dataloader):

        &#47&#47 Configure input
        real_imgs = Variable(imgs.type(Tensor), requires_grad=True)

        &#47&#47 ---------------------
        &#47&#47  Train Discriminator
        &#47&#47 ---------------------

        optimizer_D.zero_grad()

        &#47&#47 Sample noise as generator input
        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], opt.latent_dim))))

        &#47&#47 Generate a batch of images
        fake_imgs = generator(z)

        &#47&#47 Real images
        real_validity = discriminator(real_imgs)
        &#47&#47 Fake images
        fake_validity = discriminator(fake_imgs)

        &#47&#47 Compute W-div gradient penalty
        real_grad_out = Variable(Tensor(real_imgs.size(0), 1).fill_(1.0), requires_grad=False)
        real_grad = autograd.grad(
            real_validity, real_imgs, real_grad_out, create_graph=True, retain_graph=True, only_inputs=True
        )[0]
        real_grad_norm = real_grad.view(real_grad.size(0), -1).pow(2).sum(1) ** (p / 2)

        fake_grad_out = Variable(Tensor(fake_imgs.size(0), 1).fill_(1.0), requires_grad=False)
        fake_grad = autograd.grad(
            fake_validity, fake_imgs, fake_grad_out, create_graph=True, retain_graph=True, only_inputs=True
        )[0]
        <a id="change">fake_grad_norm</a> = fake_grad.view(fake_grad.size(0), -1).pow(2).sum(1) ** (p / 2)

        div_gp = torch.mean(real_grad_norm + fake_grad_norm) * k / 2
</code></pre><img src="16365195.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 8</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/eriklindernoren/PyTorch-GAN/commit/c5d6be170013db8975d96806084df573d87e5d26#diff-78348ea20beec3b70978e1513fb19b0e1f97f86d6a490f4a77e9d86072485c2cL100' target='_blank'>Link</a></div><div id='project'> Project Name: eriklindernoren/PyTorch-GAN</div><div id='commit'> Commit Name: c5d6be170013db8975d96806084df573d87e5d26</div><div id='time'> Time: 2019-03-28</div><div id='author'> Author: eriklindernoren@live.se</div><div id='file'> File Name: implementations/wgan_div/wgan_div.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: </div><BR><BR><div id='link'><a href='https://github.com/eriklindernoren/PyTorch-GAN/commit/c5d6be170013db8975d96806084df573d87e5d26#diff-bf378a0d683e41269dd85bfa274bb8ca384850e630a826c151328cdfefba1258L94' target='_blank'>Link</a></div><div id='project'> Project Name: eriklindernoren/PyTorch-GAN</div><div id='commit'> Commit Name: c5d6be170013db8975d96806084df573d87e5d26</div><div id='time'> Time: 2019-03-28</div><div id='author'> Author: eriklindernoren@live.se</div><div id='file'> File Name: implementations/softmax_gan/softmax_gan.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: </div><BR><BR><div id='link'><a href='https://github.com/eriklindernoren/PyTorch-GAN/commit/c5d6be170013db8975d96806084df573d87e5d26#diff-35bcc26ff579d20e0436ba68ebdf5a869209452863f5bcd24893fedfd8de2ab5L95' target='_blank'>Link</a></div><div id='project'> Project Name: eriklindernoren/PyTorch-GAN</div><div id='commit'> Commit Name: c5d6be170013db8975d96806084df573d87e5d26</div><div id='time'> Time: 2019-03-28</div><div id='author'> Author: eriklindernoren@live.se</div><div id='file'> File Name: implementations/gan/gan.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: </div><BR><BR><div id='link'><a href='https://github.com/eriklindernoren/PyTorch-GAN/commit/c5d6be170013db8975d96806084df573d87e5d26#diff-05f27b320cc258e5487ace4dc01b99e327e22efaee7788b71a1871ffb8cebad7L99' target='_blank'>Link</a></div><div id='project'> Project Name: eriklindernoren/PyTorch-GAN</div><div id='commit'> Commit Name: c5d6be170013db8975d96806084df573d87e5d26</div><div id='time'> Time: 2019-03-28</div><div id='author'> Author: eriklindernoren@live.se</div><div id='file'> File Name: implementations/wgan_gp/wgan_gp.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: </div><BR>