<html><h3>47fa9165313efd36310de98fec8b25be08016db2,face_alignment/api.py,FaceAlignment,get_landmarks_from_batch,#FaceAlignment#,189
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            inp.div_(255.0).unsqueeze_(0)
            inp_batch.append(inp)

        <a id="change">inp_batch = torch.cat(inp_batch, dim=0)</a>

        out = self.face_alignment_net(inp_batch)[-1].detach()
        if self.flip_input:</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 A batch for each frame
        for i, faces in enumerate(detected_faces):
            landmark_set = []
            <a id="change">for face in faces:
                center = torch.FloatTensor(
                    [(face[2] + face[0]) / 2.0,
                     (face[3] + face[1]) / 2.0])

                center[1] = center[1] - (face[3] - face[1]) * 0.12
                scale = (face[2] - face[0] + face[3] - face[1]) / self.face_detector.reference_scale
                image = image_batch[i].cpu().numpy()

                image = image.transpose(1, 2, 0)

                inp = crop(image, center, scale)
                inp = torch.from_numpy(inp.transpose((2, 0, 1))).float()

                inp = inp.to(self.device)
                inp.div_(255.0).unsqueeze_(0)

                out = self.face_alignment_net(inp)[-1].detach()
                if self.flip_input:
                    out += flip(self.face_alignment_net(flip(inp_batch))
                                [-1].detach(), is_label=True)
                out = out.cpu()
                pts, pts_img = get_preds_fromhm(out, center, scale)
                pts, pts_img = pts.view(-1, 68, 2) * 4, pts_img.view(-1, 68, 2)

                &#47&#47 TODO: Adding 3D landmark support
                if self.landmarks_type == LandmarksType._3D:
                    heatmaps = np.zeros((68, 256, 256), dtype=np.float32)
                    for i in range(68):
                        if pts[i, 0] &gt; 0:
                            heatmaps[i] = draw_gaussian(
                                heatmaps[i], pts[i], 2)
                    heatmaps = torch.from_numpy(
                        heatmaps).unsqueeze_(0)

                    heatmaps = heatmaps.to(self.device)
                    depth_pred = self.depth_prediciton_net(
                        torch.cat((inp, heatmaps), 1)).data.cpu().view(68, 1)
                    pts_img = torch.cat(
                        (pts_img, depth_pred * (1.0 / (256.0 / (200.0 * scale)))), 1)

                landmark_set.append(pts_img.numpy())

           </a> landmark_set = np.concatenate(landmark_set, axis=0)
            landmarks.append(landmark_set)
        return landmarks
</code></pre><img src="23092096.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/1adrianb/face-alignment/commit/47fa9165313efd36310de98fec8b25be08016db2#diff-c58c3b36d2d8c1184df26bbea0c29d3a6765741a1ecffac7803a533cf4c2a68dL210' target='_blank'>Link</a></div><div id='project'> Project Name: 1adrianb/face-alignment</div><div id='commit'> Commit Name: 47fa9165313efd36310de98fec8b25be08016db2</div><div id='time'> Time: 2020-07-20</div><div id='author'> Author: imad.toubal@gmail.com</div><div id='file'> File Name: face_alignment/api.py</div><div id='class'> Class Name: FaceAlignment</div><div id='method'> Method Name: get_landmarks_from_batch</div><BR><BR><div id='link'><a href='https://github.com/SenticNet/conv-emotion/commit/87d57a3d34a1eef2c6ad5519741710e3321f136c#diff-1d1c0879fec769e0236a8daedf9ec58539ee90a439cbf96ec58b7cdb862359c3L304' target='_blank'>Link</a></div><div id='project'> Project Name: SenticNet/conv-emotion</div><div id='commit'> Commit Name: 87d57a3d34a1eef2c6ad5519741710e3321f136c</div><div id='time'> Time: 2019-03-19</div><div id='author'> Author: 40890991+soujanyaporia@users.noreply.github.com</div><div id='file'> File Name: DialogueRNN/model.py</div><div id='class'> Class Name: BiE2EModel</div><div id='method'> Method Name: forward</div><BR><BR><div id='link'><a href='https://github.com/eriklindernoren/PyTorch-YOLOv3/commit/012daf57ac31d82366323e7ec27ab7c2cb678a09#diff-09d0cbaf891d623ac245ccf84485a687b554217349ca55557c60b33234b969aeL49' target='_blank'>Link</a></div><div id='project'> Project Name: eriklindernoren/PyTorch-YOLOv3</div><div id='commit'> Commit Name: 012daf57ac31d82366323e7ec27ab7c2cb678a09</div><div id='time'> Time: 2018-05-27</div><div id='author'> Author: eriklindernoren@gmail.com</div><div id='file'> File Name: utils.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: non_max_suppression</div><BR>