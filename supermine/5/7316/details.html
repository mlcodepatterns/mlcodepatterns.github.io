<html><h3>62d2ea56ae4a090aa68baf133137982a836700bd,thumt/utils/search.py,,create_inference_graph,#,430
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        if top_beams == 1:
            return ids[:, 0, 1:]
        else:
            return ids[<a id="change">:, :top_beams, 1</a>:]
    else:
        if top_beams == 1:
            return ids[:, 0, 1:], scores[:, 0]</code></pre><h3>After Change</h3><pre><code class='java'>


def create_inference_graph(model_fns, features, params):
    <a id="change">features = copy.copy(features)</a>

    if not isinstance(model_fns, (list, tuple)):
        model_fns = [model_fns]

    decode_length = params.decode_length
    beam_size = params.beam_size
    top_beams = params.top_beams
    alpha = params.decode_alpha

    &#47&#47 [batch, decoded_ids] =&gt; [batch, vocab_size]
    def symbols_to_logits_fn(decoded_ids):
        features["target"] = tf.pad(decoded_ids[:, 1:], [[0, 0], [0, 1]])
        features["target_length"] = tf.fill([tf.shape(features["target"])[0]],
                                            tf.shape(features["target"])[1])

        results = []

        for i, model_fn in enumerate(model_fns):
            results.append(model_fn(features))

        return results

    batch_size = tf.shape(features["source"])[0]
    &#47&#47 Prepend &lt;bos&gt; symbol
    bos_id = params.mapping["target"][params.bos]
    initial_ids = tf.fill([batch_size], tf.constant(bos_id, dtype=tf.int32))

    &#47&#47 Expand the inputs in to the beam size
    &#47&#47 [batch, length] =&gt; [batch, beam_size, length]
    features["source"] = tf.expand_dims(features["source"], 1)
    features["source"] = tf.tile(features["source"], [1, beam_size, 1])
    shape = tf.shape(features["source"])

    &#47&#47 [batch, beam_size, length] =&gt; [batch * beam_size, length]
    features["source"] = tf.reshape(features["source"],
                                    [shape[0] * shape[1], shape[2]])

    &#47&#47 For source sequence length
    features["source_length"] = tf.expand_dims(features["source_length"], 1)
    features["source_length"] = tf.tile(features["source_length"],
                                        [1, beam_size])
    shape = tf.shape(features["source_length"])

    &#47&#47 [batch, beam_size, length] =&gt; [batch * beam_size, length]
    features["source_length"] = tf.reshape(features["source_length"],
                                           [shape[0] * shape[1]])

    vocab_size = len(params.vocabulary["target"])
    &#47&#47 Setting decode length to input length + decode_length
    decode_length = tf.shape(features["source"])[1] + decode_length

    ids, scores = beam_search(symbols_to_logits_fn, initial_ids,
                              beam_size, decode_length, vocab_size,
                              alpha,
                              eos_id=params.mapping["target"][params.eos],
                              lp_constant=params.decode_constant)

    mask = tf.not_equal(ids, 0)
    output_length = tf.reduce_sum(tf.to_float(mask), axis=-1)

    &#47&#47 shape: [batch, beam_size]
    normalized_scores = scores / output_length

    if params.decode_normalize:
        scores, indices = tf.nn.top_k(normalized_scores, k=top_beams)
        &#47&#47 shape of ids: [batch, beam_size, max_length]
        &#47&#47 shape of coordinates: [batch, beam_size, 2]
        <a id="change">batch_pos = compute_batch_indices(batch_size, beam_size)</a>
        coordinates = tf.stack([batch_pos, indices], axis=2)
        ids = tf.gather_nd(ids, coordinates)

    &#47&#47 Return `top_beams` decoding</code></pre><img src="28230318.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/THUNLP-MT/THUMT/commit/62d2ea56ae4a090aa68baf133137982a836700bd#diff-4b46e2d7c3036aa0c556f049332e2e5198f815e30c2c79d88e836c945b10faefL432' target='_blank'>Link</a></div><div id='project'> Project Name: THUNLP-MT/THUMT</div><div id='commit'> Commit Name: 62d2ea56ae4a090aa68baf133137982a836700bd</div><div id='time'> Time: 2018-01-25</div><div id='author'> Author: playinf@stu.xmu.edu.cn</div><div id='file'> File Name: thumt/utils/search.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: create_inference_graph</div><BR><BR><div id='link'><a href='https://github.com/scikit-learn-contrib/categorical-encoding/commit/f4838c7408b81ad960c047df5984901927a86d86#diff-c79bb02bf62bfaa0d7a0fe3ca8376185c502d1c748b0c5cc0c225b166481b3f9L154' target='_blank'>Link</a></div><div id='project'> Project Name: scikit-learn-contrib/categorical-encoding</div><div id='commit'> Commit Name: f4838c7408b81ad960c047df5984901927a86d86</div><div id='time'> Time: 2018-10-26</div><div id='author'> Author: jcastaldo08@gmail.com</div><div id='file'> File Name: category_encoders/one_hot.py</div><div id='class'> Class Name: OneHotEncoder</div><div id='method'> Method Name: generate_mapping</div><BR><BR><div id='link'><a href='https://github.com/datascienceinc/Skater/commit/8c6336d24b905d39f88396e50c8cb23870c38bfe#diff-8617490ec49d27286192534236ed7620591bb71879c15e88f9a23e446a69feacL66' target='_blank'>Link</a></div><div id='project'> Project Name: datascienceinc/Skater</div><div id='commit'> Commit Name: 8c6336d24b905d39f88396e50c8cb23870c38bfe</div><div id='time'> Time: 2018-02-18</div><div id='author'> Author: pramitchoudhary@ip-172-30-0-2.us-west-2.compute.internal</div><div id='file'> File Name: skater/core/global_interpretation/interpretable_models/rule_lists.py</div><div id='class'> Class Name: BayesianRuleLists</div><div id='method'> Method Name: discretizer</div><BR>