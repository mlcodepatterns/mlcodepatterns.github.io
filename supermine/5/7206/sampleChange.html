<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    lm_mask = tf.keras.Input(shape=(num_token_predictions,), dtype=tf.int32)

    &#47&#47 Invoke the trainer model on the inputs. This causes the layer to be built.
    <a id="change">outputs = bert_trainer_model([word_ids, mask, type_ids, lm_mask])</a>

    has_encoder_outputs = dict_outputs or return_all_encoder_outputs
    if has_encoder_outputs:
      self.assertSameElements(</code></pre><h3>After Change</h3><pre><code class='java'>
        encoder_network=test_network, customized_masked_lm=customized_masked_lm)
    num_token_predictions = 20
    &#47&#47 Create a set of 2-dimensional inputs (the first dimension is implicit).
    <a id="change">inputs = dict(
        input_word_ids=tf.keras.Input(shape=(sequence_length,), dtype=tf.int32),
        input_mask=tf.keras.Input(shape=(sequence_length,), dtype=tf.int32),
        input_type_ids=tf.keras.Input(shape=(sequence_length,), dtype=tf.int32),
        masked_lm_positions=tf.keras.Input(
            shape=(num_token_predictions,), dtype=tf.int32))</a>

    &#47&#47 Invoke the trainer model on the inputs. This causes the layer to be built.
    <a id="change">outputs = bert_trainer_model(inputs)</a>

    has_encoder_outputs = dict_outputs or return_all_encoder_outputs
    if has_encoder_outputs:
      self.assertSameElements(</code></pre>