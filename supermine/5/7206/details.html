<html><h3>8cd8b2295024b21e7ee8db6cf871df824f20ab42,official/nlp/modeling/models/bert_pretrainer_test.py,BertPretrainerTest,test_bert_pretrainerv2,#BertPretrainerTest#,118
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    lm_mask = tf.keras.Input(shape=(num_token_predictions,), dtype=tf.int32)

    &#47&#47 Invoke the trainer model on the inputs. This causes the layer to be built.
    <a id="change">outputs = bert_trainer_model([word_ids, mask, type_ids, lm_mask])</a>

    has_encoder_outputs = dict_outputs or return_all_encoder_outputs
    if has_encoder_outputs:
      self.assertSameElements(</code></pre><h3>After Change</h3><pre><code class='java'>
        encoder_network=test_network, customized_masked_lm=customized_masked_lm)
    num_token_predictions = 20
    &#47&#47 Create a set of 2-dimensional inputs (the first dimension is implicit).
    <a id="change">inputs = dict(
        input_word_ids=tf.keras.Input(shape=(sequence_length,), dtype=tf.int32),
        input_mask=tf.keras.Input(shape=(sequence_length,), dtype=tf.int32),
        input_type_ids=tf.keras.Input(shape=(sequence_length,), dtype=tf.int32),
        masked_lm_positions=tf.keras.Input(
            shape=(num_token_predictions,), dtype=tf.int32))</a>

    &#47&#47 Invoke the trainer model on the inputs. This causes the layer to be built.
    <a id="change">outputs = bert_trainer_model(inputs)</a>

    has_encoder_outputs = dict_outputs or return_all_encoder_outputs
    if has_encoder_outputs:
      self.assertSameElements(</code></pre><img src="27940331.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/tensorflow/models/commit/8cd8b2295024b21e7ee8db6cf871df824f20ab42#diff-02f502cd3c44259e82caa76a9c17eaeb637de913ff270aaa3fb01caae1c84054L145' target='_blank'>Link</a></div><div id='project'> Project Name: tensorflow/models</div><div id='commit'> Commit Name: 8cd8b2295024b21e7ee8db6cf871df824f20ab42</div><div id='time'> Time: 2020-11-17</div><div id='author'> Author: hongkuny@google.com</div><div id='file'> File Name: official/nlp/modeling/models/bert_pretrainer_test.py</div><div id='class'> Class Name: BertPretrainerTest</div><div id='method'> Method Name: test_bert_pretrainerv2</div><BR><BR><div id='link'><a href='https://github.com/tensorflow/models/commit/78a367e150f625f1b138c847d49ea51498d5263a#diff-02f502cd3c44259e82caa76a9c17eaeb637de913ff270aaa3fb01caae1c84054L145' target='_blank'>Link</a></div><div id='project'> Project Name: tensorflow/models</div><div id='commit'> Commit Name: 78a367e150f625f1b138c847d49ea51498d5263a</div><div id='time'> Time: 2020-11-18</div><div id='author'> Author: hongkuny@google.com</div><div id='file'> File Name: official/nlp/modeling/models/bert_pretrainer_test.py</div><div id='class'> Class Name: BertPretrainerTest</div><div id='method'> Method Name: test_bert_pretrainerv2</div><BR><BR><div id='link'><a href='https://github.com/dirty-cat/dirty_cat/commit/f819a34e2fbea2dab4997b3b236b517fa12d115d#diff-687074a9424d2ec73413c9c6e19ae408d3f34c75fdeb709aae0f83a920152737L115' target='_blank'>Link</a></div><div id='project'> Project Name: dirty-cat/dirty_cat</div><div id='commit'> Commit Name: f819a34e2fbea2dab4997b3b236b517fa12d115d</div><div id='time'> Time: 2018-06-08</div><div id='author'> Author: gael.varoquaux@normalesup.org</div><div id='file'> File Name: examples/02_predict_employee_salaries.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: </div><BR>