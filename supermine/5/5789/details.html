<html><h3>9d56361641a64ff73ac630812ecd4964eedbc7aa,gat/graph_attention_layer.py,GraphAttention,call,#GraphAttention#,72
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                dense = Dense(1)(slice)  &#47&#47 N x 1 (basically "a(Wh_i, Wh_j)" in the paper)
                &#47&#47 TODO: masking
                e_i = K.reshape(dense, (1, -1))  &#47&#47 1 x N (e_i in the paper)
                <a id="change">softmax = K.squeeze(K.softmax(e_i))</a>  &#47&#47 N (alpha_i in the paper)
                <a id="change">softmax_broadcast = K.transpose(K.reshape(K.tile(softmax, [self.F_]), [self.F_, -1]))</a>
                node_features = K.sum(softmax_broadcast * linear_transf, axis=0)
                if self.use_bias:
                    output = K.bias_add(node_features, self.bias)
                if self.heads_combination == &quotconcat&quot and self.activation is not None:</code></pre><h3>After Change</h3><pre><code class='java'>
        outputs = []  &#47&#47 Will store the outputs of each attention head (B x F&quot or B x KF&quot)
        for head in range(self.attention_heads):
            kernel = self.kernels[head]  &#47&#47 W in the paper (F x F&quot)
            attention_kernel = <a id="change">self.attention_kernels[head]</a>  &#47&#47 Attention network a in paper (2*F&quot x 1)

            &#47&#47 Compute inputs to attention network
            linear_transf_X = K.dot(X, kernel)  &#47&#47 B x F&quot</code></pre><img src="24202577.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/danielegrattarola/keras-gat/commit/9d56361641a64ff73ac630812ecd4964eedbc7aa#diff-b5eead7f2a637c33998de1add9a690c0678e849a3d16791260f0f0a16506c7c3L72' target='_blank'>Link</a></div><div id='project'> Project Name: danielegrattarola/keras-gat</div><div id='commit'> Commit Name: 9d56361641a64ff73ac630812ecd4964eedbc7aa</div><div id='time'> Time: 2017-11-09</div><div id='author'> Author: daniele.grattarola@gmail.com</div><div id='file'> File Name: gat/graph_attention_layer.py</div><div id='class'> Class Name: GraphAttention</div><div id='method'> Method Name: call</div><BR><BR><div id='link'><a href='https://github.com/interactiveaudiolab/nussl/commit/2ffbfa3a6bd3b8de8e21a762489346054dcd9ccc#diff-5e6b3d2d75547a9fe7fd7ace6332660a0bb8ac76746e8cd3560fb141519934adL53' target='_blank'>Link</a></div><div id='project'> Project Name: interactiveaudiolab/nussl</div><div id='commit'> Commit Name: 2ffbfa3a6bd3b8de8e21a762489346054dcd9ccc</div><div id='time'> Time: 2020-03-12</div><div id='author'> Author: prem@u.northwestern.edu</div><div id='file'> File Name: nussl/separation/deep/deep_mask_estimation.py</div><div id='class'> Class Name: DeepMaskEstimation</div><div id='method'> Method Name: extract_features</div><BR><BR><div id='link'><a href='https://github.com/rusty1s/pytorch_geometric/commit/7be56405f2af0f700763249da3c368976582d792#diff-d326fb9d1b950eb547922e26b05058b90847ee3ca26a5ab52bb76be089376d52L55' target='_blank'>Link</a></div><div id='project'> Project Name: rusty1s/pytorch_geometric</div><div id='commit'> Commit Name: 7be56405f2af0f700763249da3c368976582d792</div><div id='time'> Time: 2020-12-07</div><div id='author'> Author: matthias.fey@tu-dortmund.de</div><div id='file'> File Name: examples/tgn.py</div><div id='class'> Class Name: GraphAttentionEmbedding</div><div id='method'> Method Name: forward</div><BR><BR><div id='link'><a href='https://github.com/hunkim/PyTorchZeroToAll/commit/55b880469ced115de9949d5d25ff835dabbb2caa#diff-cf9203a373ac95a34d2c5a85a3dcbf82dd624c18ffe224417c50c1fae10206eaL65' target='_blank'>Link</a></div><div id='project'> Project Name: hunkim/PyTorchZeroToAll</div><div id='commit'> Commit Name: 55b880469ced115de9949d5d25ff835dabbb2caa</div><div id='time'> Time: 2017-11-08</div><div id='author'> Author: hunkim@gmail.com</div><div id='file'> File Name: 12_2_hello_rnn.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: </div><BR>