<html><h3>bed0a0ae26451c9897cf1ee0f7302e42eba9b42c,transformer/Models.py,,get_attn_subsequent_mask,#,31
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    &quot&quot&quot Get an attention mask to avoid using the subsequent info.&quot&quot&quot

    assert seq.dim() == 2
    attn_shape = (seq.size(0), seq.size(1), <a id="change">seq.size(1)</a>)
    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype(&quotuint8&quot)
    subsequent_mask = torch.from_numpy(subsequent_mask)
    if seq.is_cuda:
        <a id="change">subsequent_mask = subsequent_mask.cuda()</a>
    return subsequent_mask

class Encoder(nn.Module):
    &quot&quot&quot A encoder model with self attention mechanism. &quot&quot&quot</code></pre><h3>After Change</h3><pre><code class='java'>

    subsequent_mask = torch.ones((len_s, len_s), device=seq.device, dtype=torch.uint8)
    subsequent_mask = torch.triu(subsequent_mask, diagonal=1)
    subsequent_mask = <a id="change">subsequent_mask</a>.unsqueeze(<a id="change">0</a>).expand(sz_b, len_s, len_s)
    return subsequent_mask

class Encoder(nn.Module):</code></pre><img src="3998909.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/jadore801120/attention-is-all-you-need-pytorch/commit/bed0a0ae26451c9897cf1ee0f7302e42eba9b42c#diff-a6a596f1b879b5a9b6619ca2e20a4a5ec1725229f46a2e80291aa2a89ef6dc5cL34' target='_blank'>Link</a></div><div id='project'> Project Name: jadore801120/attention-is-all-you-need-pytorch</div><div id='commit'> Commit Name: bed0a0ae26451c9897cf1ee0f7302e42eba9b42c</div><div id='time'> Time: 2018-08-23</div><div id='author'> Author: yhhuang@nlg.csie.ntu.edu.tw</div><div id='file'> File Name: transformer/Models.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: get_attn_subsequent_mask</div><BR><BR><div id='link'><a href='https://github.com/jadore801120/attention-is-all-you-need-pytorch/commit/0b0eabbfd972c9e3f6323bff9d39ac5fc3ba9cc7#diff-13b50db4e17eecc27131342e1828da26b0d88a948a61d844a396e77d3377f01dL52' target='_blank'>Link</a></div><div id='project'> Project Name: jadore801120/attention-is-all-you-need-pytorch</div><div id='commit'> Commit Name: 0b0eabbfd972c9e3f6323bff9d39ac5fc3ba9cc7</div><div id='time'> Time: 2018-08-23</div><div id='author'> Author: yhhuang@nlg.csie.ntu.edu.tw</div><div id='file'> File Name: transformer/Translator.py</div><div id='class'> Class Name: Translator</div><div id='method'> Method Name: translate_batch</div><BR><BR><div id='link'><a href='https://github.com/mariogeiger/se3cnn/commit/9c309a959052ec40cf92cf4baa3894f5118cf8c4#diff-96c9865e97651dada84c1a0027cbe9124208d3c0a48420dc6911b85549a6ae6cL46' target='_blank'>Link</a></div><div id='project'> Project Name: mariogeiger/se3cnn</div><div id='commit'> Commit Name: 9c309a959052ec40cf92cf4baa3894f5118cf8c4</div><div id='time'> Time: 2019-07-08</div><div id='author'> Author: geiger.mario@gmail.com</div><div id='file'> File Name: se3cnn/blocks/point_gated_block.py</div><div id='class'> Class Name: PointGatedBlock</div><div id='method'> Method Name: forward</div><BR>