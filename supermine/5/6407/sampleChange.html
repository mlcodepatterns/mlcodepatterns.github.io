<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
  train_op = optimizer.minimize(-elbo)

  &#47&#47 Merge all the summaries
  summary_op = <a id="change">tf.merge_all_summaries()</a>

  init_op = tf.initialize_all_variables()

  &#47&#47 Run training</code></pre><h3>After Change</h3><pre><code class='java'>
                                            hidden_size=FLAGS.hidden_size)
    prior_predictive = distributions.Bernoulli(logits=p_x_given_z_logits)
    prior_predictive_samples = prior_predictive.sample()
    <a id="change">tf</a>.summary.image(&quotprior_predictive&quot,
                     tf.cast(prior_predictive_samples, tf.float32))

  &#47&#47 Take samples from the prior with a placeholder
  with tf.variable_scope(&quotmodel&quot, reuse=True):
    z_input = tf.placeholder(tf.float32, [None, FLAGS.latent_dim])
    p_x_given_z_logits = generative_network(z=z_input,
                                            hidden_size=FLAGS.hidden_size)
    prior_predictive_inp = distributions.Bernoulli(logits=p_x_given_z_logits)
    prior_predictive_inp_sample = prior_predictive_inp.sample()

  &#47&#47 Build the evidence lower bound (ELBO) or the negative loss
  kl = tf.reduce_sum(distributions.kl(q_z.distribution, p_z), 1)
  expected_log_likelihood = tf.reduce_sum(p_x_given_z.log_pmf(x),
                                          [1, 2, 3])

  elbo = tf.reduce_sum(expected_log_likelihood - kl, 0)

  optimizer = tf.train.RMSPropOptimizer(learning_rate=0.001)

  train_op = optimizer.minimize(-elbo)

  &#47&#47 Merge all the summaries
  summary_op = <a id="change">tf.summary.merge_all()</a>

  init_op = tf.global_variables_initializer()

  &#47&#47 Run training</code></pre>