<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
class BeeCoder:
    def __init__(self, params, model=None, runtime=False):
        self.params = params
        self.HIDDEN_SIZE = <a id="change">[448, 448]</a>

        self.FFT_SIZE = 513
        self.UPSAMPLE_COUNT = int(12.5 * params.target_sample_rate / 1000)

        self.sparse = False
        if model is None:
            self.model = dy.Model()
        else:
            self.model = model
        input_size = self.UPSAMPLE_COUNT + self.params.mgc_order
        hidden_w = []
        hidden_b = []
        for layer_size in self.HIDDEN_SIZE:
            hidden_w.append(self.model.add_parameters((layer_size, input_size)))
            hidden_b.append(self.model.add_parameters((layer_size)))
            input_size = layer_size

        &#47&#47 self.networks.append([hidden_w, hidden_b])

        self.mlp = [hidden_w, hidden_b]

        <a id="change">self.output_w</a> = self.model.add_parameters((2, input_size))
        self.output_b = self.model.add_parameters((2))

        self.trainer = dy.AdamTrainer(self.model, alpha=params.learning_rate)</code></pre><h3>After Change</h3><pre><code class='java'>
class BeeCoder:
    def __init__(self, params, model=None, runtime=False):
        self.params = params
        self.HIDDEN_SIZE = <a id="change">[1024, 1024]</a>

        self.FFT_SIZE = 513
        self.UPSAMPLE_COUNT = int(12.5 * params.target_sample_rate / 1000)

        self.sparse = False
        if model is None:
            self.model = dy.Model()
        else:
            self.model = model
        input_size = self.UPSAMPLE_COUNT + self.params.mgc_order

        self.upsample_w = []
        self.upsample_b = []
        for ii in range(self.UPSAMPLE_COUNT):
            self.upsample_w.append(self.model.add_parameters((self.params.mgc_order, self.params.mgc_order)))
            self.upsample_b.append(self.model.add_parameters((self.params.mgc_order)))

        hidden_w = []
        hidden_b = []
        for layer_size in self.HIDDEN_SIZE:
            hidden_w.append(self.model.add_parameters((layer_size, input_size)))
            hidden_b.append(self.model.add_parameters((layer_size)))
            input_size = layer_size

        &#47&#47 self.networks.append([hidden_w, hidden_b])

        self.mlp = [hidden_w, hidden_b]

        <a id="change">self.mean_w</a> = self.model.add_parameters((1, input_size))
        <a id="change">self.mean_b = self.model.add_parameters((1))</a>
        <a id="change">self.stdev_w = self.model.add_parameters((1, input_size))</a>
        self.stdev_b = self.model.add_parameters((1))

        self.trainer = dy.AdamTrainer(self.model, alpha=params.learning_rate)
        self.dio = DatasetIO()</code></pre>