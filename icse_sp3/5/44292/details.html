<html><h3>780dcd9fd372afa8524a6515eec6a4c90b1494c9,Reinforcement_learning_TUT/8_Actor_Critic_Advantage/AC_CartPole.py,Actor,__init__,#Actor#Any#Any#Any#,22
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            )

        with tf.name_scope(&quotloss&quot):
            <a id="change">neg_log_prob = -tf.log(self.acts_prob[0, self.act_index])</a>   &#47&#47 loss without advantage
            self.loss = tf.reduce_mean(neg_log_prob * self.advantage)  &#47&#47 advantage (TD_error) guided loss

        with tf.name_scope(&quottrain&quot):</code></pre><h3>After Change</h3><pre><code class='java'>
        )

        with tf.variable_scope(&quotsquared_TD_error&quot):
            <a id="change">self.td_error = tf.reduce_mean(self.r + GAMMA * self.v_next - self.v)</a>
            self.loss = tf.square(self.td_error)    &#47&#47 TD_error = (r+gamma*V_next) - V_eval
        with tf.variable_scope(&quottrain&quot):
            self.train_op = tf.train.AdamOptimizer(lr).minimize(self.loss)
</code></pre><img src="207438925.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/MorvanZhou/tutorials/commit/780dcd9fd372afa8524a6515eec6a4c90b1494c9#diff-1c91ba16911d0498f1259a5655c2ecbf955025d4db42b2913d9a7d24d318d2f2L22' target='_blank'>Link</a></div><div id='project'> Project Name: MorvanZhou/tutorials</div><div id='commit'> Commit Name: 780dcd9fd372afa8524a6515eec6a4c90b1494c9</div><div id='time'> Time: 2017-03-09</div><div id='author'> Author: morvanzhou@gmail.com</div><div id='file'> File Name: Reinforcement_learning_TUT/8_Actor_Critic_Advantage/AC_CartPole.py</div><div id='class'> Class Name: Actor</div><div id='method'> Method Name: __init__</div><BR><BR><div id='link'><a href='https://github.com/reinforceio/tensorforce/commit/67f74e592427d15578eae688f677952d8bd98d3a#diff-2362038a7a1f95f204229e88d7cbcc7dec58a2b8e8bb4b9982f8ffe9fc92db65L80' target='_blank'>Link</a></div><div id='project'> Project Name: reinforceio/tensorforce</div><div id='commit'> Commit Name: 67f74e592427d15578eae688f677952d8bd98d3a</div><div id='time'> Time: 2020-04-25</div><div id='author'> Author: alexkuhnle@t-online.de</div><div id='file'> File Name: tensorforce/core/distributions/categorical.py</div><div id='class'> Class Name: Categorical</div><div id='method'> Method Name: tf_parametrize</div><BR><BR><div id='link'><a href='https://github.com/reinforceio/tensorforce/commit/98fe0142e39af4a9a2450ca3f3e48a53152f5091#diff-6a2a5d9c480c359b29714f74293f93786ac07abc57339989a8889c6fc4e87d58L152' target='_blank'>Link</a></div><div id='project'> Project Name: reinforceio/tensorforce</div><div id='commit'> Commit Name: 98fe0142e39af4a9a2450ca3f3e48a53152f5091</div><div id='time'> Time: 2016-12-29</div><div id='author'> Author: k@ifricke.com</div><div id='file'> File Name: tensorforce/updater/deep_q_network.py</div><div id='class'> Class Name: DeepQNetwork</div><div id='method'> Method Name: create_training_operations</div><BR>