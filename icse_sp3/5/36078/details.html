<html><h3>71ec57f993d28f83bea04953cc51365942cb4894,tf_agents/agents/behavioral_cloning/behavioral_cloning_agent_test.py,BehavioralCloningAgentTest,testTrainWithNN,#BehavioralCloningAgentTest#Any#,182
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    &#47&#47 Disable clipping to make sure we can see the difference in behavior
    agent.policy._clip = False
    &#47&#47 Remove policy_info, as BehavioralCloningAgent expects none.
    <a id="change">traj = traj.replace(policy_info=())</a>
    &#47&#47 TODO(b/123883319)
    if tf.executing_eagerly():
      train_and_loss = lambda: agent.train(traj)
    else:
      train_and_loss = agent.train(traj)
    replay = trajectory_replay.TrajectoryReplay(agent.policy)
    self.evaluate(tf.compat.v1.global_variables_initializer())
    initial_actions = self.evaluate(replay.run(traj)[0])
    for _ in range(TRAIN_ITERATIONS):
      self.evaluate(train_and_loss)
      <a id="change">post_training_actions = self.evaluate(replay.run(traj)[0])</a>
    post_training_actions = self.evaluate(replay.run(traj)[0])
    &#47&#47 We don&quott necessarily converge to the same actions as in trajectory after
    &#47&#47 10 steps of an untuned optimizer, but the policy does change.
    self.assertFalse(np.all(initial_actions == post_training_actions))</code></pre><h3>After Change</h3><pre><code class='java'>

    &#47&#47 We don&quott necessarily converge to the same actions as in trajectory after
    &#47&#47 10 steps of an untuned optimizer, but the loss should go down.
    <a id="change">self.assertGreater(initial_loss, loss)</a>

  def testTrainWithSingleOuterDimension(self):
    &#47&#47 Hard code a trajectory shaped (time=6, batch=1, ...).
    traj, time_step_spec, action_spec = create_arbitrary_trajectory()</code></pre><img src="174848905.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/tensorflow/agents/commit/71ec57f993d28f83bea04953cc51365942cb4894#diff-c536077ede234a9903f446edc8c8ab76ad7cba80c822fb15532023f4f0269b6eL182' target='_blank'>Link</a></div><div id='project'> Project Name: tensorflow/agents</div><div id='commit'> Commit Name: 71ec57f993d28f83bea04953cc51365942cb4894</div><div id='time'> Time: 2020-02-07</div><div id='author'> Author: summeryue@google.com</div><div id='file'> File Name: tf_agents/agents/behavioral_cloning/behavioral_cloning_agent_test.py</div><div id='class'> Class Name: BehavioralCloningAgentTest</div><div id='method'> Method Name: testTrainWithNN</div><BR><BR><div id='link'><a href='https://github.com/tensorflow/agents/commit/b5ae1c6bde39f5130c975992198f1f8ee5200f9a#diff-90853e5a324b50e4bb209e9a6f285e940930a2529aedc6b5c23ec9de0c4b6d5aL102' target='_blank'>Link</a></div><div id='project'> Project Name: tensorflow/agents</div><div id='commit'> Commit Name: b5ae1c6bde39f5130c975992198f1f8ee5200f9a</div><div id='time'> Time: 2020-06-22</div><div id='author'> Author: ebrevdo@google.com</div><div id='file'> File Name: tf_agents/policies/q_policy_test.py</div><div id='class'> Class Name: QPolicyTest</div><div id='method'> Method Name: testActionWithinBounds</div><BR><BR><div id='link'><a href='https://github.com/tensorflow/agents/commit/9a3e9d21273da7ae40da9f70cb6df1b077b08105#diff-a3c65ba11b28935bfaf6499226b99553162ef0501a6fba45fc961483cd708680L117' target='_blank'>Link</a></div><div id='project'> Project Name: tensorflow/agents</div><div id='commit'> Commit Name: 9a3e9d21273da7ae40da9f70cb6df1b077b08105</div><div id='time'> Time: 2019-12-05</div><div id='author'> Author: kbanoop@google.com</div><div id='file'> File Name: tf_agents/networks/actor_distribution_network_test.py</div><div id='class'> Class Name: ActorDistributionNetworkTest</div><div id='method'> Method Name: testDropoutFCLayersWithConv</div><BR>