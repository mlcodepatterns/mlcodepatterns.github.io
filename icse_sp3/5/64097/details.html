<html><h3>1c75176947730de8322acf6ad996096625e92e3a,tensorflow_lattice/python/rtl_layer.py,RTL,call,#RTL#Any#,217
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 Concat into (-1, lattice_rank) for a single lattice
        lattice_inputs.append(
            tf.concat([input_tensors[i] for i in inputs_for_unit], axis=1))
      <a id="change">if len(lattice_inputs) &gt; 1:
        &#47&#47 Stack into (-1, units, lattice_rank) for multi-unit lattice layer
        lattice_inputs = tf.stack(lattice_inputs, axis=1)
      else:
        lattice_inputs = lattice_inputs[0]
     </a> output_monotonicity = max(monotonicities)
      &#47&#47 Call each lattice layer and store based on output monotonicy.
      outputs_for_monotonicity[output_monotonicity].append(
          self._lattice_layers[monotonicities](lattice_inputs))</code></pre><h3>After Change</h3><pre><code class='java'>
      else:
        input_tensors.append(items)
    if len(input_tensors) == 1:
      <a id="change">flattened_input = input_tensors[0]</a>
    else:
      flattened_input = tf.concat(input_tensors, axis=1)

    &#47&#47 outputs_for_monotonicity[0] are non-monotonic outputs
    &#47&#47 outputs_for_monotonicity[1] are monotonic outputs
    outputs_for_monotonicity = [[], []]
    for monotonicities, inputs_for_units in self._rtl_structure:
      if len(inputs_for_units) == 1:
        inputs_for_units = inputs_for_units[0]
      <a id="change">lattice_inputs = tf.gather(flattened_input, inputs_for_units, axis=1)</a>
      output_monotonicity = max(monotonicities)
      &#47&#47 Call each lattice layer and store based on output monotonicy.
      outputs_for_monotonicity[output_monotonicity].append(
          self._lattice_layers[str(monotonicities)](lattice_inputs))</code></pre><img src="297587608.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/tensorflow/lattice/commit/1c75176947730de8322acf6ad996096625e92e3a#diff-9a3b998d3248524fa6a29ff883da259bac34265ff0749c17d3c708c952c34b8eL220' target='_blank'>Link</a></div><div id='project'> Project Name: tensorflow/lattice</div><div id='commit'> Commit Name: 1c75176947730de8322acf6ad996096625e92e3a</div><div id='time'> Time: 2020-06-15</div><div id='author'> Author: no-reply@google.com</div><div id='file'> File Name: tensorflow_lattice/python/rtl_layer.py</div><div id='class'> Class Name: RTL</div><div id='method'> Method Name: call</div><BR><BR><div id='link'><a href='https://github.com/OpenNMT/OpenNMT-py/commit/0e7bfac76b97e7630102687f7e6309e00e190091#diff-004ff622c411caa26172d7c3ca873f7011649e0573e40798b4ce022426fe6444L676' target='_blank'>Link</a></div><div id='project'> Project Name: OpenNMT/OpenNMT-py</div><div id='commit'> Commit Name: 0e7bfac76b97e7630102687f7e6309e00e190091</div><div id='time'> Time: 2018-11-13</div><div id='author'> Author: benzurdopeters@gmail.com</div><div id='file'> File Name: onmt/translate/translator.py</div><div id='class'> Class Name: Translator</div><div id='method'> Method Name: _score_target</div><BR><BR><div id='link'><a href='https://github.com/ixaxaar/pytorch-dnc/commit/2026a8939d9ccc3e26ac776db5b4788846fd166c#diff-1e2bc3913f11c22504d865b90327ccb4c0c92ea35c1103c36fd9b1f31eb26d1bL181' target='_blank'>Link</a></div><div id='project'> Project Name: ixaxaar/pytorch-dnc</div><div id='commit'> Commit Name: 2026a8939d9ccc3e26ac776db5b4788846fd166c</div><div id='time'> Time: 2017-12-03</div><div id='author'> Author: root@ixaxaar.in</div><div id='file'> File Name: dnc/sparse_memory.py</div><div id='class'> Class Name: SparseMemory</div><div id='method'> Method Name: read_from_sparse_memory</div><BR>