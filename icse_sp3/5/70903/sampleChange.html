<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    your_images_path = config.DATA.your_images_path
    your_annos_path = config.DATA.your_annos_path
    your_data = PoseInfo(your_images_path, your_annos_path, False)
    <a id="change">your_imgs_file_list = your_data.get_image_list()</a>
    your_objs_info_list = your_data.get_joint_list()
    your_mask_list = your_data.get_mask()
    if len(your_imgs_file_list) != len(your_objs_info_list):
        raise Exception("number of customized images and annotations do not match")
    else:
        print("number of customized images {}".format(len(your_imgs_file_list)))

    &#47&#47 choice dataset for training
    &#47&#47 1. only coco training set
    &#47&#47 imgs_file_list = train_imgs_file_list
    &#47&#47 train_targets = list(zip(train_objs_info_list, train_mask_list))
    &#47&#47 2. your customized data from "data/your_data" and coco training set
    imgs_file_list = train_imgs_file_list + your_imgs_file_list
    train_targets = list(zip(train_objs_info_list + your_objs_info_list, train_mask_list + your_mask_list))

    &#47&#47 define data augmentation
    def generator():
        TF Dataset generartor.
        assert len(imgs_file_list) == len(train_targets)
        for _input, _target in zip(imgs_file_list, train_targets):
            yield _input.encode(&quotutf-8&quot), cPickle.dumps(_target)

    dataset = tf.data.Dataset().from_generator(generator, output_types=(tf.string, tf.string))
    dataset = dataset.map(_map_fn, num_parallel_calls=8)
    dataset = dataset.shuffle(buffer_size=2046)
    dataset = dataset.repeat(n_epoch)
    dataset = dataset.batch(batch_size)
    dataset = dataset.prefetch(buffer_size=20)
    iterator = dataset.make_one_shot_iterator()
    one_element = iterator.get_next()

    if config.TRAIN.train_mode == &quotplaceholder&quot:
        &#47&#47&#47&#47 Train with placeholder can help your to check the data easily.
        &#47&#47&#47&#47 define model architecture
        x = tf.placeholder(tf.float32, [None, hin, win, 3], "image")
        confs = tf.placeholder(tf.float32, [None, hout, wout, n_pos], "confidence_maps")
        pafs = tf.placeholder(tf.float32, [None, hout, wout, n_pos * 2], "pafs")
        &#47&#47 if the people does not have keypoints annotations, ignore the area
        img_mask1 = tf.placeholder(tf.float32, [None, hout, wout, n_pos], &quotimg_mask1&quot)
        img_mask2 = tf.placeholder(tf.float32, [None, hout, wout, n_pos * 2], &quotimg_mask2&quot)
        num_images = <a id="change">np.shape(imgs_file_list)[0]</a>

        cnn, b1_list, b2_list, net = model(x, n_pos, img_mask1, img_mask2, True, False)

        &#47&#47&#47&#47 define loss</code></pre><h3>After Change</h3><pre><code class='java'>
    &#47&#47&#47&#47 2. if you have a folder with many folders: (which is common in industry)
    folder_list = tl.files.load_folder_list(path=&quotyour_data&quot)
    your_imgs_file_list, your_objs_info_list, your_mask_list = [], [], []
    <a id="change">for folder in folder_list:
        _imgs_file_list, _objs_info_list, _mask_list, _targets = \
            get_pose_data_list(os.path.join(folder, &quotimages&quot), os.path.join(folder, &quotcoco.json&quot))
        print(len(_imgs_file_list))
        your_imgs_file_list.extend(_imgs_file_list)
        your_objs_info_list.extend(your_objs_info_list)
        your_mask_list.extend(your_mask_list)
   </a> print("number of customized images found:", len(your_imgs_file_list))
    exit()
    &#47&#47&#47&#47 choice dataset for training
    &#47&#47&#47&#47 1. only coco training set</code></pre>