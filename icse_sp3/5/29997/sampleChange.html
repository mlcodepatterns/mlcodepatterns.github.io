<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

    def forward(self, chars, chars_mask, word_orig_idx, sentlens, wordlens):
        embs = self.dropout(self.char_emb(chars))
        char_reps = self.charlstm(embs, wordlens, hx=(self.charlstm_h_init.expand(self.args[&quotchar_num_layers&quot], embs.size(0), self.args[&quotchar_hidden_dim&quot]).contiguous(), self.charlstm_c_init.expand(self.args[&quotchar_num_layers&quot], <a id="change">embs.size(0)</a>, self.args[&quotchar_hidden_dim&quot]).contiguous()))[0]

        &#47&#47 attention
        weights = torch.sigmoid(self.char_attn(self.dropout(char_reps))).masked_fill(chars_mask.unsqueeze(2), 0)
        <a id="change">weights = weights.transpose(1, 2)</a>

        res = weights.bmm(char_reps).squeeze(1)
        res = tensor_unsort(res, word_orig_idx)
</code></pre><h3>After Change</h3><pre><code class='java'>
        char_reps = self.charlstm(embs, wordlens, hx=(self.charlstm_h_init.expand(self.args[&quotchar_num_layers&quot], batch_size, self.args[&quotchar_hidden_dim&quot]).contiguous(), self.charlstm_c_init.expand(self.args[&quotchar_num_layers&quot], batch_size, self.args[&quotchar_hidden_dim&quot]).contiguous()))[0]

        &#47&#47 attention
        weights = <a id="change">torch.sigmoid(self.char_attn(self.dropout(char_reps.data)))</a>

        <a id="change">char_reps = PackedSequence(char_reps.data * weights, char_reps.batch_sizes)</a>
        char_reps, _ = pad_packed_sequence(char_reps, batch_first=True)
        res = char_reps.sum(1)
        res = tensor_unsort(res, word_orig_idx)
</code></pre>