<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            else:
                variables_to_train = []
                for scope_name in learnable_scopes:
                    <a id="change">for var in tf.global_variables():
                        if scope_name in var.name:
                            variables_to_train.append(var)

           </a> if optimizer is None:
                optimizer = tf.train.AdamOptimizer

            &#47&#47 For batch norm it is necessary to update running averages</code></pre><h3>After Change</h3><pre><code class='java'>
            opt_scope = tf.variable_scope(optimizer_scope_name)
        with opt_scope:
            if learnable_scopes is None:
                variables_to_train = <a id="change">tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)</a>
            else:
                variables_to_train = []
                for scope_name in learnable_scopes:
                    variables_to_train.extend(<a id="change">tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope_name)</a>)

            if optimizer is None:
                optimizer = tf.train.AdamOptimizer</code></pre>