<html><h3>6de331b6e4eff01ef9e86f991d7c1c820f2fe902,allennlp/data/tokenizers/word_tokenizer.py,WordTokenizer,tokenize,#WordTokenizer#Any#,68
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        
        words = self._word_splitter.split_words(text)
        filtered_words = self._word_filter.filter_words(words)
        <a id="change">stemmed_words = [self._word_stemmer.stem_word(word) for word in filtered_words]</a>
        for start_token in self._start_tokens:
            <a id="change">stemmed_words.insert(0, Token(start_token, 0))</a>
        for end_token in self._end_tokens:
            stemmed_words.append(Token(end_token, -1))
        <a id="change">return stemmed_words</a>

    @classmethod
    def from_params(cls, params: Params) -&gt; &quotWordTokenizer&quot:
        word_splitter = WordSplitter.from_params(params.pop(&quotword_splitter&quot, {}))</code></pre><h3>After Change</h3><pre><code class='java'>
        stemming or stopword removal, depending on the parameters given to the constructor.
        
        words = self._word_splitter.split_words(text)
        <a id="change">return self._filter_and_stem(words)</a>

    @overrides
    def batch_tokenize(self, texts: List[str]) -&gt; List[List[Token]]:
        batched_words = self._word_splitter.batch_split_words(texts)</code></pre><img src="205743543.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/allenai/allennlp/commit/6de331b6e4eff01ef9e86f991d7c1c820f2fe902#diff-582a8f6ca82b54c47fa239da71d98d7ed7f57dc8064e0d83a542631b2209ed7aL68' target='_blank'>Link</a></div><div id='project'> Project Name: allenai/allennlp</div><div id='commit'> Commit Name: 6de331b6e4eff01ef9e86f991d7c1c820f2fe902</div><div id='time'> Time: 2018-01-22</div><div id='author'> Author: mattg@allenai.org</div><div id='file'> File Name: allennlp/data/tokenizers/word_tokenizer.py</div><div id='class'> Class Name: WordTokenizer</div><div id='method'> Method Name: tokenize</div><BR><BR><div id='link'><a href='https://github.com/PyThaiNLP/pythainlp/commit/a9ebcc488db9c635c5524de2ba56cee569e91552#diff-20bf0287cab5e8f64daa5877f721badf4f467a15691921264ae16a4037f7dae4L166' target='_blank'>Link</a></div><div id='project'> Project Name: PyThaiNLP/pythainlp</div><div id='commit'> Commit Name: a9ebcc488db9c635c5524de2ba56cee569e91552</div><div id='time'> Time: 2019-04-17</div><div id='author'> Author: arthit@gmail.com</div><div id='file'> File Name: pythainlp/transliterate/royin.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: romanize</div><BR><BR><div id='link'><a href='https://github.com/tyarkoni/pliers/commit/44574472fb477765de24e4f257246df5e838d591#diff-07f87f16223e09e99b7c89048ff7173c0804ba3bc1d829d81c19cd58c057e5d8L123' target='_blank'>Link</a></div><div id='project'> Project Name: tyarkoni/pliers</div><div id='commit'> Commit Name: 44574472fb477765de24e4f257246df5e838d591</div><div id='time'> Time: 2018-01-22</div><div id='author'> Author: tyarkoni@gmail.com</div><div id='file'> File Name: pliers/extractors/image.py</div><div id='class'> Class Name: FaceRecognitionFeatureExtractor</div><div id='method'> Method Name: _to_df</div><BR>