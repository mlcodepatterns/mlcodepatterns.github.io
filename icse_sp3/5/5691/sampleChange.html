<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>


def load_test_model(opt, dummy_opt):
    checkpoint = <a id="change">torch.load(opt.model,
                            map_location=lambda storage, loc: storage)</a>
    fields = onmt.io.load_fields_from_vocab(
        checkpoint[&quotvocab&quot], data_type=opt.data_type)

    model_opt = checkpoint[&quotopt&quot]
    for arg in dummy_opt:
        if arg not in model_opt:
            model_opt.__dict__[arg] = dummy_opt[arg]

    <a id="change">model = make_base_model(model_opt, fields,
                            use_gpu(opt), checkpoint)</a>
    model.eval()
    model.generator.eval()
    return fields, model, model_opt
</code></pre><h3>After Change</h3><pre><code class='java'>
    model = make_base_model(model_opt, fields,
                            use_gpu(opt), checkpoint)
    model.eval()
    model.genera<a id="change">tor.eval()
    return fields, model, model_opt


def make_base_model(model_opt, fields, gpu, checkpoint=None):
    
    Args:
        model_opt: the option loaded from checkpoint.
        fields: `Field` objects fo</a>r the model.
        gpu(bool): whether to use gpu.
        checkpoint: the model gnerated by train phase, or a resumed snapshot
                    model from a stopped training.</code></pre>