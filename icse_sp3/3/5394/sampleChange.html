<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47x_in = TimeDistributed(Dense(2*(num_0D+num_1D)),activation=&quotrelu&quot) (x_in)
        &#47&#47 x = TimeDistributed(Dense(2*(num_0D+num_1D)))
 &#47&#47               model.add(TimeDistributed(Dense(num_density_channels,bias=True),batch_input_shape=batch_input_shape))
        <a id="change">for _ in range(model_conf[&quotrnn_layers&quot]):
            x_in = rnn_model(rnn_size, return_sequences=return_sequences,&#47&#47batch_input_shape=batch_input_shape,
             stateful=stateful,kernel_regularizer=l2(regularization),recurrent_regularizer=l2(regularization),
             bias_regularizer=l2(regularization),dropout=dropout_prob,recurrent_dropout=dropout_prob) (x_in)
            x_in = Dropout(dropout_prob) (x_in)
       </a> if return_sequences:
            &#47&#47x_out = TimeDistributed(Dense(100,activation=&quottanh&quot)) (x_in)
            x_out = TimeDistributed(Dense(1,activation=output_activation)) (x_in)
        else:</code></pre><h3>After Change</h3><pre><code class='java'>
                pre_rnn_1D = MaxPooling1D(pool_size) (pre_rnn_1D)
            pre_rnn_1D = Flatten() (pre_rnn_1D)
            pre_rnn_1D = Dense(dense_size,kernel_regularizer=l2(dense_regularization),bias_regularizer=l2(dense_regularization),activity_regularizer=l2(dense_regularization)) (pre_rnn_1D)
            if use_batch_norm: <a id="change">pre_rnn_1D = BatchNormalization()(pre_rnn_1D)</a>
            pre_rnn_1D = Activation(&quotrelu&quot)(pre_rnn_1D)
            pre_rnn_1D = Dense(dense_size//4,kernel_regularizer=l2(dense_regularization),bias_regularizer=l2(dense_regularization),activity_regularizer=l2(dense_regularization)) (pre_rnn_1D)
            if use_batch_norm: pre_rnn_1D = BatchNormalization()(pre_rnn_1D)
            pre_rnn_1D = Activation(&quotrelu&quot)(pre_rnn_1D)
            pre_rnn = Concatenate() ([pre_rnn_0D,pre_rnn_1D])
        else:
            pre_rnn = pre_rnn_input        

        if model_conf[&quotrnn_layers&quot] == 0 or model_conf[&quotextra_dense_input&quot]:
            pre_rnn = Dense(dense_size,activation=&quotrelu&quot,kernel_regularizer=l2(dense_regularization),bias_regularizer=l2(dense_regularization),activity_regularizer=l2(dense_regularization)) (pre_rnn)
            pre_rnn = Dense(dense_size//2,activation=&quotrelu&quot,kernel_regularizer=l2(dense_regularization),bias_regularizer=l2(dense_regularization),activity_regularizer=l2(dense_regularization)) (pre_rnn)
            pre_rnn = Dense(dense_size//4,activation=&quotrelu&quot,kernel_regularizer=l2(dense_regularization),bias_regularizer=l2(dense_regularization),activity_regularizer=l2(dense_regularization)) (pre_rnn)
        
        pre_rnn_model = Model(inputs = pre_rnn_input,outputs=pre_rnn)
        <a id="change">pre_rnn_model.summary()</a>
        x_input = Input(batch_shape = batch_input_shape)
        x_in = TimeDistributed(pre_rnn_model) (x_input)

        if use_bidirectional:</code></pre>