<html><h3>b09284f6ba59659a9819e68244a7a785016c87c5,art/attacks/evasion/shadow_attack.py,ShadowAttack,generate,#ShadowAttack#Any#Any#,119
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            )

        x = x.astype(ART_NUMPY_DTYPE)
        x_adv = <a id="change">np.zeros_like(x, dtype=ART_NUMPY_DTYPE)</a>

        &#47&#47 Compute perturbation with implicit batching
        for i_batch in range(int(np.ceil(x.shape[0] / self.batch_size))):
</code></pre><h3>After Change</h3><pre><code class='java'>

        x_batch = x_batch + np.random.normal(scale=self.sigma, size=x_batch)

        <a id="change">y_batch = np.repeat(y, repeats=self.batch_size, axis=0)</a>

        perturbation = (
            np.random.uniform(
                low=self.estimator.clip_values[0], high=self.estimator.clip_values[1], size=x.shape
            ).astype(ART_NUMPY_DTYPE)
            - (self.estimator.clip_values[1] - self.estimator.clip_values[0]) / 2
        )

        for _ in range(self.nb_steps):

            gradients_ce = np.mean(
                self.estimator.loss_gradient(x=x_batch + perturbation, y=y_batch, sampling=False)
                * (1 - 2 * int(self.targeted)),
                axis=0,
                keepdims=True,
            )

            gradients = gradients_ce - self._get_regularisation_loss_gradients(perturbation)

            perturbation += self.learning_rate * gradients

        x_p = x_batch + perturbation

        x_adv = <a id="change">np.clip(x_p, a_min=self.estimator.clip_values[0], a_max=self.estimator.clip_values[1]).astype(
            ART_NUMPY_DTYPE
        )</a>

        return x_adv

    def _get_regularisation_loss_gradients(self, perturbation):</code></pre><img src="152414805.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/IBM/adversarial-robustness-toolbox/commit/b09284f6ba59659a9819e68244a7a785016c87c5#diff-0a6c374f6856298ddf46b9bdb1b28d21d64f17bf7660bc1a41f70a7f423b2fe9L119' target='_blank'>Link</a></div><div id='project'> Project Name: IBM/adversarial-robustness-toolbox</div><div id='commit'> Commit Name: b09284f6ba59659a9819e68244a7a785016c87c5</div><div id='time'> Time: 2020-05-24</div><div id='author'> Author: beat.buesser@ie.ibm.com</div><div id='file'> File Name: art/attacks/evasion/shadow_attack.py</div><div id='class'> Class Name: ShadowAttack</div><div id='method'> Method Name: generate</div><BR><BR><div id='link'><a href='https://github.com/dmlc/gluon-nlp/commit/1f9ad444b5dee8b2562b7bfa1cf9f576fa32a347#diff-6ba2f17caf89d5c241a4d8aefd5b7a246ab925a8ea7ba955a09ba329e49bf734L131' target='_blank'>Link</a></div><div id='project'> Project Name: dmlc/gluon-nlp</div><div id='commit'> Commit Name: 1f9ad444b5dee8b2562b7bfa1cf9f576fa32a347</div><div id='time'> Time: 2020-07-31</div><div id='author'> Author: 37728728+ZheyuYe@users.noreply.github.com</div><div id='file'> File Name: src/gluonnlp/op.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: updated_vectors_by_position</div><BR><BR><div id='link'><a href='https://github.com/NifTK/NiftyNet/commit/ad66bf0a8faf1f230891faea92c31d8a3a0baa3f#diff-c80cf3e5e643430c5cd08bb5be53934019e8c051fad8ae50eb493f714cf8b495L126' target='_blank'>Link</a></div><div id='project'> Project Name: NifTK/NiftyNet</div><div id='commit'> Commit Name: ad66bf0a8faf1f230891faea92c31d8a3a0baa3f</div><div id='time'> Time: 2017-10-04</div><div id='author'> Author: wenqi.li@ucl.ac.uk</div><div id='file'> File Name: niftynet/engine/sampler_selective.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: candidate_indices</div><BR>