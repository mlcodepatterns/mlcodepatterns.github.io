<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

  model_function = model_fn

  if <a id="change">flags_obj.multi_gpu</a>:
    <a id="change">validate_batch_size_for_multi_gpu(flags_obj.batch_size)</a>

    &#47&#47 There are two steps required if using multi-GPU: (1) wrap the model_fn,
    &#47&#47 and (2) wrap the optimizer. The first happens here, and (2) happens
    &#47&#47 in the model_fn itself when the optimizer is defined.</code></pre><h3>After Change</h3><pre><code class='java'>
  &#47&#47 Get number of GPUs as defined by the --num_gpus flags and the number of
  &#47&#47 GPUs available on the machine.
  num_gpus = flags_core.get_num_gpus(flags_obj)
  <a id="change">multi_gpu</a> = <a id="change">num_gpus &gt; 1

  if</a> <a id="change">multi_gpu</a>:
    &#47&#47 Validate that the batch size can be split into devices.
    distribution_utils.per_device_batch_size(flags_obj.batch_size, num_gpus)

    &#47&#47 There are two steps required if using multi-GPU: (1) wrap the model_fn,
    &#47&#47 and (2) wrap the optimizer. The first happens here, and (2) happens
    &#47&#47 in the model_fn itself when the optimizer is defined.
    model_function = tf.contrib.estimator.replicate_model_fn(
        model_fn, loss_reduction=tf.losses.Reduction.MEAN,
        devices=["/device:GPU:%d" % d <a id="change">for</a> d in range(num_gpus)])

  data_format = flags_obj.data_format
  if data_format is None:</code></pre>