<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

    with open(output_file, &quota&quot) as f:
        writer = csv.DictWriter(f, [&quotL&quot, &quotk&quot, &quottime&quot])
        <a id="change">for L in sorted(dataset_sizes):
            for k_ in k:
                print("L = {}; k = {}".format(L, k_))
                train_set = load_train(L)

                num_hidden = (train_set.shape[-1]
                              if num_hidden is None
                              else num_hidden)

                rbm = RBM(num_visible=train_set.shape[-1],
                          num_hidden=num_hidden)

                time_elapsed = -time.perf_counter()
                rbm.train(train_set, epochs,
                          batch_size, k=k_,
                          lr=learning_rate,
                          momentum=momentum,
                          initial_gaussian_noise=0,
                          log_every=0,
                          progbar=False)
                time_elapsed += time.perf_counter()

                writer.writerow({&quotL&quot: L,
                                 &quotk&quot: k_,
                                 &quottime&quot: time_elapsed})


</a>@cli.command("train")
@click.option(&quot--train-path&quot, default=&quot../data/Ising2d_L4.pkl.gz&quot,
              show_default=True, type=click.Path(exists=True),
              help="path to the training data")</code></pre><h3>After Change</h3><pre><code class='java'>
                     for f in listdir(&quot/home/data/critical-2d-ising/&quot)
                     if isdir(join(&quot/home/data/critical-2d-ising/&quot, f))]

    <a id="change">runs = list(product(dataset_sizes, k))</a>

    <a id="change">shuffle(runs)</a>

    with open(output_file, &quota&quot) as f:
        writer = csv.DictWriter(f, [&quotL&quot, &quotk&quot, &quottime&quot])
        <a id="change">for L, k_ in runs:
            print("L = {}; k = {}".format(L, k_))
            train_set = load_train(L)

            num_hidden = (train_set.shape[-1]
                          if num_hidden is None
                          else num_hidden)

            rbm = RBM(num_visible=train_set.shape[-1],
                      num_hidden=num_hidden)

            time_elapsed = -time.perf_counter()
            rbm.train(train_set, epochs,
                      batch_size, k=k_,
                      lr=learning_rate,
                      momentum=momentum,
                      initial_gaussian_noise=0,
                      log_every=0,
                      progbar=False)
            time_elapsed += time.perf_counter()
            torch.cuda.empty_cache()

            writer.writerow({&quotL&quot: L,
                             &quotk&quot: k_,
                             &quottime&quot: time_elapsed})


</a>@cli.command("train")
@click.option(&quot--train-path&quot, default=&quot../data/Ising2d_L4.pkl.gz&quot,
              show_default=True, type=click.Path(exists=True),
              help="path to the training data")</code></pre>