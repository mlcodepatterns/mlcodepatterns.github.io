<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        output, _ = self.lstm(encoded_X, hidden_state)
        output, _ = pad_packed_sequence(output, batch_first=True)

        <a id="change">outs = []</a>
        <a id="change">for i in range(X.size(0)):
            outs.append(output[i, seq_lengths[i] - 1,:])
       </a> output = torch.stack(outs, dim=0)
        return self.output_layer(self.dropout_layer(output))
    
    def initalize_hidden_state(self, batch_size):</code></pre><h3>After Change</h3><pre><code class='java'>

        seq_lengths, perm_idx = seq_lengths.sort(0, descending=True)
        X = X[perm_idx, :]
        <a id="change">inv_perm_idx = torch.tensor([i for i, _ in sorted(enumerate(perm_idx), key=lambda idx: idx[1])], dtype=torch.long)</a>

        encoded_X = self.embedding(X)
        encoded_X = pack_padded_sequence(encoded_X, seq_lengths, batch_first=True)
        _, (ht, _) = self.lstm(encoded_X, hidden_state)</code></pre>