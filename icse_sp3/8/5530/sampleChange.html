<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        assert(batch_size == 1), "Currently only batch_size=1 is allowed."

        boxes_batch = np.zeros(<a id="change">(batch_size, 0, 5)</a>, dtype=keras.backend.floatx())

        for batch_index, image_index in enumerate(selection):
            coco_image = self.coco.loadImgs(self.image_ids[image_index])[0]
            path  = os.path.join(self.data_dir, self.set_name, coco_image[&quotfile_name&quot])
            image = cv2.imread(path, cv2.IMREAD_COLOR)
            image, image_scale = resize_image(image, min_side=self.image_min_side, max_side=self.image_max_side)

            &#47&#47 copy image to image batch (currently only batch_size==1 is allowed)
            image_batch = np.expand_dims(image, axis=0).astype(keras.backend.floatx())

            &#47&#47 set ground truth boxes
            annotations_ids = self.coco.getAnnIds(imgIds=coco_image[&quotid&quot], iscrowd=False)

            &#47&#47 some images appear to miss annotations (like image with id 257034)
            if len(annotations_ids) == 0:
                return self.next()

            &#47&#47 parse annotations
            annotations = self.coco.loadAnns(annotations_ids)
            for idx, a in enumerate(annotations):
                box = np.zeros((1, 1, 5), dtype=keras.backend.floatx())
                box[0, 0, :4] = a[&quotbbox&quot]
                box[0, 0, 4]  = a[&quotcategory_id&quot]
                boxes_batch = np.append(boxes_batch, box, axis=1)

            &#47&#47 transform from [x, y, w, h] to [x1, y1, x2, y2]
            boxes_batch[batch_index, :, 2] = boxes_batch[batch_index, :, 0] + boxes_batch[batch_index, :, 2]
            boxes_batch[batch_index, :, 3] = boxes_batch[batch_index, :, 1] + boxes_batch[batch_index, :, 3]

            &#47&#47 scale the ground truth boxes to the selected image scale
            boxes_batch[batch_index, :, :4] *= image_scale

        &#47&#47 randomly transform images and boxes simultaneously
        image_batch, boxes_batch = random_transform_batch(image_batch, boxes_batch, self.image_data_generator)

        &#47&#47 convert the image to zero-mean
        image_batch = keras.applications.imagenet_utils.preprocess_input(image_batch)
        image_batch = self.image_data_generator.standardize(image_batch)

        <a id="change">return [image_batch, boxes_batch], None</a>
</code></pre><h3>After Change</h3><pre><code class='java'>

            &#47&#47 generate the label and regression targets
            labels, reg_targets = anchor_targets(image, boxes_batch[0])
            target = np.append(reg_targets, <a id="change">np.expand_dims(labels, axis=1)</a>, axis=1)

            &#47&#47 convert target to batch (currently only batch_size = 1 is allowed)
            <a id="change">target_batch = np.expand_dims(target, axis=0)</a>

        &#47&#47 convert the image to zero-mean
        image_batch = keras.applications.imagenet_utils.preprocess_input(image_batch)
        image_batch = self.image_data_generator.standardize(image_batch)

        <a id="change">return image_batch, target_batch</a>
</code></pre>