<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    embed_size=d_model
    Embedding = tf.get_variable("Embedding_", shape=[vocab_size, embed_size],initializer=initializer)
    input_x = tf.placeholder(tf.int32, [batch_size,sequence_length], name="input_x")
    <a id="change">input_x_=tf.reshape(input_x,(batch_size*sequence_length,))</a> &#47&#47[batch_size*sequence_length]
    embedded_words = tf.nn.embedding_lookup(Embedding, input_x_) &#47&#47[batch_size*sequence_length,embed_size]
    with tf.variable_scope("query_at_each_sentence"+str(layer_number)):
        Q = embedded_words  &#47&#47 [batch_size*sequence_length,embed_size]</code></pre><h3>After Change</h3><pre><code class='java'>
&#47&#47vectorized implementation of multi head attention for sentences with batch
def multi_head_attention_for_sentence_vectorized(layer_number):
    print("started...")
    <a id="change">start = time.time()</a>
    &#47&#47 1.set parameter
    d_model = 512
    d_k = 64
    d_v = 64
    sequence_length = 1000
    h = 8
    batch_size=128
    initializer = tf.random_normal_initializer(stddev=0.1)
    &#47&#47 2.set Q,K,V
    vocab_size=1000
    embed_size=d_model
    type=&quotdecoder&quot
    Embedding = tf.get_variable("Embedding_", shape=[vocab_size, embed_size],initializer=initializer)
    input_x = tf.placeholder(tf.int32, [batch_size,sequence_length], name="input_x")
    embedded_words = tf.nn.embedding_lookup(Embedding, input_x) &#47&#47[batch_size,sequence_length,embed_size]
    mask=get_mask(batch_size,sequence_length) &#47&#47tf.ones((batch_size,sequence_length))*-1e8  &#47&#47[batch,sequence_length]
    with tf.variable_scope("query_at_each_sentence"+str(layer_number)):
        Q = embedded_words  &#47&#47 [batch_size*sequence_length,embed_size]
        K_s=embedded_words &#47&#47[batch_size*sequence_length,embed_size]
        V_s=tf.get_variable("V_s_original_", shape=embedded_words.get_shape().as_list(),initializer=initializer) &#47&#47[batch_size,sequence_length,embed_size]
        &#47&#47 3.call method to get result
        multi_head_attention_class = MultiHeadAttention(Q, K_s, V_s, d_model, d_k, d_v, sequence_length, h,type=&quotdecoder&quot,mask=mask)
        encoder_output=multi_head_attention_class.multi_head_attention_fn() &#47&#47shape:[sequence_length,d_model]
        encoder_output=tf.reshape(encoder_output,shape=(batch_size,sequence_length,d_model))
    <a id="change">end = time.time()</a>
    print("input_x:",input_x)
    print("encoder_output:",encoder_output,";time_spent:",<a id="change">(end-start)</a>)

def get_mask(batch_size,sequence_length):
    lower_triangle=tf.matrix_band_part(tf.ones([sequence_length,sequence_length]),-1,0)</code></pre>