<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    print()
    print("Start training...")
    t = time()
    <a id="change">train_pp</a> = (<a id="change">mnist</a>.train.p
                .init_variable(&quotloss_history&quot, init_on_each_run=list)
                .init_model(&quotdynamic&quot, MyModel, &quotconv&quot,
                            config={&quotloss&quot: &quotce&quot,
                                    &quotoptimizer&quot: &quotAdam&quot,
                                    &quotimages_shape&quot: lambda batch: batch.images.shape[1:]})
                .train_model(&quotconv&quot, fetches=&quotloss&quot, feed_dict={&quotinput_images&quot: &quotimages&quot,
                                                                &quotinput_labels&quot: &quotlabels&quot},
                             append_to=&quotloss_history&quot)
                .run(BATCH_SIZE, shuffle=True, n_epochs=1, drop_last=True))
    print("End training", time() - t)

    print()
    print("Start testing...")
    t = time()
    test_pp = (mnist.test.p
                .import_model(&quotconv&quot, train_pp)
                .init_variable(&quotall_predictions&quot, init_on_each_run=list)
                .predict_model(&quotconv&quot, fetches=&quotpredicted_labels&quot, feed_dict={&quotinput_images&quot: &quotimages&quot,
                                                                              &quotinput_labels&quot: &quotlabels&quot},
                               append_to=&quotall_predictions&quot)
                .run(BATCH_SIZE, shuffle=True, n_epochs=1, drop_last=False))
    print("End testing", time() - t)

    print("Predictions")
    for pred in test_pp.get_variable("all_predictions"):
        print(pred.shape)

    <a id="change">conv</a> = train_pp.get_model_by_name("conv")
</code></pre><h3>After Change</h3><pre><code class='java'>
    print()
    print("Start training...")
    t = time()
    <a id="change">train_pp</a> = (<a id="change">mnist</a>.train.p
                .init_variable(&quotloss_history&quot, init_on_each_run=list)
                .init_variable(&quotcurrent_loss&quot, init_on_each_run=0)
                .init_model(&quotdynamic&quot, MyModel, &quotconv&quot,
                            config={&quotloss&quot: &quotce&quot,
                                    &quotoptimizer&quot: {&quotname&quot:&quotAdam&quot, &quotuse_locking&quot: True},
                                    &quotimages_shape&quot: lambda batch: batch.images.shape[1:]})
                .train_model(&quotconv&quot, fetches=&quotloss&quot, feed_dict={&quotinput_images&quot: &quotimages&quot,
                                                                &quotinput_labels&quot: &quotlabels&quot},
                             save_to=&quotcurrent_loss&quot)
                .print_variable(&quotcurrent_loss&quot)
                .save_to_variable(&quotloss_history&quot, &quotcurrent_loss&quot, mode=&quota&quot)
                .run(BATCH_SIZE, shuffle=True, n_epochs=1, drop_last=True, prefetch=6))
    print("End training", time() - t)


    print()
    print("Start testing...")
    t = time()
    test_pp = (mnist.test.p
                .import_model(&quotconv&quot, train_pp)
                .init_variable(&quotall_predictions&quot, init_on_each_run=list)
                .predict_model(&quotconv&quot, fetches=&quotpredicted_labels&quot, feed_dict={&quotinput_images&quot: &quotimages&quot,
                                                                              &quotinput_labels&quot: &quotlabels&quot},
                               append_to=&quotall_predictions&quot)
                .run(BATCH_SIZE, shuffle=True, n_epochs=1, drop_last=False, prefetch=4))
    print("End testing", time() - t)

    print("Predictions")
    for pred in test_pp.get_variable("all_predictions"):
        print(pred.shape)

    <a id="change">conv</a> = train_pp.get_model_by_name("conv")
</code></pre>