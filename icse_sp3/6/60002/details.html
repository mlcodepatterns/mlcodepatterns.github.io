<html><h3>031a862a68853167c1be5aa971563f6069fd6d4d,nltk/translate/gleu_score.py,,sentence_gleu,#Any#Any#Any#Any#,16
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    &#47&#47 For each order of ngram, calculate the no. of ngram matches and
    &#47&#47 keep track of no. of ngram in references.
    ref_ngrams = Counter(everygrams(reference, min_len, max_len))
    <a id="change">hyp_ngrams = Counter(everygrams(hypothesis, min_len, max_len))</a>
    overlap_ngrams = ref_ngrams & hyp_ngrams
    tp = sum(overlap_ngrams.values()) &#47&#47 True positives.
    <a id="change">tpfp = sum(hyp_ngrams.values())</a> &#47&#47 True positives + False positives.
    tpfn = sum(ref_ngrams.values()) &#47&#47 True positives + False negatives.

    &#47&#47 While defined as the minimum of precision and recall, we can
    &#47&#47 reduce the number of division operations by one by instead finding
    &#47&#47 the maximum of the denominators for the precision and recall
    &#47&#47 formulae, since the numerators are the same:
    &#47&#47     precision = tp / tpfp
    &#47&#47     recall = tp / tpfn
    &#47&#47     min(precision, recall) == tp / max(tpfp, tpfn)

    <a id="change">return tp / max(tpfp, tpfn)</a>


def corpus_gleu(references, hypotheses, min_len=1, max_len=4):
    </code></pre><h3>After Change</h3><pre><code class='java'>
    if not references or isinstance(references[0], string_types):
        references = [references]

    <a id="change">return corpus_gleu(
        [references],
        [hypothesis],
        min_len=min_len,
        max_len=max_len
    )</a>

def corpus_gleu(list_of_references, hypotheses, min_len=1, max_len=4):
    
    Calculate a single corpus-level GLEU score (aka. system-level GLEU) for all</code></pre><img src="278014736.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/nltk/nltk/commit/031a862a68853167c1be5aa971563f6069fd6d4d#diff-5d373fbfc401352975655c36546b2c99dd9675100bcd4ea7741c4af03b2a0549L84' target='_blank'>Link</a></div><div id='project'> Project Name: nltk/nltk</div><div id='commit'> Commit Name: 031a862a68853167c1be5aa971563f6069fd6d4d</div><div id='time'> Time: 2017-04-13</div><div id='author'> Author: goodman.m.w@gmail.com</div><div id='file'> File Name: nltk/translate/gleu_score.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: sentence_gleu</div><BR><BR><div id='link'><a href='https://github.com/PacktPublishing/Deep-Reinforcement-Learning-Hands-On/commit/f287a04243fb8cbe966161c106dce14fac274a6c#diff-e53d381e82509d0ab49e2e6997e8895d91ac6d402e93560af304247e8e3954a0L22' target='_blank'>Link</a></div><div id='project'> Project Name: PacktPublishing/Deep-Reinforcement-Learning-Hands-On</div><div id='commit'> Commit Name: f287a04243fb8cbe966161c106dce14fac274a6c</div><div id='time'> Time: 2018-01-06</div><div id='author'> Author: max.lapan@gmail.com</div><div id='file'> File Name: ch12/libbots/utils.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: calc_bleu</div><BR><BR><div id='link'><a href='https://github.com/miso-belica/sumy/commit/54157d4915902da0fb79f8fd7fdfafe536343c0f#diff-043f95d7bfc007210bf4c86052b3efef32e0d7c480807c1011680cbca8fe0f35L29' target='_blank'>Link</a></div><div id='project'> Project Name: miso-belica/sumy</div><div id='commit'> Commit Name: 54157d4915902da0fb79f8fd7fdfafe536343c0f</div><div id='time'> Time: 2013-03-18</div><div id='author'> Author: miso.belica@gmail.com</div><div id='file'> File Name: sumy/algorithms/luhn.py</div><div id='class'> Class Name: LuhnMethod</div><div id='method'> Method Name: _get_significant_words</div><BR>