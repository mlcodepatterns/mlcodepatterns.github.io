<html><h3>113c1d84a806358d5c9f1242a88edb3966a304ab,ch09/04_pong_pg.py,,,#,47
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    parser.add_argument("--cuda", default=False, action="store_true", help="Enable cuda")
    args = parser.parse_args()

    <a id="change">envs = [make_env() for _ in range(5)]</a>
    writer = SummaryWriter(comment="-pong-pg")

    <a id="change">net = common.AtariPGN(envs[0].observation_space.shape, envs[0].action_space.n)</a>
    if args.cuda:
        net.cuda()
    print(net)

    <a id="change">agent</a> = ptan.agent.PolicyAgent(net, apply_softmax=True, cuda=args.cuda)
    <a id="change">exp_source</a> = ptan.experience.ExperienceSourceFirstLast(<a id="change">envs</a>, agent, gamma=GAMMA, steps_count=REWARD_STEPS)

    <a id="change">optimizer</a> = optim.Adam(net.parameters(), lr=LEARNING_RATE, eps=1e-3)

    total_rewards = []
    step_rewards = MeanRingBuf(capacity=BASELINE_STEPS)</code></pre><h3>After Change</h3><pre><code class='java'>
    parser.add_argument("--cuda", default=False, action="store_true", help="Enable cuda")
    args = parser.parse_args()

    <a id="change">env = make_env()</a>
    writer = SummaryWriter(comment="-pong-pg")

    <a id="change">net = common.AtariPGN(env.observation_space.shape, env.action_space.n)</a>
    if args.cuda:
        net.cuda()
    print(net)

    <a id="change">agent</a> = ptan.agent.PolicyAgent(net, apply_softmax=True, cuda=args.cuda)
    <a id="change">exp_source</a> = ptan.experience.ExperienceSourceFirstLast(<a id="change">env</a>, agent, gamma=GAMMA, steps_count=REWARD_STEPS)

    <a id="change">optimizer</a> = optim.Adam(net.parameters(), lr=LEARNING_RATE, eps=1e-3)

    total_rewards = []
    step_rewards = MeanRingBuf(capacity=BASELINE_STEPS)</code></pre><img src="17850640.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 23</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/PacktPublishing/Deep-Reinforcement-Learning-Hands-On/commit/113c1d84a806358d5c9f1242a88edb3966a304ab#diff-3a80d8d623f5d2851a396ab43e6f6421ba170ee8f5c8141a84b4bb4985bf70f6L52' target='_blank'>Link</a></div><div id='project'> Project Name: PacktPublishing/Deep-Reinforcement-Learning-Hands-On</div><div id='commit'> Commit Name: 113c1d84a806358d5c9f1242a88edb3966a304ab</div><div id='time'> Time: 2017-12-05</div><div id='author'> Author: max.lapan@gmail.com</div><div id='file'> File Name: ch09/04_pong_pg.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: </div><BR><BR><div id='link'><a href='https://github.com/PacktPublishing/Deep-Reinforcement-Learning-Hands-On/commit/9205eee4cbfb730ea37c3e81a797698983fd6e87#diff-686a109e3df65b8f69b6fb44509f995775c189357dbbd1d091de0eb665501eedL70' target='_blank'>Link</a></div><div id='project'> Project Name: PacktPublishing/Deep-Reinforcement-Learning-Hands-On</div><div id='commit'> Commit Name: 9205eee4cbfb730ea37c3e81a797698983fd6e87</div><div id='time'> Time: 2017-12-06</div><div id='author'> Author: max.lapan@gmail.com</div><div id='file'> File Name: ch09/05_pong_a2c.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: </div><BR><BR><div id='link'><a href='https://github.com/PacktPublishing/Deep-Reinforcement-Learning-Hands-On/commit/433fcf96eda8e924652c4a67878f6636e533b649#diff-3a80d8d623f5d2851a396ab43e6f6421ba170ee8f5c8141a84b4bb4985bf70f6L52' target='_blank'>Link</a></div><div id='project'> Project Name: PacktPublishing/Deep-Reinforcement-Learning-Hands-On</div><div id='commit'> Commit Name: 433fcf96eda8e924652c4a67878f6636e533b649</div><div id='time'> Time: 2017-12-07</div><div id='author'> Author: max.lapan@gmail.com</div><div id='file'> File Name: ch09/04_pong_pg.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: </div><BR>