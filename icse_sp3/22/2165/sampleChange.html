<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    parser.add_argument("--cuda", default=False, action="store_true", help="Enable cuda")
    args = parser.parse_args()

    <a id="change">envs = [make_env() for _ in range(5)]</a>
    writer = SummaryWriter(comment="-pong-pg")

    <a id="change">net = common.AtariPGN(envs[0].observation_space.shape, envs[0].action_space.n)</a>
    if args.cuda:
        net.cuda()
    print(net)

    <a id="change">agent</a> = ptan.agent.PolicyAgent(net, apply_softmax=True, cuda=args.cuda)
    <a id="change">exp_source</a> = ptan.experience.ExperienceSourceFirstLast(<a id="change">envs</a>, agent, gamma=GAMMA, steps_count=REWARD_STEPS)

    <a id="change">optimizer</a> = optim.Adam(net.parameters(), lr=LEARNING_RATE, eps=1e-3)

    total_rewards = []
    step_rewards = MeanRingBuf(capacity=BASELINE_STEPS)</code></pre><h3>After Change</h3><pre><code class='java'>
    parser.add_argument("--cuda", default=False, action="store_true", help="Enable cuda")
    args = parser.parse_args()

    <a id="change">env = make_env()</a>
    writer = SummaryWriter(comment="-pong-pg")

    <a id="change">net = common.AtariPGN(env.observation_space.shape, env.action_space.n)</a>
    if args.cuda:
        net.cuda()
    print(net)

    <a id="change">agent</a> = ptan.agent.PolicyAgent(net, apply_softmax=True, cuda=args.cuda)
    <a id="change">exp_source</a> = ptan.experience.ExperienceSourceFirstLast(<a id="change">env</a>, agent, gamma=GAMMA, steps_count=REWARD_STEPS)

    <a id="change">optimizer</a> = optim.Adam(net.parameters(), lr=LEARNING_RATE, eps=1e-3)

    total_rewards = []
    step_rewards = MeanRingBuf(capacity=BASELINE_STEPS)</code></pre>