<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 stack (bidirectional) LSTM layers
        for i, output_dim in enumerate(self.lstm):

            <a id="change">if i:
                lstm = LSTM(output_dim,
                            name=&quotlstm_{i:d}&quot.format(i=i),
                            return_sequences=True,
                            activation=&quottanh&quot)
            else:
                &#47&#47 we need to provide input_shape to first LSTM
                lstm = LSTM(output_dim,
                            input_shape=input_shape,
                            name=&quotlstm_{i:d}&quot.format(i=i),
                            return_sequences=True,
                            activation=&quottanh&quot)

            &#47&#47 bi-directional LSTM
           </a> if self.bidirectional:
                lstm = Bidirectional(lstm, merge_mode=self.bidirectional)

            &#47&#47 (actually) stack LSTM</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 stack (bidirectional) LSTM layers
        for i, output_dim in enumerate(self.lstm):

            <a id="change">params = {
                &quotname&quot: &quotlstm_{i:d}&quot.format(i=i),
                &quotreturn_sequences&quot: True,
                &#47&#47 &quotgo_backwards&quot: False,
                &#47&#47 &quotstateful&quot: False,
                &#47&#47 &quotunroll&quot: False,
                &#47&#47 &quotimplementation&quot: 0,
                &quotactivation&quot: &quottanh&quot,
                &#47&#47 &quotrecurrent_activation&quot: &quothard_sigmoid&quot,
                &#47&#47 &quotuse_bias&quot: True,
                &#47&#47 &quotkernel_initializer&quot: &quotglorot_uniform&quot,
                &#47&#47 &quotrecurrent_initializer&quot: &quotorthogonal&quot,
                &#47&#47 &quotbias_initializer&quot: &quotzeros&quot,
                &#47&#47 &quotunit_forget_bias&quot: True,
                &#47&#47 &quotkernel_regularizer&quot: None,
                &#47&#47 &quotrecurrent_regularizer&quot: None,
                &#47&#47 &quotbias_regularizer&quot: None,
                &#47&#47 &quotactivity_regularizer&quot: None,
                &#47&#47 &quotkernel_constraint&quot: None,
                &#47&#47 &quotrecurrent_constraint&quot: None,
                &#47&#47 &quotbias_constraint&quot: None,
                &#47&#47 &quotdropout&quot: 0.0,
                &#47&#47 &quotrecurrent_dropout&quot: 0.0,
            }</a>

            &#47&#47 first LSTM needs to be given the input shape
            <a id="change">if i == 0:
                params[&quotinput_shape&quot] = input_shape

           </a> <a id="change">lstm = LSTM(output_dim, **params)</a>

            &#47&#47 bi-directional LSTM
            if self.bidirectional:
                lstm = Bidirectional(lstm, merge_mode=self.bidirectional)</code></pre>