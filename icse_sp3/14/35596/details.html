<html><h3>97eb274a48752985cd33d62a92eef2a16c874d5b,featuretools/computational_backends/feature_set_calculator.py,FeatureSetCalculator,_calculate_agg_features,#FeatureSetCalculator#Any#Any#Any#Any#,523
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 Sometimes approximate features get computed in a previous filter frame
        &#47&#47 and put in the current one dynamically,
        &#47&#47 so there may be existing features here
        <a id="change">features = [f for f in features if f.get_name()
                    not in frame.columns]</a>
        if not len(features):
            progress_callback(len(features) / float(self.num_features))
            return frame

        &#47&#47 handle where
        where = test_feature.where
        if where is not None and not base_frame.empty:
            base_frame = base_frame.loc[base_frame[where.get_name()]]

        &#47&#47 when no child data, just add all the features to frame with nan
        if base_frame.empty:
            for f in features:
                frame[f.get_name()] = np.nan
                progress_callback(1 / float(self.num_features))
        else:
            relationship_path = test_feature.relationship_path

            groupby_var = get_relationship_variable_id(relationship_path)

            &#47&#47 if the use_previous property exists on this feature, include only the
            &#47&#47 instances from the child entity included in that Timedelta
            use_previous = test_feature.use_previous
            if use_previous and not base_frame.empty:
                &#47&#47 Filter by use_previous values
                time_last = self.time_last
                if use_previous.is_absolute():
                    time_first = time_last - use_previous
                    ti = child_entity.time_index
                    if ti is not None:
                        base_frame = base_frame[base_frame[ti] &gt;= time_first]
                else:
                    n = use_previous.value

                    def last_n(df):
                        return df.iloc[-n:]

                    base_frame = base_frame.groupby(groupby_var, observed=True, sort=False).apply(last_n)

            to_agg = {}
            agg_rename = {}
            to_apply = set()
            &#47&#47 apply multivariable and time-dependent features as we find them, and
            &#47&#47 save aggregable features for later
            for f in features:
                if _can_agg(f):
                    variable_id = f.base_features[0].get_name()

                    if variable_id not in to_agg:
                        to_agg[variable_id] = []

                    func = f.get_function()

                    &#47&#47 for some reason, using the string count is significantly
                    &#47&#47 faster than any method a primitive can return
                    &#47&#47 https://stackoverflow.com/questions/55731149/use-a-function-instead-of-string-in-pandas-groupby-agg
                    if is_python_2() and func == pd.Series.count.__func__:
                        func = "count"
                    elif func == pd.Series.count:
                        func = "count"

                    funcname = func
                    if callable(func):
                        &#47&#47 if the same function is being applied to the same
                        &#47&#47 variable twice, wrap it in a partial to avoid
                        &#47&#47 duplicate functions
                        funcname = str(id(func))
                        if u"{}-{}".format(variable_id, funcname) in agg_rename:
                            func = partial(func)
                            funcname = str(id(func))

                        func.__name__ = funcname

                    to_agg[variable_id].append(func)
                    &#47&#47 this is used below to rename columns that pandas names for us
                    agg_rename[u"{}-{}".format(variable_id, funcname)] = f.get_name()
                    continue

                to_apply.add(f)

            &#47&#47 Apply the non-aggregable functions generate a new dataframe, and merge
            &#47&#47 it with the existing one
            if len(to_apply):
                wrap = agg_wrapper(to_apply, self.time_last)
                &#47&#47 groupby_var can be both the name of the index and a column,
                &#47&#47 to silence pandas warning about ambiguity we explicitly pass
                &#47&#47 the column (in actuality grouping by both index and group would
                &#47&#47 work)
                to_merge = base_frame.groupby(base_frame[groupby_var], observed=True, sort=False).apply(wrap)
                frame = pd.merge(left=frame, right=to_merge,
                                 left_index=True,
                                 right_index=True, how=&quotleft&quot)

                progress_callback(len(to_apply) / float(self.num_features))

            &#47&#47 Apply the aggregate functions to generate a new dataframe, and merge
            &#47&#47 it with the existing one
            if len(to_agg):
                &#47&#47 groupby_var can be both the name of the index and a column,
                &#47&#47 to silence pandas warning about ambiguity we explicitly pass
                &#47&#47 the column (in actuality grouping by both index and group would
                &#47&#47 work)
                to_merge = base_frame.groupby(base_frame[groupby_var],
                                              observed=True, sort=False).agg(to_agg)
                &#47&#47 rename columns to the correct feature names
                <a id="change">to_merge.columns</a> = [agg_rename["-".join(x)] for x in to_merge.columns.ravel()]
                to_merge = to_merge[list(agg_rename.values())]

                &#47&#47 workaround for pandas bug where categories are in the wrong order</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 Sometimes approximate features get computed in a previous filter frame
        &#47&#47 and put in the current one dynamically,
        &#47&#47 so there may be existing features here
        <a id="change">fl = []</a>
        <a id="change">for f in features:
            for ind in f.get_feature_names():
                if ind not in frame.columns:
                    fl.append(f)
                    break
       </a> features = fl
        if not len(features):
            progress_callback(len(features) / float(self.num_features))
            return frame

        &#47&#47 handle where
        where = test_feature.where
        if where is not None and not base_frame.empty:
            base_frame = base_frame.loc[base_frame[where.get_name()]]

        &#47&#47 when no child data, just add all the features to frame with nan
        if base_frame.empty:
            for f in features:
                frame[f.get_name()] = np.nan
                progress_callback(1 / float(self.num_features))
        else:
            relationship_path = test_feature.relationship_path

            groupby_var = get_relationship_variable_id(relationship_path)

            &#47&#47 if the use_previous property exists on this feature, include only the
            &#47&#47 instances from the child entity included in that Timedelta
            use_previous = test_feature.use_previous
            if use_previous and not base_frame.empty:
                &#47&#47 Filter by use_previous values
                time_last = self.time_last
                if use_previous.is_absolute():
                    time_first = time_last - use_previous
                    ti = child_entity.time_index
                    if ti is not None:
                        base_frame = base_frame[base_frame[ti] &gt;= time_first]
                else:
                    n = use_previous.value

                    def last_n(df):
                        return df.iloc[-n:]

                    base_frame = base_frame.groupby(groupby_var, observed=True, sort=False).apply(last_n)

            to_agg = {}
            agg_rename = {}
            to_apply = set()
            &#47&#47 apply multivariable and time-dependent features as we find them, and
            &#47&#47 save aggregable features for later
            for f in features:
                if _can_agg(f):

                    variable_id = f.base_features[0].get_name()
                    if variable_id not in to_agg:
                        to_agg[variable_id] = []
                    func = f.get_function()

                    &#47&#47 for some reason, using the string count is significantly
                    &#47&#47 faster than any method a primitive can return
                    &#47&#47 https://stackoverflow.com/questions/55731149/use-a-function-instead-of-string-in-pandas-groupby-agg
                    if is_python_2() and func == pd.Series.count.__func__:
                        func = "count"
                    elif func == pd.Series.count:
                        func = "count"

                    funcname = func
                    if callable(func):
                        &#47&#47 if the same function is being applied to the same
                        &#47&#47 variable twice, wrap it in a partial to avoid
                        &#47&#47 duplicate functions
                        funcname = str(id(func))
                        if u"{}-{}".format(variable_id, funcname) in agg_rename:
                            func = partial(func)
                            funcname = str(id(func))

                        func.__name__ = funcname

                    to_agg[variable_id].append(func)
                    &#47&#47 this is used below to rename columns that pandas names for us
                    agg_rename[u"{}-{}".format(variable_id, funcname)] = f.get_name()
                    continue

                to_apply.add(f)

            &#47&#47 Apply the non-aggregable functions generate a new dataframe, and merge
            &#47&#47 it with the existing one
            if len(to_apply):
                wrap = agg_wrapper(to_apply, self.time_last)
                &#47&#47 groupby_var can be both the name of the index and a column,
                &#47&#47 to silence pandas warning about ambiguity we explicitly pass
                &#47&#47 the column (in actuality grouping by both index and group would
                &#47&#47 work)
                to_merge = base_frame.groupby(base_frame[groupby_var], observed=True, sort=False).apply(wrap)
                frame = pd.merge(left=frame, right=to_merge,
                                 left_index=True,
                                 right_index=True, how=&quotleft&quot)

                progress_callback(len(to_apply) / float(self.num_features))

            &#47&#47 Apply the aggregate functions to generate a new dataframe, and merge
            &#47&#47 it with the existing one
            if len(to_agg):
                &#47&#47 groupby_var can be both the name of the index and a column,
                &#47&#47 to silence pandas warning about ambiguity we explicitly pass
                &#47&#47 the column (in actuality grouping by both index and group would
                &#47&#47 work)
                to_merge = base_frame.groupby(base_frame[groupby_var],
                                              observed=True, sort=False).agg(to_agg)

                &#47&#47 rename columns to the correct feature names
                <a id="change">to_merge.columns</a> = [agg_rename["-".join(x)] for x in to_merge.columns.ravel()]
                to_merge = to_merge[list(agg_rename.values())]

                &#47&#47 workaround for pandas bug where categories are in the wrong order</code></pre><img src="172791357.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 13</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/Featuretools/featuretools/commit/97eb274a48752985cd33d62a92eef2a16c874d5b#diff-64f51e11355f4a02dc8884cfcb81d478041e8ac4fe503c5fd69d504cb23cf723L530' target='_blank'>Link</a></div><div id='project'> Project Name: Featuretools/featuretools</div><div id='commit'> Commit Name: 97eb274a48752985cd33d62a92eef2a16c874d5b</div><div id='time'> Time: 2019-08-13</div><div id='author'> Author: ctduffy@college.harvard.edu</div><div id='file'> File Name: featuretools/computational_backends/feature_set_calculator.py</div><div id='class'> Class Name: FeatureSetCalculator</div><div id='method'> Method Name: _calculate_agg_features</div><BR><BR><div id='link'><a href='https://github.com/tensorflow/cleverhans/commit/03f07734648aa9843393f0ebf19c61c2a34c728e#diff-0673ce828ee444296b16d579f1b635a7d357326c8362c1792e9d372f1fb80d6cL182' target='_blank'>Link</a></div><div id='project'> Project Name: tensorflow/cleverhans</div><div id='commit'> Commit Name: 03f07734648aa9843393f0ebf19c61c2a34c728e</div><div id='time'> Time: 2019-03-13</div><div id='author'> Author: haojie.d.yuan@gmail.com</div><div id='file'> File Name: cleverhans/utils_keras.py</div><div id='class'> Class Name: KerasModelWrapper</div><div id='method'> Method Name: fprop</div><BR><BR><div id='link'><a href='https://github.com/pyprob/pyprob/commit/4864d55ffc8d4494175cccce948e8251bf0cef34#diff-12a2a7a434360112b70672a9524617764477f0bf9a1985627ebfdae4276656e2L86' target='_blank'>Link</a></div><div id='project'> Project Name: pyprob/pyprob</div><div id='commit'> Commit Name: 4864d55ffc8d4494175cccce948e8251bf0cef34</div><div id='time'> Time: 2018-03-31</div><div id='author'> Author: atilimgunes.baydin@gmail.com</div><div id='file'> File Name: pyprob/trace.py</div><div id='class'> Class Name: Trace</div><div id='method'> Method Name: end</div><BR>