<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    ]

  def _info(self):
    return <a id="change">tfds.core.DatasetInfo(
        features=tfds.features.FeaturesDict({
            &#47&#47 TODO(michalski): replace with Video feature.
            "video_main":
                tfds.features.Tensor(
                    shape=(FRAMES_PER_VIDEO, 64, 64, 3), dtype=tf.uint8),
            "video_aux1":
                tfds.features.Tensor(
                    shape=(FRAMES_PER_VIDEO, 64, 64, 3), dtype=tf.uint8),
            "action":
                tfds.features.Tensor(
                    shape=(FRAMES_PER_VIDEO, 4), dtype=tf.float32),
            "endeffector_pos":
                tfds.features.Tensor(
                    shape=(FRAMES_PER_VIDEO, 3), dtype=tf.float32),
        }),)</a>

  def _parse_single_video(self, example_proto):
    Parses single video from the input tfrecords.
</code></pre><h3>After Change</h3><pre><code class='java'>
    ]

  def _info(self):
    return <a id="change">tfds.core.DatasetInfo(
        name=self.name,
        description="This data set contains roughly 59,000 examples of robot "
        "pushing motions, including one training set (train) and "
        "two test sets of previously seen (testseen) and unseen "
        "(testnovel) objects.",
        features=tfds.features.FeaturesDict({
            &#47&#47 TODO(michalski): replace with Video feature.
            "video_main":
                tfds.features.Tensor(
                    shape=(FRAMES_PER_VIDEO, 64, 64, 3), dtype=tf.uint8),
            "video_aux1":
                tfds.features.Tensor(
                    shape=(FRAMES_PER_VIDEO, 64, 64, 3), dtype=tf.uint8),
            "action":
                tfds.features.Tensor(
                    shape=(FRAMES_PER_VIDEO, 4), dtype=tf.float32),
            "endeffector_pos":
                tfds.features.Tensor(
                    shape=(FRAMES_PER_VIDEO, 3), dtype=tf.float32),
        }),
        urls=["https://sites.google.com/site/brainrobotdata/home/push-dataset"],
        size_in_bytes=30.0 * tfds.core.units.GiB,
        citation="Unsupervised Learning for Physical Interaction through Video "
        " Prediction. Chelsea Finn, Ian Goodfellow, Sergey Levine",
    )</a>

  def _parse_single_video(self, example_proto):
    Parses single video from the input tfrecords.
</code></pre>