<html><h3>abb1451d02700cfb573ef4093b2c2eaa595ec727,art/attacks/evasion/projected_gradient_descent/projected_gradient_descent_pytorch.py,ProjectedGradientDescentPyTorch,generate,#ProjectedGradientDescentPyTorch#Any#Any#,109
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        adv_x_best = None
        rate_best = None

        for _ in <a id="change">trange(max(1, self.num_random_init), desc="PGD - Random Initializations", disable=not self.verbose)</a>:
            adv_x = x.astype(ART_NUMPY_DTYPE)

            &#47&#47 Compute perturbation with batching</code></pre><h3>After Change</h3><pre><code class='java'>
                batch_eps = self.eps
                batch_eps_step = self.eps_step

            <a id="change">for rand_init_num in range(max(1, self.num_random_init)):
                adversarial_batch = self._generate_batch(x=batch, targets=batch_labels, mask=mask_batch, eps=batch_eps, eps_step=batch_eps_step)
                if rand_init_num == 0:
                    &#47&#47 first iteration: use the adversarial examples as they are the only ones we have now
                    adv_x[batch_index_1:batch_index_2] = np.copy(adversarial_batch)
                else:
                    &#47&#47 return the successful adversarial examples
                    attack_success = compute_success_array(
                        self.estimator,
                        batch,
                        batch_labels,
                        adversarial_batch,
                        self.targeted,
                        batch_size=self.batch_size,
                    )
                    adv_x[batch_index_1:batch_index_2][attack_success] = adversarial_batch[attack_success]

       </a> logger.info(
            "Success rate of attack: %.2f%%",
            100 * compute_success(self.estimator, x, y, adv_x, self.targeted, batch_size=self.batch_size),
        )</code></pre><img src="172582733.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/IBM/adversarial-robustness-toolbox/commit/abb1451d02700cfb573ef4093b2c2eaa595ec727#diff-11510d44e096509a03a0ffc572136a5c77b7e469fd057a38b2b63df51fae83ecL109' target='_blank'>Link</a></div><div id='project'> Project Name: IBM/adversarial-robustness-toolbox</div><div id='commit'> Commit Name: abb1451d02700cfb573ef4093b2c2eaa595ec727</div><div id='time'> Time: 2020-11-27</div><div id='author'> Author: giulio@li-87b782cc-261a-11b2-a85c-fc0eec425ab4.ibm.com</div><div id='file'> File Name: art/attacks/evasion/projected_gradient_descent/projected_gradient_descent_pytorch.py</div><div id='class'> Class Name: ProjectedGradientDescentPyTorch</div><div id='method'> Method Name: generate</div><BR><BR><div id='link'><a href='https://github.com/pymc-devs/pymc3/commit/1c30a6f487afaeef73464a98320e35961b11873f#diff-77a49ddd0990a563bc0f6a02bf1a6e97f9162e8289819bad5034b175159a3fc2L132' target='_blank'>Link</a></div><div id='project'> Project Name: pymc-devs/pymc3</div><div id='commit'> Commit Name: 1c30a6f487afaeef73464a98320e35961b11873f</div><div id='time'> Time: 2019-12-09</div><div id='author'> Author: aloctavodia@gmail.com</div><div id='file'> File Name: pymc3/variational/inference.py</div><div id='class'> Class Name: Inference</div><div id='method'> Method Name: fit</div><BR><BR><div id='link'><a href='https://github.com/IBM/adversarial-robustness-toolbox/commit/abb1451d02700cfb573ef4093b2c2eaa595ec727#diff-0b69feec391151c9563e11c7695d92a69566cbdba26fbabac9dc36ff3baf9ec7L109' target='_blank'>Link</a></div><div id='project'> Project Name: IBM/adversarial-robustness-toolbox</div><div id='commit'> Commit Name: abb1451d02700cfb573ef4093b2c2eaa595ec727</div><div id='time'> Time: 2020-11-27</div><div id='author'> Author: giulio@li-87b782cc-261a-11b2-a85c-fc0eec425ab4.ibm.com</div><div id='file'> File Name: art/attacks/evasion/projected_gradient_descent/projected_gradient_descent_tensorflow_v2.py</div><div id='class'> Class Name: ProjectedGradientDescentTensorFlowV2</div><div id='method'> Method Name: generate</div><BR>