<html><h3>35d2fb1b63a5e2b831adc5f0598e17edf811461a,tutorials/mnist_tutorial_cw.py,,mnist_tutorial_cw,#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#,24
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
          + &quot adversarial examples&quot)

    &#47&#47 Keep track of success (adversarial example classified in target)
    results = np.zeros(<a id="change">(nb_classes, source_samples)</a>, dtype=&quoti&quot)

    &#47&#47 Rate of perturbed features for each test set example and target class
    perturbations = np.zeros((nb_classes, source_samples), dtype=&quotf&quot)

    &#47&#47 Initialize our array for grid visualization
    grid_shape = (nb_classes, nb_classes, img_rows, img_cols, channels)
    grid_viz_data = np.zeros(grid_shape, dtype=&quotf&quot)

    &#47&#47 Instantiate a SaliencyMapMethod attack object
    cw = CarliniWagnerL2(model, back=&quottf&quot, sess=sess)
    cw_params = {&quotbinary_search_steps&quot:3, &quotmax_iterations&quot:10000,
                   &quotlearning_rate&quot:0.01, &quottargeted&quot:True, &quotbatch_size&quot:100}

    &#47&#47 Loop over the samples we want to perturb into adversarial examples

    def onehot(a,b):
        r = [[0]*b for _ in a]
        for i,aa in enumerate(a):
            r[i][aa] = 1
        return r

    idxs = [np.where(np.argmax(Y_test,axis=1)==i)[0][0] for i in range(10)]
    print(idxs)

    adv = cw.generate_np(np.array([[x]*10 for x in X_test[idxs]]).reshape((100,28,28,1)),
                         np.array([onehot(range(10),10) for x in range(10)]).reshape((100,10)),
                         **cw_params)


    print(adv.shape)
    for j in range(10):
        for i in range(10):
            grid_viz_data[i,j] = adv[i*10+j]
    
    print(&quot--------------------------------------&quot)

    &#47&#47 Compute the number of adversarial examples that were successfully found
    nb_targets_tried = ((nb_classes - 1) * source_samples)
    succ_rate = float(np.sum(results)) / nb_targets_tried
    print(&quotAvg. rate of successful adv. examples {0:.4f}&quot.format(succ_rate))
    report.clean_train_adv_eval = 1. - succ_rate

    &#47&#47 Compute the average distortion introduced by the algorithm
    percent_perturbed = np.mean(perturbations)
    print(&quotAvg. rate of perturbed features {0:.4f}&quot.format(percent_perturbed))

    &#47&#47 Compute the average distortion introduced for successful samples only
    <a id="change">percent_perturb_succ = np.mean(perturbations * (results == 1))</a>
    print(&quotAvg. rate of perturbed features for successful &quot
          &quotadversarial examples {0:.4f}&quot.format(percent_perturb_succ))

    &#47&#47 Close TF session</code></pre><h3>After Change</h3><pre><code class='java'>
    idxs = [np.where(np.argmax(Y_test,axis=1)==i)[0][0] for i in range(10)]
    adv_inputs = np.array([[x]*10 for x in X_test[idxs]]).reshape((100,28,28,1))
    adv_ys = np.array([onehot(range(10),10) for x in range(10)]).reshape((100,10))
    <a id="change">adv = cw.generate_np(adv_inputs, adv_ys, **cw_params)</a>

    adv_accuracy = model_eval(sess, x, y, preds, adv, adv_ys, args={&quotbatch_size&quot: 100})

    for j in range(10):</code></pre><img src="278281556.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/tensorflow/cleverhans/commit/35d2fb1b63a5e2b831adc5f0598e17edf811461a#diff-7142976935bc2f2c264fd30912f78d210dafde8826733d5f4d40a5f5324da08fL64' target='_blank'>Link</a></div><div id='project'> Project Name: tensorflow/cleverhans</div><div id='commit'> Commit Name: 35d2fb1b63a5e2b831adc5f0598e17edf811461a</div><div id='time'> Time: 2017-08-03</div><div id='author'> Author: nicholas@carlini.com</div><div id='file'> File Name: tutorials/mnist_tutorial_cw.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: mnist_tutorial_cw</div><BR><BR><div id='link'><a href='https://github.com/tensorflow/cleverhans/commit/28af50891d3540e635c5e11fb2308bebc9580d79#diff-dda2b6c91c507ae36142c696cdabb221733b7e8b588772d2a9e93d3870229bb5L42' target='_blank'>Link</a></div><div id='project'> Project Name: tensorflow/cleverhans</div><div id='commit'> Commit Name: 28af50891d3540e635c5e11fb2308bebc9580d79</div><div id='time'> Time: 2017-03-28</div><div id='author'> Author: ngp5056@cse.psu.edu</div><div id='file'> File Name: tutorials/mnist_tutorial_th.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: main</div><BR><BR><div id='link'><a href='https://github.com/IBM/adversarial-robustness-toolbox/commit/e7feb5694cb9954ec8a09877c27f7ca8c289aabb#diff-48f7c580dacc0fab16cb8e535d2972fc7bb5a443d2d722541234d9d6e86ba75cL18' target='_blank'>Link</a></div><div id='project'> Project Name: IBM/adversarial-robustness-toolbox</div><div id='commit'> Commit Name: e7feb5694cb9954ec8a09877c27f7ca8c289aabb</div><div id='time'> Time: 2017-05-17</div><div id='author'> Author: valentina.zantedeschi@ibm.com</div><div id='file'> File Name: attack_on_mnist.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: </div><BR>