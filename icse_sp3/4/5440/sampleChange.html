<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 Since tree roots are designated to 0.  In the batched graph we can
        &#47&#47 simply find the corresponding node ID by looking at node_offset
        root_ids = mol_tree_batch.node_offset[:-1]
        n_nodes = <a id="change">len(mol_tree_batch.nodes)</a>
        edge_list = mol_tree_batch.edge_list
        n_edges = len(edge_list)

        &#47&#47 Assign structure embeddings to tree nodes</code></pre><h3>After Change</h3><pre><code class='java'>
    def run(self, mol_tree_batch, mol_tree_batch_lg):
        &#47&#47 Since tree roots are designated to 0.  In the batched graph we can
        &#47&#47 simply find the corresponding node ID by looking at node_offset
        node_offset = <a id="change">np.cumsum([0] + mol_tree_batch.batch_num_nodes)</a>
        root_ids = node_offset[:-1]
        n_nodes = mol_tree_batch.number_of_nodes()
        n_edges = mol_tree_batch.number_of_edges()

        &#47&#47 Assign structure embeddings to tree nodes
        mol_tree_batch.ndata.update({
            &quotx&quot: self.embedding(mol_tree_batch.ndata[&quotwid&quot]),
            &quoth&quot: cuda(torch.zeros(n_nodes, self.hidden_size)),
        })

        &#47&#47 Initialize the intermediate variables according to Eq (4)-(8).
        &#47&#47 Also initialize the src_x and dst_x fields.
        &#47&#47 TODO: context?
        mol_tree_batch.edata.update({
            &quots&quot: cuda(torch.zeros(n_edges, self.hidden_size)),
            &quotm&quot: cuda(torch.zeros(n_edges, self.hidden_size)),
            &quotr&quot: cuda(torch.zeros(n_edges, self.hidden_size)),
            &quotz&quot: cuda(torch.zeros(n_edges, self.hidden_size)),
            &quotsrc_x&quot: cuda(torch.zeros(n_edges, self.hidden_size)),
            &quotdst_x&quot: cuda(torch.zeros(n_edges, self.hidden_size)),
            &quotrm&quot: cuda(torch.zeros(n_edges, self.hidden_size)),
            &quotaccum_rm&quot: cuda(torch.zeros(n_edges, self.hidden_size)),
        })

        &#47&#47 Send the source/destination node features to edges
        mol_tree_batch.apply_edges(
            func=lambda edges: {&quotsrc_x&quot: edges.src[&quotx&quot], &quotdst_x&quot: edges.dst[&quotx&quot]},
        )

        &#47&#47 Message passing
        &#47&#47 I exploited the fact that the reduce function is a sum of incoming
        &#47&#47 messages, and the uncomputed messages are zero vectors.  Essentially,
        &#47&#47 we can always compute s_ij as the sum of incoming m_ij, no matter
        &#47&#47 if m_ij is actually computed or not.
        for eid in level_order(mol_tree_batch, root_ids):
            &#47&#47eid = mol_tree_batch.edge_ids(u, v)
            mol_tree_batch_lg.pull(
                eid,
                enc_tree_msg,
                enc_tree_reduce,
                self.enc_tree_update,
            )

        &#47&#47 Readout
        mol_tree_batch.update_all(
            enc_tree_gather_msg,
            enc_tree_gather_reduce,
            self.enc_tree_gather_update,
        )

        root_vecs = <a id="change">mol_tree_batch</a>.nodes[root_ids].data[&quoth&quot]

        return mol_tree_batch, root_vecs
</code></pre>