<html><h3>15049442a5b8265d489b9fdf2f75898070e74b1b,deepvariant/modeling.py,DeepVariantSlimModel,_model_fn_train,#DeepVariantSlimModel#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#,1032
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
      return None, None

    &#47&#47 Configure the learning rate using an exponetial decay.
    <a id="change">global_step = tf.compat.v1.train.get_or_create_global_step()</a>
    current_epoch = tf.cast(global_step, tf.float32) / batches_per_epoch
    decay_steps = int(1.0 * batches_per_epoch * num_epochs_per_decay)

    learning_rate = tf.compat.v1.train.exponential_decay(</code></pre><h3>After Change</h3><pre><code class='java'>
      return None, None

    &#47&#47 Configure the learning rate using an exponetial decay.
    global_step = <a id="change">tf.compat.v1.train.get_or_create_global_step()</a>
    current_epoch = tf.cast(global_step, tf.float32) / batches_per_epoch
    decay_steps = int(1.0 * batches_per_epoch * num_epochs_per_decay)

    learning_rate = tf.compat.v1.train.exponential_decay(
        learning_rate=initial_learning_rate,
        global_step=global_step,
        decay_steps=decay_steps,
        decay_rate=learning_rate_decay_factor,
        staircase=True)

    &#47&#47 Set a minimum boundary for the learning rate to be a fixed value of 1e-9.
    &#47&#47 It&quots common to see these tf.max(...) operations when training inception,
    &#47&#47 with a max of 1e-4 * initial_learning_rate but this makes it hard to
    &#47&#47 explore learning rate schedules that decay quickly or by a lot of each
    &#47&#47 step. Here we just use a very small constant 1e-9 as the minimum value.
    learning_rate = tf.maximum(learning_rate, 1e-9, name=&quotlearning_rate&quot)

    optimizer = tf.compat.v1.train.RMSPropOptimizer(
        learning_rate,
        rmsprop_decay,
        momentum=rmsprop_momentum,
        epsilon=rmsprop_epsilon)
    if self.use_tpu:
      optimizer = tpu_optimizer.CrossShardOptimizer(optimizer)
    update_ops = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.UPDATE_OPS)
    with tf.control_dependencies(update_ops):
      train_op = optimizer.minimize(total_loss, global_step=global_step)

    &#47&#47 NB. In the inception code this was "tf.trainable_variables()
    &#47&#47 + tf.moving_average_variables()", but we&quotve settled on just
    &#47&#47 tf.model_variables() in the existing production DV2.
    variables_to_average = tf.compat.v1.model_variables()
    <a id="change">variable_averages = tf.train.ExponentialMovingAverage(
        decay=moving_average_decay, num_updates=global_step)</a>
    with tf.control_dependencies([train_op
                                 ]), tf.compat.v1.name_scope(&quotmoving_average&quot):
      train_op = variable_averages.apply(variables_to_average)
    tf.compat.v1.add_to_collection(tf.compat.v1.GraphKeys.UPDATE_OPS, train_op)</code></pre><img src="267859987.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/google/deepvariant/commit/15049442a5b8265d489b9fdf2f75898070e74b1b#diff-a311251b99ae1d2131889103ec9db3436171a26d4c205599ec99b2e18aa4b79dL1' target='_blank'>Link</a></div><div id='project'> Project Name: google/deepvariant</div><div id='commit'> Commit Name: 15049442a5b8265d489b9fdf2f75898070e74b1b</div><div id='time'> Time: 2020-01-24</div><div id='author'> Author: marianattestad@google.com</div><div id='file'> File Name: deepvariant/modeling.py</div><div id='class'> Class Name: DeepVariantSlimModel</div><div id='method'> Method Name: _model_fn_train</div><BR><BR><div id='link'><a href='https://github.com/weinman/cnn_lstm_ctc_ocr/commit/0bf56c5e8db53e152e7095087499d072018283e6#diff-e5dcc7e9ea231b852d8e5d57623ff2834ac9ea3e96408e44b8857b4d379530aaL143' target='_blank'>Link</a></div><div id='project'> Project Name: weinman/cnn_lstm_ctc_ocr</div><div id='commit'> Commit Name: 0bf56c5e8db53e152e7095087499d072018283e6</div><div id='time'> Time: 2018-06-29</div><div id='author'> Author: am.lamsal@gmail.com</div><div id='file'> File Name: src/test.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: model_fn</div><BR><BR><div id='link'><a href='https://github.com/google/deepvariant/commit/f6a1e651fd6d10ad08a11dd42190202eedcaee4e#diff-a311251b99ae1d2131889103ec9db3436171a26d4c205599ec99b2e18aa4b79dL1033' target='_blank'>Link</a></div><div id='project'> Project Name: google/deepvariant</div><div id='commit'> Commit Name: f6a1e651fd6d10ad08a11dd42190202eedcaee4e</div><div id='time'> Time: 2020-02-26</div><div id='author'> Author: marianattestad@google.com</div><div id='file'> File Name: deepvariant/modeling.py</div><div id='class'> Class Name: DeepVariantSlimModel</div><div id='method'> Method Name: _model_fn_train</div><BR>