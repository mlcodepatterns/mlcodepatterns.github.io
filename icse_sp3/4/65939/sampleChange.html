<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    rollouts.obs[0].copy_(obs)

    &#47&#47 These variables are used to compute average rewards for all processes.
    episode_rewards = torch.zeros(<a id="change">[args.num_processes, 1]</a>)
    final_rewards = torch.zeros([args.num_processes, 1])

    rollouts.to(device)

    start = time.time()
    for j in range(num_updates):
        for step in range(args.num_steps):
            &#47&#47 Sample actions
            with torch.no_grad():
                value, action, action_log_prob, recurrent_hidden_states = actor_critic.act(
                        rollouts.obs[step],
                        rollouts.recurrent_hidden_states[step],
                        rollouts.masks[step])

            &#47&#47 Obser reward and next obs
            obs, reward, done, info = envs.step(action)
            episode_rewards += reward

            &#47&#47 If done then clean the history of observations.
            masks = torch.FloatTensor([[0.0] if done_ else [1.0] for done_ in done])
            final_rewards *= masks
            <a id="change">final_rewards += (1 - masks) * episode_rewards</a>
            episode_rewards *= masks

            rollouts.insert(obs, recurrent_hidden_states, action, action_log_prob, value, reward, masks)
</code></pre><h3>After Change</h3><pre><code class='java'>
    rollouts.obs[0].copy_(obs)
    rollouts.to(device)

    <a id="change">episode_rewards = deque(maxlen=10)</a>
    
    start = time.time()
    for j in range(num_updates):
        for step in range(args.num_steps):</code></pre>