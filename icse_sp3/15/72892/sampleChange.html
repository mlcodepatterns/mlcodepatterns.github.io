<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            logger.warning("Warning: Passing `preproc` to `ClassifierService.predict` is deprecated.")
        tokens_batch = self.batch_input(tokens)
        self.prepare_vectorizers(tokens_batch)
        <a id="change">if self.preproc == "client":
            examples = self.vectorize(tokens_batch)
        elif self.preproc == &quotserver&quot:
            &#47&#47 TODO: here we allow vectorizers even for preproc=server to get `word_lengths`.
            &#47&#47 vectorizers should not be available when preproc=server.
            featurized_examples = self.vectorize(tokens_batch)
            examples = {
                        &quottokens&quot: np.array([" ".join(x) for x in tokens_batch]),
                        self.model.lengths_key: featurized_examples[self.model.lengths_key]
            }

       </a> outcomes_list = self.model.predict(examples)
        return self.format_output(outcomes_list)

    def format_output(self, predicted):</code></pre><h3>After Change</h3><pre><code class='java'>

        if backend not in {&quottf&quot}:
            raise ValueError("only Tensorflow is currently supported for remote Services")
        import_user_module(&quotbaseline.{}.rem<a id="change">ote&quot.format(backend))
        exp_type = kwargs.get(&quotremote_type&quot)
        if ex</a>p_type is None:
            exp_type = &quothttp&quot if remote.startswith(&quothttp&quot) else &quotgrpc&quot
            exp_type = &quot{}-preproc&quot.format(exp_type) if preproc == &quotserver&quot else exp_type
            exp_type = f&quot{exp_type}-{task_name}&quot</code></pre>