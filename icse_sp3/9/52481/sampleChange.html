<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    &#47&#47input is a tensor of shape (batchSize, FMs, r, c, z)
    aPreluValues = np.ones( (numberOfInputChannels), dtype = &quotfloat32&quot )*0.01 &#47&#47"Delving deep into rectifiers" initializes it like this. LeakyRelus are at 0.01
    aPrelu = theano.shared(value=aPreluValues, borrow=True) &#47&#47One separate a (activation) per feature map.
    aPreluBroadCastedForMultiplWithChannels = <a id="change">aPrelu.dimshuffle(&quotx&quot, 0, &quotx&quot, &quotx&quot, &quotx&quot)</a>
    
    posTrain = T.maximum(0, inputTrain)
    negTrain = aPreluBroadCastedForMultiplWithChannels * (inputTrain - abs(inputTrain)) * 0.5
    outputTrain = posTrain + negTrain</code></pre><h3>After Change</h3><pre><code class='java'>
    &#47&#47input is a tensor of shape (batchSize, FMs, r, c, z)
    aPreluValues = np.ones( (numberOfInputChannels), dtype = &quotfloat32&quot ) * 0.01 &#47&#47"Delving deep into rectifiers" initializes it like this. LeakyRelus are at 0.01
    aPrelu = tf.Variable(aPreluValues, name="aPrelu") &#47&#47One separate a (activation) per feature map.
    aPrelu5D = <a id="change">tf.reshape(aPrelu, shape=[1, numberOfInputChannels, 1, 1, 1] )</a>
    
    posTrain = tf.maximum(0., inputTrain)
    negTrain = aPrelu5D * (inputTrain - abs(inputTrain)) * 0.5
    outputTrain = posTrain + negTrain</code></pre>