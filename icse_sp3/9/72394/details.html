<html><h3>7ec9efd5cf6a479e8c5d85dcc950f464fd15b134,tf_agents/agents/reinforce/reinforce_agent.py,ReinforceAgent,total_loss,#ReinforceAgent#Any#Any#Any#Any#,260
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
          name=&quotentropy_regularization_loss&quot,
          data=entropy_regularization_loss,
          step=self.train_step_counter)
      <a id="change">if self._baseline:
        tf.compat.v2.summary.scalar(
            name=&quotvalue_estimation_loss&quot,
            data=value_estimation_loss,
            step=self.train_step_counter)
     </a> tf.compat.v2.summary.scalar(
          name=&quottotal_loss&quot, data=total_loss, step=self.train_step_counter)

    return tf_agent.LossInfo(total_loss, ())</code></pre><h3>After Change</h3><pre><code class='java'>
    entropy_regularization_loss = self.entropy_regularization_loss(
        actions_distribution, weights)

    <a id="change">network_regularization_loss = tf.nn.scale_regularization_loss(
        self._actor_network.losses)</a>

    total_loss = (policy_gradient_loss +
                  network_regularization_loss +
                  entropy_regularization_loss)

    <a id="change">losses_dict = {
        &quotpolicy_gradient_loss&quot: policy_gradient_loss,
        &quotpolicy_network_regularization_loss&quot: network_regularization_loss,
        &quotentropy_regularization_loss&quot: entropy_regularization_loss,
        &quotvalue_estimation_loss&quot: 0.0,
        &quotvalue_network_regularization_loss&quot: 0.0,
    }</a>

    value_estimation_loss = None
    if self._baseline:
      value_estimation_loss = self.value_estimation_loss(
          value_preds, returns, num_episodes, weights)
      value_network_regularization_loss = tf.nn.scale_regularization_loss(
          self._value_network.losses)
      total_loss += value_estimation_loss + value_network_regularization_loss
      losses_dict[&quotvalue_estimation_loss&quot] = value_estimation_loss
      losses_dict[&quotvalue_network_regularization_loss&quot] = (
          value_network_regularization_loss)

    loss_info_extra = ReinforceAgentLossInfo._make(losses_dict)

    losses_dict[&quottotal_loss&quot] = total_loss  &#47&#47 Total loss not in loss_info_extra.

    <a id="change">common.summarize_scalar_dict(losses_dict,
                                 self.train_step_counter,
                                 name_scope=&quotLosses/&quot)</a>

    return tf_agent.LossInfo(total_loss, loss_info_extra)

  def policy_gradient_loss(self,</code></pre><img src="331982921.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/tensorflow/agents/commit/7ec9efd5cf6a479e8c5d85dcc950f464fd15b134#diff-bf755fac197dae2cc47fed2451d12ed15b4c17215eabaf0b1f8f2f3dcc62952bL260' target='_blank'>Link</a></div><div id='project'> Project Name: tensorflow/agents</div><div id='commit'> Commit Name: 7ec9efd5cf6a479e8c5d85dcc950f464fd15b134</div><div id='time'> Time: 2020-02-28</div><div id='author'> Author: no-reply@google.com</div><div id='file'> File Name: tf_agents/agents/reinforce/reinforce_agent.py</div><div id='class'> Class Name: ReinforceAgent</div><div id='method'> Method Name: total_loss</div><BR><BR><div id='link'><a href='https://github.com/tensorflow/agents/commit/aa3c6a5f79d82044306f3a11f1de6b7231163d90#diff-5cc6013091e2eff01f1a8513d49c798fff3da963f5e6027de432e29c94c737dcL369' target='_blank'>Link</a></div><div id='project'> Project Name: tensorflow/agents</div><div id='commit'> Commit Name: aa3c6a5f79d82044306f3a11f1de6b7231163d90</div><div id='time'> Time: 2020-02-24</div><div id='author'> Author: sguada@google.com</div><div id='file'> File Name: tf_agents/agents/dqn/dqn_agent.py</div><div id='class'> Class Name: DqnAgent</div><div id='method'> Method Name: _loss</div><BR><BR><div id='link'><a href='https://github.com/tensorflow/agents/commit/aa3c6a5f79d82044306f3a11f1de6b7231163d90#diff-6ee75ccd5f39ed3282937572ffe9ad7f7d6306e6074c0c2f9f72c2541c04b777L226' target='_blank'>Link</a></div><div id='project'> Project Name: tensorflow/agents</div><div id='commit'> Commit Name: aa3c6a5f79d82044306f3a11f1de6b7231163d90</div><div id='time'> Time: 2020-02-24</div><div id='author'> Author: sguada@google.com</div><div id='file'> File Name: tf_agents/agents/behavioral_cloning/behavioral_cloning_agent.py</div><div id='class'> Class Name: BehavioralCloningAgent</div><div id='method'> Method Name: _loss</div><BR>