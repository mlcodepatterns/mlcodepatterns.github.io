<html><h3>e12e1d254c77b363d3876893cc4943277dcc5f1f,fairseq/models/fconv.py,FConvEncoder,__init__,#FConvEncoder#Any#Any#Any#Any#Any#Any#Any#,186
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            if residual == 0:
                residual_dim = out_channels
            else:
                residual_dim = <a id="change">layer_in_channels[-residual]</a>
            self.projections.append(Linear(residual_dim, out_channels)
                                    if residual_dim != out_channels else None)
            if kernel_size % 2 == 1:
                padding = kernel_size // 2</code></pre><h3>After Change</h3><pre><code class='java'>
    Args:
        dictionary (~fairseq.data.Dictionary): encoding dictionary
        embed_dim (int, optional): embedding dimension
        embed_dict (str, optional): filename from which to load pre-traine<a id="change">d
            embeddings
       </a> max_positions (int, opt<a id="change">ional): </a>maximum supported input sequence length
        convolutions (list, optional): the convolutional layer structure. Each
            list item `i` corresponds to convolutional layer `i`. Layers are
            given as ``(out_channels, kernel_width, [residual])``. Residual
            connections are added between layers when ``residual=1`` (which is
            the defa<a id="change">ult behavior).
        dropout (float, optional): dropout to be applied before each conv layer
    

    def __init__(
        self,</a> dictionary, embed_dim=512, embed_dict=None, max_positions=1024,
        convolutions=((512, 3),) * 20, dropout=0.1,
    ):
        super().__init__(dictionary)</code></pre><img src="273497565.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 9</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/pytorch/fairseq/commit/e12e1d254c77b363d3876893cc4943277dcc5f1f#diff-6b13c5873f1c102ec844b4853a4b2b27c1c84fe72f577d3fe20f00093f971944L141' target='_blank'>Link</a></div><div id='project'> Project Name: pytorch/fairseq</div><div id='commit'> Commit Name: e12e1d254c77b363d3876893cc4943277dcc5f1f</div><div id='time'> Time: 2019-04-15</div><div id='author'> Author: myleott@fb.com</div><div id='file'> File Name: fairseq/models/fconv.py</div><div id='class'> Class Name: FConvEncoder</div><div id='method'> Method Name: __init__</div><BR><BR><div id='link'><a href='https://github.com/anhaidgroup/deepmatcher/commit/918639008702528a4c129da5fe4185c86c015835#diff-e1e5d0e38b23d2f924e196cfb6d8af106b6b44ebd9a9c2ba3fcc6780f0ba9dd4L22' target='_blank'>Link</a></div><div id='project'> Project Name: anhaidgroup/deepmatcher</div><div id='commit'> Commit Name: 918639008702528a4c129da5fe4185c86c015835</div><div id='time'> Time: 2018-04-30</div><div id='author'> Author: sidharthmsk@gmail.com</div><div id='file'> File Name: deepmatcher/models/word_contextualizers.py</div><div id='class'> Class Name: SelfAttention</div><div id='method'> Method Name: _init</div><BR><BR><div id='link'><a href='https://github.com/elbayadm/attn2d/commit/e12e1d254c77b363d3876893cc4943277dcc5f1f#diff-6b13c5873f1c102ec844b4853a4b2b27c1c84fe72f577d3fe20f00093f971944L186' target='_blank'>Link</a></div><div id='project'> Project Name: elbayadm/attn2d</div><div id='commit'> Commit Name: e12e1d254c77b363d3876893cc4943277dcc5f1f</div><div id='time'> Time: 2019-04-15</div><div id='author'> Author: myleott@fb.com</div><div id='file'> File Name: fairseq/models/fconv.py</div><div id='class'> Class Name: FConvEncoder</div><div id='method'> Method Name: __init__</div><BR>