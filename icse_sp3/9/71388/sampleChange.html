<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                with torch.no_grad():
                    _seq, _sampleLogprobs = model(fc_feats, att_feats, att_masks, opt=tmp_eval_kwargs, mode=&quotsample&quot)
                _sents = utils.decode_sequence(loader.get_vocab(), _seq)
                <a id="change">for k, sent in enumerate(_sents):
                    entry = {&quotimage_id&quot: data[&quotinfos&quot][k // sample_n][&quotid&quot], &quotcaption&quot: sent}
                    n_predictions.append(entry)
            &#47&#47 case 3 gumbel max
           </a> elif sample_n_method == &quotgumbel&quot:
                tmp_eval_kwargs.update({&quotsample_max&quot: 2, &quotbeam_size&quot: 1}) &#47&#47 randomness from sample
                with torch.no_grad():
                    _seq, _sampleLogprobs = model(fc_feats, att_feats, att_masks, opt=tmp_eval_kwargs, mode=&quotsample&quot)</code></pre><h3>After Change</h3><pre><code class='java'>
                elif sample_n_method == &quotgumbel&quot:
                    tmp_sample_max = 2
                elif sample_n_method.startswith(&quottop&quot):
                    <a id="change">tmp_sample_max = -int(sample_n_method[3:])</a>
                tmp_eval_kwargs.update({&quotsample_max&quot: tmp_sample_max, &quotbeam_size&quot: 1}) &#47&#47 randomness from sample
                with torch.no_grad():
                    _seq, _sampleLogprobs = model(fc_feats, att_feats, att_masks, opt=tmp_eval_kwargs, mode=&quotsample&quot)
                _sents = utils.decode_sequence(loader.get_vocab(), _seq)</code></pre>