<html><h3>edb300280cd7854bb58e023d01ac24160bf6d98d,neurosynth/analysis/cluster.py,Clusterer,__init__,#Clusterer#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#,22
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        self._set_clustering_algorithm(algorithm, **kwargs)

        <a id="change">if isinstance(dataset, Dataset):

            self.dataset = dataset

            if global_mask is None:
                global_mask = dataset.masker

            if features is not None:
                data = self.dataset.get_ids_by_features(features, threshold=feature_threshold, 
                            get_image_data=True)
            else:
                data = self.dataset.get_image_data()

            &#47&#47 if min_studies_per_voxel is not None:
            &#47&#47     logger.info("Thresholding voxels based on number of studies.")
            &#47&#47     sum_vox = data.sum(1)
            &#47&#47     &#47&#47 Save the indices for later reconstruction
            &#47&#47     active_vox = np.where(sum_vox &gt; min_studies_per_voxel)[0]  
            &#47&#47     n_active_vox = active_vox.shape[0]

            &#47&#47 if min_voxels_per_study is not None:
            &#47&#47     logger.info("Thresholding studies based on number of voxels.")
            &#47&#47     sum_studies = data.sum(0)
            &#47&#47     active_studies = np.where(sum_studies &gt; min_voxels_per_study)[0]
            &#47&#47     n_active_studies = active_studies.shape[0]

            &#47&#47 if min_studies_per_voxel is not None:
            &#47&#47     logger.info("Selecting voxels with more than %d studies." % min_studies_per_voxel)
            &#47&#47     data = data[active_vox, :]

            &#47&#47 if min_voxels_per_study is not None:
            &#47&#47     logger.info("Selecting studies with more than %d voxels." % min_voxels_per_study)
            &#47&#47     data = data[:, active_studies]

            self.data = data

        else:
            self.data = dataset

            if global_mask is None:
                raise ValueError("If dataset is a numpy array, a valid global_mask (filename, " +
                    "Mask instance, or nibabel image) must be passed.")

       </a> if not isinstance(global_mask, Masker):
            global_mask = Masker(global_mask)
        
        self.masker = global_mask</code></pre><h3>After Change</h3><pre><code class='java'>
        else:
            data = self.dataset.get_image_data()

        <a id="change">if min_studies_per_voxel is not None:
            logger.info("Thresholding voxels based on number of studies.")
            sum_vox = data.sum(1)
            &#47&#47 Save the indices for later reconstruction
            active_vox = sum_vox &gt; min_studies_per_voxel
            &#47&#47 n_active_vox = active_vox.shape[0]
            av = self.masker.unmask(active_vox, output=&quotvector&quot)
            self.masker.add(av)

            &#47&#47 if min_voxels_per_study is not None:
            &#47&#47     logger.info("Thresholding studies based on number of voxels.")
            &#47&#47     sum_studies = data.sum(0)
            &#47&#47     active_studies = np.where(sum_studies &gt; min_voxels_per_study)[0]
            &#47&#47     n_active_studies = active_studies.shape[0]

            &#47&#47 if min_studies_per_voxel is not None:
            &#47&#47     logger.info("Selecting voxels with more than %d studies." % min_studies_per_voxel)
            &#47&#47     data = data[active_vox, :]

            &#47&#47 if min_voxels_per_study is not None:
            &#47&#47     logger.info("Selecting studies with more than %d voxels." % min_voxels_per_study)
            &#47&#47     data = data[:, active_studies]

       </a> self.data = data

        if distance_mask is not None:
            self.masker.add(distance_mask)</code></pre><img src="186593054.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/neurosynth/neurosynth/commit/edb300280cd7854bb58e023d01ac24160bf6d98d#diff-6412c2f1b7e394a70384cc7119ba57a57c9dcc8385b18c3bd532757c251fdf0dL22' target='_blank'>Link</a></div><div id='project'> Project Name: neurosynth/neurosynth</div><div id='commit'> Commit Name: edb300280cd7854bb58e023d01ac24160bf6d98d</div><div id='time'> Time: 2014-11-07</div><div id='author'> Author: tyarkoni@gmail.com</div><div id='file'> File Name: neurosynth/analysis/cluster.py</div><div id='class'> Class Name: Clusterer</div><div id='method'> Method Name: __init__</div><BR><BR><div id='link'><a href='https://github.com/google/deepvariant/commit/7ed8c6bbcfb2dc0da9b1011ba21d12791239de79#diff-83516db48608c72884f492e81e70763b4fe1d07753bedef491563cdbef078be7L953' target='_blank'>Link</a></div><div id='project'> Project Name: google/deepvariant</div><div id='commit'> Commit Name: 7ed8c6bbcfb2dc0da9b1011ba21d12791239de79</div><div id='time'> Time: 2019-10-21</div><div id='author'> Author: gunjanbaid@google.com</div><div id='file'> File Name: deepvariant/postprocess_variants.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: main</div><BR><BR><div id='link'><a href='https://github.com/biolab/orange3/commit/976f9ea013348f6885114f0dae092e03dd0d1022#diff-cfe228ce938ea8cfbaba84bca5acaea1ef9f171d4a543f4187d9f222ef8f0a11L1644' target='_blank'>Link</a></div><div id='project'> Project Name: biolab/orange3</div><div id='commit'> Commit Name: 976f9ea013348f6885114f0dae092e03dd0d1022</div><div id='time'> Time: 2018-08-02</div><div id='author'> Author: rafael@irgolic.com</div><div id='file'> File Name: Orange/canvas/document/schemeedit.py</div><div id='class'> Class Name: SchemeEditWidget</div><div id='method'> Method Name: __nodeInsert</div><BR>