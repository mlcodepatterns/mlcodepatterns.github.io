<html><h3>3128e13109c8766eafb413f2428bba976701e929,beginner_source/transformer_tutorial.py,,,#,295
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
&#47&#47 Loop over epochs. Save the model if the validation loss is the best
&#47&#47 we&quotve seen so far. Adjust the learning rate after each epoch.

<a id="change">best_val_loss = float("inf")</a>
epochs = 3 &#47&#47 The number of epochs
best_model = None

<a id="change">for epoch in range(1, epochs + 1):
    epoch_start_time = time.time()
    train()
    val_loss = evaluate(model, val_data)
    print(&quot-&quot * 89)
    print(&quot| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | &quot
          &quotvalid ppl {:8.2f}&quot.format(epoch, (time.time() - epoch_start_time),
                                     val_loss, math.exp(val_loss)))
    print(&quot-&quot * 89)

    if val_loss &lt; best_val_loss:
        best_val_loss = val_loss
        best_model = model

    scheduler.step()


&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47
&#47&#47 Evaluate the model with the test dataset
&#47&#47 -------------------------------------
&#47&#47
&#47&#47 Apply the best model to check the result with the test dataset.

</a>test_loss = evaluate(best_model, test_data)
print(&quot=&quot * 89)
print(&quot| End of training | test loss {:5.2f} | test ppl {:8.2f}&quot.format(
    test_loss, math.exp(test_loss)))</code></pre><h3>After Change</h3><pre><code class='java'>

ntokens = len(vocab.stoi) &#47&#47 the size of vocabulary
emsize = 200 &#47&#47 embedding dimension
<a id="change">nhid = 200</a> &#47&#47 the dimension of the feedforward network model in nn.TransformerEncoder
nlayers = 2 &#47&#47 the number of nn.TransformerEncoderLayer in nn.TransformerEncoder
nhead = 2 &#47&#47 the number of heads in the multiheadattention models
dropout = 0.2 &#47&#47 the dropout value
<a id="change">model</a> = TransformerModel(ntokens, emsize, nhead, nhid, nlayers, dropout).to(device)


&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47
&#47&#47 Run the model
&#47&#47 -------------
&#47&#47


&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47
&#47&#47 `CrossEntropyLoss &lt;https://pytorch.org/docs/master/nn.html?highlight=crossentropyloss&#47&#47torch.nn.CrossEntropyLoss&gt;`__
&#47&#47 is applied to track the loss and
&#47&#47 `SGD &lt;https://pytorch.org/docs/master/optim.html?highlight=sgd&#47&#47torch.optim.SGD&gt;`__
&#47&#47 implements stochastic gradient descent method as the optimizer. The initial
&#47&#47 learning rate is set to 5.0. `StepLR &lt;https://pytorch.org/docs/master/optim.html?highlight=steplr&#47&#47torch.optim.lr_scheduler.StepLR&gt;`__ is
&#47&#47 applied to adjust the learn rate through epochs. During the
&#47&#47 training, we use
&#47&#47 `nn.utils.clip_grad_norm\_ &lt;https://pytorch.org/docs/master/nn.html?highlight=nn%20utils%20clip_grad_norm&#47&#47torch.nn.utils.clip_grad_norm_&gt;`__
&#47&#47 function to scale all the gradient together to prevent exploding.
&#47&#47

criterion = nn.CrossEntropyLoss()
lr = 5.0 &#47&#47 learning rate
<a id="change">optimizer = torch.optim.SGD(model.parameters(), lr=lr)</a>
scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)

import time
def train():</code></pre><img src="226057849.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 24</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/pytorch/tutorials/commit/3128e13109c8766eafb413f2428bba976701e929#diff-bb6ac9de5f0e95bba9a48afcd9234956764fda31eeb5744e34ac76caf313bd48L225' target='_blank'>Link</a></div><div id='project'> Project Name: pytorch/tutorials</div><div id='commit'> Commit Name: 3128e13109c8766eafb413f2428bba976701e929</div><div id='time'> Time: 2020-12-02</div><div id='author'> Author: 6156351+zhangguanheng66@users.noreply.github.com</div><div id='file'> File Name: beginner_source/transformer_tutorial.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: </div><BR><BR><div id='link'><a href='https://github.com/pytorch/tutorials/commit/3128e13109c8766eafb413f2428bba976701e929#diff-bb6ac9de5f0e95bba9a48afcd9234956764fda31eeb5744e34ac76caf313bd48L295' target='_blank'>Link</a></div><div id='project'> Project Name: pytorch/tutorials</div><div id='commit'> Commit Name: 3128e13109c8766eafb413f2428bba976701e929</div><div id='time'> Time: 2020-12-02</div><div id='author'> Author: 6156351+zhangguanheng66@users.noreply.github.com</div><div id='file'> File Name: beginner_source/transformer_tutorial.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: </div><BR><BR><div id='link'><a href='https://github.com/jindongwang/transferlearning/commit/376b01c2e338ec63e638f62a76d67f6a9323e47c#diff-c34d59512d21510b260b855fe4ad7ad06200765ef8696aeda8d4e0a794a97c94L109' target='_blank'>Link</a></div><div id='project'> Project Name: jindongwang/transferlearning</div><div id='commit'> Commit Name: 376b01c2e338ec63e638f62a76d67f6a9323e47c</div><div id='time'> Time: 2019-08-14</div><div id='author'> Author: jindongwang@outlook.com</div><div id='file'> File Name: code/deep/DeepCoral/DeepCoral.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: </div><BR><BR><div id='link'><a href='https://github.com/rusty1s/pytorch_geometric/commit/e2db3b3f1d3d23cd5bc1e295835e0f4b33e95447#diff-82556a6907b6c5ac8cfa2f65bd9fb14b506a7bd651d71d8bc93415de5f40928cL57' target='_blank'>Link</a></div><div id='project'> Project Name: rusty1s/pytorch_geometric</div><div id='commit'> Commit Name: e2db3b3f1d3d23cd5bc1e295835e0f4b33e95447</div><div id='time'> Time: 2018-03-07</div><div id='author'> Author: matthias.fey@tu-dortmund.de</div><div id='file'> File Name: examples/cora_gcn.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: </div><BR>