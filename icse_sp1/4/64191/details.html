<html><h3>4c13ae9d17d1709ed7a777ce1bb72212e8d2559d,tests/python/frontend/pytorch/test_object_detection.py,,test_detection_models,#,88
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    download(img_url, img)

    input_shape = (1, 3, in_size, in_size)
    <a id="change">target = "llvm"</a>
    input_name = "input0"
    shape_list = [(input_name, input_shape)]
    score_threshold = 0.9

    scripted_model = generate_jit_model(1)
    mod, params = relay.frontend.from_pytorch(scripted_model, shape_list)

    with tvm.transform.PassContext(opt_level=3, disabled_pass=["FoldScaleAxis"]):
        vm_exec = relay.vm.compile(mod, target=target, params=params)

    ctx = tvm.cpu()
    vm = VirtualMachine(vm_exec, ctx)
    data = process_image(img)
    pt_res = scripted_model(data)
    data = data.detach().numpy()
    vm.set_input("main", **{input_name: data})
    tvm_res = vm.run()

    &#47&#47 Note: due to accumulated numerical error, we can&quott directly compare results
    &#47&#47 with pytorch output. Some boxes might have a quite tiny difference in score
    &#47&#47 and the order can become different. We just measure how many valid boxes
    &#47&#47 there are for input image.
    pt_scores = pt_res[1].detach().numpy().tolist()
    tvm_scores = <a id="change">tvm_res</a>[1].asnumpy().tolist()
    num_pt_valid_scores = num_tvm_valid_scores = 0

    for score in pt_scores:</code></pre><h3>After Change</h3><pre><code class='java'>
    with torch.no_grad():
        pt_res = scripted_model(data)

    <a id="change">for target in ["llvm", "cuda"]:
        with tvm.transform.PassContext(opt_level=3):
            vm_exec = relay.vm.compile(mod, target=target, params=params)

        ctx = tvm.context(target, 0)
        vm = VirtualMachine(vm_exec, ctx)

        vm.set_input("main", **{input_name: data_np})
        tvm_res = vm.run()

        &#47&#47 Bounding boxes
        tvm.testing.assert_allclose(
            pt_res[0].cpu().numpy(), tvm_res[0].asnumpy(), rtol=1e-5, atol=1e-5
        )
        &#47&#47 Scores
        tvm.testing.assert_allclose(
            pt_res[1].cpu().numpy(), tvm_res[1].asnumpy(), rtol=1e-5, atol=1e-5
        )
        &#47&#47 Class ids
        np.testing.assert_equal(pt_res[2].cpu().numpy(), tvm_res[2].asnumpy())

        score_threshold = 0.9
        print("Num boxes:", pt_res[0].cpu().numpy().shape[0])
        print("Num valid boxes:", np.sum(pt_res[1].cpu().numpy() &gt;= score_threshold))</a>
</code></pre><img src="295620860.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/apache/incubator-tvm/commit/4c13ae9d17d1709ed7a777ce1bb72212e8d2559d#diff-06a26abfd301e8efac4e49e010e107daacf9ca500766ed1038bb516d62710bc9L97' target='_blank'>Link</a></div><div id='project'> Project Name: apache/incubator-tvm</div><div id='commit'> Commit Name: 4c13ae9d17d1709ed7a777ce1bb72212e8d2559d</div><div id='time'> Time: 2020-12-25</div><div id='author'> Author: masahi129@gmail.com</div><div id='file'> File Name: tests/python/frontend/pytorch/test_object_detection.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: test_detection_models</div><BR><BR><div id='link'><a href='https://github.com/dmlc/gluon-nlp/commit/5ea0c27f524a3e684d9a2e6f012e30e6da2de8aa#diff-bb03b248700d5d22a6c071289e20db45957077dacee931ca432894a61c7779b5L339' target='_blank'>Link</a></div><div id='project'> Project Name: dmlc/gluon-nlp</div><div id='commit'> Commit Name: 5ea0c27f524a3e684d9a2e6f012e30e6da2de8aa</div><div id='time'> Time: 2019-06-18</div><div id='author'> Author: linhaibin.eric@gmail.com</div><div id='file'> File Name: scripts/bert/finetune_classifier.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: test</div><BR><BR><div id='link'><a href='https://github.com/dmlc/gluon-cv/commit/ee602b6f68f0bdd19f449a86955697f8f0a2d54c#diff-c3f3262beb83a68fced6fa61c99a0759b0bcb2121f78b3182958b7fa90240b95L199' target='_blank'>Link</a></div><div id='project'> Project Name: dmlc/gluon-cv</div><div id='commit'> Commit Name: ee602b6f68f0bdd19f449a86955697f8f0a2d54c</div><div id='time'> Time: 2019-09-21</div><div id='author'> Author: yizhu59@gmail.com</div><div id='file'> File Name: gluoncv/data/transforms/video.py</div><div id='class'> Class Name: VideoMultiScaleCrop</div><div id='method'> Method Name: forward</div><BR>