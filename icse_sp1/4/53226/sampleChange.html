<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 This will make it faster when we reconstruct the LazyTensor inside functions
        with torch.no_grad():
            if solves is None:
                solves = <a id="change">[
                    base_lazy_tensor._solve(eager_rhs, base_lazy_tensor._preconditioner()[0])
                    for eager_rhs in eager_rhss
                ]</a>

        super(CachedCGLazyTensor, self).__init__(
            base_lazy_tensor, eager_rhss=eager_rhss, solves=solves,
        )</code></pre><h3>After Change</h3><pre><code class='java'>
                all_solves = base_lazy_tensor._solve(torch.cat(eager_rhss, -1), base_lazy_tensor._preconditioner()[0])
                solves = []
                for eager_rhs in eager_rhss:
                    <a id="change">solve = all_solves[..., :eager_rhs.size(-1)]</a>
                    all_solves = all_solves[..., eager_rhs.size(-1):]
                    solves.append(<a id="change">solve.detach()</a>)  &#47&#47 The detach is necessary here for some reason?

        super(CachedCGLazyTensor, self).__init__(
            base_lazy_tensor, eager_rhss=eager_rhss, solves=solves,</code></pre>