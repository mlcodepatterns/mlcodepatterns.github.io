<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            saver.save(self.session, output_file)

    def train_batch(self, x, len_x, y):
        <a id="change">return self.session.run(
            [self.loss, self.train_op, self.logits, self.output_seq_len, self.cer, self.decoded],
            feed_dict={
                self.inputs: x,
                self.input_seq_len: len_x,
                self.targets: y,
                self.dropout_rate: self.network_proto.dropout,
            }
        )</a>

    def train_dataset(self):
        return self.session.run(
            [self.loss, self.train_op, self.logits, self.output_seq_len, self.cer, self.decoded, self.targets],</code></pre><h3>After Change</h3><pre><code class='java'>
            saver.save(self.session, output_file)

    def train_batch(self, x, len_x, y):
        <a id="change">out = self.session.run(
            [self.loss, self.train_op, self.logits, self.output_seq_len, self.cer, self.decoded],
            feed_dict={
                self.inputs: x,
                self.input_seq_len: len_x,
                self.targets: y,
                self.dropout_rate: self.network_proto.dropout,
            }
        )</a>

        <a id="change">if np.isfinite(out[0]):
            &#47&#47 only update gradients if finite loss
            self.session.run(
                [self.train_op],
                feed_dict={
                    self.inputs: x,
                    self.input_seq_len: len_x,
                    self.targets: y,
                    self.dropout_rate: self.network_proto.dropout,
                }
            )
        else:
            print("WARNING: Infinite loss. Skipping batch.", file=sys.stderr)

       </a> return out

    def train_dataset(self):
        out = self.session.run(</code></pre>