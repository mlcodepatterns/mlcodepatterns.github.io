<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 Instantiate a Tensorforce agent
        agent = Agent.create(
            agent=&quottensorforce&quot,
            states=<a id="change">dict(type=&quotfloat&quot, shape=(10,))</a>,
            actions=dict(type=&quotint&quot, num_values=5),
            max_episode_timesteps=100,
            memory=10000,
            update=dict(unit=&quottimesteps&quot, batch_size=64),
            optimizer=dict(type=&quotadam&quot, learning_rate=3e-4),
            policy=dict(network=&quotauto&quot),
            objective=&quotpolicy_gradient&quot,
            reward_estimation=dict(horizon=20)
        )

        &#47&#47 Retrieve the latest (observable) environment state
        state = get_current_state()  &#47&#47 (float array of shape [10])

        &#47&#47 Query the agent for its action decision
        <a id="change">action = agent.act(states=state)</a>  &#47&#47 (scalar between 0 and 4)

        &#47&#47 Execute the decision and retrieve the current performance score
        reward = execute_decision(action)  &#47&#47 (any scalar float)</code></pre><h3>After Change</h3><pre><code class='java'>
        from tensorforce import Agent, Environment

        &#47&#47 Pre-defined or custom environment
        environment = <a id="change">Environment.create(
            environment=&quotgym&quot, level=&quotCartPole&quot, max_episode_timesteps=500
        )</a>

        &#47&#47 Instantiate a Tensorforce agent
        agent = Agent.create(
            agent=&quottensorforce&quot,
            environment=environment,  &#47&#47 alternatively: states, actions, (max_episode_timesteps)
            memory=1000,
            update=dict(unit=&quottimesteps&quot, batch_size=64),
            optimizer=dict(type=&quotadam&quot, learning_rate=3e-4),
            policy=dict(network=&quotauto&quot),
            objective=&quotpolicy_gradient&quot,
            reward_estimation=dict(horizon=20)
        )

        &#47&#47 Train for 300 episodes
        for _ in range(1):

            &#47&#47 Initialize episode
            states = environment.reset()
            terminal = False

            while not terminal:
                &#47&#47 Episode timestep
                actions = agent.act(states=states)
                <a id="change">states, terminal, reward = environment.execute(actions=actions)</a>
                agent.observe(terminal=terminal, reward=reward)

        agent.close()
        environment.close()</code></pre>