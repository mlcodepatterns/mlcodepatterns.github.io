<html><h3>d000bae3a03681b11818e98c29a64a145e0ff1ec,torchsample/modules/example.py,,,#,10
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
x_train = x_train / 255.
x_test = x_test / 255.
x_train = np.expand_dims(x_train,1).astype(&quotfloat32&quot)
x_test = <a id="change">np.expand_dims(x_test,1).astype(&quotfloat32&quot)</a>

x_train = torch.from_numpy(x_train[:10000])
y_train = torch.from_numpy(y_train[:10000])
x_test = torch.from_numpy(x_test[:1000])</code></pre><h3>After Change</h3><pre><code class='java'>

x_train = x_train / 255.
x_test = x_test / 255.
x_train = <a id="change">x_train.unsqueeze(1)</a>
x_test = x_test.unsqueeze(1)

&#47&#47 only train on a subset
x_train = x_train[:10000]</code></pre><img src="103614617.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 2</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/ncullen93/torchsample/commit/d000bae3a03681b11818e98c29a64a145e0ff1ec#diff-b4f84b9f28f1d3a2885bae70d289f948674449833702a16532ffefe76ea41ae9L10' target='_blank'>Link</a></div><div id='project'> Project Name: ncullen93/torchsample</div><div id='commit'> Commit Name: d000bae3a03681b11818e98c29a64a145e0ff1ec</div><div id='time'> Time: 2017-04-20</div><div id='author'> Author: ncullen@modv-vlan533.0018.apn.wlan.med.upenn.edu</div><div id='file'> File Name: torchsample/modules/example.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: </div><BR><BR><div id='link'><a href='https://github.com/allenai/allennlp/commit/e2f66c0de2600308044ec3ab7731dae9017378fa#diff-72a902ff76f96299e4f6d2c9193247f8bf888111e493471d67f902165b62baefL42' target='_blank'>Link</a></div><div id='project'> Project Name: allenai/allennlp</div><div id='commit'> Commit Name: e2f66c0de2600308044ec3ab7731dae9017378fa</div><div id='time'> Time: 2018-12-20</div><div id='author'> Author: vidurj@allenai.org</div><div id='file'> File Name: allennlp/modules/seq2seq_encoders/bidirectional_language_model_transformer.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: subsequent_mask</div><BR><BR><div id='link'><a href='https://github.com/jadore801120/attention-is-all-you-need-pytorch/commit/bed0a0ae26451c9897cf1ee0f7302e42eba9b42c#diff-a6a596f1b879b5a9b6619ca2e20a4a5ec1725229f46a2e80291aa2a89ef6dc5cL34' target='_blank'>Link</a></div><div id='project'> Project Name: jadore801120/attention-is-all-you-need-pytorch</div><div id='commit'> Commit Name: bed0a0ae26451c9897cf1ee0f7302e42eba9b42c</div><div id='time'> Time: 2018-08-23</div><div id='author'> Author: yhhuang@nlg.csie.ntu.edu.tw</div><div id='file'> File Name: transformer/Models.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: get_attn_subsequent_mask</div><BR>