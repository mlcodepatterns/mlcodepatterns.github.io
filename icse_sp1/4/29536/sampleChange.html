<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

    def _test_forward_per_tensor_cachemask_impl(self, device):
        for torch_type in (torch.qint8, torch.quint8):
            <a id="change">X = torch.randn(4, 8).to(device)</a>
            &#47&#47 pick the scale + zp so that some values get clipped
            obs = torch.quantization.MinMaxObserver(torch_type)
            obs(X * 0.75)
            scale, zero_point = obs.calculate_qparams()</code></pre><h3>After Change</h3><pre><code class='java'>

    def _test_forward_per_tensor_cachemask_impl(self, device):
        for torch_type in (torch.qint8, torch.quint8):
            <a id="change">Xs = (torch.randn(4, 8, device=device), torch.randn(4, 16, device=device)[:, ::2])</a>
            &#47&#47 pick the scale + zp so that some values get clipped
            <a id="change">for X in Xs:
                obs = torch.quantization.MinMaxObserver(torch_type)
                obs(X * 0.75)
                scale, zero_point = obs.calculate_qparams()
                scale, zero_point = float(scale), int(zero_point)
                quant_min, quant_max = obs._calculate_qmin_qmax()

                Y_test, _mask = torch.fake_quantize_per_tensor_affine_cachemask(
                    X, scale, zero_point, quant_min, quant_max)
                Y_ref = _fake_quantize_per_tensor_affine_reference(
                    X.cpu(), scale, zero_point, quant_min, quant_max).to(device)
                self.assertTrue(torch.allclose(Y_test, Y_ref, rtol=tolerance, atol=tolerance))

   </a> def test_forward_per_tensor_cachemask_cpu(self):
        device = torch.device(&quotcpu&quot)
        self._test_forward_per_tensor_cachemask_impl(device)
</code></pre>