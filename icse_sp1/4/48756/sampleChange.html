<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

            self.loss = -tf.reduce_prod(self.pdf_)
            self.log_loss = -tf.reduce_sum(self.log_pdf_)
            self.train_step = <a id="change">tf</a>.train.AdamOptimizer().minimize(self.log_loss)

        &#47&#47 initialize LayersPowered -&gt; provides functions for serializing tf models
        LayersPowered.__init__(self, [self.layer_in_y, core_network.output_layer])</code></pre><h3>After Change</h3><pre><code class='java'>
            self.loss = -tf.reduce_prod(self.pdf_)
            self.log_loss = -tf.reduce_sum(self.log_pdf_)

            <a id="change">optimizer = tf.train.AdamOptimizer()</a>
            if self.gradient_clipping:
                gradients, variables = zip(*optimizer.compute_gradients(self.log_loss))
                gradients, _ = tf.clip_by_global_norm(gradients, 3e5)
                self.train_step = optimizer.apply_gradients(zip(gradients, variables))
            else:
                <a id="change">self.train_step = optimizer.minimize(self.log_loss)</a>

        &#47&#47 initialize LayersPowered -&gt; provides functions for serializing tf models
        LayersPowered.__init__(self, [self.layer_in_y, core_network.output_layer])
</code></pre>