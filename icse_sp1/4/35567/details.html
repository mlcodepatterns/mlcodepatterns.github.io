<html><h3>faf3aa876462323f2fa721ebd633752d6489808f,sru/modules.py,SRU,forward,#SRU#Any#Any#Any#,536
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        orig_input = input
        if isinstance(orig_input, PackedSequence):
            input, batch_sizes, sorted_indices, unsorted_indices = input
            <a id="change">length = input.size(0)</a>
            batch_size = input.size(1)
            <a id="change">mask_pad = torch.arange(batch_size,
                                    device=batch_sizes.device).expand(length, batch_size)</a>
            mask_pad = (mask_pad &gt;= batch_sizes.view(length, 1)).contiguous()
        else:
            length = input.size(0)
            batch_size = input.size(1)</code></pre><h3>After Change</h3><pre><code class='java'>
            input, lengths = nn.utils.rnn.pad_packed_sequence(input)
            max_length = lengths.max().item()
            mask_pad = torch.ByteTensor([[0] * l + [1] * (max_length - l) for l in lengths.tolist()])
            mask_pad = <a id="change">mask_pad</a>.to(input.device).transpose(0, 1).contiguous()

        &#47&#47 The dimensions of `input` should be: `(sequence_length, batch_size, input_size)`.
        if input.dim() != 3:</code></pre><img src="172914095.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/asappresearch/sru/commit/faf3aa876462323f2fa721ebd633752d6489808f#diff-fbdb17c4f9a1012308449ed128e27fceac2cd837fa198a5afc3ef73ed9cd6d0cL1' target='_blank'>Link</a></div><div id='project'> Project Name: asappresearch/sru</div><div id='commit'> Commit Name: faf3aa876462323f2fa721ebd633752d6489808f</div><div id='time'> Time: 2020-09-18</div><div id='author'> Author: taolei@csail.mit.edu</div><div id='file'> File Name: sru/modules.py</div><div id='class'> Class Name: SRU</div><div id='method'> Method Name: forward</div><BR><BR><div id='link'><a href='https://github.com/cornellius-gp/gpytorch/commit/91b0d220c8e816766fd4565e1d2f5115d3afbefe#diff-0a5f1b492443f1d45fea644563c842fd31a4a480824e8ed0c9f9ce825fe7f039L408' target='_blank'>Link</a></div><div id='project'> Project Name: cornellius-gp/gpytorch</div><div id='commit'> Commit Name: 91b0d220c8e816766fd4565e1d2f5115d3afbefe</div><div id='time'> Time: 2018-10-12</div><div id='author'> Author: gpleiss@gmail.com</div><div id='file'> File Name: gpytorch/lazy/lazy_tensor.py</div><div id='class'> Class Name: LazyTensor</div><div id='method'> Method Name: evaluate</div><BR><BR><div id='link'><a href='https://github.com/cornellius-gp/gpytorch/commit/60a342edc8b501802135df44869353cc8604d838#diff-b110adb1897838e27a3903e77c9061e1f5378089b0e617fd7e95ea8489b61282L14' target='_blank'>Link</a></div><div id='project'> Project Name: cornellius-gp/gpytorch</div><div id='commit'> Commit Name: 60a342edc8b501802135df44869353cc8604d838</div><div id='time'> Time: 2018-01-11</div><div id='author'> Author: gpleiss@gmail.com</div><div id='file'> File Name: gpytorch/kernels/rbf_kernel.py</div><div id='class'> Class Name: RBFKernel</div><div id='method'> Method Name: forward</div><BR>