<html><h3>5fa1d7aea2c89fdfa15a688aa413ea49a480ab38,examples/pytorch_imagenet_resnet50.py,,,#,17
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

&#47&#47 Horovod: scale learning rate by the number of GPUs.
&#47&#47 Gradient Accumulation: scale learning rate by batches_per_allreduce
optimizer = <a id="change">optim.SGD(model.parameters(),
                      lr=(args.base_lr *
                          args.batches_per_allreduce * hvd.size()),
                      momentum=args.momentum, weight_decay=args.wd)</a>

&#47&#47 Horovod: (optional) compression algorithm.
compression = hvd.Compression.fp16 if args.fp16_allreduce else hvd.Compression.none
</code></pre><h3>After Change</h3><pre><code class='java'>
        lr_scaler = args.batches_per_allreduce * hvd.local_size()

&#47&#47 Horovod: scale learning rate by the number of GPUs.
<a id="change">optimizer = optim.SGD(model.parameters(),
                      lr=(args.base_lr *
                          lr_scaler),
                      momentum=args.momentum, weight_decay=args.wd)</a>

&#47&#47 Horovod: (optional) compression algorithm.
compression = hvd.Compression.fp16 if args.fp16_allreduce else hvd.Compression.none

&#47&#47 Horovod: wrap optimizer with DistributedOptimizer.
<a id="change">optimizer</a> = hvd.DistributedOptimizer(
    optimizer, named_parameters=model.named_parameters(),
    compression=compression,
    backward_passes_per_step=args.batches_per_allreduce,</code></pre><img src="152368741.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/horovod/horovod/commit/5fa1d7aea2c89fdfa15a688aa413ea49a480ab38#diff-19a5fa9b14aac49ae8de1f5bc85e046f7959f5d60ae3c3575533ff98fc6d2f5fL17' target='_blank'>Link</a></div><div id='project'> Project Name: horovod/horovod</div><div id='commit'> Commit Name: 5fa1d7aea2c89fdfa15a688aa413ea49a480ab38</div><div id='time'> Time: 2019-11-25</div><div id='author'> Author: tix@microsoft.com</div><div id='file'> File Name: examples/pytorch_imagenet_resnet50.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: </div><BR><BR><div id='link'><a href='https://github.com/deepgram/kur/commit/45406badf091b037f871a1efae3fbdd663b9cef7#diff-aa20cad93385d71e5fece42e440e7a07769cd73241a5086e75763765d16a21b1L46' target='_blank'>Link</a></div><div id='project'> Project Name: deepgram/kur</div><div id='commit'> Commit Name: 45406badf091b037f871a1efae3fbdd663b9cef7</div><div id='time'> Time: 2017-01-18</div><div id='author'> Author: ajsyp@syptech.net</div><div id='file'> File Name: kur/optimizer/sgd.py</div><div id='class'> Class Name: SGD</div><div id='method'> Method Name: get_optimizer</div><BR><BR><div id='link'><a href='https://github.com/dpressel/mead-baseline/commit/ad39d509e04a5aa00462e441ec31ca1b24f15491#diff-1e078b2f034d4fad1c6ab10e44c115f386725929adfa66292238e22ca129ecdbL19' target='_blank'>Link</a></div><div id='project'> Project Name: dpressel/mead-baseline</div><div id='commit'> Commit Name: ad39d509e04a5aa00462e441ec31ca1b24f15491</div><div id='time'> Time: 2018-06-29</div><div id='author'> Author: dpressel@gmail.com</div><div id='file'> File Name: python/baseline/pytorch/classify/train.py</div><div id='class'> Class Name: ClassifyTrainerPyTorch</div><div id='method'> Method Name: __init__</div><BR>