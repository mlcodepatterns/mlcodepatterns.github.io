<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            net = self.progressive_enhancement(config, net, xg)

            depth = filters + depth_increase
            <a id="change">if i == 0:
                depth = config.initial_depth

           </a> print("NET IS", net, depth, layers)
            net = config.block(self, net, depth)

            print(&quot[discriminator] layer&quot, net)</code></pre><h3>After Change</h3><pre><code class='java'>

        net = self.add_noise(net)

        net = <a id="change">config.block(self, net, config.initial_depth or 64)</a>
        for i in range(layers):
            xg = None
            is_last_layer = (i == layers-1)
            filters = ops.shape(net)[3]
            net = activation(net)
            &#47&#47TODO better name for `batch_norm`?
            net = self.layer_regularizer(net)

            &#47&#47 APPEND xs[i] and gs[i]
            &#47&#47if not is_last_layer:
            &#47&#47    shape = ops.shape(net)
            &#47&#47    small_x = ops.resize_images(x, [shape[1], shape[2]], 1)
            &#47&#47    small_g = ops.resize_images(g, [shape[1], shape[2]], 1)
            &#47&#47    xg = self.combine_filter(config, small_x, small_g)
            &#47&#47    xg = self.add_noise(xg)

            net = self.progressive_enhancement(config, net, xg)

            depth = filters + depth_increase
            print("NET IS", net, depth, layers)
            net = config.block(self, net, depth)

            print(&quot[discriminator] layer&quot, net)

        for i in range(config.extra_layers or 0):
            output_features = int(int(net.get_shape()[3]))
            net = activation(net)
            net = ops.conv2d(net, 3, 3, 1, 1, output_features//config.extra_layers_reduction)
            print(&quot[extra discriminator] layer&quot, net)
        k=-1

        if config.relation_layer:
            net = activation(net)
            net = self.layer_regularizer(net)
            net = self.relation_layer(net)

        net = tf.reshape(net, [ops.shape(net)[0], -1])

        if final_activation or (config.fc_layers or 0) &gt; 0:
            net = self.layer_regularizer(net)

        for i in range(config.fc_layers or 0):
            net = self.layer_regularizer(net)
            <a id="change">net = activation(net)</a>
            net = ops.linear(net, config.fc_layer_size or 300)
            net = self.layer_regularizer(net)

        if final_activation:</code></pre>