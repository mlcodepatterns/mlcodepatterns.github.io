<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
  &#47&#47 Reimplement this when TPU training summaries are supported.
  lr_repeat = tf.reshape(
      tf.tile(tf.expand_dims(learning_rate, 0), [params[&quotbatch_size&quot],]),
      [<a id="change">params[&quotbatch_size&quot]</a>, 1])
  ce_repeat = tf.reshape(
      tf.tile(tf.expand_dims(current_epoch, 0), [params[&quotbatch_size&quot],]),
      [params[&quotbatch_size&quot], 1])</code></pre><h3>After Change</h3><pre><code class='java'>
    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)

  &#47&#47 Calculate loss, which includes softmax cross entropy and L2 regularization.
  <a id="change">one_hot_labels = tf.one_hot(labels, _LABEL_CLASSES)</a>
  cross_entropy = tf.losses.softmax_cross_entropy(
      logits=logits, onehot_labels=one_hot_labels)

  &#47&#47 Add weight decay to the loss. We exclude weight decay on the batch</code></pre>