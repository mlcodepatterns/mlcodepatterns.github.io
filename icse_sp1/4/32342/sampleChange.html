<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        with self._shared_name_scope(&quotaggregated&quot):
          with tf.name_scope(&quotgradient&quot):
            loss = tf.add_n(gradient_costs)
          <a id="change">with tf.name_scope(&quotold_cost&quot):
            old_loss = tf.add_n(old_costs)

          &#47&#47 weight decay
         </a> if model_params["penalty"] != 0.0:
            penalty = model_ops.WeightDecay(model_params)
            loss += penalty
            old_loss += penalty</code></pre><h3>After Change</h3><pre><code class='java'>
              &#47&#47 calculate with div/sum so it stays on the GPU.
              print("model_params[&quotbatch_size&quot]")
              print(model_params[&quotbatch_size&quot])
              <a id="change">print("weighted_cost")</a>
              print(weighted_cost)
              gradient_cost = tf.div(tf.reduce_sum(weighted_cost),
                                     model_params["batch_size"])
              gradient_costs.append(gradient_cost)</code></pre>