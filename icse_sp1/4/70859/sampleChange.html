<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    &#47&#47 TODO: Doesn&quott make much sense over training data, averaging with initial
    &#47&#47 (bad) predictions.
    auc, update_auc_op = tf.metrics.auc(labels, logits, curve=&quotPR&quot)
    <a id="change">tf.add_to_collection(&quotmetric_ops&quot, update_auc_op)</a>
    tf.add_to_collection(&quotmetrics&quot, auc)
    tf.summary.scalar(&quotauc&quot, auc)

</code></pre><h3>After Change</h3><pre><code class='java'>
    normalized_logits = tf.sigmoid(logits)

    &#47&#47 Add one AUC metric per class, so we can see individual performance too.
    <a id="change">for cls in range(logits.shape[1]):
        auc, _ = tf.metrics.auc(
            labels[:, cls], normalized_logits[:, cls],
            curve=&quotPR&quot, name=f&quotiauc/{cls}&quot,
            metrics_collections=&quotmetrics&quot,
            updates_collections=&quotmetric_ops&quot,
        )
        tf.summary.scalar(f&quotiauc/{cls}&quot, auc)

   </a> auc, _ = tf.metrics.auc(
        labels, normalized_logits,
        curve=&quotPR&quot, name=&quotauc&quot,
        metrics_collections=&quotmetrics&quot,</code></pre>