<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
          + &quot adversarial examples&quot)

    &#47&#47 Keep track of success (adversarial example classified in target)
    <a id="change">results = np.zeros((nb_classes, source_samples), dtype=&quoti&quot)</a>

    &#47&#47 Rate of perturbed features for each test set example and target class
    perturbations = np.zeros((nb_classes, source_samples), dtype=&quotf&quot)
</code></pre><h3>After Change</h3><pre><code class='java'>
    idxs = [np.where(np.argmax(Y_test,axis=1)==i)[0][0] for i in range(10)]
    adv_inputs = np.array([[x]*10 for x in X_test[idxs]]).reshape((100,28,28,1))
    adv_ys = np.array([onehot(range(10),10) for x in range(10)]).reshape((100,10))
    adv = <a id="change">cw.generate_np(adv_inputs, adv_ys, **cw_params)</a>

    adv_accuracy = model_eval(sess, x, y, preds, adv, adv_ys, args={&quotbatch_size&quot: 100})

    for j in range(10):
        for i in range(10):
            grid_viz_data[i,j] = adv[i*10+j]
    
    print(&quot--------------------------------------&quot)

    &#47&#47 Compute the number of adversarial examples that were successfully found
    print(&quotAvg. rate of successful adv. examples {0:.4f}&quot.format(adv_accuracy))
    report.clean_train_adv_eval = adv_accuracy

    &#47&#47 Compute the average distortion introduced by the algorithm
    <a id="change">percent_perturbed = np.mean(np.sum((adv-adv_inputs)**2,axis=(1,2,3))**.5)</a>
    print(&quotAvg. L_2 norm of perturbations {0:.4f}&quot.format(percent_perturbed))

    &#47&#47 Close TF session
    sess.close()</code></pre>