<html><h3>c0833c03181a2a9a2ce50bf43281ba698f61887c,workers/data_refinery_workers/processors/smasher.py,,_smash_all,#Any#,303
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        job_context[&quotdataset&quot].success = False
        job_context[&quotjob&quot].failure_reason = "Failure reason: " + str(e)
        job_context[&quotdataset&quot].failure_reason = "Failure reason: " + str(e)
        <a id="change">job_context[&quotdataset&quot].save()</a>
        &#47&#47 Delay failing this pipeline until the failure notify has been sent
        job_context[&quotjob&quot].success = False
        job_context[&quotfailure_reason&quot] = str(e)
        return job_context</code></pre><h3>After Change</h3><pre><code class='java'>

    &#47&#47 Finally, compress all files into a zip
    final_zip_base = "/home/user/data_store/smashed/" + str(job_context["dataset"].pk)
    <a id="change">try:
        shutil.make_archive(final_zip_base, &quotzip&quot, job_context["output_dir"])
    except:
        raise utils.ProcessorJobError(&quotSmash Error while generating zip file&quot, success=False)

   </a> job_context["output_file"] = final_zip_base + ".zip"

    job_context[&quotdataset&quot].success = True
    job_context[&quotdataset&quot].save()</code></pre><img src="78629704.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/AlexsLemonade/refinebio/commit/c0833c03181a2a9a2ce50bf43281ba698f61887c#diff-4664b217f1e6c9c1c142b3f19a6a38fef1336837681c28f8696055f754d91c97L278' target='_blank'>Link</a></div><div id='project'> Project Name: AlexsLemonade/refinebio</div><div id='commit'> Commit Name: c0833c03181a2a9a2ce50bf43281ba698f61887c</div><div id='time'> Time: 2019-12-24</div><div id='author'> Author: arielsvn@gmail.com</div><div id='file'> File Name: workers/data_refinery_workers/processors/smasher.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: _smash_all</div><BR><BR><div id='link'><a href='https://github.com/dpressel/mead-baseline/commit/3a113ee3efe296452f9c169a58713fdfe1873439#diff-f36922b50dc24cdba7ee967110f40f7ba064332c0528f466e5b184ba8c53ffadL47' target='_blank'>Link</a></div><div id='project'> Project Name: dpressel/mead-baseline</div><div id='commit'> Commit Name: 3a113ee3efe296452f9c169a58713fdfe1873439</div><div id='time'> Time: 2018-11-08</div><div id='author'> Author: mtbarta@gmail.com</div><div id='file'> File Name: python/mead/tf/exporters.py</div><div id='class'> Class Name: TensorFlowExporter</div><div id='method'> Method Name: run</div><BR><BR><div id='link'><a href='https://github.com/AlexsLemonade/refinebio/commit/14ad858086a43963bfe1c2c2e1fbd1500d644d19#diff-91c63c372e03da54032e6a1ed67e25baf2dcb8bbc8132ad4b271fcffdb4ad7f1L54' target='_blank'>Link</a></div><div id='project'> Project Name: AlexsLemonade/refinebio</div><div id='commit'> Commit Name: 14ad858086a43963bfe1c2c2e1fbd1500d644d19</div><div id='time'> Time: 2017-05-04</div><div id='author'> Author: kurt.wheeler91@gmail.com</div><div id='file'> File Name: foreman/data_refinery_foreman/surveyor/external_source.py</div><div id='class'> Class Name: ExternalSourceSurveyor</div><div id='method'> Method Name: handle_batch</div><BR>