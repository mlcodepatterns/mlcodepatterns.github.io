<html><h3>5135e42987c9a6349e3c198fabdb939774d21fbb,contents/10_A3C/A3C_continuous_action.py,ACNet,__init__,#ACNet#Any#Any#,45
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                with tf.name_scope(&quota_loss&quot):
                    log_prob = normal_dist.log_prob(self.a_his)
                    exp_v = log_prob * td
                    entropy = <a id="change">normal_dist.entropy()</a>  &#47&#47 encourage exploration
                    <a id="change">self.exp_v</a> = ENTROPY_BETA * entropy + exp_v
                    <a id="change">self.a_loss</a> = tf.reduce_mean(-self.exp_v)

                with tf.name_scope(&quotchoose_a&quot):  &#47&#47 use local params to choose action
                    self.A = tf.clip_by_value(tf.squeeze(normal_dist.sample(1), axis=0), A_BOUND[0], A_BOUND[1])
                with tf.name_scope(&quotlocal_grad&quot):
                    self.a_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope + &quot/actor&quot)
                    self.c_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope + &quot/critic&quot)
                    <a id="change">self.a_grads</a> = tf.gradients(self.a_loss, self.a_params)
                    self.c_grads = tf.gradients(self.c_loss, self.c_params)

            with tf.name_scope(&quotsync&quot):
                with tf.name_scope(&quotpull&quot):
                    self.pull_a_params_op = [l_p.assign(g_p) for l_p, g_p in zip(self.a_params, globalAC.a_params)]
                    self.pull_c_params_op = [l_p.assign(g_p) for l_p, g_p in zip(self.c_params, globalAC.c_params)]
                with tf.name_scope(&quotpush&quot):
                    <a id="change">self.update_a_op</a> = OPT_A.apply_gradients(zip(self.a_grads, globalAC.a_params))
                    self.update_c_op = OPT_C.apply_gradients(zip(self.c_grads, globalAC.c_params))

    def _build_net(self ):</code></pre><h3>After Change</h3><pre><code class='java'>
                with tf.name_scope(&quota_loss&quot):
                    log_prob = normal_dist.log_prob(self.a_his)
                    exp_v = log_prob * td
                    entropy = tf.stop_gradient(<a id="change">normal_dist.entropy()</a>)  &#47&#47 encourage exploration
                    <a id="change">self.exp_v</a> = ENTROPY_BETA * entropy + exp_v
                    <a id="change">self.a_loss</a> = tf.reduce_mean(-self.exp_v)

                with tf.name_scope(&quotchoose_a&quot):  &#47&#47 use local params to choose action
                    self.A = tf.clip_by_value(tf.squeeze(normal_dist.sample(1), axis=0), A_BOUND[0], A_BOUND[1])
                with tf.name_scope(&quotlocal_grad&quot):
                    self.a_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope + &quot/actor&quot)
                    self.c_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope + &quot/critic&quot)
                    <a id="change">self.a_grads</a> = tf.gradients(self.a_loss, self.a_params)
                    self.c_grads = tf.gradients(self.c_loss, self.c_params)

            with tf.name_scope(&quotsync&quot):
                with tf.name_scope(&quotpull&quot):
                    self.pull_a_params_op = [l_p.assign(g_p) for l_p, g_p in zip(self.a_params, globalAC.a_params)]
                    self.pull_c_params_op = [l_p.assign(g_p) for l_p, g_p in zip(self.c_params, globalAC.c_params)]
                with tf.name_scope(&quotpush&quot):
                    <a id="change">self.update_a_op</a> = OPT_A.apply_gradients(zip(self.a_grads, globalAC.a_params))
                    self.update_c_op = OPT_C.apply_gradients(zip(self.c_grads, globalAC.c_params))

    def _build_net(self):</code></pre><img src="65874157.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 10</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/commit/5135e42987c9a6349e3c198fabdb939774d21fbb#diff-50f8d206bd929924ae7b626b133492fb3556c336f9c7af89e6c1394f15356ea3L73' target='_blank'>Link</a></div><div id='project'> Project Name: MorvanZhou/Reinforcement-learning-with-tensorflow</div><div id='commit'> Commit Name: 5135e42987c9a6349e3c198fabdb939774d21fbb</div><div id='time'> Time: 2017-08-10</div><div id='author'> Author: morvanzhou@gmail.com</div><div id='file'> File Name: contents/10_A3C/A3C_continuous_action.py</div><div id='class'> Class Name: ACNet</div><div id='method'> Method Name: __init__</div><BR><BR><div id='link'><a href='https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/commit/c885f2d6ec036f86a83587793c02caa2c8cac2b0#diff-50f8d206bd929924ae7b626b133492fb3556c336f9c7af89e6c1394f15356ea3L71' target='_blank'>Link</a></div><div id='project'> Project Name: MorvanZhou/Reinforcement-learning-with-tensorflow</div><div id='commit'> Commit Name: c885f2d6ec036f86a83587793c02caa2c8cac2b0</div><div id='time'> Time: 2017-09-23</div><div id='author'> Author: morvanzhou@gmail.com</div><div id='file'> File Name: contents/10_A3C/A3C_continuous_action.py</div><div id='class'> Class Name: ACNet</div><div id='method'> Method Name: __init__</div><BR><BR><div id='link'><a href='https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/commit/c885f2d6ec036f86a83587793c02caa2c8cac2b0#diff-c6751cb820fadef672034f3a8172e7f689c80fa71d4074c450de74fc6e757511L71' target='_blank'>Link</a></div><div id='project'> Project Name: MorvanZhou/Reinforcement-learning-with-tensorflow</div><div id='commit'> Commit Name: c885f2d6ec036f86a83587793c02caa2c8cac2b0</div><div id='time'> Time: 2017-09-23</div><div id='author'> Author: morvanzhou@gmail.com</div><div id='file'> File Name: contents/10_A3C/A3C_RNN.py</div><div id='class'> Class Name: ACNet</div><div id='method'> Method Name: __init__</div><BR><BR><div id='link'><a href='https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/commit/5135e42987c9a6349e3c198fabdb939774d21fbb#diff-c6751cb820fadef672034f3a8172e7f689c80fa71d4074c450de74fc6e757511L73' target='_blank'>Link</a></div><div id='project'> Project Name: MorvanZhou/Reinforcement-learning-with-tensorflow</div><div id='commit'> Commit Name: 5135e42987c9a6349e3c198fabdb939774d21fbb</div><div id='time'> Time: 2017-08-10</div><div id='author'> Author: morvanzhou@gmail.com</div><div id='file'> File Name: contents/10_A3C/A3C_RNN.py</div><div id='class'> Class Name: ACNet</div><div id='method'> Method Name: __init__</div><BR>