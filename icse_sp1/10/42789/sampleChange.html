<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            fk_i_hat = fk_hat
            nb_iter = 0

            <a id="change">while fk_i_hat == fk_hat and nb_iter &lt; self.max_iter:
                grad_diff = grd - grd[fk_hat]
                f_diff = f - f[fk_hat]

                &#47&#47 Masking true label
                mask = [0] * self.classifier.nb_classes
                mask[fk_hat] = 1
                norm = np.linalg.norm(grad_diff.reshape(self.classifier.nb_classes, -1), axis=1) + tol
                value = np.ma.array(np.abs(f_diff) / norm, mask=mask)

                l = value.argmin(fill_value=np.inf)
                r = (abs(f_diff[l]) / (pow(np.linalg.norm(grad_diff[l]), 2) + tol)) * grad_diff[l]

                &#47&#47 Add perturbation and clip result
                xj = np.clip(xj + r, clip_min, clip_max)

                &#47&#47 Recompute prediction for new xj
                f = self.classifier.predict(xj, logits=True)[0]
                grd = self.classifier.class_gradient(xj, logits=True)[0]
                fk_i_hat = np.argmax(f)

                nb_iter += 1

           </a> x_adv[j] = np.clip(x[j] + (1 + self.epsilon) * (xj[0] - x[j]), clip_min, clip_max)

        preds = np.argmax(self.classifier.predict(x), axis=1)
        preds_adv = np.argmax(self.classifier.predict(x_adv), axis=1)</code></pre><h3>After Change</h3><pre><code class='java'>
            grd = self.classifier.class_gradient(xj, logits=True)[0]
            fk_hat = np.argmax(f)

            <a id="change">for _ in range(self.max_iter):
                grad_diff = grd - grd[fk_hat]
                f_diff = f - f[fk_hat]

                &#47&#47 Choose coordinate and compute perturbation
                norm = np.linalg.norm(grad_diff.reshape(self.classifier.nb_classes, -1), axis=1) + tol
                value = np.abs(f_diff) / norm
                value[fk_hat] = np.inf
                l = np.argmin(value)
                r = (abs(f_diff[l]) / (pow(np.linalg.norm(grad_diff[l]), 2) + tol)) * grad_diff[l]

                &#47&#47 Add perturbation and clip result
                xj = np.clip(xj + r, clip_min, clip_max)

                &#47&#47 Recompute prediction for new xj
                f = self.classifier.predict(xj, logits=True)[0]
                grd = self.classifier.class_gradient(xj, logits=True)[0]
                fk_i_hat = np.argmax(f)

                &#47&#47 Stop if misclassification has been achieved
                if fk_i_hat != fk_hat:
                    break

            &#47&#47 Apply overshoot parameter
           </a> x_adv[j] = np.clip(x[j] + (1 + self.epsilon) * (xj[0] - x[j]), clip_min, clip_max)

        preds = np.argmax(preds, axis=1)
        preds_adv = np.argmax(self.classifier.predict(x_adv), axis=1)</code></pre>