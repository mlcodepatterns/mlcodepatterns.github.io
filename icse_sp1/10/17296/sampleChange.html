<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
         should not be subsampled
        :return: No return value.
        
        with <a id="change">enclosing_scope(self._name, name)</a>:
            inputs = tuple(inputs)
            if extra_inputs is None:
                extra_inputs = tuple()</code></pre><h3>After Change</h3><pre><code class='java'>
        :return: No return value.
        
        params = target.get_params(trainable=True)
        with <a id="change">tf.name_scope(
                name, "ConjugateGradientOptimizer",
                [loss, target, leq_constraint, inputs, extra_inputs,
                 params])</a>:  &#47&#47 yapf: disable
            inputs = tuple(inputs)
            if extra_inputs is None:
                extra_inputs = tuple()
            else:
                extra_inputs = tuple(extra_inputs)

            constraint_term, constraint_value = leq_constraint

            with <a id="change">tf.name_scope("loss_gradients", values=[loss, params])</a>:
                grads = tf.gradients(loss, xs=params)
                for idx, (grad, param) in enumerate(zip(grads, params)):
                    if grad is None:</code></pre>