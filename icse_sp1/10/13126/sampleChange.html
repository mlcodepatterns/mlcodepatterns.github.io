<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
from torchtext.datasets import Multi30k
from torchtext.data import Field, BucketIterator

SRC = <a id="change">Field(tokenize = "spacy",
            tokenizer_language="de",
            init_token = &quot&lt;sos&gt;&quot,
            eos_token = &quot&lt;eos&gt;&quot,
            lower = True)</a>

TRG = Field(tokenize = "spacy",
            tokenizer_language="en",
            init_token = &quot&lt;sos&gt;&quot,
            eos_token = &quot&lt;eos&gt;&quot,
            lower = True)

<a id="change">train_data, valid_data, test_data = Multi30k.splits(exts = (&quot.de&quot, &quot.en&quot),
                                                    fields = (SRC, TRG))</a>

&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47
&#47&#47 Now that we&quotve defined ``train_data``, we can see an extremely useful
&#47&#47 feature of ``torchtext``&quots ``Field``: the ``build_vocab`` method
&#47&#47 now allows us to create the vocabulary associated with each language

<a id="change">SRC.build_vocab(train_data, min_freq = 2)</a>
TRG.build_vocab(train_data, min_freq = 2)

&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47
&#47&#47 Once these lines of code have been run, ``SRC.vocab.stoi`` will  be a</code></pre><h3>After Change</h3><pre><code class='java'>
from torchtext.utils import download_from_url, extract_archive
import io

<a id="change">url_base = &quothttps://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/&quot</a>
train_urls = (&quottrain.de.gz&quot, &quottrain.en.gz&quot)
<a id="change">val_urls = (&quotval.de.gz&quot, &quotval.en.gz&quot)</a>
test_urls = (&quottest_2016_flickr.de.gz&quot, &quottest_2016_flickr.en.gz&quot)

train_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in train_urls]
<a id="change">val_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in val_urls]</a>
test_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in test_urls]

de_tokenizer = get_tokenizer(&quotspacy&quot, language=&quotde&quot)
en_tokenizer = get_tokenizer(&quotspacy&quot, language=&quoten&quot)</code></pre>