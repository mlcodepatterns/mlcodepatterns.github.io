<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
else:
    ctx = mx.gpu(args.gpu)

<a id="change">if isinstance(args.bos, str):
    args.bos = [args.bos]

</a>lm_model, vocab = nlp.model.get_model(name=args.lm_model,
                                      dataset_name=&quotwikitext-2&quot,
                                      pretrained=True,
                                      ctx=ctx)</code></pre><h3>After Change</h3><pre><code class='java'>
&#47&#47 beam search sampler options
subparsers = parser.add_subparsers(help=&quotSequence generation methods.&quot,
                                   dest=&quotcommand&quot)
<a id="change">subparsers.required = True</a>
<a id="change">beam_search_parser = subparsers.add_parser(&quotbeam-search&quot, help=&quotUse beam search for decoding.&quot)</a>
beam_search_parser.add_argument(&quot--alpha&quot, type=float, default=0.0,
                                help=&quotAlpha in the length penalty term.&quot)
beam_search_parser.add_argument(&quot--k&quot, type=int, default=5, help=&quotK in the length penalty term.&quot)

&#47&#47 random sampler options
<a id="change">random_sample_parser = subparsers.add_parser(&quotrandom-sample&quot,
                                             help=&quotUse random sampling for decoding.&quot)</a>
random_sample_parser.add_argument(&quot--temperature&quot, type=float, default=1.0,
                                  help=&quotSoftmax temperature used in sampling.&quot)
random_sample_parser.add_argument(&quot--use-top-k&quot, type=int, required=False,
                                  help=&quotSample only from the top-k candidates.&quot)</code></pre>