<html><h3>2c4a6e537126f4123de7c97f30587310d3712c06,tests/data/tokenizers/word_splitter_test.py,TestSpacyWordSplitter,test_tokenize_handles_special_cases,#TestSpacyWordSplitter#,87
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        sentence = "Mr. and Mrs. Jones, etc., went to, e.g., the store"
        expected_tokens = ["Mr.", "and", "Mrs.", "Jones", ",", "etc", ".", ",", "went", "to", ",",
                           "e.g.", ",", "the", "store"]
        tokens, offsets = <a id="change">self.word_splitter.split_words(sentence)</a>
        assert tokens == expected_tokens
        for token, (start, end) in zip(tokens, offsets):
            assert sentence[start:end] == token
</code></pre><h3>After Change</h3><pre><code class='java'>
        sentence = "Mr. and Mrs. Jones, etc., went to, e.g., the store"
        expected_tokens = ["Mr.", "and", "Mrs.", "Jones", ",", "etc", ".", ",", "went", "to", ",",
                           "e.g.", ",", "the", "store"]
        tokens = <a id="change">[t.text for t in self.word_splitter.split_words(sentence)]</a>
        assert tokens == expected_tokens
</code></pre><img src="232149494.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 10</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/allenai/allennlp/commit/2c4a6e537126f4123de7c97f30587310d3712c06#diff-e0e27cc5ca57374a51f36bafc6c1d9a3b0785c0aa62b2a75c79c632134461e92L89' target='_blank'>Link</a></div><div id='project'> Project Name: allenai/allennlp</div><div id='commit'> Commit Name: 2c4a6e537126f4123de7c97f30587310d3712c06</div><div id='time'> Time: 2017-09-13</div><div id='author'> Author: mattg@allenai.org</div><div id='file'> File Name: tests/data/tokenizers/word_splitter_test.py</div><div id='class'> Class Name: TestSpacyWordSplitter</div><div id='method'> Method Name: test_tokenize_handles_special_cases</div><BR><BR><div id='link'><a href='https://github.com/allenai/allennlp/commit/2c4a6e537126f4123de7c97f30587310d3712c06#diff-e0e27cc5ca57374a51f36bafc6c1d9a3b0785c0aa62b2a75c79c632134461e92L43' target='_blank'>Link</a></div><div id='project'> Project Name: allenai/allennlp</div><div id='commit'> Commit Name: 2c4a6e537126f4123de7c97f30587310d3712c06</div><div id='time'> Time: 2017-09-13</div><div id='author'> Author: mattg@allenai.org</div><div id='file'> File Name: tests/data/tokenizers/word_splitter_test.py</div><div id='class'> Class Name: TestSimpleWordSplitter</div><div id='method'> Method Name: test_tokenize_handles_special_cases</div><BR><BR><div id='link'><a href='https://github.com/allenai/allennlp/commit/dcd6487ea8612c56f44613fa6060f75eb20ab7d3#diff-a9b6a19f386be4501e68a7d75292a249746ce27c92bf471902a0f74fbbc3d8ceL27' target='_blank'>Link</a></div><div id='project'> Project Name: allenai/allennlp</div><div id='commit'> Commit Name: dcd6487ea8612c56f44613fa6060f75eb20ab7d3</div><div id='time'> Time: 2018-02-28</div><div id='author'> Author: markn@allenai.org</div><div id='file'> File Name: allennlp/service/predictors/constituency_parser.py</div><div id='class'> Class Name: ConstituencyParserPredictor</div><div id='method'> Method Name: _json_to_instance</div><BR><BR><div id='link'><a href='https://github.com/allenai/allennlp/commit/2c4a6e537126f4123de7c97f30587310d3712c06#diff-e0e27cc5ca57374a51f36bafc6c1d9a3b0785c0aa62b2a75c79c632134461e92L24' target='_blank'>Link</a></div><div id='project'> Project Name: allenai/allennlp</div><div id='commit'> Commit Name: 2c4a6e537126f4123de7c97f30587310d3712c06</div><div id='time'> Time: 2017-09-13</div><div id='author'> Author: mattg@allenai.org</div><div id='file'> File Name: tests/data/tokenizers/word_splitter_test.py</div><div id='class'> Class Name: TestSimpleWordSplitter</div><div id='method'> Method Name: test_tokenize_handles_contraction</div><BR><BR><div id='link'><a href='https://github.com/allenai/allennlp/commit/2c4a6e537126f4123de7c97f30587310d3712c06#diff-e0e27cc5ca57374a51f36bafc6c1d9a3b0785c0aa62b2a75c79c632134461e92L17' target='_blank'>Link</a></div><div id='project'> Project Name: allenai/allennlp</div><div id='commit'> Commit Name: 2c4a6e537126f4123de7c97f30587310d3712c06</div><div id='time'> Time: 2017-09-13</div><div id='author'> Author: mattg@allenai.org</div><div id='file'> File Name: tests/data/tokenizers/word_splitter_test.py</div><div id='class'> Class Name: TestSimpleWordSplitter</div><div id='method'> Method Name: test_tokenize_handles_complex_punctuation</div><BR><BR><div id='link'><a href='https://github.com/allenai/allennlp/commit/2c4a6e537126f4123de7c97f30587310d3712c06#diff-e0e27cc5ca57374a51f36bafc6c1d9a3b0785c0aa62b2a75c79c632134461e92L36' target='_blank'>Link</a></div><div id='project'> Project Name: allenai/allennlp</div><div id='commit'> Commit Name: 2c4a6e537126f4123de7c97f30587310d3712c06</div><div id='time'> Time: 2017-09-13</div><div id='author'> Author: mattg@allenai.org</div><div id='file'> File Name: tests/data/tokenizers/word_splitter_test.py</div><div id='class'> Class Name: TestSimpleWordSplitter</div><div id='method'> Method Name: test_tokenize_handles_final_apostrophe</div><BR><BR><div id='link'><a href='https://github.com/allenai/allennlp/commit/2c4a6e537126f4123de7c97f30587310d3712c06#diff-e0e27cc5ca57374a51f36bafc6c1d9a3b0785c0aa62b2a75c79c632134461e92L81' target='_blank'>Link</a></div><div id='project'> Project Name: allenai/allennlp</div><div id='commit'> Commit Name: 2c4a6e537126f4123de7c97f30587310d3712c06</div><div id='time'> Time: 2017-09-13</div><div id='author'> Author: mattg@allenai.org</div><div id='file'> File Name: tests/data/tokenizers/word_splitter_test.py</div><div id='class'> Class Name: TestSpacyWordSplitter</div><div id='method'> Method Name: test_tokenize_handles_final_apostrophe</div><BR><BR><div id='link'><a href='https://github.com/allenai/allennlp/commit/2c4a6e537126f4123de7c97f30587310d3712c06#diff-e0e27cc5ca57374a51f36bafc6c1d9a3b0785c0aa62b2a75c79c632134461e92L74' target='_blank'>Link</a></div><div id='project'> Project Name: allenai/allennlp</div><div id='commit'> Commit Name: 2c4a6e537126f4123de7c97f30587310d3712c06</div><div id='time'> Time: 2017-09-13</div><div id='author'> Author: mattg@allenai.org</div><div id='file'> File Name: tests/data/tokenizers/word_splitter_test.py</div><div id='class'> Class Name: TestSpacyWordSplitter</div><div id='method'> Method Name: test_tokenize_handles_multiple_contraction</div><BR><BR><div id='link'><a href='https://github.com/allenai/allennlp/commit/2c4a6e537126f4123de7c97f30587310d3712c06#diff-e0e27cc5ca57374a51f36bafc6c1d9a3b0785c0aa62b2a75c79c632134461e92L66' target='_blank'>Link</a></div><div id='project'> Project Name: allenai/allennlp</div><div id='commit'> Commit Name: 2c4a6e537126f4123de7c97f30587310d3712c06</div><div id='time'> Time: 2017-09-13</div><div id='author'> Author: mattg@allenai.org</div><div id='file'> File Name: tests/data/tokenizers/word_splitter_test.py</div><div id='class'> Class Name: TestSpacyWordSplitter</div><div id='method'> Method Name: test_tokenize_handles_contraction</div><BR><BR><div id='link'><a href='https://github.com/allenai/allennlp/commit/2c4a6e537126f4123de7c97f30587310d3712c06#diff-e0e27cc5ca57374a51f36bafc6c1d9a3b0785c0aa62b2a75c79c632134461e92L30' target='_blank'>Link</a></div><div id='project'> Project Name: allenai/allennlp</div><div id='commit'> Commit Name: 2c4a6e537126f4123de7c97f30587310d3712c06</div><div id='time'> Time: 2017-09-13</div><div id='author'> Author: mattg@allenai.org</div><div id='file'> File Name: tests/data/tokenizers/word_splitter_test.py</div><div id='class'> Class Name: TestSimpleWordSplitter</div><div id='method'> Method Name: test_tokenize_handles_multiple_contraction</div><BR>