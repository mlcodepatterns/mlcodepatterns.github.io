<html><h3>15355d6b1d45c157badd1c21157b529e817b7c3c,tf_agents/agents/reinforce/reinforce_agent.py,ReinforceAgent,_train,#ReinforceAgent#Any#Any#,121
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
      clip_gradients = eager_utils.clip_gradient_norms_fn(
          self._gradient_clipping)

    <a id="change">loss_info = eager_utils.create_train_step(
        loss_info,
        self._optimizer,
        total_loss_fn=lambda loss_info: loss_info.loss,
        global_step=self.train_step_counter,
        transform_grads_fn=clip_gradients,
        summarize_gradients=self._summarize_grads_and_vars,
        variables_to_train=lambda: self._actor_network.trainable_weights,
    )</a>

    if self._summarize_grads_and_vars:
      with tf.name_scope(&quotVariables/&quot):
        for var in self._actor_network.trainable_weights:
          tf.compat.v2.summary.histogram(
              name=var.name.replace(&quot:&quot, &quot_&quot),
              data=var,
              step=self.train_step_counter)

    <a id="change">return loss_info</a>

  @eager_utils.future_in_eager_mode
  def _loss(self, time_steps, actions, returns, weights):
    tf.nest.assert_same_structure(time_steps, self.time_step_spec)</code></pre><h3>After Change</h3><pre><code class='java'>
    self._optimizer.apply_gradients(
        grads_and_vars, global_step=self.train_step_counter)

    <a id="change">return tf.nest.map_structure(tf.identity, loss_info)</a>

  def _loss(self, time_steps, actions, returns, weights):
    tf.nest.assert_same_structure(time_steps, self.time_step_spec)
    actions_distribution = self.collect_policy.distribution(time_steps).action</code></pre><img src="77200985.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/tensorflow/agents/commit/15355d6b1d45c157badd1c21157b529e817b7c3c#diff-bf755fac197dae2cc47fed2451d12ed15b4c17215eabaf0b1f8f2f3dcc62952bL121' target='_blank'>Link</a></div><div id='project'> Project Name: tensorflow/agents</div><div id='commit'> Commit Name: 15355d6b1d45c157badd1c21157b529e817b7c3c</div><div id='time'> Time: 2019-03-08</div><div id='author'> Author: sfishman@google.com</div><div id='file'> File Name: tf_agents/agents/reinforce/reinforce_agent.py</div><div id='class'> Class Name: ReinforceAgent</div><div id='method'> Method Name: _train</div><BR><BR><div id='link'><a href='https://github.com/tensorflow/agents/commit/748bede752a95aee4d73c2fd208202bcdf164e0e#diff-9d1dc6f7dabf30332683b2d4dd740f2c92444006f183c4c03036f3a82c2ba493L43' target='_blank'>Link</a></div><div id='project'> Project Name: tensorflow/agents</div><div id='commit'> Commit Name: 748bede752a95aee4d73c2fd208202bcdf164e0e</div><div id='time'> Time: 2019-04-15</div><div id='author'> Author: vcarbune@google.com</div><div id='file'> File Name: tf_agents/policies/random_tf_policy.py</div><div id='class'> Class Name: RandomTFPolicy</div><div id='method'> Method Name: _action</div><BR><BR><div id='link'><a href='https://github.com/tensorflow/agents/commit/a281f8a17967302aa382881d5473b2993843fc6d#diff-14a74851a6f0c01b20e90c31a2eb43d5501d1b4a839575cbc600d828089c0421L244' target='_blank'>Link</a></div><div id='project'> Project Name: tensorflow/agents</div><div id='commit'> Commit Name: a281f8a17967302aa382881d5473b2993843fc6d</div><div id='time'> Time: 2019-02-20</div><div id='author'> Author: eholly@google.com</div><div id='file'> File Name: tf_agents/utils/tensor_normalizer.py</div><div id='class'> Class Name: StreamingTensorNormalizer</div><div id='method'> Method Name: _update_ops</div><BR>