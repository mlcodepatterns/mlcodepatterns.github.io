<html><h3>9d56361641a64ff73ac630812ecd4964eedbc7aa,gat/graph_attention_layer.py,GraphAttention,call,#GraphAttention#Any#,72
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            &#47&#47 Compute output features for each node in the batch
            &#47&#47 TODO: change the for loop to a loop over tf.unstack(combinations)
            combination_slices = tf.unstack(K.reshape(combinations, (B, -1, 2 * self.F_)))
            <a id="change">output_features = []</a>
            for slice in combination_slices:
                dense = Dense(1)(slice)  &#47&#47 N x 1 (basically "a(Wh_i, Wh_j)" in the paper)
                &#47&#47 TODO: masking
                e_i = K.reshape(dense, (1, -1))  &#47&#47 1 x N (e_i in the paper)</code></pre><h3>After Change</h3><pre><code class='java'>

    def call(self, inputs):
        X = inputs[0]  &#47&#47 input graph (B x F)
        <a id="change">G = inputs[1]</a>  &#47&#47 full graph (N x F) (this is necessary in code, but not in theory. Check section 2.2 of the paper)
        B = K.shape(X)[0]  &#47&#47 Get batch size at runtime
        N = K.shape(G)[0]  &#47&#47 Get number of nodes in the graph at runtime

        outputs = []  &#47&#47 Will store the outputs of each attention head (B x F&quot or B x KF&quot)
        for head in range(self.attention_heads):
            kernel = self.kernels[head]  &#47&#47 W in the paper (F x F&quot)
            <a id="change">attention_kernel = self.attention_kernels[head]</a>  &#47&#47 Attention network a in paper (2*F&quot x 1)

            &#47&#47 Compute inputs to attention network
            linear_transf_X = K.dot(X, kernel)  &#47&#47 B x F&quot
            linear_transf_G = <a id="change">K.dot(G, kernel)</a>  &#47&#47 N x F&quot

            &#47&#47 Repeat feature vectors of input: [[1], [2]] becomes [[1], [1], [2], [2]]
            repeated = K.reshape(K.tile(linear_transf_X, [1, N]), (-1, self.F_))  &#47&#47 B*N x F&quot
            &#47&#47 Tile feature vectors of full graph: [[1], [2]] becomes [[1], [2], [1], [2]]
            tiled = K.tile(linear_transf_G, [B, 1])  &#47&#47 B*N x F&quot
            &#47&#47 Build combinations
            combinations = K.concatenate([repeated, tiled])  &#47&#47 N*B x 2F&quot
            combination_slices = K.reshape(combinations, (B, -1, 2 * self.F_))  &#47&#47 B x N x 2F&quot

            &#47&#47 Attention head
            dense = K.dot(combination_slices, attention_kernel)  &#47&#47 B x N x 1 (a(Wh_i, Wh_j) in the paper)
            <a id="change">dense = K.squeeze(dense, -1)</a>  &#47&#47 B x N
            dense = K.softmax(dense)  &#47&#47 B x N

            &#47&#47 TODO: masking with Vaswani method (add -inf to masked coefficients)</code></pre><img src="18643614.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/danielegrattarola/keras-gat/commit/9d56361641a64ff73ac630812ecd4964eedbc7aa#diff-b5eead7f2a637c33998de1add9a690c0678e849a3d16791260f0f0a16506c7c3L72' target='_blank'>Link</a></div><div id='project'> Project Name: danielegrattarola/keras-gat</div><div id='commit'> Commit Name: 9d56361641a64ff73ac630812ecd4964eedbc7aa</div><div id='time'> Time: 2017-11-09</div><div id='author'> Author: daniele.grattarola@gmail.com</div><div id='file'> File Name: gat/graph_attention_layer.py</div><div id='class'> Class Name: GraphAttention</div><div id='method'> Method Name: call</div><BR><BR><div id='link'><a href='https://github.com/nilearn/nilearn/commit/38b1a68f9f74ebb1a0f8cf2f73a9e606f7c022c2#diff-7ddcbcf1d70180009d3be4b0226ddbd27f1c38db566a968d3cc372fe4d5d97b3L173' target='_blank'>Link</a></div><div id='project'> Project Name: nilearn/nilearn</div><div id='commit'> Commit Name: 38b1a68f9f74ebb1a0f8cf2f73a9e606f7c022c2</div><div id='time'> Time: 2015-07-28</div><div id='author'> Author: elvis.dohmatob@inria.fr</div><div id='file'> File Name: nilearn/decoding/tests/test_same_api.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: test_smoothlasso_and_tv_same_for_pure_l1_another_test</div><BR><BR><div id='link'><a href='https://github.com/rodluger/starry/commit/4f75512036063f707ac077a22bc028c81edfef27#diff-bebbd846478ed3d47443619dea3e20d87ac5f9ee476cf645463a142a5fd1df88L1123' target='_blank'>Link</a></div><div id='project'> Project Name: rodluger/starry</div><div id='commit'> Commit Name: 4f75512036063f707ac077a22bc028c81edfef27</div><div id='time'> Time: 2019-12-17</div><div id='author'> Author: rodluger@gmail.com</div><div id='file'> File Name: starry/kepler.py</div><div id='class'> Class Name: System</div><div id='method'> Method Name: draw</div><BR><BR><div id='link'><a href='https://github.com/keras-team/keras/commit/c2244d2a4cb5f86968fb117f75469283a19b8a24#diff-254a51c95545edd5f7188d4a7e71c1de4944ba8bddb7d769c1fae2d1b527d081L1837' target='_blank'>Link</a></div><div id='project'> Project Name: keras-team/keras</div><div id='commit'> Commit Name: c2244d2a4cb5f86968fb117f75469283a19b8a24</div><div id='time'> Time: 2018-10-21</div><div id='author'> Author: gabrieldemarmiesse@gmail.com</div><div id='file'> File Name: tests/keras/backend/backend_test.py</div><div id='class'> Class Name: TestBackend</div><div id='method'> Method Name: test_sparse_dot</div><BR>