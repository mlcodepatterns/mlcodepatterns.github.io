<html><h3>69cdc613de1b60860f9e1017fe5e960427fe53a1,tests/attacks/evasion/test_fast_gradient.py,,test_l2_norm_images,#Any#Any#,204
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>


def test_l2_norm_images(fix_get_mnist_subset, image_classifier_list):
    <a id="change">(x_train_mnist, y_train_mnist, x_test_mnist, y_test_mnist)</a> = fix_get_mnist_subset
    classifier_list = image_classifier_list(FastGradientMethod)
    &#47&#47 TODO this if statement must be removed once we have a classifier for both image and tabular data
    if classifier_list is None:</code></pre><h3>After Change</h3><pre><code class='java'>
        attack = FastGradientMethod(classifier, eps=1, norm=2, batch_size=128)
        expected_values = {}

        <a id="change">expected_values["x_test_mean"] = ExpectedValue(0.007636424, 0.001)</a>
        expected_values["x_test_min"] = ExpectedValue(-0.211054801, 0.001)
        expected_values["x_test_max"] = ExpectedValue(0.209592223, 0.001)
        expected_values["y_test_pred_adv_expected"] = ExpectedValue(
        np.asarray([[0.19395831, 0.11625732, 0.08293699, 0.04129186, 0.17826456, 0.06290703,</code></pre><img src="191460896.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/IBM/adversarial-robustness-toolbox/commit/69cdc613de1b60860f9e1017fe5e960427fe53a1#diff-601b70e7da026b7b19a80fcefc8175b7e6535ac61a04736e833ac15a2ec3f589L205' target='_blank'>Link</a></div><div id='project'> Project Name: IBM/adversarial-robustness-toolbox</div><div id='commit'> Commit Name: 69cdc613de1b60860f9e1017fe5e960427fe53a1</div><div id='time'> Time: 2020-02-06</div><div id='author'> Author: killian.levacher@gmail.com</div><div id='file'> File Name: tests/attacks/evasion/test_fast_gradient.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: test_l2_norm_images</div><BR><BR><div id='link'><a href='https://github.com/IBM/adversarial-robustness-toolbox/commit/4a7b5983d440e4c840f49f45c8bab91fc0e2966f#diff-45609ddaaeae758fa5371bf75fef8aba5ea44085ced73be74eb17ceb9b7aa768L147' target='_blank'>Link</a></div><div id='project'> Project Name: IBM/adversarial-robustness-toolbox</div><div id='commit'> Commit Name: 4a7b5983d440e4c840f49f45c8bab91fc0e2966f</div><div id='time'> Time: 2020-02-19</div><div id='author'> Author: killian.levacher@gmail.com</div><div id='file'> File Name: tests/classifiersT/test_tensorflow.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: test_loss_gradient</div><BR><BR><div id='link'><a href='https://github.com/IBM/adversarial-robustness-toolbox/commit/64171b3cdf5f0fca6bb11e48831946db63263684#diff-601b70e7da026b7b19a80fcefc8175b7e6535ac61a04736e833ac15a2ec3f589L100' target='_blank'>Link</a></div><div id='project'> Project Name: IBM/adversarial-robustness-toolbox</div><div id='commit'> Commit Name: 64171b3cdf5f0fca6bb11e48831946db63263684</div><div id='time'> Time: 2020-02-06</div><div id='author'> Author: killian.levacher@gmail.com</div><div id='file'> File Name: tests/attacks/evasion/test_fast_gradient.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: test_minimal_perturbations_images</div><BR>