<html><h3>bffeefe23c0c8f372e337a925e8c28b97556e5fc,Reinforcement_learning_TUT/8_Actor_Critic_Advantage/AC_continue_Pendulum.py,,,#,120
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
actor = Actor(n_features=env.observation_space.shape[0], action_range=[env.action_space.low[0], env.action_space.high[0]], lr=0.001)
critic = Critic(n_features=env.observation_space.shape[0], lr=0.002)

<a id="change">with tf.Session() as sess:
    if OUTPUT_GRAPH:
        tf.summary.FileWriter("logs/", sess.graph)

    actor.sess, critic.sess = sess, sess    &#47&#47 define the tf session
    tf.global_variables_initializer().run()

    for i_episode in range(3000):
        observation = env.reset()
        t = 0
        ep_rs = []
        while True:
            &#47&#47 if RENDER:
            env.render()
            action, mu, sigma = actor.choose_action(observation)

            observation_, reward, done, info = env.step(action)
            reward /= 10
            TD_target = reward + GAMMA * critic.evaluate(observation_)    &#47&#47 r + gamma * V_next
            TD_eval = critic.evaluate(observation)    &#47&#47 V_now
            TD_error = TD_target - TD_eval

            actor.update(s=observation, a=action, adv=TD_error)
            critic.update(s=observation, target=TD_target)

            observation = observation_
            t += 1
            &#47&#47 print(reward)
            ep_rs.append(reward)
            if t &gt; EPISODE_TIME_THRESHOLD:
                ep_rs_sum = sum(ep_rs)
                if &quotrunning_reward&quot not in globals():
                    running_reward = ep_rs_sum
                else:
                    running_reward = running_reward * 0.9 + ep_rs_sum * 0.1
                if running_reward &gt; DISPLAY_REWARD_THRESHOLD: RENDER = True  &#47&#47 rendering
                print("episode:", i_episode, "  reward:", int(running_reward))
                break
</a>
</code></pre><h3>After Change</h3><pre><code class='java'>
env = gym.make(&quotPendulum-v0&quot)
env.seed(1)  &#47&#47 reproducible

<a id="change">sess = tf.Session()</a>

actor = Actor(sess, n_features=env.observation_space.shape[0], action_range=[env.action_space.low[0], env.action_space.high[0]], lr=LR_A)
critic = Critic(sess, n_features=env.observation_space.shape[0], lr=LR_C)
</code></pre><img src="175295074.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/MorvanZhou/tutorials/commit/bffeefe23c0c8f372e337a925e8c28b97556e5fc#diff-8dabb4015c7f5064a98306ea1edf432e761d96ceb64210714ae14cc7b11e9c7bL123' target='_blank'>Link</a></div><div id='project'> Project Name: MorvanZhou/tutorials</div><div id='commit'> Commit Name: bffeefe23c0c8f372e337a925e8c28b97556e5fc</div><div id='time'> Time: 2017-03-10</div><div id='author'> Author: morvanzhou@gmail.com</div><div id='file'> File Name: Reinforcement_learning_TUT/8_Actor_Critic_Advantage/AC_continue_Pendulum.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: </div><BR><BR><div id='link'><a href='https://github.com/mortendahl/tf-encrypted/commit/f54c2b1361fb86f55a36064158c6baa658ffffb9#diff-f887ccc08a50c670fa1c1f2cb2f6538794b657fffe9e1c248fd07974997b76caL173' target='_blank'>Link</a></div><div id='project'> Project Name: mortendahl/tf-encrypted</div><div id='commit'> Commit Name: f54c2b1361fb86f55a36064158c6baa658ffffb9</div><div id='time'> Time: 2019-06-26</div><div id='author'> Author: suriyaku@gmail.com</div><div id='file'> File Name: examples/mnist/run.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: </div><BR><BR><div id='link'><a href='https://github.com/apple/coremltools/commit/40220c28a320d5fe351b893e256db48deb864d09#diff-792b3741c01aa67bfc73054de5854d6bb15ef3d53bac4d77db992d6c1e01c790L73' target='_blank'>Link</a></div><div id='project'> Project Name: apple/coremltools</div><div id='commit'> Commit Name: 40220c28a320d5fe351b893e256db48deb864d09</div><div id='time'> Time: 2020-07-17</div><div id='author'> Author: aseem.elec@gmail.com</div><div id='file'> File Name: coremltools/converters/mil/frontend/tensorflow/tf_graph_pass/constant_propagation.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: _constant_propagation</div><BR><BR><div id='link'><a href='https://github.com/tensorflow/cleverhans/commit/fcdff410dd2eb91ec850734a8ea4c0c72e19d9b9#diff-fc833d1b8f0c65be4bc200a8836b156cfbb47b700ba3489f339dfb2c54fb8c0dL84' target='_blank'>Link</a></div><div id='project'> Project Name: tensorflow/cleverhans</div><div id='commit'> Commit Name: fcdff410dd2eb91ec850734a8ea4c0c72e19d9b9</div><div id='time'> Time: 2018-10-03</div><div id='author'> Author: papernot@google.com</div><div id='file'> File Name: tests_tf/test_defenses.py</div><div id='class'> Class Name: TestDefenses</div><div id='method'> Method Name: test_feature_pairing</div><BR>