<html><h3>4fe23146a18a946e68d5af27da0ebb3e86c1e3b4,foreman/data_refinery_foreman/surveyor/test_end_to_end.py,ArrayexpressRedownloadingTestCase,test_array_express_redownloading,#ArrayexpressRedownloadingTestCase#,143
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            &#47&#47 processor jobs were successful, including the one that
            &#47&#47 got recreated.
            logger.info("Downloader Jobs finished, waiting for processor Jobs to complete.")
            <a id="change">successful_processor_jobs = []</a>
            for processor_job in processor_jobs:
                &#47&#47 One of the two calls to wait_for_job will fail
                &#47&#47 because the job is going to delete itself when it
                &#47&#47 finds that the file it wants to process is missing.
                try:
                    processor_job = wait_for_job(processor_job, ProcessorJob, start_time)
                    <a id="change">if processor_job.success:
                        successful_processor_jobs.append(processor_job)
               </a> except:
                    pass

            self.assertEqual(len(successful_processor_jobs), NUM_SAMPLES_IN_EXPERIMENT)</code></pre><h3>After Change</h3><pre><code class='java'>
            &#47&#47 Once the Downloader job succeeds, it should create one
            &#47&#47 and only one processor job, after which the total goes back up
            &#47&#47 to NUM_SAMPLES_IN_EXPERIMENT:
            <a id="change">processor_jobs = ProcessorJob.objects.all()</a>
            self.assertEqual(processor_jobs.count(), NUM_SAMPLES_IN_EXPERIMENT)

            &#47&#47 And finally we can make sure that all of the
            &#47&#47 processor jobs were successful, including the one that</code></pre><img src="20104810.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/AlexsLemonade/refinebio/commit/4fe23146a18a946e68d5af27da0ebb3e86c1e3b4#diff-234f84a9592c7ea2ce65dcdb80f019c3b804c4d6ad16053c9ddfc6e0a64d5013L227' target='_blank'>Link</a></div><div id='project'> Project Name: AlexsLemonade/refinebio</div><div id='commit'> Commit Name: 4fe23146a18a946e68d5af27da0ebb3e86c1e3b4</div><div id='time'> Time: 2019-04-11</div><div id='author'> Author: kurt.wheeler91@gmail.com</div><div id='file'> File Name: foreman/data_refinery_foreman/surveyor/test_end_to_end.py</div><div id='class'> Class Name: ArrayexpressRedownloadingTestCase</div><div id='method'> Method Name: test_array_express_redownloading</div><BR><BR><div id='link'><a href='https://github.com/PIQuIL/QuCumber/commit/9a2903dac097a7f3633f6c828533ed385c7159c9#diff-88f94f9ee4f72507e49385a2ac8be9457e0e07ab44eb55782f3f642c17084dc4L75' target='_blank'>Link</a></div><div id='project'> Project Name: PIQuIL/QuCumber</div><div id='commit'> Commit Name: 9a2903dac097a7f3633f6c828533ed385c7159c9</div><div id='time'> Time: 2019-07-17</div><div id='author'> Author: emerali@users.noreply.github.com</div><div id='file'> File Name: qucumber/utils/data.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: extract_refbasis_samples</div><BR><BR><div id='link'><a href='https://github.com/AlexsLemonade/refinebio/commit/99d2d1aced54a9673b9e25b6c1f992acd20535e1#diff-d43f5b4ab55a6d011d9b17d7c11abee8db7065fbb74fe18f28e8572c8c3f0c11L76' target='_blank'>Link</a></div><div id='project'> Project Name: AlexsLemonade/refinebio</div><div id='commit'> Commit Name: 99d2d1aced54a9673b9e25b6c1f992acd20535e1</div><div id='time'> Time: 2019-08-16</div><div id='author'> Author: arielsvn@gmail.com</div><div id='file'> File Name: common/data_refinery_common/rna_seq.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: get_quant_results_for_experiment</div><BR>