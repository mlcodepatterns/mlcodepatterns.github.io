<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        config.optimizer["loss"] = loss.sample

        self.optimizer = self.gan.create_optimizer(config.optimizer)
        self.optimizer = <a id="change">tf</a>.contrib.tpu.CrossShardOptimizer(self.optimizer)
        d_vars = self.d_vars or self.gan.d_vars()
        g_vars = self.g_vars or self.gan.g_vars()

        d_grads = tf.gradients(d_loss, d_vars)
        g_grads = tf.gradients(g_loss, g_vars)
        apply_vec = list(zip((d_grads + g_grads), (d_vars + g_vars))).copy()
        <a id="change">self.gan.gradient_mean = sum([tf.reduce_mean(tf.abs(grad)) for grad in d_grads+g_grads])/len(d_grads+g_grads)</a>
        self.g_loss = g_loss
        self.d_loss = d_loss
        self.gan.trainer = self
</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47self.gan.gradient_mean = sum([tf.reduce_mean(tf.abs(grad)) for grad in d_grads+g_grads])/len(d_grads+g_grads)
        &#47&#47apply_vec = list(zip((d_grads + g_grads), (d_vars + g_vars))).copy()
        apply_vec = list(d_grads + g_grads).copy()
        <a id="change">print("APPLY", apply_vec)</a>
        self.g_loss = g_loss
        self.d_loss = d_loss
        self.gan.trainer = self
</code></pre>