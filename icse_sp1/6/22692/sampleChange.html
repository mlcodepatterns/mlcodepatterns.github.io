<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

    vf_loss = tf.reduce_mean(mse(tf.squeeze(train_model.vf), R))

    self.params = params = <a id="change">tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=&quotmodel&quot)</a>

    self.params_common = params_common = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=&quotmodel/common&quot)

    self.params_pi1 = params_pi1 = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=&quotmodel/pi1&quot) + params_common</code></pre><h3>After Change</h3><pre><code class='java'>
    train_loss_xy0 = pg_loss_xy0 + vf_coef * vf_loss

    self.grads_check_xy0 = grads_xy0 = tf.gradients(train_loss_xy0, params_xy0)
    <a id="change">if max_grad_norm is not None:
      grads_xy0, _ = tf.clip_by_global_norm(grads_xy0, max_grad_norm)

   </a> grads_xy0 = list(zip(grads_xy0, params_xy0))
    trainer_xy0 = tf.train.RMSPropOptimizer(learning_rate=lr, decay=alpha, epsilon=epsilon)
    _train_xy0 = trainer_xy0.apply_gradients(grads_xy0)
</code></pre>