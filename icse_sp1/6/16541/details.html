<html><h3>6aa2cf60e7b62c83548a27c80a1f34e38160e0e1,softlearning/algorithms/sac.py,SAC,_init_actor_update,#SAC#,278
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        policy_kl_loss = tf.reduce_mean(policy_kl_losses)

        policy_regularization_losses = <a id="change">tf.get_collection(
            tf.GraphKeys.REGULARIZATION_LOSSES,
            scope=self._policy.name)</a>
        <a id="change">policy_regularization_loss = tf.reduce_sum(
            policy_regularization_losses)</a>

        policy_loss = (policy_kl_loss + policy_regularization_loss)

        &#47&#47 We update the V towards the min of two Q-functions in order to</code></pre><h3>After Change</h3><pre><code class='java'>
                - min_Q_log_target
                - policy_prior_log_probs)
        else:
            <a id="change">raise NotImplementedError(
                "TODO(hartikainen): Make sure to stop policy gradients"
                " correctly. See old GaussianPolicy implementation.")</a>
            policy_kl_losses = (
                log_pis * tf.stop_gradient(
                    alpha * log_pis - min_Q_log_target + V_value
                    - policy_prior_log_probs))</code></pre><img src="96532948.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/rail-berkeley/softlearning/commit/6aa2cf60e7b62c83548a27c80a1f34e38160e0e1#diff-c427dfbb58b5337d68da626b8e4cbd3324fb1836da0ca03e40cb9be61520c9ddL276' target='_blank'>Link</a></div><div id='project'> Project Name: rail-berkeley/softlearning</div><div id='commit'> Commit Name: 6aa2cf60e7b62c83548a27c80a1f34e38160e0e1</div><div id='time'> Time: 2018-10-28</div><div id='author'> Author: hartikainen@berkeley.edu</div><div id='file'> File Name: softlearning/algorithms/sac.py</div><div id='class'> Class Name: SAC</div><div id='method'> Method Name: _init_actor_update</div><BR><BR><div id='link'><a href='https://github.com/rail-berkeley/softlearning/commit/6aa2cf60e7b62c83548a27c80a1f34e38160e0e1#diff-c427dfbb58b5337d68da626b8e4cbd3324fb1836da0ca03e40cb9be61520c9ddL278' target='_blank'>Link</a></div><div id='project'> Project Name: rail-berkeley/softlearning</div><div id='commit'> Commit Name: 6aa2cf60e7b62c83548a27c80a1f34e38160e0e1</div><div id='time'> Time: 2018-10-28</div><div id='author'> Author: hartikainen@berkeley.edu</div><div id='file'> File Name: softlearning/algorithms/sac.py</div><div id='class'> Class Name: SAC</div><div id='method'> Method Name: _init_actor_update</div><BR><BR><div id='link'><a href='https://github.com/deepchem/deepchem/commit/f1df735684946dbbcefe41e41c7b1c3f2f751a07#diff-972803a74a51af2d54b7671dbbc4d2dd3f051e00445d4a58cf6bdfe53c4008f7L203' target='_blank'>Link</a></div><div id='project'> Project Name: deepchem/deepchem</div><div id='commit'> Commit Name: f1df735684946dbbcefe41e41c7b1c3f2f751a07</div><div id='time'> Time: 2017-06-05</div><div id='author'> Author: peastman@stanford.edu</div><div id='file'> File Name: deepchem/models/tensorgraph/layers.py</div><div id='class'> Class Name: Dense</div><div id='method'> Method Name: create_tensor</div><BR><BR><div id='link'><a href='https://github.com/tensorflow/cleverhans/commit/28e57ccc6bab553b67c04d7da02cd9e1523e48f3#diff-03fb0571c04ee9e7419e6ccd45ee165932c4cefe547a151499f0b49037e71b09L73' target='_blank'>Link</a></div><div id='project'> Project Name: tensorflow/cleverhans</div><div id='commit'> Commit Name: 28e57ccc6bab553b67c04d7da02cd9e1523e48f3</div><div id='time'> Time: 2018-07-09</div><div id='author'> Author: dberth@google.com</div><div id='file'> File Name: cleverhans/model.py</div><div id='class'> Class Name: Model</div><div id='method'> Method Name: get_layer_names</div><BR>