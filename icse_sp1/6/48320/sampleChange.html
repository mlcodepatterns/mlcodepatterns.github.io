<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                        y = q_targets
                    losses = self.net.training_step(batch[&quotstates&quot], y)
                    logger.debug(f&quotlosses {losses}&quot)
                    batch_losses += <a id="change">losses.item()</a>
                batch_losses /= self.training_iters_per_batch
                nanflat_loss_a += batch_losses
            nanflat_loss_a /= self.training_epoch
            loss_a = self.nanflat_to_data_a(&quotloss&quot, nanflat_loss_a)</code></pre><h3>After Change</h3><pre><code class='java'>
        total_t = util.s_get(self, &quotaeb_space.clock&quot).get(&quottotal_t&quot)
        self.to_train = (total_t &gt; self.training_min_timestep and total_t % self.training_frequency == 0)
        if self.to_train == 1:
            total_loss = <a id="change">torch.tensor(0.0)</a>
            for _ in range(self.training_epoch):
                batch = self.sample()
                with torch.no_grad():
                    q_targets = self.calc_q_targets(batch)
                loss = self.net.training_step(batch[&quotstates&quot], q_targets)
                <a id="change">total_loss += loss</a>
            loss = total_loss / self.training_epoch
            &#47&#47 reset
            self.to_train = 0
            self.body.log_probs = []
            self.body.entropies = []
            logger.debug(f&quotLoss: {loss}&quot)
            <a id="change">self.last_loss = loss.item()</a>
        return self.last_loss
</code></pre>