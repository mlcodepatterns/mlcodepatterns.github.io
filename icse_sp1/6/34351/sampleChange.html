<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            begin, end = b * batch_size,  min((b + 1) * batch_size, x_emb.shape[0])
            preds[begin:end] = self._preds_from_embedding([x_emb[begin:end]])[0]

            <a id="change">if not logits:
                exp = np.exp(preds[begin:end] - np.max(preds[begin:end], axis=1, keepdims=True))
                preds[begin:end] = exp / np.sum(exp, axis=1, keepdims=True)

       </a> return preds

    def to_embedding(self, x):
        </code></pre><h3>After Change</h3><pre><code class='java'>
            &#47&#47 Predict
            x_batch = nd.array(x_emb[begin:end], ctx=self._ctx)
            x_batch.attach_grad()
            <a id="change">with autograd.record(train_mode=False):
                preds = self._model(x_batch)

           </a> if logits is False:
                preds = preds.softmax()

            results[begin:end] = preds.asnumpy()</code></pre>