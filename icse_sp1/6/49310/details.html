<html><h3>3128e13109c8766eafb413f2428bba976701e929,beginner_source/transformer_tutorial.py,,,#,295
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                                     val_loss, math.exp(val_loss)))
    print(&quot-&quot * 89)

    <a id="change">if val_loss &lt; best_val_loss:
        best_val_loss = val_loss
        best_model = model

   </a> scheduler.step()


&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47</code></pre><h3>After Change</h3><pre><code class='java'>
nhid = 200 &#47&#47 the dimension of the feedforward network model in nn.TransformerEncoder
nlayers = 2 &#47&#47 the number of nn.TransformerEncoderLayer in nn.TransformerEncoder
nhead = 2 &#47&#47 the number of heads in the multiheadattention models
<a id="change">dropout = 0.2</a> &#47&#47 the dropout value
model = TransformerModel(ntokens, emsize, nhead, nhid, nlayers, dropout).to(device)


&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47
&#47&#47 Run the model
&#47&#47 -------------
&#47&#47


&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47
&#47&#47 `CrossEntropyLoss &lt;https://pytorch.org/docs/master/nn.html?highlight=crossentropyloss&#47&#47torch.nn.CrossEntropyLoss&gt;`__
&#47&#47 is applied to track the loss and
&#47&#47 `SGD &lt;https://pytorch.org/docs/master/optim.html?highlight=sgd&#47&#47torch.optim.SGD&gt;`__
&#47&#47 implements stochastic gradient descent method as the optimizer. The initial
&#47&#47 learning rate is set to 5.0. `StepLR &lt;https://pytorch.org/docs/master/optim.html?highlight=steplr&#47&#47torch.optim.lr_scheduler.StepLR&gt;`__ is
&#47&#47 applied to adjust the learn rate through epochs. During the
&#47&#47 training, we use
&#47&#47 `nn.utils.clip_grad_norm\_ &lt;https://pytorch.org/docs/master/nn.html?highlight=nn%20utils%20clip_grad_norm&#47&#47torch.nn.utils.clip_grad_norm_&gt;`__
&#47&#47 function to scale all the gradient together to prevent exploding.
&#47&#47

criterion = nn.CrossEntropyLoss()
lr = 5.0 &#47&#47 learning rate
optimizer = <a id="change">torch.optim.SGD(model.parameters(), lr=lr)</a>
<a id="change">scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)</a>

import time
def train():
    model.train() &#47&#47 Turn on the train mode</code></pre><img src="229146090.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/pytorch/tutorials/commit/3128e13109c8766eafb413f2428bba976701e929#diff-bb6ac9de5f0e95bba9a48afcd9234956764fda31eeb5744e34ac76caf313bd48L225' target='_blank'>Link</a></div><div id='project'> Project Name: pytorch/tutorials</div><div id='commit'> Commit Name: 3128e13109c8766eafb413f2428bba976701e929</div><div id='time'> Time: 2020-12-02</div><div id='author'> Author: 6156351+zhangguanheng66@users.noreply.github.com</div><div id='file'> File Name: beginner_source/transformer_tutorial.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: </div><BR><BR><div id='link'><a href='https://github.com/jindongwang/transferlearning/commit/376b01c2e338ec63e638f62a76d67f6a9323e47c#diff-c34d59512d21510b260b855fe4ad7ad06200765ef8696aeda8d4e0a794a97c94L109' target='_blank'>Link</a></div><div id='project'> Project Name: jindongwang/transferlearning</div><div id='commit'> Commit Name: 376b01c2e338ec63e638f62a76d67f6a9323e47c</div><div id='time'> Time: 2019-08-14</div><div id='author'> Author: jindongwang@outlook.com</div><div id='file'> File Name: code/deep/DeepCoral/DeepCoral.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: </div><BR><BR><div id='link'><a href='https://github.com/IBM/adversarial-robustness-toolbox/commit/9a3a5f4ecfc2bdb2e6b34feec20869528d5d7661#diff-1b59e7f2a5a7a420ab5596b5174c84a0ef5eb61f17ad38cc0d9b0fa639ebf488L60' target='_blank'>Link</a></div><div id='project'> Project Name: IBM/adversarial-robustness-toolbox</div><div id='commit'> Commit Name: 9a3a5f4ecfc2bdb2e6b34feec20869528d5d7661</div><div id='time'> Time: 2020-09-28</div><div id='author'> Author: M.N.Tran@ibm.com</div><div id='file'> File Name: art/estimators/classification/pytorch.py</div><div id='class'> Class Name: PyTorchClassifier</div><div id='method'> Method Name: __init__</div><BR>