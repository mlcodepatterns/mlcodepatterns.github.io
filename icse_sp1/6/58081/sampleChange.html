<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        lower_left = fant_train_covar.matmul(L_inverse)
        schur_root = torch.cholesky(fant_fant_covar - lower_left.matmul(lower_left.transpose(-2, -1)))
        upper_right = <a id="change">torch.zeros(m, schur_root.size(-1), device=L.device, dtype=L.dtype)</a>

        &#47&#47 Form new root Z = [L 0; lower_left schur_root]
        num_fant = schur_root.size(-2)
        m, n = L.shape[-2:]
        new_root = torch.zeros(*batch_shape, m + num_fant, n + num_fant, device=L.device, dtype=L.dtype)
        new_root[..., :m, :n] = L
        <a id="change">new_root[..., :m, n:] = upper_right</a>
        new_root[..., m:, :n] = lower_left
        new_root[..., m:, n:] = schur_root

        &#47&#47 Use pseudo-inverse of Z as new inv root</code></pre><h3>After Change</h3><pre><code class='java'>
        new_root[..., m:, n:] = schur_root

        &#47&#47 Use pseudo-inverse of Z as new inv root
        <a id="change">try:
            Q, R = torch.qr(new_root)
            Rdiag = torch.diagonal(R, dim1=-2, dim2=-1)
            &#47&#47 if R is almost singular, add jitter (Rdiag is a view, so this works)
            zeroish = Rdiag.abs() &lt; 1e-6
            if torch.any(zeroish):
                Rdiag[zeroish] = 1e-6
            new_covar_cache = torch.triangular_solve(Q.transpose(-2, -1), R)[0]
        except RuntimeError as e:
            &#47&#47 TODO: Deprecate once batch QR supported in latest torch stable
            if "invalid argument 1: A should be 2 dimensional" not in e.args[0]:
                raise e
            cap_mat = new_root.transpose(-2, -1).matmul(new_root)
            if cap_mat.requires_grad or new_root.requires_grad:
                new_covar_cache = torch.solve(new_root.transpose(-2, -1), cap_mat)[0]
            else:
                new_covar_cache = torch.cholesky_solve(new_root.transpose(-2, -1), torch.cholesky(cap_mat))
       </a> new_covar_cache = new_covar_cache.transpose(-2, -1)

        &#47&#47 Expand inputs accordingly if necessary (for fantasies at the same points)
        if full_inputs[0].dim() &lt;= full_targets.dim():</code></pre>