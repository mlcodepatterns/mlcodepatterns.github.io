<html><h3>706a4e840607d50dc94249150366a23ba720a900,examples/deep_fqi_atari/extractor.py,Extractor,_build,#Extractor#Any#,65
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                shape=[None, convnet_pars[&quotheight&quot], convnet_pars[&quotwidth&quot],
                       convnet_pars[&quothistory_length&quot]],
                name=&quottarget_prediction&quot)
            <a id="change">self._action = tf.placeholder(&quotuint8&quot, [None], name=&quotaction&quot)</a>

            loss = tf.losses.sigmoid_cross_entropy(self._target_prediction,
                                                   self._prediction)
            tf.summary.scalar(&quotloss&quot, loss)</code></pre><h3>After Change</h3><pre><code class='java'>
                                                   self._prediction)
            tf.summary.scalar(&quotloss&quot, loss)
            self._merged = tf.summary.merge(
                <a id="change">tf.get_collection(tf.GraphKeys.SUMMARIES,
                                  scope=self._scope_name)</a>
            )

            optimizer = convnet_pars[&quotoptimizer&quot]
            if optimizer[&quotname&quot] == &quotrmspropcentered&quot:
                opt = tf.train.RMSPropOptimizer(learning_rate=optimizer[&quotlr&quot],
                                                decay=optimizer[&quotdecay&quot],
                                                centered=True)
            elif optimizer[&quotname&quot] == &quotrmsprop&quot:
                opt = tf.train.RMSPropOptimizer(learning_rate=optimizer[&quotlr&quot],
                                                decay=optimizer[&quotdecay&quot])
            elif optimizer[&quotname&quot] == &quotadam&quot:
                opt = tf.train.AdamOptimizer()
            elif optimizer[&quotname&quot] == &quotadadelta&quot:
                opt = tf.train.AdadeltaOptimizer()
            else:
                raise ValueError(&quotUnavailable optimizer selected.&quot)

            self._train_step = opt.minimize(loss=loss)

            <a id="change">initializer = tf.variables_initializer(
                tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,
                                  scope=self._scope_name))</a>

        self._session.run(initializer)

        self._train_writer = tf.summary.FileWriter(</code></pre><img src="131949151.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/AIRLab-POLIMI/mushroom/commit/706a4e840607d50dc94249150366a23ba720a900#diff-b34b932d72cd2575c7a2a65583c04f0b758a356a4427ed8cd3d94dc9f188dc2fL47' target='_blank'>Link</a></div><div id='project'> Project Name: AIRLab-POLIMI/mushroom</div><div id='commit'> Commit Name: 706a4e840607d50dc94249150366a23ba720a900</div><div id='time'> Time: 2017-09-06</div><div id='author'> Author: carlo.deramo@gmail.com</div><div id='file'> File Name: examples/deep_fqi_atari/extractor.py</div><div id='class'> Class Name: Extractor</div><div id='method'> Method Name: _build</div><BR><BR><div id='link'><a href='https://github.com/MorvanZhou/tutorials/commit/45a1d730e78a711132dbf16e856c32e5711d7f12#diff-e46eef7660ab55a7d7d657b194333531f7826c2d1ebe5000f216f49d436a9ba2L160' target='_blank'>Link</a></div><div id='project'> Project Name: MorvanZhou/tutorials</div><div id='commit'> Commit Name: 45a1d730e78a711132dbf16e856c32e5711d7f12</div><div id='time'> Time: 2017-02-21</div><div id='author'> Author: morvanzhou@hotmail.com</div><div id='file'> File Name: Reinforcement_learning_TUT/6_OpenAI_gym/RL_brain.py</div><div id='class'> Class Name: DeepQNetwork</div><div id='method'> Method Name: _replace_target_params</div><BR><BR><div id='link'><a href='https://github.com/MorvanZhou/tutorials/commit/45a1d730e78a711132dbf16e856c32e5711d7f12#diff-e161ae73e3eddf9075e10c8f87b93e0cf8b437331808c6723b6f879286a70242L160' target='_blank'>Link</a></div><div id='project'> Project Name: MorvanZhou/tutorials</div><div id='commit'> Commit Name: 45a1d730e78a711132dbf16e856c32e5711d7f12</div><div id='time'> Time: 2017-02-21</div><div id='author'> Author: morvanzhou@hotmail.com</div><div id='file'> File Name: Reinforcement_learning_TUT/5_Deep_Q_Network/RL_brain.py</div><div id='class'> Class Name: DeepQNetwork</div><div id='method'> Method Name: _replace_target_params</div><BR>