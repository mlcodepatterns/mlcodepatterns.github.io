<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        self.probs = nn.LogSoftmax(dim=1)
        self.output_to_attn = nn.Linear(self.hsz, self.hsz, bias=False)
        self.attn_softmax = nn.Softmax(dim=1)
        <a id="change">self.attn_out = nn.Linear(2 * self.hsz, self.hsz, bias=False)</a>
        self.attn_tanh = pytorch_activation("tanh")
        self.nlayers = nlayers

    def attn(self, output_t, context, src_mask=None):</code></pre><h3>After Change</h3><pre><code class='java'>
        self.preds = nn.Linear(self.hsz, self.nc)
        self.probs = nn.LogSoftmax(dim=1)
        self.nlayers = nlayers
        <a id="change">attn_type = kwargs.get(&quotattn_type&quot, &quotluong&quot).lower()</a>
        if attn_type == &quotdot&quot:
            self.attn_module = LuongDotProductAttention(enc_hsz)
        else:
            self.attn_module = LuongGeneralAttention(enc_hsz)</code></pre>