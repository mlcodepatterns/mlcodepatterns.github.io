<html><h3>4887ef8baecbf5315ec0f235e56a4f93cd05aad7,cleverhans/attacks_tf.py,,spm,#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#,1947
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                                          tf.argmax(preds_adv, axis=-1))))
  &#47&#47 Return the adv_x with worst accuracy
  adv_xs = tf.stack(adv_xs)
  accs = <a id="change">tf.stack(accs)</a>
  <a id="change">return tf.gather(adv_xs, tf.argmin(accs))</a>
</code></pre><h3>After Change</h3><pre><code class='java'>
    sampled_dys = np.random.choice(dys, n_samples)
    sampled_angles = np.random.choice(angles, n_samples)
    transforms = zip(sampled_dxs, sampled_dys, sampled_angles)
  <a id="change">transformed_ims = parallel_apply_transformations(x, transforms, black_border_size)</a>

  def _compute_xent(x):
    preds = model.get_logits(x)
    return tf.nn.softmax_cross_entropy_with_logits_v2(
        labels=y, logits=preds)

  <a id="change">all_xents = tf.map_fn(
      _compute_xent,
      transformed_ims,
      parallel_iterations=1)</a> &#47&#47 Must be 1 to avoid keras race conditions

  &#47&#47 Return the adv_x with worst accuracy

  &#47&#47 all_xents is n_total_samples x batch_size (SB)
  all_xents = tf.stack(all_xents) &#47&#47 SB

  &#47&#47 We want the worst case sample, with the largest xent_loss
  <a id="change">worst_sample_idx = tf.argmax(all_xents, axis=0)</a>  &#47&#47 B

  batch_size = tf.shape(x)[0]
  keys = tf.stack(<a id="change">[
      tf.range(batch_size, dtype=tf.int32),
      tf.cast(worst_sample_idx, tf.int32)
  ]</a>, axis=1)
  transformed_ims_bshwc = tf.einsum(&quotsbhwc-&gt;bshwc&quot, transformed_ims)
  after_lookup = tf.gather_nd(transformed_ims_bshwc, keys)  &#47&#47 BHWC
  <a id="change">return after_lookup</a>


def parallel_apply_transformations(x, transforms, black_border_size=0):
  transforms = tf.convert_to_tensor(transforms, dtype=tf.float32)</code></pre><img src="329893753.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 8</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/tensorflow/cleverhans/commit/4887ef8baecbf5315ec0f235e56a4f93cd05aad7#diff-f99e58542b7acaf899aa5aff042e15768b4f6cd9d34460d5a8fa0d4054c89399L1955' target='_blank'>Link</a></div><div id='project'> Project Name: tensorflow/cleverhans</div><div id='commit'> Commit Name: 4887ef8baecbf5315ec0f235e56a4f93cd05aad7</div><div id='time'> Time: 2018-10-04</div><div id='author'> Author: nottombrown@gmail.com</div><div id='file'> File Name: cleverhans/attacks_tf.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: spm</div><BR><BR><div id='link'><a href='https://github.com/onnx/onnx-tensorflow/commit/58ace0a10f2859a7bfbb9b56238ba47e4175f5ac#diff-13342ebe1647b44944c033952ea2461ebe10167ba199c5d043ddaf5789a73631L18' target='_blank'>Link</a></div><div id='project'> Project Name: onnx/onnx-tensorflow</div><div id='commit'> Commit Name: 58ace0a10f2859a7bfbb9b56238ba47e4175f5ac</div><div id='time'> Time: 2020-10-09</div><div id='author'> Author: wtsang@us.ibm.com</div><div id='file'> File Name: onnx_tf/handlers/backend/min.py</div><div id='class'> Class Name: Min</div><div id='method'> Method Name: _common</div><BR><BR><div id='link'><a href='https://github.com/onnx/onnx-tensorflow/commit/58ace0a10f2859a7bfbb9b56238ba47e4175f5ac#diff-e94a07094a2c51f4954e2fc2354da2366ec45e1a5f4101333ef24a498217e5d2L18' target='_blank'>Link</a></div><div id='project'> Project Name: onnx/onnx-tensorflow</div><div id='commit'> Commit Name: 58ace0a10f2859a7bfbb9b56238ba47e4175f5ac</div><div id='time'> Time: 2020-10-09</div><div id='author'> Author: wtsang@us.ibm.com</div><div id='file'> File Name: onnx_tf/handlers/backend/max.py</div><div id='class'> Class Name: Max</div><div id='method'> Method Name: _common</div><BR>