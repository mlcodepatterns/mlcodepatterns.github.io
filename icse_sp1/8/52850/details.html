<html><h3>78eba7b3f82b8420deac3cd28318dbfead0f9b9e,python/baseline/pytorch/seq2seq/model.py,Seq2SeqModel,encode,#Seq2SeqModel#Any#Any#,160
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        embed_in_seq = self.embed(input)
        &#47&#47if self.training:
        packed = torch.nn.utils.rnn.pack_padded_sequence(embed_in_seq, src_len.data.tolist())
        <a id="change">output_tbh</a>, hidden = self.encoder_rnn(packed)
        output_tbh, _ = torch.nn.utils.rnn.pad_packed_sequence(output_tbh)
        &#47&#47else:
        &#47&#47    output_tbh, hidden = self.encoder_rnn(embed_in_seq)
        <a id="change">return output_tbh, hidden</a>

    def decoder(self, context_tbh, h_i, output_i, dst, src_mask):
        embed_out_tbh = self.tgt_embedding(dst)
        context_bth = context_tbh.transpose(0, 1)</code></pre><h3>After Change</h3><pre><code class='java'>
            lengths = lengths.cuda()
        example[&quotsrc_len&quot] = lengths
        for key in self.src_embeddings.keys():
            tensor = torch.from_numpy(batch_dict[key]<a id="change">)
            tensor = tensor[perm_i</a>dx]
     <a id="change">       example[key] = tensor

           </a> if self.gpu:
                example[key] = example[key].cuda(<a id="change">)

        if &quottgt&quot in batch_dict:
         </a>   tgt = torch.from_<a id="change">numpy(batch_dict[&quottgt&quot])
         </a>   example[&quotdst&quot] = tgt[:, :-1]
<a id="change">            exa</a>mple[&quottgt&quot] = tgt[:, 1:]
            example[&quotdst&quot] = example[&quotdst&quot][perm_idx]
            example[&quottgt&quot] = example[&quottgt&quot][perm_idx]
            if self.gpu:</code></pre><img src="244672101.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 8</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/dpressel/mead-baseline/commit/78eba7b3f82b8420deac3cd28318dbfead0f9b9e#diff-e9ca49dfce62c7314c62739aed9d61b482bb144c9cd1f234d2314560130b8264L100' target='_blank'>Link</a></div><div id='project'> Project Name: dpressel/mead-baseline</div><div id='commit'> Commit Name: 78eba7b3f82b8420deac3cd28318dbfead0f9b9e</div><div id='time'> Time: 2018-10-30</div><div id='author'> Author: dpressel@gmail.com</div><div id='file'> File Name: python/baseline/pytorch/seq2seq/model.py</div><div id='class'> Class Name: Seq2SeqModel</div><div id='method'> Method Name: encode</div><BR><BR><div id='link'><a href='https://github.com/dpressel/mead-baseline/commit/51498b09368a61bfb06849693688df6eb54d4787#diff-09da5dfa578a379fc3744b3fbc2b963469fa456c7a224b7c5028cdbf3af9cb83L494' target='_blank'>Link</a></div><div id='project'> Project Name: dpressel/mead-baseline</div><div id='commit'> Commit Name: 51498b09368a61bfb06849693688df6eb54d4787</div><div id='time'> Time: 2019-11-14</div><div id='author'> Author: blester125@gmail.com</div><div id='file'> File Name: python/eight_mile/tf/embeddings.py</div><div id='class'> Class Name: PositionalLookupTableEmbeddings</div><div id='method'> Method Name: encode</div><BR><BR><div id='link'><a href='https://github.com/dpressel/mead-baseline/commit/51498b09368a61bfb06849693688df6eb54d4787#diff-09da5dfa578a379fc3744b3fbc2b963469fa456c7a224b7c5028cdbf3af9cb83L445' target='_blank'>Link</a></div><div id='project'> Project Name: dpressel/mead-baseline</div><div id='commit'> Commit Name: 51498b09368a61bfb06849693688df6eb54d4787</div><div id='time'> Time: 2019-11-14</div><div id='author'> Author: blester125@gmail.com</div><div id='file'> File Name: python/eight_mile/tf/embeddings.py</div><div id='class'> Class Name: PositionalCharConvEmbeddings</div><div id='method'> Method Name: encode</div><BR>