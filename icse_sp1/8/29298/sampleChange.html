<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        :return: `None`
        
        &#47&#47 Check if train and output_ph available
        <a id="change">if self._train is None or self._output_ph is None:
            raise ValueError("Need the training objective and the output placeholder to train the model.")

       </a> num_batch = int(np.ceil(len(inputs) / batch_size))
        ind = np.arange(len(inputs))

        &#47&#47 Start training
        for _ in range(nb_epochs):
            &#47&#47 Shuffle the examples
            random.shuffle(ind)

            &#47&#47 Train for one epoch
            for m in range(num_batch):
                if m &lt; num_batch - 1:
                    i_batch = inputs[ind[m * batch_size:(m + 1) * batch_size]]
                    o_batch = outputs[ind[m * batch_size:(m + 1) * batch_size]]
                else:
                    i_batch = inputs[ind[m*batch_size:]]
                    o_batch = outputs[ind[m * batch_size:]]

                &#47&#47 Run train step
                if self._learning is None:
                    self._sess.run(self._train, feed_dict={self._input_ph: i_batch, self._output_ph: o_batch})
                else:
                    <a id="change">self._sess.run(self._train, feed_dict={self._input_ph: i_batch, self._output_ph: o_batch,
                                                           self._learning: True})</a>

    def class_gradient(self, inputs, logits=False):
        
        Compute per-class derivatives w.r.t. `input`.</code></pre><h3>After Change</h3><pre><code class='java'>
                &#47&#47 Actual training
                m_batch = self._model(i_batch)
                loss = self._loss(m_batch, o_batch)
                <a id="change">loss.backward()</a>
                self._optimizer.step()

    def class_gradient(self, inputs, logits=False):
        </code></pre>