<html><h3>64764718080b11c8fb91df34c12e0ce8ac54aa4e,art/classifiers/pytorch.py,PyTorchClassifier,fit,#PyTorchClassifier#Any#Any#Any#Any#,67
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        :return: `None`
        
        &#47&#47 Check if train and output_ph available
        <a id="change">if self._train is None or self._output_ph is None:
            raise ValueError("Need the training objective and the output placeholder to train the model.")

       </a> num_batch = int(np.ceil(len(inputs) / batch_size))
        ind = np.arange(len(inputs))

        &#47&#47 Start training
        for _ in range(nb_epochs):
            &#47&#47 Shuffle the examples
            random.shuffle(ind)

            &#47&#47 Train for one epoch
            for m in range(num_batch):
                if m &lt; num_batch - 1:
                    i_batch = inputs[ind[m * batch_size:(m + 1) * batch_size]]
                    o_batch = outputs[ind[m * batch_size:(m + 1) * batch_size]]
                else:
                    i_batch = inputs[ind[m*batch_size:]]
                    o_batch = outputs[ind[m * batch_size:]]

                &#47&#47 Run train step
                if self._learning is None:
                    self._sess.run(self._train, feed_dict={self._input_ph: i_batch, self._output_ph: o_batch})
                else:
                    <a id="change">self._sess.run(self._train, feed_dict={self._input_ph: i_batch, self._output_ph: o_batch,
                                                           self._learning: True})</a>

    def class_gradient(self, inputs, logits=False):
        
        Compute per-class derivatives w.r.t. `input`.</code></pre><h3>After Change</h3><pre><code class='java'>
                &#47&#47 Actual training
                m_batch = self._model(i_batch)
                loss = self._loss(m_batch, o_batch)
                <a id="change">loss.backward()</a>
                self._optimizer.step()

    def class_gradient(self, inputs, logits=False):
        </code></pre><img src="148268950.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/IBM/adversarial-robustness-toolbox/commit/64764718080b11c8fb91df34c12e0ce8ac54aa4e#diff-6919a2dfe30728fa2663270e78bb7c97a68c14f9308dc2b5d31cbe6eca2e5599L67' target='_blank'>Link</a></div><div id='project'> Project Name: IBM/adversarial-robustness-toolbox</div><div id='commit'> Commit Name: 64764718080b11c8fb91df34c12e0ce8ac54aa4e</div><div id='time'> Time: 2018-05-15</div><div id='author'> Author: M.N.Tran@ibm.com</div><div id='file'> File Name: art/classifiers/pytorch.py</div><div id='class'> Class Name: PyTorchClassifier</div><div id='method'> Method Name: fit</div><BR><BR><div id='link'><a href='https://github.com/IBM/adversarial-robustness-toolbox/commit/9b9a42de05056b418f98e3635f2cffd747123548#diff-6919a2dfe30728fa2663270e78bb7c97a68c14f9308dc2b5d31cbe6eca2e5599L114' target='_blank'>Link</a></div><div id='project'> Project Name: IBM/adversarial-robustness-toolbox</div><div id='commit'> Commit Name: 9b9a42de05056b418f98e3635f2cffd747123548</div><div id='time'> Time: 2018-05-16</div><div id='author'> Author: M.N.Tran@ibm.com</div><div id='file'> File Name: art/classifiers/pytorch.py</div><div id='class'> Class Name: PyTorchClassifier</div><div id='method'> Method Name: class_gradient</div><BR><BR><div id='link'><a href='https://github.com/IBM/adversarial-robustness-toolbox/commit/9b9a42de05056b418f98e3635f2cffd747123548#diff-6919a2dfe30728fa2663270e78bb7c97a68c14f9308dc2b5d31cbe6eca2e5599L136' target='_blank'>Link</a></div><div id='project'> Project Name: IBM/adversarial-robustness-toolbox</div><div id='commit'> Commit Name: 9b9a42de05056b418f98e3635f2cffd747123548</div><div id='time'> Time: 2018-05-16</div><div id='author'> Author: M.N.Tran@ibm.com</div><div id='file'> File Name: art/classifiers/pytorch.py</div><div id='class'> Class Name: PyTorchClassifier</div><div id='method'> Method Name: loss_gradient</div><BR>