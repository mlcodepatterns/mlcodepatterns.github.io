<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        batch_data_t = batch_data_t.cuda()
        batch_targets_t = batch_targets_t.cuda()
    batch_data = Variable(batch_data_t, requires_grad=False)
    <a id="change">batch_targets = Variable(batch_targets_t, requires_grad=False)</a>
    for i in range(0, training_data.size(0), BATCH_SIZE):
        optimizer.zero_grad()
        batch_data.data[:] = training_data[i:i+BATCH_SIZE]
        batch_targets.data[:] = training_labels[i:i+BATCH_SIZE]
        loss = <a id="change">criterion(model(batch_data), batch_targets)</a>
        loss.backward()
        loss = loss.data[0]
        optimizer.step()
        print(&quotEpoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.4f}&quot.format(epoch,</code></pre><h3>After Change</h3><pre><code class='java'>
    batch_data = torch.FloatTensor(opt.batchSize, 1, 28, 28)
    batch_targets = torch.LongTensor(opt.batchSize)
    if cuda:
        <a id="change">batch_data, batch_targets = batch_data.cuda(), batch_targets.cuda()</a>

    &#47&#47 create autograd Variables over these buffers
    batch_data, batch_targets = Variable(batch_data), Variable(batch_targets)

    for i in range(0, training_data.size(0)-opt.batchSize+1, opt.batchSize):
        <a id="change">start, end = i, i+opt.batchSize</a>
        optimizer.zero_grad()
        batch_data.data[:] = training_data[start:end]
        batch_targets.data[:] = training_labels[start:end]
        output = model(batch_data)
        <a id="change">loss = criterion(output, batch_targets)</a>
        loss.backward()
        loss = loss.data[0]
        optimizer.step()
        print(&quotTrain Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.4f}&quot</code></pre>