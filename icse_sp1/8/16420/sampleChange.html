<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        batch_size = data.size(0)
        running_batch_sizes += batch_size
        real_label = Variable(torch.ones(batch_size))
        fake_label = Variable(<a id="change">torch.zeros(batch_size)</a>)

        &#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47
        &#47&#47 (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))
        &#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47
        real_img = Variable(target)
        if torch.cuda.is_available():
            real_img = real_img.cuda()
            <a id="change">real_label = real_label.cuda()</a>

        &#47&#47 compute loss of real_img
        real_out = netD(real_img)
        d_loss_real = discriminator_criterion(real_out, real_label)
        real_scores = real_out.data.sum()
        running_real_scores += real_scores

        &#47&#47 compute loss of fake_img
        z = Variable(data)
        if torch.cuda.is_available():
            z = z.cuda()
            fake_label = fake_label.cuda()
        fake_img = netG(z)
        fake_out = netD(fake_img)
        d_loss_fake = discriminator_criterion(fake_out, fake_label)
        fake_scores = fake_out.data.sum()

        d_loss = d_loss_real + d_loss_fake

        &#47&#47 bp and optimize
        optimizerD.zero_grad()
        d_loss.backward(retain_graph=True)
        optimizerD.step()

        &#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47
        &#47&#47 (2) Update G network: maximize log(D(G(z)))
        &#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47
        index = 1
        while ((fabs((real_scores - fake_scores) / batch_size) &gt; G_THRESHOLD) or g_update_first) and (
                    index &lt;= G_STOP_THRESHOLD):
            &#47&#47 compute loss of fake_img
            g_loss = generator_criterion(fake_out, real_label, fake_img, real_img)
            &#47&#47 bp and optimize
            optimizerG.zero_grad()
            g_loss.backward()
            optimizerG.step()
            fake_img = netG(z)
            fake_out = netD(fake_img)
            fake_scores = fake_out.data.sum()
            g_update_first = False
            index += 1

        g_loss = generator_criterion(fake_out, real_label, fake_img, real_img)
        running_g_loss += g_loss.data[0] * batch_size
        <a id="change">d_loss_fake = discriminator_criterion(fake_out, fake_label)</a>
        d_loss = <a id="change">d_loss_real + d_loss_fake</a>
        running_d_loss += d_loss.data[0] * batch_size
        running_fake_scores += fake_scores

        train_bar.set_description(desc=&quot[%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f&quot</code></pre><h3>After Change</h3><pre><code class='java'>
        fake_out = netD(fake_img)
        fake_scores = fake_out.data.sum()

        d_loss = - torch.mean(<a id="change">torch.log(real_out) + torch.log(1 - fake_out)</a>)

        &#47&#47 bp and optimize
        optimizerD.zero_grad()</code></pre>