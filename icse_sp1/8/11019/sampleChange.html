<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    def __init__(self, d_model, num_heads, pdrop, scale=True, layers=1, activation=&quotrelu&quot, d_ff=None, name=None, **kwargs):
        super(TransformerEncoderStack, self).__init__(name=name)
        self.encoders = []
        <a id="change">self.ln</a> = <a id="change">LayerNorm(name=&quotln_out&quot)</a>
        for i in range(layers):
            self.encoders.append(TransformerEncoder(d_model, num_heads, pdrop, scale, activation, d_ff))

    def call(self, inputs, mask=None):</code></pre><h3>After Change</h3><pre><code class='java'>
    def __init__(self, num_heads, d_model, pdrop, scale=True, layers=1, activation_type=&quotrelu&quot, d_ff=None, name=None, **kwargs):
        super().__init__(name=name)
        self.encoders = []
        <a id="change">self.ln</a> = <a id="change">tf.keras.layers.LayerNormalization(epsilon=1e-6)</a>
        for i in range(layers):
            self.encoders.append(TransformerEncoder(num_heads, d_model, pdrop, scale, activation_type, d_ff))

    def call(self, inputs):</code></pre>