<html><h3>9c526695805c9639896b31364958d0e77bdeba62,gpytorch/kernels/kernel.py,Kernel,__init__,#Kernel#Any#Any#Any#Any#Any#Any#,86
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        eps=1e-6,
    ):
        super(Kernel, self).__init__()
        <a id="change">if active_dims is not None and not torch.is_tensor(active_dims):
            active_dims = torch.tensor(active_dims, dtype=torch.long)
       </a> <a id="change">self.register_buffer("active_dims", active_dims)</a>
        self.ard_num_dims = ard_num_dims
        self.batch_size = batch_size
        self.__has_lengthscale = has_lengthscale
        if has_lengthscale:</code></pre><h3>After Change</h3><pre><code class='java'>
        :func:`gpytorch.lazy.LazyTensor.evaluate` method on the output.

    This base :class:`Kernel` class includes a lengthscale parameter
    :mat<a id="change">h:`\Theta`, which is used by many common kernel functions.
    There are a few options for the lengthscale:

    * Default: No lengthscale (i.e. :math:`\Theta` is the identity matrix).

    * Single lengthscale: One lengthscale can be applied to all input dimensions/batches
      (i.e. :math:`\Theta` is a constant diagonal matrix).
      This is controlled by setting `has_lengthscale=True`.

    * ARD: Each input dimension gets its own separate lengthscale
      (i.e. :math:`\Theta` is a non-constant diagonal matrix).
      This is controlled by the `ard_num_dims` keyword argument (as well has `has_lengthscale=True`).

    In batch-mode (i.e. when :math:`x_1` and :math:`x_2` are batches of input matrices), each
    batch of data can </a>have its own lengthscale parameter by setting the `batch_size`
    keyword argument to the appropriate number of batches.

    .. note::</code></pre><img src="173717242.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/cornellius-gp/gpytorch/commit/9c526695805c9639896b31364958d0e77bdeba62#diff-48fce01a785fa7385b13c3ea8887f064cd66292a00cf2ee5c506b013e2a78231L21' target='_blank'>Link</a></div><div id='project'> Project Name: cornellius-gp/gpytorch</div><div id='commit'> Commit Name: 9c526695805c9639896b31364958d0e77bdeba62</div><div id='time'> Time: 2018-11-14</div><div id='author'> Author: gardner.jake@gmail.com</div><div id='file'> File Name: gpytorch/kernels/kernel.py</div><div id='class'> Class Name: Kernel</div><div id='method'> Method Name: __init__</div><BR><BR><div id='link'><a href='https://github.com/cornellius-gp/gpytorch/commit/5b629fe89f1fdf7dd4126135825149ff848128be#diff-0d9e10b600d4a19bef412b4c00471298d76b7fe3876cdc4e28f6c35300118608L15' target='_blank'>Link</a></div><div id='project'> Project Name: cornellius-gp/gpytorch</div><div id='commit'> Commit Name: 5b629fe89f1fdf7dd4126135825149ff848128be</div><div id='time'> Time: 2017-06-29</div><div id='author'> Author: jrg365@cornell.edu</div><div id='file'> File Name: gpytorch/inference/posterior_models.py</div><div id='class'> Class Name: _ExactGPPosterior</div><div id='method'> Method Name: __init__</div><BR><BR><div id='link'><a href='https://github.com/cornellius-gp/gpytorch/commit/d44475866914c19f23c0f8a833951f9989250334#diff-48fce01a785fa7385b13c3ea8887f064cd66292a00cf2ee5c506b013e2a78231L88' target='_blank'>Link</a></div><div id='project'> Project Name: cornellius-gp/gpytorch</div><div id='commit'> Commit Name: d44475866914c19f23c0f8a833951f9989250334</div><div id='time'> Time: 2018-11-17</div><div id='author'> Author: balandat@fb.com</div><div id='file'> File Name: gpytorch/kernels/kernel.py</div><div id='class'> Class Name: Kernel</div><div id='method'> Method Name: __init__</div><BR>