<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        "image/format": tf.FixedLenFeature((), tf.string, "jpeg"),
        "image/class/label": tf.FixedLenFeature([], tf.int64, -1),
        "image/class/text": tf.FixedLenFeature([], tf.string, ""),
        "image/object/bbox/xmin": <a id="change">tf.VarLenFeature(dtype=tf.float32)</a>,
        "image/object/bbox/ymin": <a id="change">tf.VarLenFeature(dtype=tf.float32)</a>,
        "image/object/bbox/xmax": <a id="change">tf.VarLenFeature(dtype=tf.float32)</a>,
        "image/object/bbox/ymax": <a id="change">tf.VarLenFeature(dtype=tf.float32)</a>,
        "image/object/class/label": tf.VarLenFeature(dtype=tf.int64),
    }
</code></pre><h3>After Change</h3><pre><code class='java'>
  def dataset_parser(self, value):
    Parse an Imagenet record from value.
    keys_to_features = {
        "image/encoded": <a id="change">tf.FixedLenFeature(()</a>, tf.string, ""),
        "image/format": tf.FixedLenFeature((), tf.string, "jpeg"),
        "image/class/label": <a id="change">tf.FixedLenFeature([]</a>, tf.int64, -1),
        "image/class/text": <a id="change">tf.FixedLenFeature([]</a>, tf.string, ""),
        "image/object/bbox/xmin": <a id="change">tf.VarLenFeature(dtype=tf.float32)</a>,
        "image/object/bbox/ymin": <a id="change">tf.VarLenFeature(dtype=tf.float32)</a>,
        "image/object/bbox/xmax": <a id="change">tf.VarLenFeature(dtype=tf.float32)</a>,
        "image/object/bbox/ymax": <a id="change">tf.VarLenFeature(dtype=tf.float32)</a>,
        "image/object/class/label": <a id="change">tf.VarLenFeature(dtyp</a>e=tf.int64),
    }

    parsed = <a id="change">tf.parse_single_examp</a>le(value, keys_to_features)

    image = tf.image.decode_image(
        <a id="change">tf.reshape(parsed["im</a>age/encoded"], shape=[]), _NUM_CHANNELS)
    image = tf.image.convert_image_dtype(image, dtype=tf.float32)

    &#47&#47 TODO(shivaniagrawal): height and width of image from model
    image = vgg_preprocessing.preprocess_image(
        image=image,
        output_height=224,
        output_width=224,
        is_training=self.is_training)

    label = <a id="change">tf.cast(
        tf.r</a><a id="change">eshape(parsed["im</a>age/class/label"], shape=[]), dtype=tf.int32)

    return image, <a id="change">tf.one_hot(label, _LA</a>BEL_CLASSES)

  def __call__(self, params):
    Input function which provides a single batch for train or eval.</code></pre>