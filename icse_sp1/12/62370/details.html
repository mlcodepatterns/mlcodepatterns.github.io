<html><h3>58f4620699ac8e8eecbc0746dfcc8a497f01d6ba,tensorlayer/activation.py,,leaky_relu,#Any#Any#Any#,42
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    &#47&#47 x = tf.nn.relu(x)
    &#47&#47 m_x = tf.nn.relu(-x)
    &#47&#47 x -= alpha * m_x
    <a id="change">x = tf.maximum(x, alpha * x, name=name)</a>
    <a id="change">return x</a>


def swish(x, name=&quotswish&quot):
    Swish function.</code></pre><h3>After Change</h3><pre><code class='java'>

    

    <a id="change">if not (0 &lt; alpha &lt;= 1):
        raise ValueError("`alpha` value must be in [0, 1]`")

    with tf.name_scope(name, "leaky_relu") as name_scope:
        x = tf.convert_to_tensor(x, name="features")
        return tf.maximum(x, alpha * x, name=name_scope)


def leaky_relu6(x, alpha=0.2, name="leaky_relu6"):
    :func:`leaky_relu6` can be used through its shortcut: :func:`tl.act.lrelu6`.

    This activation function is a modified version :func:`leaky_relu` introduced by the following paper:
    `Rectifier Nonlinearities Improve Neural Network Acoustic Models [A. L. Maas et al., 2013] &lt;https://ai.stanford.edu/~amaas/papers/relu_hybrid_icml2013_final.pdf&gt;`__

    This activation function also follows the behaviour of the activation function :func:`tf.nn.relu6` introduced by the following paper:
    `Convolutional Deep Belief Networks on CIFAR-10 [A. Krizhevsky, 2010] &lt;http://www.cs.utoronto.ca/~kriz/conv-cifar10-aug2010.pdf&gt;`__

    The function return the following results:
      - When x &lt; 0: ``f(x) = alpha_low * x``.
      - When x in [0, 6]: ``f(x) = x``.
      - When x &gt; 6: ``f(x) = 6``.

    Parameters
    ----------
    x : Tensor
        Support input type ``float``, ``double``, ``int32``, ``int64``, ``uint8``, ``int16``, or ``int8``.
    alpha : float
        Slope.
    name : str
        The function name (optional).

    Examples
    --------
    &gt;&gt;&gt; import tensorlayer as tl
    &gt;&gt;&gt; net = tl.layers.DenseLayer(net, 100, act=lambda x : tl.act.leaky_relu6(x, 0.2), name=&quotdense&quot)

    Returns
    -------
    Tensor
        A ``Tensor`` in the same type as ``x``.

    References
    ----------
    - `Rectifier Nonlinearities Improve Neural Network Acoustic Models [A. L. Maas et al., 2013] &lt;https://ai.stanford.edu/~amaas/papers/relu_hybrid_icml2013_final.pdf&gt;`__
    - `Convolutional Deep Belief Networks on CIFAR-10 [A. Krizhevsky, 2010] &lt;http://www.cs.utoronto.ca/~kriz/conv-cifar10-aug2010.pdf&gt;`__
    

    if not (0 &lt; alpha &lt;= 1):
        raise ValueError("`alpha` value must be in [0, 1]`")

    with tf.name_scope(name, "leaky_relu6") as name_scope:
        x = tf.convert_to_tensor(x, name="features")
        return tf.minimum(tf.maximum(x, alpha * x), 6, name=name_scope)


def leaky_twice_relu6(x</a>, alpha_low=0.2, alpha_high=0.2, name="leaky_relu6"):
    :func:`leaky_twice_relu6` can be used through its shortcut: :func:`:func:`tl.act.ltrelu6`.

    This activation function is a modified version :func:`leaky_relu` introduced by the following paper:</code></pre><img src="287690325.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 8</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/tensorlayer/tensorlayer/commit/58f4620699ac8e8eecbc0746dfcc8a497f01d6ba#diff-fbbf2e5c0c8f7f982f1f21477db91c6661e370163db852d18a9d4b446ce2be0bL75' target='_blank'>Link</a></div><div id='project'> Project Name: tensorlayer/tensorlayer</div><div id='commit'> Commit Name: 58f4620699ac8e8eecbc0746dfcc8a497f01d6ba</div><div id='time'> Time: 2018-06-08</div><div id='author'> Author: contact@jonathandekhtiar.eu</div><div id='file'> File Name: tensorlayer/activation.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: leaky_relu</div><BR><BR><div id='link'><a href='https://github.com/analysiscenter/batchflow/commit/e0df81789b43a95c32a8aa9e6ce64baba216c5fe#diff-09f3d6d8059370385bbd0e49bbd5256a8a9c1f02b71b648651b91e4440f407ebL196' target='_blank'>Link</a></div><div id='project'> Project Name: analysiscenter/batchflow</div><div id='commit'> Commit Name: e0df81789b43a95c32a8aa9e6ce64baba216c5fe</div><div id='time'> Time: 2017-12-15</div><div id='author'> Author: g.ivanov@analysiscenter.ru</div><div id='file'> File Name: dataset/batch_image.py</div><div id='class'> Class Name: BaseImagesBatch</div><div id='method'> Method Name: rotate</div><BR><BR><div id='link'><a href='https://github.com/biolab/orange3/commit/d2cc0fb493b359fcbcd25410d1ddfe50954766aa#diff-8431f47157ec489403d29777e0fee60457e4c54fd92521a5661bfbfd499c6456L7' target='_blank'>Link</a></div><div id='project'> Project Name: biolab/orange3</div><div id='commit'> Commit Name: d2cc0fb493b359fcbcd25410d1ddfe50954766aa</div><div id='time'> Time: 2013-06-03</div><div id='author'> Author: jure.zbontar@gmail.com</div><div id='file'> File Name: Orange/classification/linear_regression.py</div><div id='class'> Class Name: LinearRegressionLearner</div><div id='method'> Method Name: fit</div><BR>