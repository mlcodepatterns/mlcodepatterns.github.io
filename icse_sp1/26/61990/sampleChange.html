<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

    net_discr = Discriminator(input_shape=input_shape)
    net_gener = Generator(output_shape=input_shape)
    <a id="change">if args.cuda:
        net_discr.cuda()
        net_gener.cuda()

   </a> objective = nn.BCELoss()
    gen_optimizer = optim.Adam(params=net_gener.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))
    dis_optimizer = optim.Adam(params=net_discr.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))
    writer = SummaryWriter()

    gen_losses = []
    dis_losses = []
    iter_no = 0

    true_labels_v = Variable(torch.FloatTensor([1.0] * BATCH_SIZE))
    fake_labels_v = Variable(torch.FloatTensor([0.0] * BATCH_SIZE))
    if <a id="change">args</a>.cuda:
        true_labels_v = true_labels_v.cuda()
        fake_labels_v = fake_labels_v.cuda()

    for batch_v in iterate_batches(envs):
        &#47&#47 generate extra fake samples, input is 4D: batch, filters, x, y
        gen_input_v = Variable(torch.FloatTensor(BATCH_SIZE, LATENT_VECTOR_SIZE, 1, 1).normal_(0, 1))
        <a id="change">if args.cuda:
            batch_v = batch_v.cuda()
            gen_input_v = gen_input_v.cuda()
       </a> gen_output_v = net_gener(gen_input_v)

        &#47&#47 train discriminator
        dis_optimizer.zero_grad()
        dis_output_true_v = net_discr(batch_v)
        dis_output_fake_v = net_discr(gen_output_v.detach())
        dis_loss = objective(dis_output_true_v, true_labels_v) + objective(dis_output_fake_v, fake_labels_v)
        dis_loss.backward()
        dis_optimizer.step()
        dis_losses.append(dis_loss.data.cpu().numpy())

        &#47&#47 train generator
        gen_optimizer.zero_grad()
        dis_output_v = net_discr(gen_output_v)
        <a id="change">gen_loss_v</a> = objective(dis_output_v, true_labels_v)
        gen_loss_v.backward()
        gen_optimizer.step()
        gen_losses.append(<a id="change">gen_loss_v.data.cpu().numpy()</a>)

        iter_no += 1
        if iter_no % REPORT_EVERY_ITER == 0:</code></pre><h3>After Change</h3><pre><code class='java'>
    parser.add_argument("--cuda", default=False, action=&quotstore_true&quot, help="Enable cuda computation")
    args = parser.parse_args()

    <a id="change">device = torch.device("cuda" if args.cuda else "cpu")</a>
    envs = [InputWrapper(gym.make(name)) for name in (&quotBreakout-v0&quot, &quotAirRaid-v0&quot, &quotPong-v0&quot)]
    input_shape = envs[0].observation_space.shape

    net_discr = <a id="change">Discriminator(input_shape=input_shape).to(device)</a>
    net_gener = Generator(output_shape=input_shape).to(device)

    objective = nn.BCELoss()
    gen_optimizer = optim.Adam(params=net_gener.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))
    dis_optimizer = optim.Adam(params=net_discr.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))
    writer = SummaryWriter()

    gen_losses = []
    dis_losses = []
    iter_no = 0

    true_labels_v = torch.ones(BATCH_SIZE, dtype=torch.float32, device=<a id="change">device</a>)
    fake_labels_v = torch.zeros(BATCH_SIZE, dtype=torch.float32, device=<a id="change">device</a>)

    for batch_v in iterate_batches(envs):
        &#47&#47 generate extra fake samples, input is 4D: batch, filters, x, y
        <a id="change">gen_input_v</a> = torch.FloatTensor(BATCH_SIZE, LATENT_VECTOR_SIZE, 1, 1).normal_(0, 1).to(device)
        batch_v = batch_v.to(<a id="change">device</a>)
        gen_output_v = net_gener(gen_input_v)

        &#47&#47 train discriminator
        dis_optimizer.zero_grad()
        dis_output_true_v = net_discr(batch_v)
        dis_output_fake_v = net_discr(gen_output_v.detach())
        dis_loss = objective(dis_output_true_v, true_labels_v) + objective(dis_output_fake_v, fake_labels_v)
        dis_loss.backward()
        dis_optimizer.step()
        dis_losses.append(dis_loss.item())

        &#47&#47 train generator
        gen_optimizer.zero_grad()
        dis_output_v = net_discr(gen_output_v)
        <a id="change">gen_loss_v</a> = objective(dis_output_v, true_labels_v)
        gen_loss_v.backward()
        gen_optimizer.step()
        gen_losses.append(<a id="change">gen_loss_v</a>.item())

        iter_no += 1
        if iter_no % REPORT_EVERY_ITER == 0:</code></pre>