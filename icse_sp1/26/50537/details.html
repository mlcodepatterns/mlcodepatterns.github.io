<html><h3>7239447415c21586291d5c993e30fba5df54b9db,foolbox/models/pytorch.py,PyTorchModel,batch_gradients,#PyTorchModel#Any#Any#,155
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 lazy import
        import torch
        import torch.nn as nn
        <a id="change">if self._old_pytorch():  &#47&#47 pragma: no cover
            from torch.autograd import Variable

       </a> input_shape = images.shape
        images, dpdx = self._process_input(images)
        target = np.asarray(labels)
        target = torch.from_numpy(labels).long().to(self.device)
        images = torch.from_numpy(images).to(self.device)

        <a id="change">if self._old_pytorch():  &#47&#47 pragma: no cover
            target = Variable(target)
            images = Variable(images, requires_grad=True)
        else:
            images.requires_grad_()

       </a> predictions = self._model(images)
        ce = nn.CrossEntropyLoss()
        loss = ce(predictions, target)
        loss.backward()
        <a id="change">grad</a> = images.grad

        <a id="change">if self._old_pytorch():  &#47&#47 pragma: no cover
            grad = grad.data
       </a> <a id="change">grad = grad.to("cpu")</a>
        <a id="change">if not self._old_pytorch():
            grad = grad.detach()
       </a> <a id="change">grad = grad.numpy()</a>
        grad = self._process_gradient(dpdx, grad)
        assert grad.shape == input_shape
        return grad
</code></pre><h3>After Change</h3><pre><code class='java'>
        target = np.asarray(labels)
        target = torch.from_numpy(labels).long().to(self.device)
        images = torch.from_numpy(images).to(self.device)
        <a id="change">images.requires_grad_()</a>

        predictions = self._model(images)
        ce = nn.CrossEntropyLoss()
        loss = ce(predictions, target)</code></pre><img src="234534203.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 19</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/bethgelab/foolbox/commit/7239447415c21586291d5c993e30fba5df54b9db#diff-607d4506afad4e24aefcce271c9b0e4ee0a55ee96eaaea094eb5f40404eb03a5L130' target='_blank'>Link</a></div><div id='project'> Project Name: bethgelab/foolbox</div><div id='commit'> Commit Name: 7239447415c21586291d5c993e30fba5df54b9db</div><div id='time'> Time: 2019-05-17</div><div id='author'> Author: git@jonasrauber.de</div><div id='file'> File Name: foolbox/models/pytorch.py</div><div id='class'> Class Name: PyTorchModel</div><div id='method'> Method Name: batch_gradients</div><BR><BR><div id='link'><a href='https://github.com/bethgelab/foolbox/commit/7239447415c21586291d5c993e30fba5df54b9db#diff-607d4506afad4e24aefcce271c9b0e4ee0a55ee96eaaea094eb5f40404eb03a5L215' target='_blank'>Link</a></div><div id='project'> Project Name: bethgelab/foolbox</div><div id='commit'> Commit Name: 7239447415c21586291d5c993e30fba5df54b9db</div><div id='time'> Time: 2019-05-17</div><div id='author'> Author: git@jonasrauber.de</div><div id='file'> File Name: foolbox/models/pytorch.py</div><div id='class'> Class Name: PyTorchModel</div><div id='method'> Method Name: batch_backward</div><BR><BR><div id='link'><a href='https://github.com/bethgelab/foolbox/commit/7239447415c21586291d5c993e30fba5df54b9db#diff-607d4506afad4e24aefcce271c9b0e4ee0a55ee96eaaea094eb5f40404eb03a5L105' target='_blank'>Link</a></div><div id='project'> Project Name: bethgelab/foolbox</div><div id='commit'> Commit Name: 7239447415c21586291d5c993e30fba5df54b9db</div><div id='time'> Time: 2019-05-17</div><div id='author'> Author: git@jonasrauber.de</div><div id='file'> File Name: foolbox/models/pytorch.py</div><div id='class'> Class Name: PyTorchModel</div><div id='method'> Method Name: predictions_and_gradient</div><BR>