<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

    def test_train_on_single_set_test_on_batch(self):
        &#47&#47 We&quotre manually going to set the hyperparameters to something they shouldn&quott be
        <a id="change">likelihood = GaussianLikelihood()</a>
        gp_model = ExactGPModel(train_x1, train_y1, likelihood)
        mll = gpytorch.ExactMarginalLogLikelihood(likelihood, gp_model)
        gp_model.covar_module.base_kernel.initialize(log_lengthscale=-1)
        <a id="change">gp_model.mean_module.initialize(constant=0)</a>
        likelihood.initialize(log_noise=0)

        &#47&#47 Find optimal model hyperparameters
        gp_model.train()</code></pre><h3>After Change</h3><pre><code class='java'>

    def test_train_on_single_set_test_on_batch(self):
        &#47&#47 We&quotre manually going to set the hyperparameters to something they shouldn&quott be
        likelihood = <a id="change">GaussianLikelihood(
            log_noise_prior=gpytorch.priors.NormalPrior(loc=torch.zeros(1), scale=torch.ones(1), log_transform=True)
        )</a>
        gp_model = ExactGPModel(train_x1, train_y1, likelihood)
        mll = gpytorch.ExactMarginalLogLikelihood(likelihood, gp_model)

        &#47&#47 Find optimal model hyperparameters
        gp_model.train()
        likelihood.train()
        optimizer = optim.Adam(list(gp_model.parameters()) + list(likelihood.parameters()), lr=0.1)
        optimizer.n_iter = 0
        gp_model.train()
        likelihood.train()
        <a id="change">optimizer = optim.Adam(gp_model.parameters(), lr=0.1)</a>
        for _ in range(50):
            optimizer.zero_grad()
            output = gp_model(train_x1)
            loss = -mll(output, train_y1).sum()</code></pre>