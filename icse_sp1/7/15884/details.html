<html><h3>10a674a0d6fa608e1920313955b8aa09b48b0fa8,theano/gpuarray/blas.py,GpuGemm,make_node,#GpuGemm#Any#Any#Any#Any#Any#,161
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        C = as_gpuarray_variable(C, ctx_name)
        with theano.configparser.change_flags(warn_float64=&quotignore&quot):
            alpha = as_tensor_variable(alpha).astype(&quotfloat64&quot)
            beta = <a id="change">as_tensor_variable(beta).astype(&quotfloat64&quot)</a>
        assert alpha.ndim == 0
        assert beta.ndim == 0
        assert A.ndim == 2
        assert B.ndim == 2</code></pre><h3>After Change</h3><pre><code class='java'>
        alpha = as_tensor_variable(alpha)
        beta = as_tensor_variable(beta)

        <a id="change">if not (A.dtype == B.dtype == C.dtype == alpha.dtype == beta.dtype):
            raise TypeError(Gemm.E_mixed,
                            (A.dtype, B.dtype, C.dtype,
                             alpha.dtype, beta.dtype))
        if not A.dtype.startswith(&quotfloat&quot):
            raise TypeError(Gemm.E_float, (A.dtype))
        assert alpha.ndim == 0
        assert beta.ndim == 0
        assert A.ndim == 2
        assert B.ndim == 2
        assert C.ndim == 2
        assert A.dtype == B.dtype == C.dtype
        return Apply(self, [C, alpha, A, B, beta], [C.type()])

    def perform(self, node, inputs, outputs):
        C, alpha, A, B, beta = inputs
        inplace = self.inplace
        if inplace and not C.flags.forc:
            inplace = False
        outputs[0][0] = blas.gemm(alpha, A, B, beta, C,
                                  overwrite_c=inplace)

    def c_code(self, node, name, inp, out, sub):
        vars = dict(out=out[0], C=inp[0], alpha=inp[1], A=inp[2], B=inp[3],
                    beta=inp[4], fail=sub[&quotfail&quot], name=name)
        if self.inplace:
            code = 
                   if (!GpuArray_ISONESEGMENT(&%(C)s-&gt;ga)) {
                     %(out)s = theano_try_copy(%(out)s, %(C)s);
                     if (%(out)s == NULL) {
                       %(fail)s
                     }
                   } else {
                     Py_XDECREF(%(out)s);
                     %(out)s = %(C)s;
                     Py_INCREF(%(out)s);
                   }
                    % vars
        else:
            code = 
                   %(out)s = theano_try_copy(%(out)s, %(C)s);
                   if (%(out)s == NULL) {
                       %(fail)s
                   }
                    % vars
        code += 
        if (pygpu_blas_rgemm(cb_no_trans, cb_no_trans,
                             ((dtype_%(alpha)s *)PyArray_DATA(%(alpha)s))[0],
                             %(A)s, %(B)s,
                             ((dtype_%(beta)s *)PyArray_DATA(%(beta)s))[0],
                             %(out)s, 0) == -1) {
            %(fail)s
        }
         % vars
        if config.gpuarray.sync:
            code += 
            GpuArray_sync(&%(out)s-&gt;ga);
             % vars
        return code

    def c_code_cache_version(self):
        return (5,)

gpugemm_no_inplace = GpuGemm(inplace=False)
gpugemm_inplace = GpuGemm(inplace=True)


class GpuGer(BlasOp):
    
    Ger on the GPU.

    
    __props__ = (&quotinplace&quot,)

    def __init__(self, inplace=False):
        self.inplace = inplace
        if self.inplace:
            self.destroy_map = {0: [0]}

    def make_node(self, A, alpha, x, y):
        ctx_name = infer_context_name(A, x, y)
        A = as_gpuarray_variable(A, ctx_name)
        x = as_gpuarray_variable(x, ctx_name)
        y = as_gpuarray_variable(y, ctx_name)
        alpha = as_tensor_variable(alpha)
        if len(set([A.dtype, alpha.dtype, x.dtype, y.dtype])) != 1:
            raise TypeError(&quotger requires matching dtypes&quot,
                            (A.dtype, alpha.dtype, x.dtype, y.dtype))

        assert alpha.ndim == 0
        assert A.ndim == 2
        assert x.ndim == 1
        assert y.ndim == 1
        assert A.dtype == x.dtype == y.dtype
        return Apply(self, [A, alpha, x, y], [A.type()])

    def perform(self, node, inp, out):
        A, alpha, x, y = inp
        inplace = self.inplace
        if inplace and not A.flags.forc:
            inplace = False
        out[0][0] = blas.ger(alpha, x, y, A,
                             overwrite_a=inplace)

    def c_code(self, node, name, inp, out, sub):
        vars = dict(out=out[0], A=inp[0], alpha=inp[1], x=inp[2], y=inp[3],
                    fail=sub[&quotfail&quot], name=name)
        if self.inplace:
            code = 
                   if (!GpuArray_ISONESEGMENT(&%(A)s-&gt;ga)) {
                     %(out)s = theano_try_copy(%(out)s, %(A)s);
                     if (%(out)s == NULL) {
                       %(fail)s
                     }
                   } else {
                     Py_XDECREF(%(out)s);
                     %(out)s = %(A)s;
                     Py_INCREF(%(out)s);
                   }
                    % vars
        else:
            code = 
                   %(out)s = theano_try_copy(%(out)s, %(A)s);
                   if (%(out)s == NULL) {
                       %(fail)s
                   }
                    % vars
        code += 
        if (pygpu_blas_rger(((dtype_%(alpha)s *)PyArray_DATA(%(alpha)s))[0],
                            %(x)s, %(y)s, %(out)s, 0) == -1) {
            %(fail)s
        }
         % vars
        if config.gpuarray.sync:
            code += 
            GpuArray_sync(&%(out)s-&gt;ga);
             % vars
        return code

    def c_code_cache_version(self):
        return (3,)


gpuger_no_inplace = GpuGer(inplace=False)
gpuger_inplace = GpuGer(inplace=True)


class GpuDot22(BlasOp):
    
    Dot22 on the GPU.

    
    _f16_ok = True
    __props__ = ()

    def make_node(self, x, y):
        ctx_name = infer_context_name(x, y)
        x = as_gpuarray_variable(x, ctx_name)
        y = as_gpuarray_variable(y, ctx_name)
        assert x.ndim == 2
        assert y.ndim == 2
        assert x.dtype == y.dtype
        otype = x.type.clone(
            broadcastable=(x.type.broadcastab</a>le[0], y.type.broadcastable[1]))
        return Apply(self, [x, y], [otype()])

    def perform(self, node, inputs, outputs):</code></pre><img src="93758870.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/Theano/Theano/commit/10a674a0d6fa608e1920313955b8aa09b48b0fa8#diff-bdd32dd2fcaa8c6c260fdcf5cf6ea35e2cd867a11e4ad88f3985a01551f5cc20L162' target='_blank'>Link</a></div><div id='project'> Project Name: Theano/Theano</div><div id='commit'> Commit Name: 10a674a0d6fa608e1920313955b8aa09b48b0fa8</div><div id='time'> Time: 2017-03-28</div><div id='author'> Author: nouiz@nouiz.org</div><div id='file'> File Name: theano/gpuarray/blas.py</div><div id='class'> Class Name: GpuGemm</div><div id='method'> Method Name: make_node</div><BR><BR><div id='link'><a href='https://github.com/scikit-image/scikit-image/commit/0bf6d2940a46cd414be5d738232e49602fb90826#diff-6014adb7ff0006b49e7b08cce78e0ec1e35b405b6094bf61587ffc20ff9016d8L387' target='_blank'>Link</a></div><div id='project'> Project Name: scikit-image/scikit-image</div><div id='commit'> Commit Name: 0bf6d2940a46cd414be5d738232e49602fb90826</div><div id='time'> Time: 2018-05-22</div><div id='author'> Author: lagru@mailbox.org</div><div id='file'> File Name: skimage/morphology/extrema.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: local_maxima</div><BR><BR><div id='link'><a href='https://github.com/scipy/scipy/commit/4082e490922171edc86cc8f59a7f380a2e4c2f23#diff-0fd32f5f810aa9b07146f14d003e3e16ad377f8ed182d642b424d162393f1560L169' target='_blank'>Link</a></div><div id='project'> Project Name: scipy/scipy</div><div id='commit'> Commit Name: 4082e490922171edc86cc8f59a7f380a2e4c2f23</div><div id='time'> Time: 2020-05-13</div><div id='author'> Author: peter.mahler.larsen@gmail.com</div><div id='file'> File Name: scipy/spatial/_spherical_voronoi.py</div><div id='class'> Class Name: SphericalVoronoi</div><div id='method'> Method Name: __init__</div><BR>