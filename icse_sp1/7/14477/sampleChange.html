<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>


        &#47&#47 check if all results are available and rerun failed fit_evals
        <a id="change">for i, j in zip(param_ids, fold_ids):
            if (i, j) not in set(score_dict.keys()):
                _fit_eval(i, j)
       </a> assert len(score_dict.keys()) == len(param_list) * len(train_splits)
        print(score_dict)

        &#47&#47 Select the best parameter setting</code></pre><h3>After Change</h3><pre><code class='java'>


        &#47&#47 check if all results are available and rerun failed fit_evals. Try three times
        <a id="change">for i in range(3):
            failed_runs = [x for x in zip(param_ids, fold_ids) if x not in score_dict]
            if not failed_runs:
                break
            if verbose:
                print("{} runs succeeded, {} runs failed. Rerunning failed runs".format(len(score_dict.keys()),
                                                                                        len(failed_runs)))
            for (p, f) in failed_runs:
                try:
                    _fit_eval(p, f, verbose=verbose, i_rand=i)
                except Exception as e:
                    print(e)

        &#47&#47 make sure we ultimately have an output for every parameter - fold - combination
       </a> assert len(score_dict.keys()) == len(param_list) * len(train_splits)

        &#47&#47 Select the best parameter setting
        scores_array = np.zeros((len(param_list), len(train_splits)))</code></pre>