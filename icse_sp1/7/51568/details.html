<html><h3>d3f1a5ad4507e88b016e0a829f4ba142294c16e6,tensorflow_ranking/python/losses.py,_SoftmaxLoss,_precompute,#_SoftmaxLoss#Any#Any#Any#,871
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    label_sum = tf.reduce_sum(input_tensor=labels, axis=1, keepdims=True)
    &#47&#47 Padding for rows with label_sum = 0.
    nonzero_mask = tf.greater(tf.reshape(label_sum, [-1]), 0.0)
    <a id="change">padded_labels = tf.compat.v1.where(nonzero_mask, labels,
                                       _EPSILON * tf.ones_like(labels))</a>
    padded_label_sum = tf.reduce_sum(
        input_tensor=padded_labels, axis=1, keepdims=True)
    labels_for_softmax = padded_labels / padded_label_sum
    <a id="change">logits_for_softmax = logits</a>
    &#47&#47 Padded labels have 0 weights in label_sum.
    <a id="change">weights_for_softmax = tf.reshape(label_sum, [-1])</a>
    <a id="change">return labels_for_softmax, logits_for_softmax, weights_for_softmax</a>

  def compute_unreduced_loss(self, labels, logits, weights):
    See `_RankingLoss`.
    labels, logits, weights = self._precompute(labels, logits, weights)</code></pre><h3>After Change</h3><pre><code class='java'>
      labels = self._lambda_weight.individual_weights(labels, ranks)
    if weights is not None:
      labels *= weights
    <a id="change">return labels, logits</a>

  def compute_unreduced_loss(self, labels, logits):
    See `_RankingLoss`.
    label_sum = tf.reduce_sum(input_tensor=labels, axis=1, keepdims=True)</code></pre><img src="238197074.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/tensorflow/ranking/commit/d3f1a5ad4507e88b016e0a829f4ba142294c16e6#diff-52afaff1e0b2beae35a65c83a5bc728d2d8f339569e11e6ff1ad54258349af5cL877' target='_blank'>Link</a></div><div id='project'> Project Name: tensorflow/ranking</div><div id='commit'> Commit Name: d3f1a5ad4507e88b016e0a829f4ba142294c16e6</div><div id='time'> Time: 2019-11-12</div><div id='author'> Author: xuanhui@google.com</div><div id='file'> File Name: tensorflow_ranking/python/losses.py</div><div id='class'> Class Name: _SoftmaxLoss</div><div id='method'> Method Name: _precompute</div><BR><BR><div id='link'><a href='https://github.com/hls-fpga-machine-learning/hls4ml/commit/8c4ca59b578a5e4bc7ef82c69722247307280160#diff-5e502d0d275264e7ec7d945a7f8c8f34be901ff95b0a4269e5e47ffd6886e44fL59' target='_blank'>Link</a></div><div id='project'> Project Name: hls-fpga-machine-learning/hls4ml</div><div id='commit'> Commit Name: 8c4ca59b578a5e4bc7ef82c69722247307280160</div><div id='time'> Time: 2020-11-18</div><div id='author'> Author: sioni.summers10@imperial.ac.uk</div><div id='file'> File Name: hls4ml/converters/keras/qkeras.py</div><div id='class'> Class Name: QKerasPO2Quantizer</div><div id='method'> Method Name: __call__</div><BR><BR><div id='link'><a href='https://github.com/hls-fpga-machine-learning/hls4ml/commit/8c4ca59b578a5e4bc7ef82c69722247307280160#diff-3c0c1eb3b0221b3f7bb54876209a35e37e46690db9ef543c3b29ecff491817b1L20' target='_blank'>Link</a></div><div id='project'> Project Name: hls-fpga-machine-learning/hls4ml</div><div id='commit'> Commit Name: 8c4ca59b578a5e4bc7ef82c69722247307280160</div><div id='time'> Time: 2020-11-18</div><div id='author'> Author: sioni.summers10@imperial.ac.uk</div><div id='file'> File Name: hls4ml/model/optimizer/passes/qkeras.py</div><div id='class'> Class Name: QKerasPO2Quantizer</div><div id='method'> Method Name: __call__</div><BR>