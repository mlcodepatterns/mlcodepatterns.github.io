<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

      if loss is None:
        loss = self._loss_fn
      <a id="change">with tf.GradientTape() as tape:
        if len(inputs) == 1:
          inputs = inputs[0]
        outputs = self.model(inputs)
        if isinstance(outputs, tf.Tensor):
          outputs = [outputs]
        if self._loss_outputs is not None:
          outputs = [outputs[i] for i in self._loss_outputs]
        batch_loss = loss(outputs, labels, weights)
     </a> if variables is None:
        vars = self.model.trainable_variables
      else:
        vars = variables</code></pre><h3>After Change</h3><pre><code class='java'>

      zero_grads = [tf.zeros(v.shape) for v in variables]
      self._tf_optimizer.apply_gradients(zip(zero_grads, variables))
    <a id="change">if var_key not in self._gradient_fn_for_vars:
      self._gradient_fn_for_vars[var_key] = self._create_gradient_fn(variables)
   </a> apply_gradient_for_batch = self._gradient_fn_for_vars[var_key]
    time1 = time.time()

    &#47&#47 Main training loop.</code></pre>