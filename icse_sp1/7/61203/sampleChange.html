<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        check_single_tensor_operation(&quottanh&quot, (4, 2), BACKENDS)

        &#47&#47 dropout
        val = np.random.random(<a id="change">(100, 100)</a>)
        x_list = [k.variable(val) <a id="change">for</a> k in BACKENDS]
        z_list = []
        for x, k in zip(x_list, BACKENDS):
            z_list.append(k.eval(k.dropout(x, level=0.2)))

        for i in range(len(z_list) - 1):
            assert z_list[i].shape == z_list[i + 1].shape
            &#47&#47 dropout patterns are different, only check mean
            assert np.abs(z_list[i].mean() - z_list[i + 1].mean()) &lt; 0.05

        check_two_tensor_operation(&quotbinary_crossentropy&quot, (4, 2), (4, 2), BACKENDS, from_logits=True)
        &#47&#47 cross_entropy call require the label is a valid probability distribution,
        &#47&#47 otherwise it is garbage in garbage out...
        &#47&#47 due to the algo difference, we can&quott guarantee CNTK has the same result on the garbage input.
        &#47&#47 so create a seperate test case for valid lable input
        check_two_tensor_operation(&quotcategorical_crossentropy&quot, (4, 2), (4, 2), [KTH, KTF], from_logits=True)
        check_cross_entropy_with_valid_probability_distribution()
        check_two_tensor_operation(&quotbinary_crossentropy&quot, (4, 2), (4, 2), BACKENDS, from_logits=False)
        check_two_tensor_operation(&quotcategorical_crossentropy&quot, (4, 2), (4, 2), BACKENDS, from_logits=False)

        check_single_tensor_operation(&quotl2_normalize&quot, (4, 3), BACKENDS, axis=-1)
        check_single_tensor_operation(&quotl2_normalize&quot, (4, 3), BACKENDS, axis=1)

        &#47&#47 Test invalid use cases
        <a id="change">for x, k in zip(x_list, [KTH, KTF]):
            with pytest.raises(ValueError):
                z = k.dropout(x, level=-0.5)

   </a> def test_in_top_k(self):
        batch_size = 20
        num_classes = 10
</code></pre><h3>After Change</h3><pre><code class='java'>
        check_two_tensor_operation(&quotcategorical_crossentropy&quot, (4, 2), (4, 2), [KTH, KTF], from_logits=True)
        xval = np.asarray([[0.26157712, 0.0432167], [-0.43380741, 0.30559841],
                           [0.20225059, -0.38956559], [-0.13805378, 0.08506755]], dtype=np.float32)
        <a id="change">yval = np.asarray([[0.46221867, 0.53778133], [0.51228984, 0.48771016],
                           [0.64916514, 0.35083486], [0.47028078, 0.52971922]], dtype=np.float32)</a>
        check_two_tensor_operation(&quotcategorical_crossentropy&quot, xval, yval,
                                   BACKENDS, cntk_two_dynamicity=True, from_logits=True)
        check_two_tensor_operation(&quotbinary_crossentropy&quot, (4, 2), (4, 2), BACKENDS, from_logits=False)
        check_two_tensor_operation(&quotcategorical_crossentropy&quot, (4, 2), (4, 2), BACKENDS, from_logits=False)</code></pre>