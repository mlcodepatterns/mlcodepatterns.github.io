<html><h3>b445c177a4543617c843f24943bb00e69ab24b36,sequenceLabelling/tokenizer.py,,tokenizeAndFilter,#Any#,15
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    return pattern.split(text)

def tokenizeAndFilter(text):
    tokens = <a id="change">tokenize(text)</a>
    finalTokens = []
    for token in tokens:
        if token not in blanks:
            finalTokens.append(token)</code></pre><h3>After Change</h3><pre><code class='java'>

def tokenizeAndFilter(text):
    &#47&#47tokens = tokenize(text)
    <a id="change">offset = 0</a>
    offsets = []
    tokens = []
    <a id="change">for index, match in enumerate(pattern.split(text)):
        print(index, match)
        tokens.append(match)
        position = (offset, offset+len(match))
        offsets.append(position)
        offset = offset+len(match)
    &#47&#47tokens = pattern.split(text)

   </a> finalTokens = []
    finalOffsets = []
    i = 0
    for token in tokens:</code></pre><img src="257010128.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/kermitt2/delft/commit/b445c177a4543617c843f24943bb00e69ab24b36#diff-a2da2313b7efb023ecc294820197614353a9ab5741f72d63b272eca4140f8b95L16' target='_blank'>Link</a></div><div id='project'> Project Name: kermitt2/delft</div><div id='commit'> Commit Name: b445c177a4543617c843f24943bb00e69ab24b36</div><div id='time'> Time: 2018-05-02</div><div id='author'> Author: patrice.lopez@science-miner.com</div><div id='file'> File Name: sequenceLabelling/tokenizer.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: tokenizeAndFilter</div><BR><BR><div id='link'><a href='https://github.com/lingpy/lingpy/commit/875a33806acea37f602d0ad20fb77cd42432bbb6#diff-1c73bc26dcce2401b2fa9da126c3b0acc85e523ec1635c04b5d59e90e78baef0L11' target='_blank'>Link</a></div><div id='project'> Project Name: lingpy/lingpy</div><div id='commit'> Commit Name: 875a33806acea37f602d0ad20fb77cd42432bbb6</div><div id='time'> Time: 2013-11-08</div><div id='author'> Author: bambooforest@gmail.com</div><div id='file'> File Name: scripts/tokenize/tokenize_pad.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: </div><BR><BR><div id='link'><a href='https://github.com/WZBSocialScienceCenter/tmtoolkit/commit/d1196006be574c16473df6efed448f9fa308a680#diff-51378749b59c3a776a9dbdcd863747e10ffe4991a82e8215a12c939d11a1c7bcL399' target='_blank'>Link</a></div><div id='project'> Project Name: WZBSocialScienceCenter/tmtoolkit</div><div id='commit'> Commit Name: d1196006be574c16473df6efed448f9fa308a680</div><div id='time'> Time: 2019-03-06</div><div id='author'> Author: markus.konrad@wzb.eu</div><div id='file'> File Name: tests/test_preprocess.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: test_tmpreproc_en_transform_tokens_lambda</div><BR>