<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            else:
                raise ValueError("Must stream updates to all existing columns (extra: %s)" % ", ".join(sorted(extra)))

        if <a id="change">not (pd and isinstance(new_data, pd.DataFrame))</a>:
            import numpy as np

            lengths = set()</code></pre><h3>After Change</h3><pre><code class='java'>
            newkeys = set(_df.columns)
            index_name = ColumnDataSource._df_index_name(_df)
            newkeys.add(index_name)
            <a id="change">new_data = dict(_df.iteritems())</a>
            new_data[index_name] = _df.index.values
        else:
            newkeys = set(new_data.keys())

        oldkeys = set(self.data.keys())

        if newkeys != oldkeys:
            missing = oldkeys - newkeys
            extra = newkeys - oldkeys
            if missing and extra:
                raise ValueError(
                    "Must stream updates to all existing columns (missing: %s, extra: %s)" % (", ".join(sorted(missing)), ", ".join(sorted(extra)))
                )
            elif missing:
                raise ValueError("Must stream updates to all existing columns (missing: %s)" % ", ".join(sorted(missing)))
            else:
                raise ValueError("Must stream updates to all existing columns (extra: %s)" % ", ".join(sorted(extra)))

        if needs_length_check:
            import numpy as np

            lengths = set()
            arr_types = (np.ndarray, pd.Series) if pd else np.ndarray
            for k, x in new_data.items():
                if isinstance(x, arr_types):
                    if len(x.shape) != 1:
                        raise ValueError("stream(...) only supports 1d sequences, got ndarray with size %r" % (x.shape,))
                    lengths.add(x.shape[0])
                else:
                    lengths.add(len(x))

            if len(lengths) &gt; 1:
                raise ValueError("All streaming column updates must be the same length")

        &#47&#47 slighgly awkward that we have to call converty_datetime_array here ourselves
        &#47&#47 but the downstream code expects things to already be ms-since-epoch
        <a id="change">for key in new_data:
            new_data[key] = convert_datetime_array(new_data[key])

       </a> self.data._stream(self.document, self, new_data, rollover, setter)

    def patch(self, patches, setter=None):
        &quot&quot&quot Efficiently update data source columns at specific locations</code></pre>