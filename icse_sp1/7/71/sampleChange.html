<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
             can be aligned to a brightfield image by this method since the relevant 
             features are bright in one modality where they are dim in the other. &lt;/li&gt;
             &lt;/ul&gt;&quot&quot&quot)
        self.wants_cropping = <a id="change">cps.Binary("Crop output images to retain just the aligned regions?",
                                         True, doc=&quot&quot&quot
             If cropping is chosen, all output images are cropped to retain 
             just those regions that exist in all channels after alignment. 
             If cropping is not chosen, the unaligned portions of each
             image are padded (with zeroes) and appear as black space.&quot&quot&quot)</a>
    
    def add_image(self, can_remove = True):
        &quot&quot&quotAdd an image + associated questions and buttons&quot&quot&quot
        group = cps.SettingsGroup()</code></pre><h3>After Change</h3><pre><code class='java'>
             &lt;/ul&gt;&quot&quot&quot)
        self.crop_mode = cps.Choice(
            "Crop mode", [C_CROP, C_PAD, C_SAME_SIZE],
            doc = <a id="change">The crop mode determines how the output images are cropped
            or padded after alignment. The alignment phase calculates the
            areas in each image that are found to be overlapping. In almost
            all cases, there will be portions of some or all of the images
            that don&quott overlap with every other aligned image. These portions
            have no counterpart in some image and analysis of these regions 
            will not be able to use the information from all images. There
            are three choices for cropping:
            &lt;br&gt;&lt;ul&gt;
            &lt;li&gt;&lt;i&gt;%(C_CROP)s&lt;/i&gt; - crop every image to the region of that
            image that overlaps with every other image. This makes downstream
            analysis more accurate and simpler because all of the output images
            have valid pixel data at all positions in the image but it discards
            parts of images. Also, the output images may not be the same size
            as the input images which may cause problems if downstream modules
            use aligned and unaligned images in combination.&lt;/li&gt;
            &lt;li&gt;&lt;i&gt;%(C_PAD)s&lt;/i&gt; - align every image and pad with masked black
            pixels to make each image the same size. This results in larger
            images, but preserves all information in each of the images. This
            may be the best choice if images undergo an operation such as
            smoothing that could use the information that would otherwise be
            cropped.&lt;/li&gt;
            &lt;li&gt;&lt;i&gt;%(C_SAME_SIZE)s&lt;/i&gt; - maintain the sizes of the images but
            align them, masking the unaligned portions. &lt;b&gt;Align&lt;/b&gt; finds the
            global alignment that preserves the most pixels among all the images
            and then repositions each image within an image of similar size
            to the input image. This is a reasonable option for alignments
            with small displacements since it maintains a consistent image
            size which may be useful if output images from different image sets
            will be compared against each other after processing.&lt;/li&gt;&lt;/ul % globals()</a>)
                                                                              
    def add_image(self, can_remove = True):
        &quot&quot&quotAdd an image + associated questions and buttons&quot&quot&quot</code></pre>