<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        import torch  &#47&#47 lgtm [py/repeated-import]

        x = torch.tensor(x, device=self._device)
        <a id="change">if y is not None:
            y = torch.tensor(y, device=self._device)

       </a> with torch.no_grad():
            x, y = self.forward(x, y)

        result = x.cpu().numpy()</code></pre><h3>After Change</h3><pre><code class='java'>
        x_preprocess = x.copy()

        &#47&#47 Filter one input at a time
        <a id="change">for i, x_preprocess_i in enumerate(tqdm(x_preprocess, desc="Apply audio filter", disable=not self.verbose)):
            if np.min(x_preprocess_i) &lt; -1.0 or np.max(x_preprocess_i) &gt; 1.0:
                raise ValueError(
                    "Audio signals must be normalized to the range `[-1.0, 1.0]` to apply the audio filter function."
                )

            x_preprocess_i = torch.tensor(x_preprocess_i, device=self._device)

            with torch.no_grad():
                x_preprocess_i, _ = self.forward(x_preprocess_i)

            x_preprocess[i] = x_preprocess_i.cpu().numpy()

       </a> return x_preprocess, y

    &#47&#47 Backward compatibility.
    def estimate_gradient(self, x: np.ndarray, grad: np.ndarray) -&gt; np.ndarray:</code></pre>