<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
          "Number of input channels must be known at module build time")
    input_channels = self._input_shape[2]

    <a id="change">if self._input_shape[0] is None:
      raise base.UnderspecifiedError(
          "Batch size must be known at module build time")
   </a> batch_size = self._input_shape[0]

    if self._use_default_output_shape:
      self._output_shape = (
          lambda: _default_transpose_size(self._input_shape[1:-1],  &#47&#47 pylint: disable=g-long-lambda
                                          self.stride[2],
                                          kernel_shape=self.kernel_shape,
                                          padding=self.padding))

    if len(self.output_shape) != 1:
      raise base.IncompatibleShapeError(
          "Output shape must be specified as (output_length)")

    if inputs.dtype != tf.float32:
      raise TypeError("Input must have dtype tf.float32, but dtype was {}"
                      .format(inputs.dtype))

    weight_shape = (
        1,
        self._kernel_shape[0],
        self.output_channels,
        input_channels)

    bias_shape = (self.output_channels,)

    if "w" not in self._initializers:
      fan_in_shape = (weight_shape[1], weight_shape[3])
      self._initializers["w"] = create_weight_initializer(fan_in_shape)

    if "b" not in self._initializers and self._use_bias:
      self._initializers["b"] = create_bias_initializer(bias_shape)

    self._w = tf.get_variable("w",
                              shape=weight_shape,
                              initializer=self._initializers["w"],
                              partitioner=self._partitioners.get("w", None),
                              regularizer=self._regularizers.get("w", None))

    tf_out_shape = (<a id="change">(batch_size, 1,)</a> + self._output_shape +
                    (self.output_channels,))

    &#47&#47 Add an extra dimension to the input - a height of 1.</code></pre><h3>After Change</h3><pre><code class='java'>
    batch_size = tf.expand_dims(tf.shape(inputs)[0], 0)
    out_shape = (1, self.output_shape[0])
    out_channels = (self.output_channels,)
    <a id="change">out_shape_tuple = out_shape + out_channels</a>
    conv_output_shape = tf.convert_to_tensor(out_shape_tuple)
    <a id="change">tf_out_shape = tf.concat([batch_size, conv_output_shape], 0)</a>

    &#47&#47 Add an extra dimension to the input - a height of 1.
    inputs = tf.expand_dims(inputs, 1)
</code></pre>