<html><h3>0be455f86d595c12333541c09f2c5861dd76c2d4,eval_utils.py,,eval_split,#Any#Any#Any#Any#,97
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                        n_predictions.append(entry)
            &#47&#47 case 2 sample_max =0 temperature xx
            elif sample_n_method == &quotsample&quot:
                <a id="change">tmp_eval_kwargs.update({&quotsample_max&quot: 0, &quotbeam_size&quot: 1})</a> &#47&#47 randomness from sample
                with torch.no_grad():
                    _seq, _sampleLogprobs = model(fc_feats, att_feats, att_masks, opt=tmp_eval_kwargs, mode=&quotsample&quot)
                _sents = utils.decode_sequence(loader.get_vocab(), _seq)
                <a id="change">for k, sent in enumerate(_sents):
                    entry = {&quotimage_id&quot: data[&quotinfos&quot][k // sample_n][&quotid&quot], &quotcaption&quot: sent}
                    n_predictions.append(entry)
            &#47&#47 case 3 gumbel max
           </a> elif sample_n_method == &quotgumbel&quot:
                tmp_eval_kwargs.update({&quotsample_max&quot: 2, &quotbeam_size&quot: 1}) &#47&#47 randomness from sample
                with torch.no_grad():
                    _seq, _sampleLogprobs = model(fc_feats, att_feats, att_masks, opt=tmp_eval_kwargs, mode=&quotsample&quot)</code></pre><h3>After Change</h3><pre><code class='java'>
            &#47&#47 case 2 sample_max =0 temperature xx / gumbel / topk sampling
            elif sample_n_method == &quotsample&quot or \
                 sample_n_method == &quotgumbel&quot or \
                 <a id="change">sample_n_method.startswith(&quottop&quot)</a>:
                if sample_n_method == &quotsample&quot:
                    <a id="change">tmp_sample_max = 0</a>
                elif sample_n_method == &quotgumbel&quot:
                    <a id="change">tmp_sample_max = 2</a>
                elif <a id="change">sample_n_method</a>.startswith(&quottop&quot):
                    tmp_sample_max = -int(sample_n_method[3:])
                tmp_eval_kwargs.update({&quotsample_max&quot: tmp_sample_max, &quotbeam_size&quot: 1}) &#47&#47 randomness from sample
                with torch.no_grad():</code></pre><img src="310391457.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/ruotianluo/ImageCaptioning.pytorch/commit/0be455f86d595c12333541c09f2c5861dd76c2d4#diff-ae2a626e48c778173c824cfa192d3be5f4faa116442b6a03936ad0358eb6fe5cL106' target='_blank'>Link</a></div><div id='project'> Project Name: ruotianluo/ImageCaptioning.pytorch</div><div id='commit'> Commit Name: 0be455f86d595c12333541c09f2c5861dd76c2d4</div><div id='time'> Time: 2019-04-27</div><div id='author'> Author: rluo@ttic.edu</div><div id='file'> File Name: eval_utils.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: eval_split</div><BR><BR><div id='link'><a href='https://github.com/biolab/orange3/commit/8d4d199c35f5163ed21ae705a16ce3c8548d60c6#diff-048724bfc81d355b9b693097eb2f3eb634750e239b04c4c723ae2f1e994eefa6L191' target='_blank'>Link</a></div><div id='project'> Project Name: biolab/orange3</div><div id='commit'> Commit Name: 8d4d199c35f5163ed21ae705a16ce3c8548d60c6</div><div id='time'> Time: 2012-11-28</div><div id='author'> Author: janez.demsar@fri.uni-lj.si</div><div id='file'> File Name: Orange/data/io.py</div><div id='class'> Class Name: BasketReader</div><div id='method'> Method Name: prescan_file</div><BR>