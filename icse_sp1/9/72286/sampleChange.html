<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            if phase == &quottar&quot and epoch_acc &gt; best_acc:
                best_acc = epoch_acc
        print()
        fname = <a id="change">&quotfinetune_result&quot + model_name + \
            str(LEARNING_RATE) + str(args.source) + \
            &quot-&quot + str(args.target) + &quot.csv&quot</a>
        np.savetxt(fname, np.asarray(a=acc_hist, dtype=float), delimiter=&quot,&quot,
                   fmt=&quot%.4f&quot)
    time_pass = time.time() - since
    print(&quotTraining complete in {:.0f}m {:.0f}s&quot.format(</code></pre><h3>After Change</h3><pre><code class='java'>
    criterion = nn.CrossEntropyLoss()
    stop = 0
    for epoch in range(1, args.n_epoch + 1):
        <a id="change">stop += 1</a>
        &#47&#47 You can uncomment this line for scheduling learning rate
        &#47&#47 lr_schedule(optimizer, epoch)
        for phase in [&quotsrc&quot, &quotval&quot, &quottar&quot]:
            if phase == &quotsrc&quot:
                model.train()
            else:
                model.eval()
            total_loss, correct = 0, 0
            for inputs, labels in dataloaders[phase]:
                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)
                optimizer.zero_grad()
                with torch.set_grad_enabled(phase == &quotsrc&quot):
                    outputs = model(inputs)
                    loss = criterion(outputs, labels)
                preds = torch.max(outputs, 1)[1]
                if phase == &quotsrc&quot:
                    loss.backward()
                    optimizer.step()
                total_loss += loss.item() * inputs.size(0)
                correct += torch.sum(preds == labels.data)
            epoch_loss = total_loss / len(dataloaders[phase].dataset)
            epoch_acc = correct.double() / len(dataloaders[phase].dataset)
            print(&quotEpoch: [{:02d}/{:02d}]---{}, loss: {:.6f}, acc: {:.4f}&quot.format(epoch, args.n_epoch, phase, epoch_loss,
                                                                                  epoch_acc))
            if phase == &quotval&quot and epoch_acc &gt; best_acc:
                stop = 0
                best_acc = epoch_acc
                torch.save(model.state_dict(), &quotmodel.pkl&quot)
        <a id="change">if stop &gt;= args.early_stop:
            break
       </a> print()
    model.load_state_dict(torch.load(&quotmodel.pkl&quot))
    acc_test = test(model, dataloaders[&quottar&quot])
    time_pass = time.time() - since</code></pre>