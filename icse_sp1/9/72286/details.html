<html><h3>2733bef356c53286d475a67476d88d4840923830,code/deep/finetune_AlexNet_ResNet/finetune_office31.py,,finetune,#Any#Any#Any#,87
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            if phase == &quottar&quot and epoch_acc &gt; best_acc:
                best_acc = epoch_acc
        print()
        fname = <a id="change">&quotfinetune_result&quot + model_name + \
            str(LEARNING_RATE) + str(args.source) + \
            &quot-&quot + str(args.target) + &quot.csv&quot</a>
        np.savetxt(fname, np.asarray(a=acc_hist, dtype=float), delimiter=&quot,&quot,
                   fmt=&quot%.4f&quot)
    time_pass = time.time() - since
    print(&quotTraining complete in {:.0f}m {:.0f}s&quot.format(</code></pre><h3>After Change</h3><pre><code class='java'>
    criterion = nn.CrossEntropyLoss()
    stop = 0
    for epoch in range(1, args.n_epoch + 1):
        <a id="change">stop += 1</a>
        &#47&#47 You can uncomment this line for scheduling learning rate
        &#47&#47 lr_schedule(optimizer, epoch)
        for phase in [&quotsrc&quot, &quotval&quot, &quottar&quot]:
            if phase == &quotsrc&quot:
                model.train()
            else:
                model.eval()
            total_loss, correct = 0, 0
            for inputs, labels in dataloaders[phase]:
                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)
                optimizer.zero_grad()
                with torch.set_grad_enabled(phase == &quotsrc&quot):
                    outputs = model(inputs)
                    loss = criterion(outputs, labels)
                preds = torch.max(outputs, 1)[1]
                if phase == &quotsrc&quot:
                    loss.backward()
                    optimizer.step()
                total_loss += loss.item() * inputs.size(0)
                correct += torch.sum(preds == labels.data)
            epoch_loss = total_loss / len(dataloaders[phase].dataset)
            epoch_acc = correct.double() / len(dataloaders[phase].dataset)
            print(&quotEpoch: [{:02d}/{:02d}]---{}, loss: {:.6f}, acc: {:.4f}&quot.format(epoch, args.n_epoch, phase, epoch_loss,
                                                                                  epoch_acc))
            if phase == &quotval&quot and epoch_acc &gt; best_acc:
                stop = 0
                best_acc = epoch_acc
                torch.save(model.state_dict(), &quotmodel.pkl&quot)
        <a id="change">if stop &gt;= args.early_stop:
            break
       </a> print()
    model.load_state_dict(torch.load(&quotmodel.pkl&quot))
    acc_test = test(model, dataloaders[&quottar&quot])
    time_pass = time.time() - since</code></pre><img src="328471188.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/jindongwang/transferlearning/commit/2733bef356c53286d475a67476d88d4840923830#diff-3a0171c82ffe1293d5696d6703828e34998b1c16890b633015cd0292eaabef25L89' target='_blank'>Link</a></div><div id='project'> Project Name: jindongwang/transferlearning</div><div id='commit'> Commit Name: 2733bef356c53286d475a67476d88d4840923830</div><div id='time'> Time: 2020-09-30</div><div id='author'> Author: jindongwang@outlook.com</div><div id='file'> File Name: code/deep/finetune_AlexNet_ResNet/finetune_office31.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: finetune</div><BR><BR><div id='link'><a href='https://github.com/PaddlePaddle/edl/commit/667d856a2fc27732d745cd7d926e9739ad12995c#diff-eb9f61d5d3f799fa0d15fe3af68d92468b2010ca09ad41ec983b3bb21c6fb388L184' target='_blank'>Link</a></div><div id='project'> Project Name: PaddlePaddle/edl</div><div id='commit'> Commit Name: 667d856a2fc27732d745cd7d926e9739ad12995c</div><div id='time'> Time: 2019-09-28</div><div id='author'> Author: wangjiawei04@baidu.com</div><div id='file'> File Name: example/ctr/ctr/train.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: train</div><BR><BR><div id='link'><a href='https://github.com/michaelhush/M-LOOP/commit/6e5cf676b113af8d70e34224f23bc8eace618856#diff-9f657823841d670472ac4a74f250306a7a967c04bb48f71aedd04a228fe3401fL120' target='_blank'>Link</a></div><div id='project'> Project Name: michaelhush/M-LOOP</div><div id='commit'> Commit Name: 6e5cf676b113af8d70e34224f23bc8eace618856</div><div id='time'> Time: 2017-05-02</div><div id='author'> Author: harry.slatyer@gmail.com</div><div id='file'> File Name: mloop/nnlearner.py</div><div id='class'> Class Name: SingleNeuralNet</div><div id='method'> Method Name: fit</div><BR>