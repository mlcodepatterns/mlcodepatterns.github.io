<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
GLOBAL_RUNNING_R = []
GLOBAL_EP = 0  &#47&#47 will increase during training, stop training when it &gt;= MAX_GLOBAL_EP

<a id="change">env = gym.make(GAME)</a>

<a id="change">N_S = env.observation_space.shape[0]</a>
N_A = <a id="change">env</a>.action_space.shape[0]

A_BOUND = [<a id="change">env</a>.action_space.low, <a id="change">env</a>.action_space.high]
A_BOUND[0] = A_BOUND[0].reshape(1, N_A)
<a id="change">A_BOUND[1] = A_BOUND[1].reshape(1, N_A)</a>
&#47&#47 print(A_BOUND)


class ACNet(object):</code></pre><h3>After Change</h3><pre><code class='java'>
ENTROPY_BETA = 0.005  &#47&#47 factor for entropy boosted exploration
LR_A = 0.00005  &#47&#47 learning rate for actor
LR_C = 0.0001  &#47&#47 learning rate for critic
GLOBAL_RUNNING_R = <a id="change">[]</a>
GLOBAL_EP = 0  &#47&#47 will increase during training, stop training when it &gt;= MAX_GLOBAL_EP


&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47  Asynchronous Advantage Actor Critic (A3C)  &#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47</code></pre>