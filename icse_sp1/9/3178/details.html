<html><h3>67addeaef37856340f2d220af9a7cad3c4256235,visdialch/decoders/disc.py,DiscriminativeDecoder,forward,#DiscriminativeDecoder#Any#Any#,22
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 score each option
        scores = []
        for opt_id in range(num_options):
            <a id="change">opt = options[:, opt_id, :, :]</a>
            opt_len = options_len[:, opt_id]
            opt_embed = self.option_rnn(opt, opt_len)
            scores.append(torch.sum(opt_embed * enc_out, 1))
</code></pre><h3>After Change</h3><pre><code class='java'>

        &#47&#47 repeat encoder output for every option
        &#47&#47 shape: (batch_size, num_rounds, num_options, max_sequence_length)
        encoder_output = <a id="change">encoder_output</a>.unsqueeze(<a id="change">2</a>).repeat(1, 1, num_options, 1)

        &#47&#47 shape now same as `options`, can calculate dot product similarity
        &#47&#47 shape: (batch_size * num_rounds * num_options, lstm_hidden_state)
        encoder_output = encoder_output.view(
            batch_size * num_rounds * num_options, self.config["lstm_hidden_size"]
        )

        &#47&#47 shape: (batch_size * num_rounds * num_options)
        <a id="change">scores = torch.sum(options_embed * encoder_output, 1)</a>
        &#47&#47 shape: (batch_size, num_rounds, num_options)
        scores = scores.view(batch_size, num_rounds, num_options)
        return scores
</code></pre><img src="22131777.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/batra-mlp-lab/visdial-challenge-starter-pytorch/commit/67addeaef37856340f2d220af9a7cad3c4256235#diff-5fb8bef254641f668f3b055ea01ab95846ce96ce973e6c096a07f8cbcc7beab6L22' target='_blank'>Link</a></div><div id='project'> Project Name: batra-mlp-lab/visdial-challenge-starter-pytorch</div><div id='commit'> Commit Name: 67addeaef37856340f2d220af9a7cad3c4256235</div><div id='time'> Time: 2019-01-03</div><div id='author'> Author: karandesai281196@gmail.com</div><div id='file'> File Name: visdialch/decoders/disc.py</div><div id='class'> Class Name: DiscriminativeDecoder</div><div id='method'> Method Name: forward</div><BR><BR><div id='link'><a href='https://github.com/interactiveaudiolab/nussl/commit/fa6f47e7aee228226421c52e61cce4e1ab4cc099#diff-8e24ae1876b6acf6b147b64965b92678414c0a4211393f8daeb7aa2777614063L41' target='_blank'>Link</a></div><div id='project'> Project Name: interactiveaudiolab/nussl</div><div id='commit'> Commit Name: fa6f47e7aee228226421c52e61cce4e1ab4cc099</div><div id='time'> Time: 2020-03-15</div><div id='author'> Author: prem@u.northwestern.edu</div><div id='file'> File Name: tests/ml/test_loss.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: test_permutation_invariant_loss_tf</div><BR><BR><div id='link'><a href='https://github.com/kevinzakka/recurrent-visual-attention/commit/a43041b983084c012e6da8dee1a4d74d653f60d1#diff-ae5323d7b76e8ae717b053d5c11b6e16ad4c1cfb3e978c0403a6c6b795078b87L71' target='_blank'>Link</a></div><div id='project'> Project Name: kevinzakka/recurrent-visual-attention</div><div id='commit'> Commit Name: a43041b983084c012e6da8dee1a4d74d653f60d1</div><div id='time'> Time: 2017-11-23</div><div id='author'> Author: kevinarmandzakka@gmail.com</div><div id='file'> File Name: modules.py</div><div id='class'> Class Name: glimpse_sensor</div><div id='method'> Method Name: _extract_single_patch</div><BR>