<html><h3>7809052793d5c014b417790d4fb199706d14619b,gluonnlp/data/dataset.py,LanguageModelDataset,bptt_batchify,#LanguageModelDataset#Any#Any#Any#Any#,174
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        if last_batch == &quotkeep&quot:
            sample_len = len(self._data[0]) // batch_size
            has_short_batch = _slice_pad_length(sample_len*batch_size, seq_len+1, 1) &gt; 0
            <a id="change">if has_short_batch:
                batches.append(data[seq_len*len(batches):, :])
       </a> return SimpleDataset(batches).transform(lambda x: (x[:min(len(x)-1, seq_len), :], x[1:, :]))
</code></pre><h3>After Change</h3><pre><code class='java'>
        if last_batch == &quotkeep&quot:
            sample_len = len(self._data[0]) // batch_size
            has_short_batch = _slice_pad_length(sample_len*batch_size, seq_len+1, 1) &gt; 0
            <a id="change">if has_short_batch:
                ctx = data[0].context if len(data) else None
                last_batch = self._data[0][seq_len*batch_size*len(batches):]
                excess_size = len(last_batch) % batch_size
                if excess_size:
                    assert vocab.padding_token, &quotPadding token must be specified in vocab when &quot \
                                                &quotlast_batch="keep".&quot
                    padding_size = batch_size - excess_size
                    last_batch.extend([vocab.padding_token]*padding_size)
                batches.append(mx.nd.array(vocab[last_batch], ctx=ctx).reshape(batch_size, -1).T)
       </a> return SimpleDataset(batches).transform(lambda x: (x[:min(len(x)-1, seq_len), :], x[1:, :]))
</code></pre><img src="303632681.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/dmlc/gluon-nlp/commit/7809052793d5c014b417790d4fb199706d14619b#diff-e65d904f83e854a287965667f5aa22a784f2cf18b5348d76831968c1b18c6164L174' target='_blank'>Link</a></div><div id='project'> Project Name: dmlc/gluon-nlp</div><div id='commit'> Commit Name: 7809052793d5c014b417790d4fb199706d14619b</div><div id='time'> Time: 2018-05-24</div><div id='author'> Author: szha@users.noreply.github.com</div><div id='file'> File Name: gluonnlp/data/dataset.py</div><div id='class'> Class Name: LanguageModelDataset</div><div id='method'> Method Name: bptt_batchify</div><BR><BR><div id='link'><a href='https://github.com/snipsco/snips-nlu/commit/7c50d9677032e4ea15c5c5ca5c96a85994aa39a4#diff-43024cab9cb67d220fcda02c23f588407c8e2fed3c69360a116891b316f818bbL37' target='_blank'>Link</a></div><div id='project'> Project Name: snipsco/snips-nlu</div><div id='commit'> Commit Name: 7c50d9677032e4ea15c5c5ca5c96a85994aa39a4</div><div id='time'> Time: 2018-02-15</div><div id='author'> Author: clement.doumouro@gmail.com</div><div id='file'> File Name: nlu_dataset/assistant_dataset.py</div><div id='class'> Class Name: AssistantDataset</div><div id='method'> Method Name: json</div><BR><BR><div id='link'><a href='https://github.com/interactiveaudiolab/nussl/commit/734e0fc83fc1abdfd3f02dea791efb89dcaf90f8#diff-542891d1156706136e4c0299fe5d844ae0079f4f4860f05e5b4fc3d5c8d90ad0L74' target='_blank'>Link</a></div><div id='project'> Project Name: interactiveaudiolab/nussl</div><div id='commit'> Commit Name: 734e0fc83fc1abdfd3f02dea791efb89dcaf90f8</div><div id='time'> Time: 2020-03-01</div><div id='author'> Author: prem@u.northwestern.edu</div><div id='file'> File Name: nussl/datasets/transforms.py</div><div id='class'> Class Name: SumSources</div><div id='method'> Method Name: __call__</div><BR>