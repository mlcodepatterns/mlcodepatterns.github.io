<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        between any pair of models on the given dataset.
    

    <a id="change">progress_bar</a> = IntProgress(min=0, max=len(datasets)*len(metrics), 
                               description="Iterating datasets and metrics")
    <a id="change">display(progress_bar)</a>    

    data = np.zeros(shape=(len(datasets), len(metrics), 2), dtype=np.float32)
    for idx_dataset, dataset in enumerate(datasets):
        y_pred_a = model_a.score(dataset, detailed=False, cache=cache)
        y_pred_b = model_b.score(dataset, detailed=False, cache=cache)
        for idx_metric, metric in enumerate(metrics):
            <a id="change">progress_bar.value</a> += 1

            metrics_a = metric.eval(dataset, y_pred_a)[1]
            metrics_b = metric.eval(dataset, y_pred_b)[1]

            p1, p2 = _randomization(metrics_a, metrics_b, n_perm=n_perm)

            data[idx_dataset][idx_metric][0] = p1
            data[idx_dataset][idx_metric][1] = p2

    <a id="change">progress_bar.bar_style = "success"</a>
    <a id="change">progress_bar.close()</a>

    performance = xr.DataArray(data,
                               name=&quotStatistical Significance&quot,
                               coords=[datasets, metrics, [&quotone-sided&quot, &quottwo-sided&quot]],</code></pre><h3>After Change</h3><pre><code class='java'>
        A DataArray containing the statistical significance of the performance
        difference between any pair of models on the given dataset.
    
    <a id="change">if ipywidgets:
        progress_bar = ipywidgets.IntProgress(
            min=0, max=len(datasets)*len(metrics),
            description="Iterating datasets and metrics")
        display(progress_bar)

   </a> data = np.zeros(shape=(len(datasets), len(metrics), 2), dtype=np.float32)
    for idx_dataset, dataset in enumerate(datasets):
        y_pred_a = model_a.score(dataset, detailed=False, cache=cache)
        y_pred_b = model_b.score(dataset, detailed=False, cache=cache)
        for idx_metric, metric in enumerate(metrics):
            <a id="change">if ipywidgets:
                progress_bar.value += 1

           </a> metrics_a = metric.eval(dataset, y_pred_a)[1]
            metrics_b = metric.eval(dataset, y_pred_b)[1]

            p1, p2 = _randomization(metrics_a, metrics_b, n_perm=n_perm)

            data[idx_dataset][idx_metric][0] = p1
            data[idx_dataset][idx_metric][1] = p2

    <a id="change">if ipywidgets:
        progress_bar.bar_style = "success"
        progress_bar.close()

   </a> performance = xr.DataArray(
        data,
        name=&quotStatistical Significance&quot,
        coords=[datasets, metrics, [&quotone-sided&quot, &quottwo-sided&quot]],</code></pre>