<html><h3>5b6da0cf476a8adf7320766760a0756d53df0e48,opennmt/encoders/self_attention_encoder.py,SelfAttentionEncoder,encode,#SelfAttentionEncoder#Any#Any#Any#,40
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    self.position_encoding_reducer = SumReducer()

  def encode(self, inputs, sequence_length=None, mode=tf.estimator.ModeKeys.TRAIN):
    <a id="change">with tf.variable_scope("position_embedding"):
      input_dim = inputs.get_shape().as_list()[-1]
      position_embedding = create_position_embedding(
        input_dim,
        128,
        sequence_length)
      inputs = self.position_encoding_reducer.reduce(inputs, position_embedding)

   </a> inputs = tf.layers.dropout(
      inputs,
      rate=self.dropout,
      training=mode == tf.estimator.ModeKeys.TRAIN)</code></pre><h3>After Change</h3><pre><code class='java'>
    self.position_encoder = position_encoder
    self.keep_layers_output = keep_layers_output

  def encode(<a id="change">self</a>, inputs, sequence_length=None, mode=tf.estimator.ModeKeys.TRAIN):
    <a id="change">if self.position_encoder is not None:
      inputs = self.position_encoder(inputs, sequence_length=sequence_length)

   </a> inputs = tf.layers.dropout(
      inputs,
      rate=self.dropout,
      training=mode == tf.estimator.ModeKeys.TRAIN)</code></pre><img src="133925467.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 17</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/OpenNMT/OpenNMT-tf/commit/5b6da0cf476a8adf7320766760a0756d53df0e48#diff-78564f81397b24fd44ce7ca75d7fa59d0bc28e5f529f74877579db0e00f053e8L40' target='_blank'>Link</a></div><div id='project'> Project Name: OpenNMT/OpenNMT-tf</div><div id='commit'> Commit Name: 5b6da0cf476a8adf7320766760a0756d53df0e48</div><div id='time'> Time: 2017-08-22</div><div id='author'> Author: guillaume.klein@systrangroup.com</div><div id='file'> File Name: opennmt/encoders/self_attention_encoder.py</div><div id='class'> Class Name: SelfAttentionEncoder</div><div id='method'> Method Name: encode</div><BR><BR><div id='link'><a href='https://github.com/OpenNMT/OpenNMT-tf/commit/5b6da0cf476a8adf7320766760a0756d53df0e48#diff-eda033ffac91babb4c104f5015a854b32c7c784f70776af112ded75dc3af149eL43' target='_blank'>Link</a></div><div id='project'> Project Name: OpenNMT/OpenNMT-tf</div><div id='commit'> Commit Name: 5b6da0cf476a8adf7320766760a0756d53df0e48</div><div id='time'> Time: 2017-08-22</div><div id='author'> Author: guillaume.klein@systrangroup.com</div><div id='file'> File Name: opennmt/encoders/conv_encoder.py</div><div id='class'> Class Name: ConvEncoder</div><div id='method'> Method Name: encode</div><BR><BR><div id='link'><a href='https://github.com/OpenNMT/OpenNMT-tf/commit/5b6da0cf476a8adf7320766760a0756d53df0e48#diff-c60905dae72132d03a5b0c8b514b10766b681565075afe76acedd57537c3f622L37' target='_blank'>Link</a></div><div id='project'> Project Name: OpenNMT/OpenNMT-tf</div><div id='commit'> Commit Name: 5b6da0cf476a8adf7320766760a0756d53df0e48</div><div id='time'> Time: 2017-08-22</div><div id='author'> Author: guillaume.klein@systrangroup.com</div><div id='file'> File Name: opennmt/decoders/self_attention_decoder.py</div><div id='class'> Class Name: SelfAttentionDecoder</div><div id='method'> Method Name: decode</div><BR><BR><div id='link'><a href='https://github.com/OpenNMT/OpenNMT-tf/commit/5b6da0cf476a8adf7320766760a0756d53df0e48#diff-78564f81397b24fd44ce7ca75d7fa59d0bc28e5f529f74877579db0e00f053e8L40' target='_blank'>Link</a></div><div id='project'> Project Name: OpenNMT/OpenNMT-tf</div><div id='commit'> Commit Name: 5b6da0cf476a8adf7320766760a0756d53df0e48</div><div id='time'> Time: 2017-08-22</div><div id='author'> Author: guillaume.klein@systrangroup.com</div><div id='file'> File Name: opennmt/encoders/self_attention_encoder.py</div><div id='class'> Class Name: SelfAttentionEncoder</div><div id='method'> Method Name: encode</div><BR>