<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                &quottime: {log[time]:.3f}, data_time: {log[data_time]:.3f}, &quot.
                format(log=runner.log_buffer.output))
        &#47&#47 statistic memory
        <a id="change">if runner.mode == &quottrain&quot and torch.cuda.is_available():
            mem = torch.cuda.max_memory_allocated()
            mem_mb = torch.tensor([mem / (1024 * 1024)],
                                  dtype=torch.int,
                                  device=torch.device(&quotcuda&quot))
            if runner.world_size &gt; 1:
                dist.reduce(mem_mb, 0, op=dist.ReduceOp.MAX)
            log_str += &quotmemory: {}, &quot.format(mem_mb.item())
       </a> log_items = []
        for name, val in runner.log_buffer.output.items():
            if name in [&quottime&quot, &quotdata_time&quot]:
                continue</code></pre><h3>After Change</h3><pre><code class='java'>
                format(log=runner.log_buffer.output))
        &#47&#47 statistic memory
        &#47&#47 training mode if the output contains the key "time"
        <a id="change">if &quottime&quot in runner.log_buffer.output and torch.cuda.is_available():
            mem_mb = self._get_max_memory(runner)
            log_str += &quotmemory: {}, &quot.format(mem_mb.item())
       </a> log_items = []
        for name, val in runner.log_buffer.output.items():
            if name in [&quottime&quot, &quotdata_time&quot]:
                continue</code></pre>