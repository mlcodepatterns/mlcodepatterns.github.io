<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            &#47&#47 vectorizers should not be available when preproc=server.
            featurized_examples = self.vectorize(tokens_batch)
            examples = {
                        &quottokens&quot: np.array(<a id="change">[" ".join(x) for x in tokens_batch]</a>),
                        self.model.lengths_key: featurized_examples[self.model.lengths_key]
            }

        outcomes_list = self.model.predict(examples)
        <a id="change">return self.format_output(outcomes_list)</a>

    def format_output(self, predicted):
        results = []
        for outcomes in predicted:</code></pre><h3>After Change</h3><pre><code class='java'>
        version = kwargs.get(&quotversion&quot)

        if backend not in {&quottf&quot}:
            raise ValueError("only Tensorfl<a id="change">ow is curren</a>tly supported for remote Services")
      <a id="change">  import_user_module(&quotbaseline.{}.remote&quot.format(backend))
        exp_type = kwargs.get(&quotremote_type&quot)
        if exp_type is None:
            exp_type = &quothttp&quot</a> <a id="change">if remote.star</a>tswith(&quothttp&quot) else &quotgrpc&quot
            exp_type = &quot{}-preproc&quot.format(exp_type) if preproc == &quotserver&quot else exp_type
            exp_type = f&quot{exp_type}-{task_name}&quot
        model = create_remote(</code></pre>