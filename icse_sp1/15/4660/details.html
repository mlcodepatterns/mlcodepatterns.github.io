<html><h3>171e9e18a10f2daea090bc6f4815db41072d66b6,ch10/03_pong_a2c_rollouts.py,,,#,115
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                        break

                optimizer.zero_grad()
                states_v = <a id="change">Variable(torch.from_numpy(mb_states))</a>
                mb_adv = mb_rewards - mb_values
                adv_v = <a id="change">Variable(torch.from_numpy(mb_adv))</a>
                actions_t = torch.from_numpy(mb_actions)
                vals_ref_v = <a id="change">Variable(torch.from_numpy(mb_rewards))</a>
                <a id="change">if args.cuda:
                    states_v = states_v.cuda()
                    adv_v = adv_v.cuda()
                    actions_t = actions_t.cuda()
                    vals_ref_v = vals_ref_v.cuda()

               </a> logits_v, value_v = net(states_v)
                loss_value_v = F.mse_loss(value_v, vals_ref_v)

                log_prob_v = F.log_softmax(logits_v, dim=1)</code></pre><h3>After Change</h3><pre><code class='java'>
                vals_ref_v = torch.FloatTensor(mb_rewards).to(device)

                logits_v, value_v = net(states_v)
                loss_value_v = F.mse_loss(<a id="change">value_v.squeeze(-1)</a>, vals_ref_v)

                log_prob_v = F.log_softmax(logits_v, dim=1)
                log_prob_actions_v = adv_v * log_prob_v[range(len(mb_states)), actions_t]</code></pre><img src="30327279.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 14</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/PacktPublishing/Deep-Reinforcement-Learning-Hands-On/commit/171e9e18a10f2daea090bc6f4815db41072d66b6#diff-3127b6eeb9f67b6225c6a2477817085516f6694a6a98b4f484633768f899b193L111' target='_blank'>Link</a></div><div id='project'> Project Name: PacktPublishing/Deep-Reinforcement-Learning-Hands-On</div><div id='commit'> Commit Name: 171e9e18a10f2daea090bc6f4815db41072d66b6</div><div id='time'> Time: 2018-04-27</div><div id='author'> Author: max.lapan@gmail.com</div><div id='file'> File Name: ch10/03_pong_a2c_rollouts.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: </div><BR><BR><div id='link'><a href='https://github.com/PacktPublishing/Deep-Reinforcement-Learning-Hands-On/commit/1e9c3ee592be5e11dcce932a73009488d6f85474#diff-4167e56f1146ee4586776221565ff5ec0cdeed70670f15816d5f232f757fbd6aL81' target='_blank'>Link</a></div><div id='project'> Project Name: PacktPublishing/Deep-Reinforcement-Learning-Hands-On</div><div id='commit'> Commit Name: 1e9c3ee592be5e11dcce932a73009488d6f85474</div><div id='time'> Time: 2018-04-29</div><div id='author'> Author: max.lapan@gmail.com</div><div id='file'> File Name: ch17/02_imag.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: </div><BR><BR><div id='link'><a href='https://github.com/PacktPublishing/Deep-Reinforcement-Learning-Hands-On/commit/1e9c3ee592be5e11dcce932a73009488d6f85474#diff-f0bf571463d6a24e7ec7c08e3b48b5dea2f2559833e5c8491ce3a32a1e0aab1bL154' target='_blank'>Link</a></div><div id='project'> Project Name: PacktPublishing/Deep-Reinforcement-Learning-Hands-On</div><div id='commit'> Commit Name: 1e9c3ee592be5e11dcce932a73009488d6f85474</div><div id='time'> Time: 2018-04-29</div><div id='author'> Author: max.lapan@gmail.com</div><div id='file'> File Name: ch17/lib/common.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: train_a2c</div><BR>