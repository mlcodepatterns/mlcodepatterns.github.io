<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>


&#47&#47 Cloud TPU Cluster Resolvers
<a id="change">flags.DEFINE_string(
    "tpu", default=None,
    help="The Cloud TPU to use for training. This should be either the name "
    "used when creating the Cloud TPU, or a grpc://ip.address.of.tpu:8470 url.")</a>
flags.DEFINE_string(
    "gcp_project", default=None,
    help="Project name for the Cloud TPU-enabled project. If not specified, we "
    "will attempt to automatically detect the GCE project from metadata.")
flags.DEFINE_string(
    "tpu_zone", default=None,
    help="GCE zone where the Cloud TPU is located in. If not specified, we "
    "will attempt to automatically detect the GCE project from metadata.")

&#47&#47 Model specific paramenters
flags.DEFINE_string("data_dir", "", "Location of training files.")
<a id="change">flags.DEFINE_string("model_dir", "", "Where to store model checkpoints.")</a>
flags.DEFINE_integer("save_checkpoints_secs", 3600,
                     "Interval between saving model checkpoints.")
<a id="change">flags.DEFINE_integer("num_shards", 8, "Number of TPU shards.")</a>
flags.DEFINE_integer("batch_size", 1024, "Batch size for training and eval.")
flags.DEFINE_boolean("use_tpu", True, "If true, use TPU device.")

<a id="change">flags.DEFINE_string("optimizer", "momentum", "Optimizer: momentum|adam|rmsprop")</a>
flags.DEFINE_float("momentum", 0.9, "Momentum parameter for SGD optimizer.")
flags.DEFINE_integer("num_epochs", 150,
                     "Number of epochs of the training set to process.")
flags.DEFINE_integer("num_evals", 10,
                     "How many times to run an evaluation during training.")
flags.DEFINE_float("learning_rate", 0.03, "Learning rate.")
flags.DEFINE_float("min_learning_rate", 0.005, "The minimal end learning rate.")
<a id="change">flags.DEFINE_integer("iterations_per_loop", 100,
                     "Number of global step increased per session run.")</a>
flags.DEFINE_integer("num_examples_per_epoch", 1300 * 1000,
                     "Number of examples to train per epoch.")
flags.DEFINE_integer("num_eval_examples", 50 * 1000,
                     "Number of examples to evaluate per run.")</code></pre><h3>After Change</h3><pre><code class='java'>
import squeezenet_model
from configs import squeezenet_config

<a id="change">common_tpu_flags.define_common_tpu_flags()</a>
common_hparams_flags.define_common_hparams_flags()

flags.DEFINE_integer("num_examples_per_epoch", None,
                     "Number of examples to train per epoch.")</code></pre>