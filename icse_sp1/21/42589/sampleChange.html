<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>


&#47&#47 Cloud TPU Cluster Resolvers
<a id="change">flags.DEFINE_string(
    &quottpu&quot, default=None,
    help=&quotThe Cloud TPU to use for training. This should be either the name &quot
    &quotused when creating the Cloud TPU, or a grpc://ip.address.of.tpu:8470 url.&quot)</a>
flags.DEFINE_string(
    &quotgcp_project&quot, default=None,
    help=&quotProject name for the Cloud TPU-enabled project. If not specified, we &quot
    &quotwill attempt to automatically detect the GCE project from metadata.&quot)
flags.DEFINE_string(
    &quottpu_zone&quot, default=None,
    help=&quotGCE zone where the Cloud TPU is located in. If not specified, we &quot
    &quotwill attempt to automatically detect the GCE project from metadata.&quot)

&#47&#47 Model specific paramenters
<a id="change">flags.DEFINE_string(
    &quotdata_dir&quot, &quot&quot,
    &quotDirectory where input data is stored&quot)</a>

<a id="change">flags.DEFINE_string(
    &quotmodel_dir&quot, None,
    &quotDirectory where model output is stored&quot)</a>

flags.DEFINE_string(
    &quottflite_export_dir&quot,
    default=None,
    help=(&quotThe directory where the exported tflite files will be stored.&quot))

flags.DEFINE_string(
    &quotexport_dir&quot,
    default=None,
    help=(&quotThe directory where the exported SavedModel will be stored.&quot))

flags.DEFINE_integer(
    &quotnum_shards&quot, 8,
    &quotNumber of shards (workers).&quot)

flags.DEFINE_integer(
    &quotiterations&quot, 100,
    &quotNumber of iterations per TPU training loop.&quot)

flags.DEFINE_integer(
    &quottrain_batch_size&quot, 1024,
    &quotGlobal (not per-shard) batch size for training&quot)

flags.DEFINE_integer(
    &quoteval_total_size&quot, 0,
    &quotTotal batch size for evaluation, use the entire validation set if 0&quot)

flags.DEFINE_integer(
    &quoteval_batch_size&quot, 1024,
    &quotGlobal (not per-shard) batch size for evaluation&quot)

<a id="change">flags.DEFINE_integer(
    &quottrain_steps&quot, 8000000,
    &quotNumber of steps use for training.&quot)</a>

flags.DEFINE_integer(
    &quottrain_steps_per_eval&quot, 2000,
    &quotNumber of training steps to run between evaluations.&quot)

flags.DEFINE_string(
    &quotmode&quot, &quottrain_and_eval&quot,
    &quotMode to run: train, eval, train_and_eval&quot)

flags.DEFINE_integer(
    &quotmin_eval_interval&quot, 180,
    &quotMinimum number of seconds between evaluations&quot)

flags.DEFINE_integer(
    &quoteval_timeout&quot, None,
    &quotEvaluation timeout: Maximum number of seconds that &quot
    &quotmay elapse while no new checkpoints are observed&quot)

<a id="change">flags.DEFINE_bool(
    &quotuse_tpu&quot, True,
    &quotUse TPUs rather than plain CPUs&quot)</a>

flags.DEFINE_boolean(
    &quotper_host_input_for_training&quot, True,
    &quotIf true, input_fn is invoked per host rather than per shard.&quot)</code></pre><h3>After Change</h3><pre><code class='java'>
from tensorflow.contrib.framework.python.ops import arg_scope
from tensorflow.contrib.training.python.training import evaluation

<a id="change">common_tpu_flags.define_common_tpu_flags()</a>
common_hparams_flags.define_common_hparams_flags()

&#47&#47 Model specific parameters
flags.DEFINE_string(</code></pre>