<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        for aligned_states_chunk in aligned_meters:
            aligned_states_chunk.dropna(inplace=True)
            aligned_states_chunk = aligned_states_chunk.astype(int)
            <a id="change">score = sklearn_f1_score(aligned_states_chunk.icol(0),
                                     aligned_states_chunk.icol(1))</a>
            scores_for_meter = scores_for_meter.append(
                {&quotscore&quot: score, &quotnum_samples&quot: len(aligned_states_chunk)},
                ignore_index=True)

        &#47&#47 Calculate weighted mean
        num_samples = scores_for_meter[&quotnum_samples&quot].sum()
        if num_samples &gt; 0:
            scores_for_meter[&quotproportion&quot] = (
                scores_for_meter[&quotnum_samples&quot] / num_samples)
            avg_score = (
                scores_for_meter[&quotscore&quot] * scores_for_meter[&quotproportion&quot]
            ).sum()
        else:
            warn("No aligned samples when calculating F1-score for prediction"
                 " meter {} and ground truth meter {}."
                 .format(pred_meter, ground_truth_meter))
            avg_score = np.NaN
        <a id="change">f1_scores[pred_meter.instance()]</a> = avg_score

    return pd.Series(f1_scores)
</code></pre><h3>After Change</h3><pre><code class='java'>
        for aligned_states_chunk in aligned_meters:
            aligned_states_chunk.dropna(inplace=True)
            aligned_states_chunk = aligned_states_chunk.astype(int)
            <a id="change">score = sklearn_f1_score(aligned_states_chunk.iloc[:, 0],
                                     aligned_states_chunk.iloc[:, 1])</a>
            scores_for_meter = scores_for_meter.append(
                {&quotscore&quot: score, &quotnum_samples&quot: len(aligned_states_chunk)},
                ignore_index=True)

        &#47&#47 Calculate weighted mean
        num_samples = scores_for_meter[&quotnum_samples&quot].sum()
        if num_samples &gt; 0:
            scores_for_meter[&quotproportion&quot] = (
                scores_for_meter[&quotnum_samples&quot] / num_samples)
            avg_score = (
                scores_for_meter[&quotscore&quot] * scores_for_meter[&quotproportion&quot]
            ).sum()
        else:
            warn("No aligned samples when calculating F1-score for prediction"
                 " meter {} and ground truth meter {}."
                 .format(pred_meter, ground_truth_meter))
            avg_score = np.NaN
        <a id="change">f1_scores[pred_meter.instance()]</a> = avg_score

    return pd.Series(f1_scores)
</code></pre>