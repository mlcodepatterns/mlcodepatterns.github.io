<html><h3>678f40aa5244d57280310f9421b9ba0727241fbc,chainerrl/agents/ddpg.py,DDPG,act_and_train,#DDPG#Any#Any#,285
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        self.logger.debug(&quott:%s r:%s&quot, self.t, reward)

        <a id="change">if self.async_update and self.update_future:
            self.update_future.result()
            self.update_future = None

       </a> if self.clip_reward:
            reward = np.clip(reward, -1, 1)

        greedy_action = self.act(state)
        action = self.explorer.select_action(self.t, lambda: greedy_action)
        self.t += 1

        &#47&#47 Update the target network
        if self.t % self.target_update_frequency == 0:
            self.sync_target_network()

        if self.last_state is not None:
            assert self.last_action is not None
            &#47&#47 Add a transition to the replay buffer
            self.replay_buffer.append(
                state=self.last_state,
                action=self.last_action,
                reward=reward,
                next_state=state,
                next_action=action,
                is_state_terminal=False)

        self.last_state = state
        self.last_action = action

        <a id="change">self.update_if_necessary()</a>

        return self.last_action

    def update_if_necessary(self):</code></pre><h3>After Change</h3><pre><code class='java'>
                actor_loss += self.compute_actor_loss(batch)
            self.actor_optimizer.update(lambda: actor_loss / max_epi_len)

    def act_and_train(<a id="change">self</a>, state, reward):

        self.logger.debug(&quott:%s r:%s&quot, self.t, reward)

        if self.clip_reward:
            reward = np.clip(reward, -1, 1)

        greedy_action = self.act(state)
        action = self.explorer.select_action(self.t, lambda: greedy_action)
        <a id="change">self.t</a> += 1

        &#47&#47 Update the target network
        if self.t % self.target_update_frequency == 0:
            self.sync_target_network()

        if self.last_state is not None:
            assert self.last_action is not None
            &#47&#47 Add a transition to the replay buffer
            self.replay_buffer.append(
                state=self.last_state,
                action=self.last_action,
                reward=reward,
                next_state=state,
                next_action=action,
                is_state_terminal=False)

        self.last_state = state
        self.last_action = action

        <a id="change">self.replay_updator.update_if_necessary(self.t)</a>

        return self.last_action

    def act(self, state):</code></pre><img src="286852201.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 14</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/chainer/chainerrl/commit/678f40aa5244d57280310f9421b9ba0727241fbc#diff-09bd834e9c5b254d3004f12c3c102e03e6c657ee68d66311b6e2d6e14a9a4ec4L284' target='_blank'>Link</a></div><div id='project'> Project Name: chainer/chainerrl</div><div id='commit'> Commit Name: 678f40aa5244d57280310f9421b9ba0727241fbc</div><div id='time'> Time: 2017-02-08</div><div id='author'> Author: muupan@gmail.com</div><div id='file'> File Name: chainerrl/agents/ddpg.py</div><div id='class'> Class Name: DDPG</div><div id='method'> Method Name: act_and_train</div><BR><BR><div id='link'><a href='https://github.com/chainer/chainerrl/commit/678f40aa5244d57280310f9421b9ba0727241fbc#diff-09bd834e9c5b254d3004f12c3c102e03e6c657ee68d66311b6e2d6e14a9a4ec4L285' target='_blank'>Link</a></div><div id='project'> Project Name: chainer/chainerrl</div><div id='commit'> Commit Name: 678f40aa5244d57280310f9421b9ba0727241fbc</div><div id='time'> Time: 2017-02-08</div><div id='author'> Author: muupan@gmail.com</div><div id='file'> File Name: chainerrl/agents/ddpg.py</div><div id='class'> Class Name: DDPG</div><div id='method'> Method Name: act_and_train</div><BR><BR><div id='link'><a href='https://github.com/chainer/chainerrl/commit/678f40aa5244d57280310f9421b9ba0727241fbc#diff-499f1803e854873cce3c2bb719180fe3472485535e563beda875480fc3cc0542L350' target='_blank'>Link</a></div><div id='project'> Project Name: chainer/chainerrl</div><div id='commit'> Commit Name: 678f40aa5244d57280310f9421b9ba0727241fbc</div><div id='time'> Time: 2017-02-08</div><div id='author'> Author: muupan@gmail.com</div><div id='file'> File Name: chainerrl/agents/dqn.py</div><div id='class'> Class Name: DQN</div><div id='method'> Method Name: act_and_train</div><BR><BR><div id='link'><a href='https://github.com/chainer/chainerrl/commit/678f40aa5244d57280310f9421b9ba0727241fbc#diff-01486dbffdd7bf41878f76d71ac479b4e5f5cbb3553042a04fac48eb68ab085dL207' target='_blank'>Link</a></div><div id='project'> Project Name: chainer/chainerrl</div><div id='commit'> Commit Name: 678f40aa5244d57280310f9421b9ba0727241fbc</div><div id='time'> Time: 2017-02-08</div><div id='author'> Author: muupan@gmail.com</div><div id='file'> File Name: chainerrl/agents/pgt.py</div><div id='class'> Class Name: PGT</div><div id='method'> Method Name: act_and_train</div><BR>