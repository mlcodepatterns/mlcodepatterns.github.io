<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    ) -&gt; None:
        super().__init__(vocab, regularizer)

        <a id="change">self.label_namespace</a> = label_namespace
        self.text_field_embedder = text_field_embedder
        self.num_classes = self.vocab.get_vocab_size(label_namespace)
        self.encoder = encoder
        self._verbose_metrics = verbose_metrics
        <a id="change">self.tag_projection_layer = TimeDistributed(
            Linear(self.encoder.get_output_dim(), self.num_classes)
        )</a>

        check_dimensions_match(
            text_field_embedder.get_output_dim(),
            encoder.get_input_dim(),
            "text field embedding dim",
            "encoder input dim",
        )

        &#47&#47 We keep calculate_span_f1 as a constructor argument for API consistency with
        &#47&#47 the CrfTagger, even it is redundant in this class
        &#47&#47 (label_encoding serves the same purpose).
        <a id="change">if calculate_span_f1 and not label_encoding:
            raise ConfigurationError(
                "calculate_span_f1 is True, but no label_encoding was specified."
            )
       </a> <a id="change">self.metrics = {
            "accuracy": CategoricalAccuracy(),
            "accuracy3": CategoricalAccuracy(top_k=3),
        }</a>

        if calculate_span_f1 or label_encoding:
            <a id="change">self._f1_metric</a> = SpanBasedF1Measure(
                vocab, tag_namespace=label_namespace, label_encoding=label_encoding
            )
        else:</code></pre><h3>After Change</h3><pre><code class='java'>
        self.num_classes = self.vocab.get_vocab_size(label_namespace)
        self.encoder = encoder
        self._verbose_metrics = verbose_metrics
        self.tag_projection_layer = TimeDistribut<a id="change">ed(
</a>            Linear(self.encoder.get_output_dim(), self.num_classes)
        )

        check_dimensions_match(
            text_field_embedder.get_output_dim(),
            encoder.get_input_dim(),
            "text field embedding dim",
            "encoder input dim",
        )

        &#47&#47 We keep calculate_span_f1 as a constructor argument for API consistency with
        &#47&#47 the CrfTagger, even it is redundant in this class
        &#47&#47 (label_encoding serves the same purpose).
        if calculate_span_f1 and not label_encoding:
            raise ConfigurationError(
                "calculate_span_f1 is True, but no label_encoding was specified."
            )
        self.metrics = {
            "accuracy": CategoricalAccuracy(),
            "accuracy3": CategoricalAccuracy(top_k=3),
        }

        if calculate_span_f1 or label_encoding:
            self._f1_metric = SpanBasedF1Measure(
                vocab, tag_namespace=label_namespace, label_encoding=label_encoding
            )
        else:
            self._f1_metric = None

        initializer(self)

    @overrides
 <a id="change">   def forward(
        self,  &#47&#47 type: ignore
        tokens: TextFieldTensors,
        tags: torch.LongTensor = None,
   </a>     meta<a id="change">data: List[Dict[str, Any]] = None,
    ) -&gt; Dict[str,</a> torch.Tensor]:

        
        &#47&#47 Parameters

      <a id="change">  tokens : TextFieldTen</a>sors, required
            The output of `TextField.as_array()`, which should typically be passed directly to a
            `TextFieldEmbedder`. This output is a dictionary mapping keys to `TokenIndexer`
            tensors.  At its most basic, using a `SingleIdTokenIndexer` this is : `{"tokens":</code></pre>