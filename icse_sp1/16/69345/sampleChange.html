<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                 rule_namespace: str = &quotrule_labels&quot) -&gt; None:
        super(NlvrSemanticParser, self).__init__(vocab=vocab)

        <a id="change">self._sentence_embedder = sentence_embedder</a>
        self._denotation_accuracy = Average()
        self._consistency = Average()
        self._encoder = encoder
        <a id="change">self._rule_namespace</a> = rule_namespace

        self._action_embedder = Embedding(num_embeddings=vocab.get_vocab_size(<a id="change">self._rule_namespace</a>),
                                          embedding_dim=action_embedding_dim)

        &#47&#47 This is what we pass as input in the first step of decoding, when we don&quott have a
        &#47&#47 previous action.
        <a id="change">self._first_action_embedding = torch.nn.Parameter(torch.FloatTensor(action_embedding_dim))</a>
        torch.nn.init.normal(self._first_action_embedding)

    @overrides
    def forward(self):  &#47&#47 type: ignore</code></pre><h3>After Change</h3><pre><code class='java'>
    abstract class and does not have a ``forward`` method implemented. Classes that inherit from
    this class are expected to define their own logic depending on the kind of supervision they use.
    Accordingly, they should use the appropriate ``DecoderTrainer``. This class provides some common
    functionality for<a id="change"> thi</a>ngs like defining an initial ``RnnState``, embedding actions, evaluating
    the denotations of completed logical forms, etc.  There is a lot of overlap with
    ``WikiTablesSemanticParser`` here. We may want to eventually move the common functionality into
    a more general transition-based parsing class.

    Parameters
    ----------
    vocab : ``Vocabulary``
    sentence_embedder : ``TextFieldEmbedder``
        Embedder for sentences.
    action_embedding_dim : ``int``
        Dimension to use for action embeddings.
    encoder : ``Seq2SeqEncoder``
        The encoder to use for the input question.
    dropout : ``float``, optional (default=0.0)
        Dropout on the encoder outputs.
    rule_namespace : ``str``, optional (default=rule_labels)
        The vocabulary namespace to use for production rules.  The default corresponds to the
       <a id="change"> default used in the dataset</a> reader, so you likely don&quott need to modify this.
    
    def __init__(self,
                 vocab: Vocabulary,
                 sentence_embedder: TextFieldEmbedder,
                 action_embedding_dim: int,
                 encoder: Seq2SeqEncoder,
                 dropout: float = 0.0,
        <a id="change">         rule_namespace: str = &quotrule_labels&quot) -&gt; None:
        super(NlvrSemanticParser, self</a>).__init__(vocab=vocab)

        self._sentence_embedder = sentence_embedder
        self._denotation_accuracy = Average()
        self._consistency = Average()
        self._encoder = encoder
        if<a id="change"> dropout &gt; 0:
            self._dropout = torch.nn.Dropout(p=dropout)
    </a>    else:
            self._dropout = lambda x: x
        self._rule_namespace = rule_namespace

        self._action_embedder = Embedding(num_embeddings=voca<a id="change">b.get_vocab_s</a>ize(self._rule_namespace),
                                          embedding_dim=action_embedding_dim)

        &#47&#47 This is what we pass as input in the first step of decoding, when we don&quott have a</code></pre>