<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>


def train(epoch):
    <a id="change">batch_data_t = torch.FloatTensor(BATCH_SIZE, 784)</a>
    <a id="change">if cuda:
        batch_data_t = batch_data_t.cuda()
   </a> <a id="change">batch_data = Variable(batch_data_t, requires_grad=False)</a>
    <a id="change">for i in range(0, training_data.size(0), BATCH_SIZE):
        optimizer.zero_grad()
        batch_data.data[:] = training_data[i:i + BATCH_SIZE]
        recon_batch_data, mu, logvar = model(batch_data)
        loss = loss_function(recon_batch_data, batch_data, mu, logvar)
        loss.backward()
        loss = loss.data[0]
        optimizer.step()
        if i % 10 == 0:
            print(&quotEpoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.4f}&quot.format(
                epoch,
                i + BATCH_SIZE, training_data.size(0),
                float(i + BATCH_SIZE) / training_data.size(0) * 100,
                loss / BATCH_SIZE))


</a>def test(epoch):
    test_loss = 0
    batch_data_t = torch.FloatTensor(TEST_BATCH_SIZE, 784)
    if cuda:</code></pre><h3>After Change</h3><pre><code class='java'>
def train(epoch):
    model.train()
    train_loss = 0
    <a id="change">for batch in train_loader:
        batch = Variable(batch)

        optimizer.zero_grad()
        recon_batch, mu, logvar = model(batch)
        loss = loss_function(recon_batch, batch, mu, logvar)
        loss.backward()
        train_loss += loss
        optimizer.step()

   </a> print(&quot====&gt; Epoch: {} Loss: {:.4f}&quot.format(
          epoch,
          train_loss.data[0] / training_data.size(0)))
</code></pre>