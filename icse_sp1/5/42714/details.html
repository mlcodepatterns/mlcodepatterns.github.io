<html><h3>f19ace982075ea009af81f5e9f687cc2276f50ea,scripts/bert/fp16_utils.py,,grad_global_norm,#Any#Any#,24
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            ctx = arr.context
            groups[ctx].append(arr)
        return groups
    <a id="change">norm_groups = group_by_ctx(norm_arrays)</a>

    &#47&#47 reduce
    ctx, dtype = arrays[0].context, &quotfloat32&quot
    norms = [nd.add_n(*g).as_in_context(ctx) <a id="change">for</a> g in <a id="change">norm_groups.values()</a>]
    total_norm = nd.add_n(*norms).sqrt()
    scale = total_norm / max_norm
    &#47&#47 is_finite = 0 if NaN or Inf, 1 otherwise.</code></pre><h3>After Change</h3><pre><code class='java'>
            Set this to 1 if you normalized loss manually with `loss = mean(loss)`.
        max_norm : NDArray, optional, default is None
            max value for global 2-norm of gradients.
<a id="change">        </a>
      <a id="change">  self.fp32_trainer.allreduce_</a>grads()
        step_size = batch_size * self._scaler.loss_scale
        if max_norm:
            _, ratio, is_finite = nlp.utils.grad_global_norm(self.fp32_trainer._params,</code></pre><img src="200593844.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/dmlc/gluon-nlp/commit/f19ace982075ea009af81f5e9f687cc2276f50ea#diff-978189d71446b5d60c49613b692de0fa5d50ae07bd06f3d620526f814c3a677eL64' target='_blank'>Link</a></div><div id='project'> Project Name: dmlc/gluon-nlp</div><div id='commit'> Commit Name: f19ace982075ea009af81f5e9f687cc2276f50ea</div><div id='time'> Time: 2020-01-20</div><div id='author'> Author: 50716238+MoisesHer@users.noreply.github.com</div><div id='file'> File Name: scripts/bert/fp16_utils.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: grad_global_norm</div><BR><BR><div id='link'><a href='https://github.com/mozilla/bugbug/commit/f16992b25bb153df3ab87c5111db2a101cf68c73#diff-f3557fe3a5b0819ec4d3a2f85a607a9450e4b9f18168838e95d3d2672564f8b4L91' target='_blank'>Link</a></div><div id='project'> Project Name: mozilla/bugbug</div><div id='commit'> Commit Name: f16992b25bb153df3ab87c5111db2a101cf68c73</div><div id='time'> Time: 2020-04-09</div><div id='author'> Author: mcastelluccio@mozilla.com</div><div id='file'> File Name: bugbug/models/testselect.py</div><div id='class'> Class Name: TestSelectModel</div><div id='method'> Method Name: train_test_split</div><BR><BR><div id='link'><a href='https://github.com/keras-team/keras/commit/8e95a38e7a4be3a3edd8139dbd26e994e50d0a0c#diff-41a886696316763b03254c3581a5273818cfb9846ac120be265502499546bb65L191' target='_blank'>Link</a></div><div id='project'> Project Name: keras-team/keras</div><div id='commit'> Commit Name: 8e95a38e7a4be3a3edd8139dbd26e994e50d0a0c</div><div id='time'> Time: 2021-04-04</div><div id='author'> Author: scottzhu@google.com</div><div id='file'> File Name: keras/distribute/multi_worker_test.py</div><div id='class'> Class Name: KerasMultiWorkerTestIndependentWorker</div><div id='method'> Method Name: testSimpleModelIndependentWorkerSync</div><BR><BR><div id='link'><a href='https://github.com/dmlc/gluon-cv/commit/2318052dc79966bf36675606b7d992a347418292#diff-87133caacd759cd8f7b3e725bdc45f56dc7573655627f0127f3cddf936737254L236' target='_blank'>Link</a></div><div id='project'> Project Name: dmlc/gluon-cv</div><div id='commit'> Commit Name: 2318052dc79966bf36675606b7d992a347418292</div><div id='time'> Time: 2019-01-07</div><div id='author'> Author: cheungchih@gmail.com</div><div id='file'> File Name: scripts/detection/ssd/train_ssd.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: </div><BR>