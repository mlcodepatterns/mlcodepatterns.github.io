<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 Therefore, we compute the representation of all nodes layer by layer.  The nodes
        &#47&#47 on each layer are of course splitted in batches.
        &#47&#47 TODO: can we standardize this?
        <a id="change">nodes = th.arange(g.number_of_nodes())</a>
        for l, layer in enumerate(self.layers):
            y = th.zeros(g.number_of_nodes(), self.n_hidden if l != len(self.layers) - 1 else self.n_classes)

            sampler = dgl.dataloading.MultiLayerFullNeighborSampler(1)</code></pre><h3>After Change</h3><pre><code class='java'>
    
    Evaluate the model on the validation set specified by ``val_mask``.
    g : The entire graph.
    inputs : T<a id="change">he features o</a>f all the nodes.
    labels : The labels of all the nodes.
    val_mask : A 0-1 mask indicating which nodes do we actually compute the accuracy for.
    device : The GPU device to evaluate on.</code></pre>