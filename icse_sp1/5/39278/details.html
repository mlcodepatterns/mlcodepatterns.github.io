<html><h3>916af892b3e7bfa43cab877ee3f2fd7a50f576a8,torch/quantization/fx/quantization_patterns.py,LinearReLUQuantizeHandler,convert,#LinearReLUQuantizeHandler#Any#Any#Any#Any#Any#,372
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                    scale_node, zero_point_node = create_qparam_nodes(quantizer, self.linear_node.name, scale, zero_point)

                    qlinear_args = (linear_input, packed_weight, scale_node, zero_point_node)
                    <a id="change">return quantizer.quantized_graph.create_node(
                        "call_function", qlinear_op, qlinear_args, kwargs)</a>
                else:
                    linear_input = load_arg(quantized=False)(self.linear_node.args[0])
                    qlinear_args = (linear_input, packed_weight)  &#47&#47 type: ignore
                    op_out = quantizer.quantized_graph.create_node(</code></pre><h3>After Change</h3><pre><code class='java'>
                    scale_node, zero_point_node = create_qparam_nodes(quantizer, self.linear_node.name, scale, zero_point)

                    qlinear_args = (linear_input, packed_weight, scale_node, zero_point_node)
                    <a id="change">op = quantizer.quantized_graph.create_node(
                        "call_function", qlinear_op, qlinear_args, kwargs)</a>
                    &#47&#47 Store the name of the fused op to get the path of node after fusion as well.
                    &#47&#47 TODO: may need to change the key to Node regenerate the map in each transformation,
                    &#47&#47 since we might not be able to rely on the name
                    quantizer.node_name_to_scope[op.name] = quantizer.node_name_to_scope[self.linear_node.name]
                    <a id="change">return op</a>
                else:
                    linear_input = load_arg(quantized=False)(self.linear_node.args[0])
                    qlinear_args = (linear_input, packed_weight)  &#47&#47 type: ignore
                    op_out = quantizer.quantized_graph.create_node(</code></pre><img src="188691055.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/pytorch/pytorch/commit/916af892b3e7bfa43cab877ee3f2fd7a50f576a8#diff-08baa459e72443eecb6e4a42ba583b90c798c7e0f404b3b604a73d7e8e24586eL377' target='_blank'>Link</a></div><div id='project'> Project Name: pytorch/pytorch</div><div id='commit'> Commit Name: 916af892b3e7bfa43cab877ee3f2fd7a50f576a8</div><div id='time'> Time: 2021-01-28</div><div id='author'> Author: supriyar@fb.com</div><div id='file'> File Name: torch/quantization/fx/quantization_patterns.py</div><div id='class'> Class Name: LinearReLUQuantizeHandler</div><div id='method'> Method Name: convert</div><BR><BR><div id='link'><a href='https://github.com/pytorch/pytorch/commit/0818dbf49db7df046ddcf6e4335feebefb34d3ad#diff-08baa459e72443eecb6e4a42ba583b90c798c7e0f404b3b604a73d7e8e24586eL175' target='_blank'>Link</a></div><div id='project'> Project Name: pytorch/pytorch</div><div id='commit'> Commit Name: 0818dbf49db7df046ddcf6e4335feebefb34d3ad</div><div id='time'> Time: 2021-02-27</div><div id='author'> Author: jerryzh@fb.com</div><div id='file'> File Name: torch/quantization/fx/quantization_patterns.py</div><div id='class'> Class Name: Mul</div><div id='method'> Method Name: convert</div><BR><BR><div id='link'><a href='https://github.com/pytorch/pytorch/commit/4c3f59b70e98acf5bca2c1c26ebee5a018be0de4#diff-08baa459e72443eecb6e4a42ba583b90c798c7e0f404b3b604a73d7e8e24586eL113' target='_blank'>Link</a></div><div id='project'> Project Name: pytorch/pytorch</div><div id='commit'> Commit Name: 4c3f59b70e98acf5bca2c1c26ebee5a018be0de4</div><div id='time'> Time: 2021-01-28</div><div id='author'> Author: supriyar@fb.com</div><div id='file'> File Name: torch/quantization/fx/quantization_patterns.py</div><div id='class'> Class Name: Add</div><div id='method'> Method Name: convert</div><BR><BR><div id='link'><a href='https://github.com/pytorch/pytorch/commit/916af892b3e7bfa43cab877ee3f2fd7a50f576a8#diff-08baa459e72443eecb6e4a42ba583b90c798c7e0f404b3b604a73d7e8e24586eL241' target='_blank'>Link</a></div><div id='project'> Project Name: pytorch/pytorch</div><div id='commit'> Commit Name: 916af892b3e7bfa43cab877ee3f2fd7a50f576a8</div><div id='time'> Time: 2021-01-28</div><div id='author'> Author: supriyar@fb.com</div><div id='file'> File Name: torch/quantization/fx/quantization_patterns.py</div><div id='class'> Class Name: ConvRelu</div><div id='method'> Method Name: convert</div><BR>