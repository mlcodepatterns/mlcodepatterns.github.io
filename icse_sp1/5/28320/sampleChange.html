<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                &#47&#47 TODO compute miss for dfferent target types
                miss = tf.reduce_mean(tf.cast(
                    tf.not_equal(tf.argmax(predictions, -1), labels[..., 0]),
                    dtype=<a id="change">tf.float32</a>))

                grads = train_step.compute_gradients(loss)
                tower_losses.append(loss)
                tower_misses.append(miss)
                tower_grads.append(grads)

                &#47&#47 note: only use batch stats from one GPU for batch_norm
                if i == 0:
                    bn_updates = tf.get_collection(tf.GraphKeys.UPDATE_OPS)

        ave_loss = tf.reduce_mean(tower_losses)
        ave_miss = tf.reduce_mean(tower_misses)
        ave_grads = util.average_grads(tower_grads)
        apply_grad_op = train_step.apply_gradients(ave_grads)
        &#47&#47 summary for visualisations
        &#47&#47 tracking current batch loss
        summaries = [<a id="change">tf.summary.scalar("total-miss", ave_miss)</a>,
                     tf.summary.scalar("total-loss", ave_loss)]

        &#47&#47 Track the moving averages of all trainable variables.</code></pre><h3>After Change</h3><pre><code class='java'>
                    for p in range(0,4):
                        plt.subplot(4, 2, 2*p+1)
                        temp1 = sess.run(predictions[0])
                        temp1 = temp1[<a id="change">p,:,12,:,0</a>]
                        temp1.reshape(24, 24)
                        plt.imshow(temp1, cmap=&quotgray&quot)
                        plt.subplot(4, 2, 2*p+2)</code></pre>