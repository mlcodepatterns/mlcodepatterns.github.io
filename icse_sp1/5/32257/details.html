<html><h3>980fe014b6215730ac4fdfa451b067e6fb44e622,tensorforce/agents/dpg.py,DeterministicPolicyGradient,__init__,#DeterministicPolicyGradient#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#,129
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            entropy_regularization=entropy_regularization, **kwargs
        )

        action_spec = next(iter(<a id="change">self.actions_spec.values()</a>))
        <a id="change">if len(self.actions_spec) &gt; 1 or action_spec.type != &quotfloat&quot or \
                (action_spec.shape != () and action_spec.shape != (1,)):
            raise TensorforceError.value(
                name=&quotDeterministicPolicyGradient&quot, argument=&quotactions&quot, value=actions,
                hint=&quotcontains more than a single float action&quot
            )</a>
</code></pre><h3>After Change</h3><pre><code class='java'>
        if start_updating is not None:
            update[&quotstart&quot] = start_updating

        optimizer = dict(type=&quotadam&quot, learning_rate=learning_rat<a id="change">e)
        objective = &quotdeterministic_policy_gradient&quot

        </a>reward_estimation = dict(
            horizon=horizon, discount=discount, predict_horizon_values=&quotlate&quot,
            estimate_advantage=False, predict_action_values=True,
            predict_terminal_values=predict_terminal_values</code></pre><img src="158965305.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/reinforceio/tensorforce/commit/980fe014b6215730ac4fdfa451b067e6fb44e622#diff-443d67fa7edec8251762387ef1b41ae3875573f7549712628000f7f0dbcc09e6L131' target='_blank'>Link</a></div><div id='project'> Project Name: reinforceio/tensorforce</div><div id='commit'> Commit Name: 980fe014b6215730ac4fdfa451b067e6fb44e622</div><div id='time'> Time: 2020-08-13</div><div id='author'> Author: alexkuhnle@t-online.de</div><div id='file'> File Name: tensorforce/agents/dpg.py</div><div id='class'> Class Name: DeterministicPolicyGradient</div><div id='method'> Method Name: __init__</div><BR><BR><div id='link'><a href='https://github.com/google/tangent/commit/31269a5197170026985db35c4703cc6e9c805ebf#diff-ecb77585ab61d1ae79c638178a3dc07e3ae607652f2ec744edb6a3fc7f5dc63eL669' target='_blank'>Link</a></div><div id='project'> Project Name: google/tangent</div><div id='commit'> Commit Name: 31269a5197170026985db35c4703cc6e9c805ebf</div><div id='time'> Time: 2017-11-10</div><div id='author'> Author: bart.vanmerrienboer@gmail.com</div><div id='file'> File Name: tangent/reverse_ad.py</div><div id='class'> Class Name: ReverseAD</div><div id='method'> Method Name: visit_Call</div><BR><BR><div id='link'><a href='https://github.com/google/tangent/commit/31269a5197170026985db35c4703cc6e9c805ebf#diff-39af86c7e43f945607daadb68cb31cb6871e7464e7b205b70d1ec8533953cc91L203' target='_blank'>Link</a></div><div id='project'> Project Name: google/tangent</div><div id='commit'> Commit Name: 31269a5197170026985db35c4703cc6e9c805ebf</div><div id='time'> Time: 2017-11-10</div><div id='author'> Author: bart.vanmerrienboer@gmail.com</div><div id='file'> File Name: tangent/forward_ad.py</div><div id='class'> Class Name: ForwardAD</div><div id='method'> Method Name: visit_Call</div><BR>