<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
          all_grads = []
          for grad, var in avg_grads:
            all_grads.append(tf.reshape(grad, [-1]))
          <a id="change">grads = tf.abs(tf.concat(all_grads, 0))</a>
          &#47&#47 exclude grads with zero values.
          <a id="change">indices_for_non_zero_grads = tf.where(tf.not_equal(grads, 0))</a>
          log_grads = tf.reshape(
              <a id="change">tf.log(tf.gather(grads, indices_for_non_zero_grads))</a>, [-1])
          tf.summary.histogram(&quotlog_gradients&quot, log_grads)

        if self.params.summary_verbosity &gt;= 3:</code></pre><h3>After Change</h3><pre><code class='java'>
      with tf.device(device):
        with tf.name_scope(&quotaverage_loss&quot):
          average_loss = tf.reduce_mean(losses)
        <a id="change">with tf.name_scope(&quotget_gradients_to_apply&quot):
          avg_grads = self.variable_mgr.get_gradients_to_apply(d,
                                                               gradient_state)

       </a> gradient_clip = self.params.gradient_clip
        &#47&#47 TODO(reedwm): Greatly simplify the learning rate code.
        if self.params.variable_update == &quothorovod&quot:
          &#47&#47 Each worker independently increments global_step.</code></pre>