<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        tokens_batch = self.batch_input(tokens)
        self.prepare_vectorizers(tokens_batch)
        if self.preproc == "client":
            <a id="change">examples = self.vectorize(tokens_batch)</a>
        elif self.preproc == &quotserver&quot:
            &#47&#47 TODO: here we allow vectorizers even for preproc=server to get `word_lengths`.
            &#47&#47 vectorizers should not be available when preproc=server.
            <a id="change">featurized_examples = self.vectorize(tokens_batch)</a>
            examples = {
                        &quottokens&quot: np.array([" ".join(x) for x in tokens_batch]),
                        self.model.lengths_key: featurized_examples[self.model.lengths_key]
            }</code></pre><h3>After Change</h3><pre><code class='java'>

        if backend not in {&quottf&quot}:
            raise ValueError("only Tensorflow is currently supported for remote Services")
        import_user_module(&quotbaseline.{}.remote&quot.format(<a id="change">backend))
        exp_type </a>= kwargs.get(&quotremote_type&quot)
        if exp_type is None:
            exp_type = &quothttp&quot if remote.startswith(&quothttp&quot) else &quotgrpc&quot
            exp_type = &quot{}-preproc&quot.format(exp_type) if preproc == &quotserver&quot else exp_type</code></pre>