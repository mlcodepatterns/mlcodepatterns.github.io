<html><h3>2a548989f90026395d3d47ccf15ac331728c64bf,ml/rl/training/parametric_dqn_trainer.py,ParametricDQNTrainer,train,#ParametricDQNTrainer#Any#,58
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        self.loss = value_loss.detach()

        value_loss.backward()
        <a id="change">self._maybe_run_optimizer(self.q_network_optimizer, self.minibatches_per_step)</a>

        &#47&#47 Use the soft update rule to update target network
        self._maybe_soft_update(
            self.q_network, self.q_network_target, self.tau, self.minibatches_per_step</code></pre><h3>After Change</h3><pre><code class='java'>

        target_q_values = reward + (discount_tensor * filtered_max_q_vals)

        <a id="change">with torch.enable_grad():
            &#47&#47 Get Q-value of action taken
            current_state_action = rlt.StateAction(
                state=learning_input.state, action=learning_input.action
            )
            q_values = self.q_network(current_state_action).q_value
            self.all_action_scores = q_values.detach()

            value_loss = self.q_network_loss(q_values, target_q_values)
            self.loss = value_loss.detach()

            value_loss.backward()
            self._maybe_run_optimizer(
                self.q_network_optimizer, self.minibatches_per_step
            )

        &#47&#47 Use the soft update rule to update target network
       </a> self._maybe_soft_update(
            self.q_network, self.q_network_target, self.tau, self.minibatches_per_step
        )
</code></pre><img src="259910829.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/facebookresearch/Horizon/commit/2a548989f90026395d3d47ccf15ac331728c64bf#diff-a421c1688e7de52470d40f812d85accc1903ba475daa8bd7034891dbc49631f4L100' target='_blank'>Link</a></div><div id='project'> Project Name: facebookresearch/Horizon</div><div id='commit'> Commit Name: 2a548989f90026395d3d47ccf15ac331728c64bf</div><div id='time'> Time: 2019-06-22</div><div id='author'> Author: jjg@fb.com</div><div id='file'> File Name: ml/rl/training/parametric_dqn_trainer.py</div><div id='class'> Class Name: ParametricDQNTrainer</div><div id='method'> Method Name: train</div><BR><BR><div id='link'><a href='https://github.com/facebookresearch/Horizon/commit/2a548989f90026395d3d47ccf15ac331728c64bf#diff-1e05823efcf5119bf771fc16f182df9cf4b8aac20b722908d7557012b69896d4L246' target='_blank'>Link</a></div><div id='project'> Project Name: facebookresearch/Horizon</div><div id='commit'> Commit Name: 2a548989f90026395d3d47ccf15ac331728c64bf</div><div id='time'> Time: 2019-06-22</div><div id='author'> Author: jjg@fb.com</div><div id='file'> File Name: ml/rl/training/dqn_trainer.py</div><div id='class'> Class Name: DQNTrainer</div><div id='method'> Method Name: calculate_cpes</div><BR><BR><div id='link'><a href='https://github.com/facebookresearch/Horizon/commit/2a548989f90026395d3d47ccf15ac331728c64bf#diff-1458fd4d72c999f6eec93ce7d3414a04bc3864600342529de8965ee95e44dbc6L163' target='_blank'>Link</a></div><div id='project'> Project Name: facebookresearch/Horizon</div><div id='commit'> Commit Name: 2a548989f90026395d3d47ccf15ac331728c64bf</div><div id='time'> Time: 2019-06-22</div><div id='author'> Author: jjg@fb.com</div><div id='file'> File Name: ml/rl/training/sac_trainer.py</div><div id='class'> Class Name: SACTrainer</div><div id='method'> Method Name: train</div><BR>