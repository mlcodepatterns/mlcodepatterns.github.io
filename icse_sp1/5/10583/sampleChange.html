<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    shapes, func, y0, t, rtol, atol, method, options, event_fn, decreasing_time = _check_inputs(func, y0, t, rtol, atol, method, options, event_fn, SOLVERS)

    if "norm" in options and "norm" not in adjoint_options:
        adjoint_shapes = [<a id="change">torch.Size(())</a>, y0.shape, y0.shape] + [torch.Size([sum(param.numel() for param in adjoint_params)])]
        <a id="change">adjoint_options["norm"] = _wrap_norm([_rms_norm, options["norm"], options["norm"]], adjoint_shapes)</a>

    ans = OdeintAdjointMethod.apply(shapes, func, y0, t, rtol, atol, method, options, event_fn, adjoint_rtol, adjoint_atol,
                                    adjoint_method, adjoint_options, t.requires_grad, *adjoint_params)
</code></pre><h3>After Change</h3><pre><code class='java'>
        adjoint_params = tuple(adjoint_params)  &#47&#47 in case adjoint_params is a generator.

    &#47&#47 Filter params that don&quott require gradients.
    <a id="change">for p in adjoint_params:
        if not p.requires_grad:
            &#47&#47 Issue a warning if a user-specified norm is specified.
            if &quotnorm&quot in adjoint_options and adjoint_options[&quotnorm&quot] != &quotseminorm&quot:
                warnings.warn("An adjoint parameter was passed without requiring gradient. For efficiency this will be "
                              "excluded from the adjoint pass, and will not appear as a tensor in the adjoint norm.")

   </a> adjoint_params = tuple(p for p in adjoint_params if p.requires_grad)

    &#47&#47 Normalise to non-tupled state.
    shapes, func, y0, t, rtol, atol, method, options, event_fn, decreasing_time = _check_inputs(func, y0, t, rtol, atol, method, options, event_fn, SOLVERS)</code></pre>