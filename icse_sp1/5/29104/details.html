<html><h3>7459ce340e207f1764cf8bd94afe15bed6196fa8,petastorm/pytorch.py,DataLoader,__iter__,#DataLoader#,135
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                &#47&#47 Batch is ready? Collate and emmit
                if len(batch) == self.batch_size:
                    yield self.collate_fn(batch)
                    <a id="change">batch = []</a>

        &#47&#47 Once reader can not emit new rows, we might still have a bunch of rows waiting in the shuffling buffer.
        &#47&#47 Telling shuffling buffer thatt we are finished allows to deplete the buffer completely, regardless its
        &#47&#47 min_after_dequeue setting.
        self._shuffling_buffer.finish()

        &#47&#47 Some code duplication with the main reading loop. Not sure how to reorganize to avoid this without
        &#47&#47 overcomplicating the code too much.
        while self._shuffling_buffer.can_retrieve():
            post_shuffled_row = self._shuffling_buffer.retrieve()
            batch.append(post_shuffled_row)

            &#47&#47 Batch is ready? Collate and emmit
            if len(batch) == self.batch_size:
                <a id="change">yield self.collate_fn(batch)</a>
                batch = []

        if batch:
            yield self.collate_fn(batch)</code></pre><h3>After Change</h3><pre><code class='java'>
            &#47&#47 Using dict will result in the yielded structures being dicts as well
            row_as_dict = row._asdict()

            <a id="change">keys = row_as_dict.keys()</a>

            &#47&#47 Promote some types that are incompatible with pytorch to be pytorch friendly.
            _sanitize_pytorch_types(row_as_dict)

            &#47&#47 Add rows to shuffling buffer
            if not self.reader.is_batched_reader:
                self._shuffling_buffer.add_many([row_as_dict])
            else:
                &#47&#47 Transposition:
                &#47&#47   row_as_dict:        {&quota&quot: [1,2,3], &quotb&quot:[4,5,6]}
                &#47&#47   row_group_as_tuple: [(1, 4), (2, 5), (3, 6)]
                &#47&#47 The order within a tuple is defined by key order in &quotkeys&quot
                row_group_as_tuple = list(zip(*(row_as_dict[k] for k in keys)))

                &#47&#47 Adding data as &quotrow-by-row&quot into a shuffling buffer. This is a pretty
                &#47&#47 slow implementation though. Probably can comeup with a faster way to shuffle,
                &#47&#47 perhaps at the expense of a larger memory consumption...
                self._shuffling_buffer.add_many(row_group_as_tuple)

            &#47&#47 _yield_batches will emit as much batches as are allowed by the shuffling_buffer (RandomShufflingBuffer
            &#47&#47 will avoid underflowing below a certain number of samples to guarantee some samples decorrelation)
            for batch in self._yield_batches(keys):
                yield batch

        &#47&#47 Once reader can not read new rows, we might still have a bunch of rows waiting in the shuffling buffer.
        &#47&#47 Telling shuffling buffer that we are finished allows to deplete the buffer completely, regardless its
        &#47&#47 min_after_dequeue setting.
        self._shuffling_buffer.finish()

        <a id="change">for batch in self._yield_batches(keys):
            yield batch

        &#47&#47 Yield the last and partial batch
       </a> if self._batch_acc:
            yield self.collate_fn(self._batch_acc)

    def _yield_batches(self, keys):</code></pre><img src="146996322.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/uber/petastorm/commit/7459ce340e207f1764cf8bd94afe15bed6196fa8#diff-d14e9ff9c6b380e9a8aec500d4d5b8d139175c72a6574c98928b9e68276cfde1L135' target='_blank'>Link</a></div><div id='project'> Project Name: uber/petastorm</div><div id='commit'> Commit Name: 7459ce340e207f1764cf8bd94afe15bed6196fa8</div><div id='time'> Time: 2019-08-27</div><div id='author'> Author: yevgeni@uber.com</div><div id='file'> File Name: petastorm/pytorch.py</div><div id='class'> Class Name: DataLoader</div><div id='method'> Method Name: __iter__</div><BR><BR><div id='link'><a href='https://github.com/pantsbuild/pants/commit/05d6ff5b4ef75c31fdc68644d02bc70cffd54005#diff-8edb2009bae647a330fd7533bcaf9651b09a254736941c81fd9ee027118cc1adL122' target='_blank'>Link</a></div><div id='project'> Project Name: pantsbuild/pants</div><div id='commit'> Commit Name: 05d6ff5b4ef75c31fdc68644d02bc70cffd54005</div><div id='time'> Time: 2016-08-16</div><div id='author'> Author: lahosken@gmail.com</div><div id='file'> File Name: src/python/pants/help/build_dictionary_info_extracter.py</div><div id='class'> Class Name: BuildDictionaryInfoExtracter</div><div id='method'> Method Name: _get_args_for_target_type</div><BR><BR><div id='link'><a href='https://github.com/bokeh/bokeh/commit/4ace574968a1001c80b1689239d767f9e4497d78#diff-d9bf2b0ea1bac8d21016a8ee27d7b782ef2e96ac1445f3cf4d3511d2d95ff0e7L125' target='_blank'>Link</a></div><div id='project'> Project Name: bokeh/bokeh</div><div id='commit'> Commit Name: 4ace574968a1001c80b1689239d767f9e4497d78</div><div id='time'> Time: 2015-08-14</div><div id='author'> Author: nroth@dealnews.com</div><div id='file'> File Name: bokeh/charts/builder/scatter_builder.py</div><div id='class'> Class Name: ScatterBuilder</div><div id='method'> Method Name: _yield_renderers</div><BR>