<html><h3>1a55589989981eca04d228127878b500fb7a8a12,kitti_eval/depth_evaluation_utils.py,,read_scene_data,#Any#Any#Any#Any#,59
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    cams = []
    displacements = []
    demi_length = (seq_length - 1) // 2
    shift_range = [step*i for i in list(<a id="change">range(-demi_length,0)</a>) + list(range(1, demi_length + 1))]

    print(&quotgetting test metadata ... &quot)
    for sample in tqdm(test_list):
        tgt_img_path = data_root/sample
        date, scene, cam_id, _, index = sample[:-4].split(&quot/&quot)

        ref_imgs_path = [tgt_img_path.dirname()/&quot{:010d}.png&quot.format(int(index) + shift) for shift in shift_range]

        caped_shift_range = shift_range[:]  &#47&#47 ensures ref_imgs are present, if not, set shift to 0 so that it will be discarded later
        <a id="change">for i,img in enumerate(ref_imgs_path):
            if not img.isfile():
                ref_imgs_path[i] = tgt_img_path
                caped_shift_range[i] = 0

       </a> vel_path = data_root/date/scene/&quotvelodyne_points&quot/&quotdata&quot/&quot{}.bin&quot.format(index[:10])

        if tgt_img_path.isfile():
            gt_files.append(vel_path)</code></pre><h3>After Change</h3><pre><code class='java'>

        scene_length = len(tgt_img_path.parent.files(&quot*.png&quot))

        ref_indices = shift_range + <a id="change">np.clip(int(index), step*demi_length, scene_length - step*demi_length - 1)</a>

        ref_imgs_path = [tgt_img_path.dirname()/&quot{:010d}.png&quot.format(i) for i in ref_indices]
        vel_path = data_root/date/scene/&quotvelodyne_points&quot/&quotdata&quot/&quot{}.bin&quot.format(index[:10])
</code></pre><img src="287939147.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/ClementPinard/SfmLearner-Pytorch/commit/1a55589989981eca04d228127878b500fb7a8a12#diff-c69cd4f9ab17486582ebdcc6070d797ed9dc6800c854784bef030801fce3455dL67' target='_blank'>Link</a></div><div id='project'> Project Name: ClementPinard/SfmLearner-Pytorch</div><div id='commit'> Commit Name: 1a55589989981eca04d228127878b500fb7a8a12</div><div id='time'> Time: 2018-03-13</div><div id='author'> Author: clement.pinard@parrot.com</div><div id='file'> File Name: kitti_eval/depth_evaluation_utils.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: read_scene_data</div><BR><BR><div id='link'><a href='https://github.com/tiberiu44/TTS-Cube/commit/288e2868ce5f35a9c8ecf3e3fa913f293adcf7e7#diff-9d17b1c68e41c8fdd5b8f4fddb08fcad8f39df3ea7fa9bb8de1c41a95d338ea8L161' target='_blank'>Link</a></div><div id='project'> Project Name: tiberiu44/TTS-Cube</div><div id='commit'> Commit Name: 288e2868ce5f35a9c8ecf3e3fa913f293adcf7e7</div><div id='time'> Time: 2018-10-31</div><div id='author'> Author: boros@adobe.com</div><div id='file'> File Name: cube/models/vocoder.py</div><div id='class'> Class Name: BeeCoder</div><div id='method'> Method Name: learn</div><BR><BR><div id='link'><a href='https://github.com/Microsoft/nni/commit/afb4e78c5c9c4782482777fd8587c636711ab2e5#diff-d19bbefa8492d37c29a6505d8f699ff6413aeb4f1bc3cf75ffed18a66a57d163L100' target='_blank'>Link</a></div><div id='project'> Project Name: Microsoft/nni</div><div id='commit'> Commit Name: afb4e78c5c9c4782482777fd8587c636711ab2e5</div><div id='time'> Time: 2019-08-04</div><div id='author'> Author: suiguoxin@gmail.com</div><div id='file'> File Name: src/sdk/pynni/nni/gridsearch_tuner/gridsearch_tuner.py</div><div id='class'> Class Name: GridSearchTuner</div><div id='method'> Method Name: _parse_quniform</div><BR>