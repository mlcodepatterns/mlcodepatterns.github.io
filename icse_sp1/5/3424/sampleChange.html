<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            if d == 1:  &#47&#47 scalars
                if self.training:
                    field_mean = field.mean(0).mean(-1).view(-1)  &#47&#47 [feature]
                    self.running_mean[irm: irm + m] = (1 - self.momentum) * self.running_mean[irm: irm + m] + self.momentum * <a id="change">field_mean.detach()</a>
                else:
                    field_mean = self.running_mean[irm: irm + m]
                irm += m
                field = field - field_mean.view(1, m, 1, 1)  &#47&#47 [batch, feature, repr, x * y * z]</code></pre><h3>After Change</h3><pre><code class='java'>
        &quot&quot&quot

        new_means = []
        <a id="change">new_vars = []</a>

        fields = []
        ix = 0
        irm = 0
        irv = 0
        iw = 0
        ib = 0
        for m, d in self.Rs:
            field = input[:, ix: ix + m * d]  &#47&#47 [batch, feature * repr, x, y, z]
            ix += m * d
            field = field.contiguous().view(input.size(0), m, d, -1)  &#47&#47 [batch, feature, repr, x * y * z]

            if d == 1:  &#47&#47 scalars
                if self.training:
                    field_mean = field.mean(0).mean(-1).view(-1).detach()  &#47&#47 [feature]
                    new_means.append(self._roll_avg(self.running_mean[irm:irm+m], field_mean))
                else:
                    field_mean = self.running_mean[irm: irm + m]
                irm += m
                field = field - field_mean.view(1, m, 1, 1)  &#47&#47 [batch, feature, repr, x * y * z]

            if self.training:
                field_norm = torch.sum(field ** 2, dim=2)  &#47&#47 [batch, feature, x * y * z]
                if self.reduce == &quotmean&quot:
                    field_norm = field_norm.mean(-1)  &#47&#47 [batch, feature]
                elif self.reduce == &quotmax&quot:
                    field_norm = field_norm.max(-1)[0]  &#47&#47 [batch, feature]
                else:
                    raise ValueError("Invalid reduce option")
                field_norm = field_norm.mean(0).detach()  &#47&#47 [feature]
                <a id="change">new_vars.append(self._roll_avg(self.running_var[irv: irv+m], field_norm))</a>
            else:
                field_norm = self.running_var[irv: irv + m]
            irv += m

            field_norm = (field_norm + self.eps).pow(-0.5).view(1, m, 1, 1)  &#47&#47 [batch, feature, repr, x * y * z]

            if self.affine:
                weight = self.weight[iw: iw + m]  &#47&#47 [feature]
                iw += m
                field_norm = field_norm * weight.view(1, m, 1, 1)  &#47&#47 [batch, feature, repr, x * y * z]

            field = field * field_norm  &#47&#47 [batch, feature, repr, x * y * z]

            if self.affine and d == 1:  &#47&#47 scalars
                bias = self.bias[ib: ib + m]  &#47&#47 [feature]
                ib += m
                field += bias.view(1, m, 1, 1)  &#47&#47 [batch, feature, repr, x * y * z]

            fields.append(field.view(input.size(0), m * d, *input.size()[2:]))

        assert ix == input.size(1)
        if self.training:
            assert irm == self.running_mean.numel()
            assert irv == self.running_var.size(0)
        if self.affine:
            assert iw == self.weight.size(0)
            assert ib == self.bias.numel()

        self.running_mean = torch.cat(new_means) 
        <a id="change">self.running_var = torch.cat(new_vars)</a>

        return torch.cat(fields, dim=1)  &#47&#47 [batch, stacked feature, x, y, z]

</code></pre>