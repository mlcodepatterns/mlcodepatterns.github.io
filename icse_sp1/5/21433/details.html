<html><h3>e3fcbb639e115e8afe9600bd06aee81acfda6704,reagent/training/world_model/seq2reward_trainer.py,Seq2RewardTrainer,train,#Seq2RewardTrainer#Any#,38
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        loss.backward()
        self.optimizer.step()
        detached_loss = loss.cpu().detach().item()
        q_values = <a id="change">(
            self.get_Q(
                training_batch,
                training_batch.batch_size(),
                self.params.multi_steps,
                len(self.params.action_names),
            )
            .mean(0)
            .tolist()
        )</a>

        return (detached_loss, q_values)

    def get_loss(self, training_batch: rlt.MemoryNetworkInput):</code></pre><h3>After Change</h3><pre><code class='java'>
        self.optimizer.step()
        detached_loss = loss.cpu().detach().item()

        <a id="change">if self.view_q_value:
            q_values = (
                get_Q(self.seq2reward_network, training_batch, self.all_permut)
                .cpu()
                .mean(0)
                .tolist()
            )
        else:
            q_values = [0] * len(self.params.action_names)

       </a> logger.info(f"Seq2Reward trainer output: {(detached_loss, q_values)}")
        return (detached_loss, q_values)

    def get_loss(self, training_batch: rlt.MemoryNetworkInput):</code></pre><img src="117145435.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/facebookresearch/Horizon/commit/e3fcbb639e115e8afe9600bd06aee81acfda6704#diff-8fd50bf3e9d5dde8c471d92042ed9a6c1e4de03e3ad51534a2e57975f7b52a1fL38' target='_blank'>Link</a></div><div id='project'> Project Name: facebookresearch/Horizon</div><div id='commit'> Commit Name: e3fcbb639e115e8afe9600bd06aee81acfda6704</div><div id='time'> Time: 2020-10-13</div><div id='author'> Author: czxttkl@fb.com</div><div id='file'> File Name: reagent/training/world_model/seq2reward_trainer.py</div><div id='class'> Class Name: Seq2RewardTrainer</div><div id='method'> Method Name: train</div><BR><BR><div id='link'><a href='https://github.com/IndicoDataSolutions/finetune/commit/e9eb9d3cdef98f21f754b577b88dc259a9914ede#diff-8b667dd402b2d410da2ac4418121539b339e2f5cb5bc458f8ab8d6ef48713f18L37' target='_blank'>Link</a></div><div id='project'> Project Name: IndicoDataSolutions/finetune</div><div id='commit'> Commit Name: e9eb9d3cdef98f21f754b577b88dc259a9914ede</div><div id='time'> Time: 2019-07-17</div><div id='author'> Author: matthew.bayer@indico.io</div><div id='file'> File Name: finetune/target_models/regressor.py</div><div id='class'> Class Name: Regressor</div><div id='method'> Method Name: predict</div><BR><BR><div id='link'><a href='https://github.com/IndicoDataSolutions/finetune/commit/9b2f98b435d6b21a0f5d49c1a5a23c97e7357d6f#diff-e3c8c393c2aa40ef8899860048ac5c916165e0ec17c4c1b653b42c1e1769557eL46' target='_blank'>Link</a></div><div id='project'> Project Name: IndicoDataSolutions/finetune</div><div id='commit'> Commit Name: 9b2f98b435d6b21a0f5d49c1a5a23c97e7357d6f</div><div id='time'> Time: 2019-07-17</div><div id='author'> Author: matthew.bayer@indico.io</div><div id='file'> File Name: finetune/target_models/ordinal_regressor.py</div><div id='class'> Class Name: OrdinalRegressor</div><div id='method'> Method Name: predict</div><BR>