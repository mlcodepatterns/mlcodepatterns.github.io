<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
          depth_multiplier=1,
          bias_initializer=tf.zeros_initializer())
    else:
      self._conv2d_op = <a id="change">functools.partial(
          tf.layers.conv2d,
          kernel_initializer=tf.random_normal_initializer(stddev=0.01),
          bias_initializer=tf.zeros_initializer())</a>

    self._use_batch_norm = use_batch_norm
    self._batch_norm_activation = batch_norm_activation
</code></pre><h3>After Change</h3><pre><code class='java'>
    self._num_convs = num_convs
    self._upsample_factor = upsample_factor
    self._upsample_num_filters = upsample_num_filters
    <a id="change">if activation == &quotrelu&quot:
      self._activation = tf.nn.relu
    elif activation == &quotswish&quot:
      self._activation = tf.nn.swish
    else:
      raise ValueError(&quotActivation {} not implemented.&quot.format(activation))
   </a> self._use_batch_norm = use_batch_norm
    self._batch_norm_activation = batch_norm_activation

  def __call__(self, features, is_training):</code></pre>