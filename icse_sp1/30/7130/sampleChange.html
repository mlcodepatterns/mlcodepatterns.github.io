<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        &#47&#47 Creats the cell function
        &#47&#47 cell_instance_fn=lambda: cell_fn(num_units=n_hidden, **cell_init_args) &#47&#47 HanSheng
        <a id="change">self.cell</a> = <a id="change">cell_fn(num_units=n_hidden, **cell_init_args)</a>

        &#47&#47 Apply dropout
        if dropout:
            if type(dropout) in [tuple, list]:
                in_keep_prob = dropout[0]
                out_keep_prob = dropout[1]
            elif isinstance(dropout, float):
                in_keep_prob, out_keep_prob = dropout, dropout
            else:
                raise Exception("Invalid dropout type (must be a 2-D tuple of "
                                "float)")
            try: &#47&#47 TF1.0
                DropoutWrapper_fn = tf.contrib.rnn.DropoutWrapper
            except:
                DropoutWrapper_fn = tf.nn.rnn_cell.DropoutWrapper

            &#47&#47 cell_instance_fn1=cell_instance_fn        &#47&#47 HanSheng
            &#47&#47 cell_instance_fn=DropoutWrapper_fn(
            &#47&#47                     cell_instance_fn1(),
            &#47&#47                     input_keep_prob=in_keep_prob,
            &#47&#47                     output_keep_prob=out_keep_prob)
            <a id="change">self.cell = DropoutWrapper_fn(self.cell,
                      input_keep_prob=in_keep_prob, output_keep_prob=1.0)</a>&#47&#47out_keep_prob)

        &#47&#47 Apply multiple layers
        if n_layer &gt; 1:
            try:
                MultiRNNCell_fn = tf.contrib.rnn.MultiRNNCell
            except:
                MultiRNNCell_fn = tf.nn.rnn_cell.MultiRNNCell

            &#47&#47 cell_instance_fn2=cell_instance_fn &#47&#47 HanSheng
            try:
                &#47&#47 cell_instance_fn=lambda: MultiRNNCell_fn([cell_instance_fn2() for _ in range(n_layer)], state_is_tuple=True) &#47&#47 HanSheng
                <a id="change">self.cell = MultiRNNCell_fn([self.cell] * n_layer, state_is_tuple=True)</a>
            except: &#47&#47 when GRU
                &#47&#47 cell_instance_fn=lambda: MultiRNNCell_fn([cell_instance_fn2() for _ in range(n_layer)]) &#47&#47 HanSheng
                self.cell = MultiRNNCell_fn([self.cell] * n_layer)

        if dropout:
            <a id="change">self.cell</a> = DropoutWrapper_fn(self.cell,
                      input_keep_prob=1.0, output_keep_prob=out_keep_prob)

        &#47&#47 self.cell=cell_instance_fn() &#47&#47 HanSheng</code></pre><h3>After Change</h3><pre><code class='java'>
                      input_keep_prob=in_keep_prob, output_keep_prob=1.0)&#47&#47out_keep_prob)
        else:
            cell_creator = rnn_creator
        <a id="change">self.cell = cell_creator()</a>
        &#47&#47 Apply multiple layers
        if n_layer &gt; 1:
            try:
                MultiRNNCell_fn = tf.contrib.rnn.MultiRNNCell
            except:
                MultiRNNCell_fn = tf.nn.rnn_cell.MultiRNNCell

            &#47&#47 cell_instance_fn2=cell_instance_fn &#47&#47 HanSheng
            try:
                &#47&#47 cell_instance_fn=lambda: MultiRNNCell_fn([cell_instance_fn2() for _ in range(n_layer)], state_is_tuple=True) &#47&#47 HanSheng
                <a id="change">self.cell = MultiRNNCell_fn([cell_creator() for _ in range(n_layer)], state_is_tuple=True)</a>
            except: &#47&#47 when GRU
                &#47&#47 cell_instance_fn=lambda: MultiRNNCell_fn([cell_instance_fn2() for _ in range(n_layer)]) &#47&#47 HanSheng
                self.cell = <a id="change">MultiRNNCell_fn([cell_creator() for _ in range(n_layer)])</a>

        if dropout:
            <a id="change">self.cell</a> = DropoutWrapper_fn(self.cell,
                      input_keep_prob=1.0, output_keep_prob=out_keep_prob)

        &#47&#47 self.cell=cell_instance_fn() &#47&#47 HanSheng</code></pre>