<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
      warmup: number of entries in stats[&quotstep_timestamp_log&quot] to ignore.
    

    <a id="change">extras = {}</a>
    if &quotaccuracy_top_1&quot in stats:
      <a id="change">extras[&quotaccuracy_top_1&quot] = self._json_description(
          stats[&quotaccuracy_top_1&quot],
          priority=0,
          min_value=top_1_min,
          max_value=top_1_max)</a>
      <a id="change">extras[&quottop_1_train_accuracy&quot] = self._json_description(
          stats[&quottraining_accuracy_top_1&quot], priority=1)</a>

    if (warmup and &quotstep_timestamp_log&quot in stats and
        len(stats[&quotstep_timestamp_log&quot]) &gt; warmup):
      &#47&#47 first entry in the time_log is start of step 1. The rest of the
      &#47&#47 entries are the end of each step recorded
      time_log = stats[&quotstep_timestamp_log&quot]
      elapsed = time_log[-1].timestamp - time_log[warmup].timestamp
      num_examples = (
          total_batch_size * log_steps * (len(time_log) - warmup - 1))
      examples_per_sec = num_examples / elapsed
      <a id="change">extras[&quotexp_per_second&quot] = self._json_description(
          examples_per_sec, priority=2)</a>

    if &quotavg_exp_per_second&quot in stats:
      extras[&quotavg_exp_per_second&quot] = self._json_description(
          stats[&quotavg_exp_per_second&quot], priority=3)</code></pre><h3>After Change</h3><pre><code class='java'>
      warmup: number of entries in stats[&quotstep_timestamp_log&quot] to ignore.
    

    <a id="change">metrics = []</a>
    if &quotaccuracy_top_1&quot in stats:
      <a id="change">metrics.append({&quotname&quot: &quotaccuracy_top_1&quot,
                      &quotvalue&quot: stats[&quotaccuracy_top_1&quot],
                      &quotmin_value&quot: top_1_min,
                      &quotmax_value&quot: top_1_max})</a>
      metrics.append({&quotname&quot: &quottop_1_train_accuracy&quot,
                      &quotvalue&quot: stats[&quottraining_accuracy_top_1&quot]})

    if (warmup and &quotstep_timestamp_log&quot in stats and
        len(stats[&quotstep_timestamp_log&quot]) &gt; warmup):
      &#47&#47 first entry in the time_log is start of step 1. The rest of the
      &#47&#47 entries are the end of each step recorded
      time_log = stats[&quotstep_timestamp_log&quot]
      elapsed = time_log[-1].timestamp - time_log[warmup].timestamp
      num_examples = (
          total_batch_size * log_steps * (len(time_log) - warmup - 1))
      examples_per_sec = num_examples / elapsed
      metrics.append(<a id="change">{&quotname&quot: &quotexp_per_second&quot,
                      &quotvalue&quot: examples_per_sec}</a>)

    if &quotavg_exp_per_second&quot in stats:
      <a id="change">metrics.append({&quotname&quot: &quotavg_exp_per_second&quot,
                      &quotvalue&quot: stats[&quotavg_exp_per_second&quot]})</a>

    self.report_benchmark(iters=-1, wall_time=wall_time_sec, metrics=metrics)
</code></pre>