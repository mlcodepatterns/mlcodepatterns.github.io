<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

def test_fm_airflow_config_uploads_data_source_to_s3(sagemaker_session, cpu_instance_type):
    with timeout(seconds=AIRFLOW_CONFIG_TIMEOUT_IN_SECONDS):
        <a id="change">data_path = os.path.join(DATA_DIR, "one_p_mnist", "mnist.pkl.gz")</a>
        pickle_args = <a id="change">{} if sys.version_info.major == 2 else {"encoding": "latin1"}</a>

        &#47&#47 Load the data into memory as numpy arrays
        <a id="change">with gzip.open(data_path, "rb") as f:
            train_set, _, _ = pickle.load(f, **pickle_args)

       </a> fm = FactorizationMachines(
            role=ROLE,
            train_instance_count=SINGLE_INSTANCE_COUNT,
            train_instance_type=cpu_instance_type,</code></pre><h3>After Change</h3><pre><code class='java'>
            sagemaker_session=sagemaker_session,
        )

        <a id="change">training_set = datasets.one_p_mnist()</a>
        records = fm.record_set(training_set[0][:200], training_set[1][:200].astype("float32"))

        training_config = _build_airflow_workflow(
            estimator=fm, instance_type=cpu_instance_type, inputs=records</code></pre>