<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        num_samples = self._network.num_noise_samples
        num_batch_samples = num_time_steps * num_samples
        num_classes = numpy.int64(self._network.vocabulary.num_classes())
        <a id="change">random = self._network.random</a>

        <a id="change">if self._network.noise_probs is None:
            &#47&#47 The upper bound is exclusive, so this always creates samples that
            &#47&#47 are &lt; num_classes.
            sample = random.uniform((num_batch_samples,)) * num_classes
            sample = sample.astype(&quotint64&quot)
        else:
            class_probs = self._network.noise_probs[None, :]
            &#47&#47 We could repeat the distribution for each time step, and sample k
            &#47&#47 noise words per time step. Since k &lt; number of outputs, we would
            &#47&#47 never have a problem with sampling without replacement.
            &#47&#47 Unfortunately that is very inefficient.
            sample = multinomial(random, class_probs, num_batch_samples)
            sample.reshape([num_time_steps, num_samples])
            &#47&#47 For some reason (maybe a rounding error) it may happen that the
            &#47&#47 sample contains a very high or negative value.
            sample = tensor.maximum(sample, 0)
            sample = tensor.minimum(sample, num_classes - 1)

       </a> sample = sample.reshape([num_time_steps, num_samples])
        return sample, self._get_target_seq_preact(layer_input, sample)

    def _get_shared_sample_tensors(self, layer_input):</code></pre><h3>After Change</h3><pre><code class='java'>
        num_samples = self._network.num_noise_samples
        num_batch_samples = num_time_steps * num_samples
        num_classes = numpy.int64(self._network.vocabulary.num_classes())
        <a id="change">noise_sampler = self._network.noise_sampler</a>

        &#47&#47 Sampling k noise words per time step is inefficient with multinomial.
        <a id="change">sample = noise_sampler.sample(1, num_batch_samples)</a>
        sample = sample.reshape([num_time_steps, num_samples])
        return sample, self._get_target_seq_preact(layer_input, sample)

    def _get_shared_sample_tensors(self, layer_input):</code></pre>