<html><h3>8d3f66f01a4decd1b240a8e6fa2af4abfd7d25d1,art/attacks/evasion/carlini.py,CarliniL2Method,__init__,#CarliniL2Method#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#,71
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        :param batch_size: Size of the batch on which adversarial samples are generated.
        
        super(CarliniL2Method, self).__init__(classifier)
        <a id="change">if not isinstance(classifier, ClassifierGradients):
            raise ClassifierError(self.__class__, [ClassifierGradients], classifier)

       </a> <a id="change">kwargs = {
            "confidence": confidence,
            "targeted": targeted,
            "learning_rate": learning_rate,
            "binary_search_steps": binary_search_steps,
            "max_iter": max_iter,
            "initial_const": initial_const,
            "max_halving": max_halving,
            "max_doubling": max_doubling,
            "batch_size": batch_size,
        }</a>
        <a id="change">assert self.set_params(**kwargs)</a>

        &#47&#47 There are internal hyperparameters:
        &#47&#47 Abort binary search for c if it exceeds this threshold (suggested in Carlini and Wagner (2016)):
        self._c_upper_bound = 10e10</code></pre><h3>After Change</h3><pre><code class='java'>
    ]

    def __init__(
        <a id="change">self</a>,
        classifier: ClassifierGradients,
        confidence: float = 0.0,
        targeted: bool = False,
        learning_rate: float = 0.01,
        binary_search_steps: int = 10,
        max_iter: int = 10,
        initial_const: float = 0.01,
        max_halving: int = 5,
        max_doubling: int = 5,
        batch_size: int = 1,
    ) -&gt; None:
        
        Create a Carlini L_2 attack instance.

        :param classifier: A trained classifier.
        :param confidence: Confidence of adversarial examples: a higher value produces examples that are farther away,
               from the original input, but classified with higher confidence as the target class.
        :param targeted: Should the attack target one specific class.
        :param learning_rate: The initial learning rate for the attack algorithm. Smaller values produce better results
               but are slower to converge.
        :param binary_search_steps: Number of times to adjust constant with binary search (positive value). If
                                    `binary_search_steps` is large, then the algorithm is not very sensitive to the
                                    value of `initial_const`. Note that the values gamma=0.999999 and c_upper=10e10 are
                                    hardcoded with the same values used by the authors of the method.
        :param max_iter: The maximum number of iterations.
        :param initial_const: The initial trade-off constant `c` to use to tune the relative importance of distance and
                confidence. If `binary_search_steps` is large, the initial constant is not important, as discussed in
                Carlini and Wagner (2016).
        :param max_halving: Maximum number of halving steps in the line search optimization.
        :param max_doubling: Maximum number of doubling steps in the line search optimization.
        :param batch_size: Size of the batch on which adversarial samples are generated.
        
        super(CarliniL2Method, self).__init__(classifier)

        <a id="change">self.confidence = confidence</a>
        <a id="change">self.targeted = targeted</a>
        <a id="change">self.learning_rate = learning_rate</a>
        <a id="change">self.binary_search_steps = binary_search_steps</a>
        <a id="change">self.max_iter = max_iter</a>
        <a id="change">self.initial_const = initial_const</a>
        <a id="change">self.max_halving = max_halving</a>
        self.max_doubling = max_doubling
        <a id="change">self.batch_size = batch_size</a>
        <a id="change">self._check_params()</a>

        &#47&#47 There are internal hyperparameters:
        &#47&#47 Abort binary search for c if it exceeds this threshold (suggested in Carlini and Wagner (2016)):
        self._c_upper_bound = 10e10</code></pre><img src="198465084.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 27</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/IBM/adversarial-robustness-toolbox/commit/8d3f66f01a4decd1b240a8e6fa2af4abfd7d25d1#diff-059f7d0f0ab5f748bb8fa980953c57e78d8a9ac20d59f33e559f32044d212831L72' target='_blank'>Link</a></div><div id='project'> Project Name: IBM/adversarial-robustness-toolbox</div><div id='commit'> Commit Name: 8d3f66f01a4decd1b240a8e6fa2af4abfd7d25d1</div><div id='time'> Time: 2020-05-10</div><div id='author'> Author: irinutza.n@gmail.com</div><div id='file'> File Name: art/attacks/evasion/carlini.py</div><div id='class'> Class Name: CarliniL2Method</div><div id='method'> Method Name: __init__</div><BR><BR><div id='link'><a href='https://github.com/IBM/adversarial-robustness-toolbox/commit/8d3f66f01a4decd1b240a8e6fa2af4abfd7d25d1#diff-059f7d0f0ab5f748bb8fa980953c57e78d8a9ac20d59f33e559f32044d212831L620' target='_blank'>Link</a></div><div id='project'> Project Name: IBM/adversarial-robustness-toolbox</div><div id='commit'> Commit Name: 8d3f66f01a4decd1b240a8e6fa2af4abfd7d25d1</div><div id='time'> Time: 2020-05-10</div><div id='author'> Author: irinutza.n@gmail.com</div><div id='file'> File Name: art/attacks/evasion/carlini.py</div><div id='class'> Class Name: CarliniLInfMethod</div><div id='method'> Method Name: __init__</div><BR><BR><div id='link'><a href='https://github.com/IBM/adversarial-robustness-toolbox/commit/8d3f66f01a4decd1b240a8e6fa2af4abfd7d25d1#diff-c9dadddf8b8e45d4e714f406f4754477c509c144e6a21c52e17657082330f7acL64' target='_blank'>Link</a></div><div id='project'> Project Name: IBM/adversarial-robustness-toolbox</div><div id='commit'> Commit Name: 8d3f66f01a4decd1b240a8e6fa2af4abfd7d25d1</div><div id='time'> Time: 2020-05-10</div><div id='author'> Author: irinutza.n@gmail.com</div><div id='file'> File Name: art/attacks/evasion/elastic_net.py</div><div id='class'> Class Name: ElasticNet</div><div id='method'> Method Name: __init__</div><BR>