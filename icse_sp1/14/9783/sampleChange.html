<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            &#47&#47 case 2 sample_max =0 temperature xx
            elif sample_n_method == &quotsample&quot:
                tmp_eval_kwargs.update({&quotsample_max&quot: 0, &quotbeam_size&quot: 1}) &#47&#47 randomness from sample
                <a id="change">with torch.no_grad():
                    _seq, _sampleLogprobs = model(fc_feats, att_feats, att_masks, opt=tmp_eval_kwargs, mode=&quotsample&quot)
               </a> _sents = utils.decode_sequence(loader.get_vocab(), _seq)
                for k, sent in enumerate(_sents):
                    entry = {&quotimage_id&quot: data[&quotinfos&quot][k // sample_n][&quotid&quot], &quotcaption&quot: sent}
                    n_predictions.append(entry)</code></pre><h3>After Change</h3><pre><code class='java'>
                 sample_n_method == &quotgumbel&quot or \
                 sample_n_method.startswith(&quottop&quot):
                if sample_n_method == &quotsample&quot:
                    <a id="change">tmp_sample_max = 0</a>
                elif <a id="change">sample_n_method</a> == &quotgumbel&quot:
                    <a id="change">tmp_sample_max = 2</a>
                elif <a id="change">sample_n_method.startswith(&quottop&quot)</a>:
                    <a id="change">tmp_sample_max = -int(sample_n_method[3:])</a>
                tmp_eval_kwargs.update({&quotsample_max&quot: tmp_sample_max, &quotbeam_size&quot: 1}) &#47&#47 randomness from sample
                with torch.no_grad():
                    _seq, _sampleLogprobs = model(fc_feats, att_feats, att_masks, opt=tmp_eval_kwargs, mode=&quotsample&quot)
                _sents = utils.decode_sequence(loader.get_vocab(), _seq)</code></pre>