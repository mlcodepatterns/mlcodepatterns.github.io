<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    gt_win, pred_win = None, None
    end = time.time()
    bar = Bar(&quotProcessing&quot, max=len(val_loader))
    <a id="change">for i, (inputs, target, meta) in enumerate(val_loader):
        &#47&#47 measure data loading time
        data_time.update(time.time() - end)

        target = target.cuda(async=True)

        input_var = torch.autograd.Variable(inputs.cuda(), volatile=True)
        target_var = torch.autograd.Variable(target, volatile=True)

        &#47&#47 compute output
        output = model(input_var)
        score_map = output[-1].data.cpu()
        if flip:
            flip_input_var = torch.autograd.Variable(
                    torch.from_numpy(fliplr(inputs.clone().numpy())).float().cuda(), 
                    volatile=True
                )
            flip_output_var = model(flip_input_var)
            flip_output = flip_back(flip_output_var[-1].data.cpu())
            score_map += flip_output



        loss = 0
        for o in output:
            loss += criterion(o, target_var)
        acc = accuracy(score_map, target.cpu(), idx)

        &#47&#47 generate predictions
        preds = final_preds(score_map, meta[&quotcenter&quot], meta[&quotscale&quot], [64, 64])
        for n in range(score_map.size(0)):
            predictions[meta[&quotindex&quot][n], :, :] = preds[n, :, :]


        if debug:
            gt_batch_img = batch_with_heatmap(inputs, target)
            pred_batch_img = batch_with_heatmap(inputs, score_map)
            if not gt_win or not pred_win:
                plt.subplot(121)
                gt_win = plt.imshow(gt_batch_img)
                plt.subplot(122)
                pred_win = plt.imshow(pred_batch_img)
            else:
                gt_win.set_data(gt_batch_img)
                pred_win.set_data(pred_batch_img)
            plt.pause(.5)
            plt.draw()

        &#47&#47 measure accuracy and record loss
        losses.update(loss.data[0], inputs.size(0))
        acces.update(acc[0], inputs.size(0))

        &#47&#47 measure elapsed time
        batch_time.update(time.time() - end)
        end = time.time()

        &#47&#47 plot progress
        bar.suffix  = &quot({batch}/{size}) Data: {data:.6f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | Acc: {acc: .4f}&quot.format(
                    batch=i + 1,
                    size=len(val_loader),
                    data=data_time.val,
                    bt=batch_time.avg,
                    total=bar.elapsed_td,
                    eta=bar.eta_td,
                    loss=losses.avg,
                    acc=acces.avg
                    )
        bar.next()

   </a> bar.finish()
    return losses.avg, acces.avg, predictions

if __name__ == &quot__main__&quot:</code></pre><h3>After Change</h3><pre><code class='java'>
    end = time.time()
    bar = Bar(&quotProcessing&quot, max=len(val_loader))

    <a id="change">with torch.no_grad():
        for i, (input, target, meta) in enumerate(val_loader):
            &#47&#47 measure data loading time
            data_time.update(time.time() - end)

            target = target.cuda(async=True)

            input = input.to(device, non_blocking=True)
            target = target.to(device, non_blocking=True)

            &#47&#47 compute output
            output = model(input)
            score_map = output[-1].data.cpu()
            if flip:
                flip_input_var = torch.from_numpy(fliplr(input.clone().numpy())).float().to(device)
                flip_output_var = model(flip_input_var)
                flip_output = flip_back(flip_output_var[-1].data.cpu())
                score_map += flip_output



            loss = 0
            for o in output:
                loss += criterion(o, target)
            acc = accuracy(score_map, target.cpu(), idx)

            &#47&#47 generate predictions
            preds = final_preds(score_map, meta[&quotcenter&quot], meta[&quotscale&quot], [64, 64])
            for n in range(score_map.size(0)):
                predictions[meta[&quotindex&quot][n], :, :] = preds[n, :, :]


            if debug:
                gt_batch_img = batch_with_heatmap(input, target)
                pred_batch_img = batch_with_heatmap(input, score_map)
                if not gt_win or not pred_win:
                    plt.subplot(121)
                    gt_win = plt.imshow(gt_batch_img)
                    plt.subplot(122)
                    pred_win = plt.imshow(pred_batch_img)
                else:
                    gt_win.set_data(gt_batch_img)
                    pred_win.set_data(pred_batch_img)
                plt.pause(.5)
                plt.draw()

            &#47&#47 measure accuracy and record loss
            losses.update(loss.item(), input.size(0))
            acces.update(acc[0], input.size(0))

            &#47&#47 measure elapsed time
            batch_time.update(time.time() - end)
            end = time.time()

            &#47&#47 plot progress
            bar.suffix  = &quot({batch}/{size}) Data: {data:.6f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | Acc: {acc: .4f}&quot.format(
                        batch=i + 1,
                        size=len(val_loader),
                        data=data_time.val,
                        bt=batch_time.avg,
                        total=bar.elapsed_td,
                        eta=bar.eta_td,
                        loss=losses.avg,
                        acc=acces.avg
                        )
            bar.next()

   </a> bar.finish()
    return losses.avg, acces.avg, predictions

if __name__ == &quot__main__&quot:</code></pre>