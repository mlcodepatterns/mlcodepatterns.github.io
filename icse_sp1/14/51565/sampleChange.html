<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        if len(attacks_requesting_batched_predictions) &gt; 0:
            logging.debug(&quotcalling native forward with {}&quot.format(len(attacks_requesting_batched_predictions)))  &#47&#47 noqa: E501
            <a id="change">batched_predictions_args = list(map(np.stack,
                                                zip(*batched_predictions_args)))</a>
            batched_predictions_args = <a id="change">list(batched_predictions_args)</a>
            &#47&#47 get original shape (&#47&#47attacks, batch size)
            batch_shape = batched_predictions_args[0].shape
            &#47&#47 merge individual batches into one super-batch
            <a id="change">batched_predictions_args[0] = batched_predictions_args[0].reshape(
                -1, *batch_shape[2:])</a>

            batched_predictions = model.forward(*batched_predictions_args)
            &#47&#47 split super-batch back into individual batches
            batched_predictions = batched_predictions.reshape(</code></pre><h3>After Change</h3><pre><code class='java'>
            logging.debug(&quotcalling native forward with {}&quot.format(len(attacks_requesting_batched_predictions)))  &#47&#47 noqa: E501

            &#47&#47 we are only interested in the first argument
            inputs = [<a id="change">x[0]</a> <a id="change">for</a> x in batched_predictions_args]

            &#47&#47 merge individual batches into one larger super-batch
            <a id="change">batch_lengths = [len(x) for x in inputs]</a>
            <a id="change">batch_splits = np.cumsum(batch_lengths)</a>
            <a id="change">inputs = np.concatenate([x for x in inputs])</a>

            &#47&#47 split super-batch back into individual batches
            batched_predictions = model.forward(inputs)
            batched_predictions = np.split(batched_predictions, batch_splits,</code></pre>