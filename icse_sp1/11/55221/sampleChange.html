<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        spatial_rank = layer_util.infer_spatial_rank(input_tensor)
        look_up_operations(self.func, SUPPORTED_OP)
        if self.func == &quotCONSTANT&quot:
            <a id="change">kernel_shape = np.hstack((
                [self.kernel_size] * spatial_rank, 1, 1)).flatten()</a>
            np_kernel = layer_util.trivial_kernel(kernel_shape)
            kernel = tf.constant(np_kernel, dtype=tf.float32)
            output_tensor = [tf.expand_dims(x, -1)
                             for x in tf.unstack(input_tensor, axis=-1)]</code></pre><h3>After Change</h3><pre><code class='java'>
    def layer_op(self, input_tensor):
        spatial_rank = layer_util.infer_spatial_rank(input_tensor)
        look_up_operations(self.func, SUPPORTED_OP)
        <a id="change">kernel_size_all_dims = get_list_parameter(self.kernel_size, spatial_rank)</a>
        stride_all_dims = get_list_parameter(self.stride, spatial_rank)
        if self.func == &quotCONVOLUTION&quot:
            <a id="change">full_kernel_size = kernel_size_all_dims + [1, 1]</a>
            np_kernel = layer_util.trivial_kernel(full_kernel_size)
            kernel = tf.constant(np_kernel, dtype=tf.float32)
            output_tensor = [tf.expand_dims(x, -1)
                             for x in tf.unstack(input_tensor, axis=-1)]</code></pre>