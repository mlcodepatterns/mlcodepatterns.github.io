<html><h3>3c874575bf40e8b1fa2280371131a8f29ebb3e98,src/gluonnlp/models/roberta.py,RobertaModel,hybrid_forward,#RobertaModel#Any#Any#Any#,227
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        embedding = self.get_initial_embedding(F, tokens)

        contextual_embeddings, additional_outputs = self.encoder(embedding, valid_length)
        <a id="change">outputs.append(contextual_embeddings)</a>
        if self._output_all_encodings:
            contextual_embeddings = contextual_embeddings[-1]

        if self.use_pooler:</code></pre><h3>After Change</h3><pre><code class='java'>

    def hybrid_forward(self, F, tokens, valid_length):
        embedding = self.get_initial_embedding(F, tokens)
        <a id="change">if self._layout != self._compute_layout:
            contextual_embeddings, additional_outputs = self.encoder(F.np.swapaxes(embedding, 0, 1),
                                                                     valid_length)
            contextual_embeddings = F.np.swapaxes(contextual_embeddings, 0, 1)
        else:
            contextual_embeddings, additional_outputs = self.encoder(embedding, valid_length)
       </a> if self.use_pooler:
            if isinstance(contextual_embeddings, list):
                pooled_out = self.apply_pooling(contextual_embeddings[-1])
            else:
                pooled_out = self.apply_pooling(contextual_embeddings)
            return contextual_embeddings, pooled_out
        else:
            <a id="change">return contextual_embeddings</a>

    def get_initial_embedding(self, F, inputs):
        Get the initial token embeddings that considers the token type and positional embeddings
</code></pre><img src="97305036.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/dmlc/gluon-nlp/commit/3c874575bf40e8b1fa2280371131a8f29ebb3e98#diff-f785f4b12e26803ddbf1fcadc9a9560c86ea5ed4b7a81bf267a46faa9545f5a4L227' target='_blank'>Link</a></div><div id='project'> Project Name: dmlc/gluon-nlp</div><div id='commit'> Commit Name: 3c874575bf40e8b1fa2280371131a8f29ebb3e98</div><div id='time'> Time: 2020-07-28</div><div id='author'> Author: xshiab@connect.ust.hk</div><div id='file'> File Name: src/gluonnlp/models/roberta.py</div><div id='class'> Class Name: RobertaModel</div><div id='method'> Method Name: hybrid_forward</div><BR><BR><div id='link'><a href='https://github.com/dmlc/gluon-nlp/commit/3c874575bf40e8b1fa2280371131a8f29ebb3e98#diff-734a5a4c8a46c2229a31b7a08a43bbb63bbeb3005dcf7157141440c6db83394aL513' target='_blank'>Link</a></div><div id='project'> Project Name: dmlc/gluon-nlp</div><div id='commit'> Commit Name: 3c874575bf40e8b1fa2280371131a8f29ebb3e98</div><div id='time'> Time: 2020-07-28</div><div id='author'> Author: xshiab@connect.ust.hk</div><div id='file'> File Name: src/gluonnlp/models/mobilebert.py</div><div id='class'> Class Name: MobileBertModel</div><div id='method'> Method Name: hybrid_forward</div><BR><BR><div id='link'><a href='https://github.com/kengz/SLM-Lab/commit/8c17debc9dc6552da8c317c0c852b55f03c80c61#diff-3128082003b6c4b20739dedf2640ff4463dfbf882e5ce9fda2fb4a7abf503a90L168' target='_blank'>Link</a></div><div id='project'> Project Name: kengz/SLM-Lab</div><div id='commit'> Commit Name: 8c17debc9dc6552da8c317c0c852b55f03c80c61</div><div id='time'> Time: 2017-12-24</div><div id='author'> Author: kengzwl@gmail.com</div><div id='file'> File Name: slm_lab/experiment/monitor.py</div><div id='class'> Class Name: DataSpace</div><div id='method'> Method Name: add</div><BR>