<html><h3>5a68c464caac68e4623f9a7b173bcf24aa719a5c,tensorflow_datasets/text/trivia_qa.py,TriviaQA,_generate_examples,#TriviaQA#Any#Any#Any#,230
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    for filepath in files:
      logging.info("generating examples from = %s", filepath)
      with tf.io.gfile.GFile(filepath) as f:
        <a id="change">triviaqa = json.load(f)</a>
        <a id="change">for article in triviaqa["Data"]:
          if "Answer" in article:
            answer = article["Answer"]
            answer_dict = {
                "aliases":
                    _strip(answer["Aliases"]),
                "normalized_aliases":
                    _strip(answer["NormalizedAliases"]),
                "matched_wiki_entity_name":
                    answer.get("MatchedWikiEntryName", "").strip(),
                "normalized_matched_wiki_entity_name":
                    answer.get("NormalizedMatchedWikiEntryName", "").strip(),
                "normalized_value":
                    answer["NormalizedValue"].strip(),
                "type":
                    answer["Type"].strip(),
                "value":
                    answer["Value"].strip(),
            }
          else:
            answer_dict = {
                "aliases":
                    [],
                "normalized_aliases":
                    [],
                "matched_wiki_entity_name":
                    "&lt;unk&gt;",
                "normalized_matched_wiki_entity_name":
                    "&lt;unk&gt;",
                "normalized_value":
                    "&lt;unk&gt;",
                "type":
                    "",
                "value":
                    "&lt;unk&gt;",
            }

          if self.builder_config.exclude_context:
            article["SearchResults"] = []
            article["EntityPages"] = []

          def _add_context(collection, context_field, file_dir):
            Adds context from file, or skips if file does not exist.
            new_items = []
            for item in collection:
              if "Filename" not in item:
                logging.info("Missing context &quotFilename&quot, skipping.")
                continue

              new_item = item.copy()
              fname = item["Filename"]
              try:
                with tf.io.gfile.GFile(os.path.join(file_dir, fname)) as f:
                  new_item[context_field] = f.read()
              except (IOError, tf.errors.NotFoundError):
                logging.info("File does not exist, skipping: %s", fname)
                continue
              new_items.append(new_item)
            return new_items

          def _strip_if_str(v):
            return v.strip() if isinstance(v, six.string_types) else v
          def _transpose_and_strip_dicts(dicts, field_names):
            return {
                tfds.core.naming.camelcase_to_snakecase(k):
                    [_strip_if_str(d[k]) for d in dicts]
                for k in field_names
            }

          search_results = _transpose_and_strip_dicts(
              _add_context(
                  article.get("SearchResults", []), "SearchContext", web_dir),
              ["Description", "Filename", "Rank", "Title", "Url",
               "SearchContext"])

          entity_pages = _transpose_and_strip_dicts(
              _add_context(
                  article.get("EntityPages", []), "WikiContext", wiki_dir),
              ["DocSource", "Filename", "Title", "WikiContext"])

          question = article["Question"].strip()
          question_id = article["QuestionId"]
          question_source = article["QuestionSource"].strip()

          yield "%s_%s" % (os.path.basename(filepath), question_id), {
              "entity_pages": entity_pages,
              "search_results": search_results,
              "question": question,
              "question_id": question_id,
              "question_source": question_source,
              "answer": answer_dict,
          }</a>
</code></pre><h3>After Change</h3><pre><code class='java'>
        for line in f:
          if line == "        {\n":
            current_record = line
          elif <a id="change">line.startswith("        }")</a>:  &#47&#47 Handles final record as well.
            <a id="change">article = json.loads(current_record + "}")</a>
            current_record = ""
            example = parse_example(article)
            yield "%s_%s" % (fname, example["question_id"]), example
          else:</code></pre><img src="215240550.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/tensorflow/datasets/commit/5a68c464caac68e4623f9a7b173bcf24aa719a5c#diff-22ce9f90357c0799e340f5c022d8805d4f0fa08d68e07d371d11a1e9475192d2L238' target='_blank'>Link</a></div><div id='project'> Project Name: tensorflow/datasets</div><div id='commit'> Commit Name: 5a68c464caac68e4623f9a7b173bcf24aa719a5c</div><div id='time'> Time: 2019-12-06</div><div id='author'> Author: adarob@google.com</div><div id='file'> File Name: tensorflow_datasets/text/trivia_qa.py</div><div id='class'> Class Name: TriviaQA</div><div id='method'> Method Name: _generate_examples</div><BR><BR><div id='link'><a href='https://github.com/mynlp/ccg2lambda/commit/66a06524eba0b22d14204baeb2ca6d4c9db7d1d0#diff-37fa1888a83fa218c233a05619fe4c22640ec718b32ccc03f7bf56c2d25ffe41L258' target='_blank'>Link</a></div><div id='project'> Project Name: mynlp/ccg2lambda</div><div id='commit'> Commit Name: 66a06524eba0b22d14204baeb2ca6d4c9db7d1d0</div><div id='time'> Time: 2017-05-12</div><div id='author'> Author: pascual@nii.ac.jp</div><div id='file'> File Name: scripts/semantic_types.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: convert_coq_to_nltk_type</div><BR><BR><div id='link'><a href='https://github.com/SeldonIO/seldon-core/commit/384d9c3cf0e79c592f43c8fd23623f95fbee91ac#diff-9f016d3777d731463c2969cd7d16bb014363bee6bf98af9fe7ca66c4392949adL111' target='_blank'>Link</a></div><div id='project'> Project Name: SeldonIO/seldon-core</div><div id='commit'> Commit Name: 384d9c3cf0e79c592f43c8fd23623f95fbee91ac</div><div id='time'> Time: 2018-11-26</div><div id='author'> Author: cc@seldon.io</div><div id='file'> File Name: release.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: update_core_jsonnet</div><BR><BR><div id='link'><a href='https://github.com/studioml/studio/commit/f31b7ad689b1435e76744af4ff443607643a37fd#diff-6c550278fcd895eb2e50ac72e5134d24cc25d853c6d5935d844666778d52cbcaL128' target='_blank'>Link</a></div><div id='project'> Project Name: studioml/studio</div><div id='commit'> Commit Name: f31b7ad689b1435e76744af4ff443607643a37fd</div><div id='time'> Time: 2017-12-28</div><div id='author'> Author: peter.zhokhov@sentient.ai</div><div id='file'> File Name: studio/experiment.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: create_experiment</div><BR>