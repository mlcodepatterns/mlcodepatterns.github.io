<html><h3>61228f3243eaee39cba31a9abd2afc6ead9612a8,implementations/bicyclegan/bicyclegan.py,,,#,136
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

    &#47&#47 Update learning rates
    lr_scheduler_G.step()
    <a id="change">lr_scheduler_D_VAE.step()</a>
    lr_scheduler_D_LR.step()

    if opt.checkpoint_interval != -1 and epoch % opt.checkpoint_interval == 0:
        &#47&#47 Save model checkpoints</code></pre><h3>After Change</h3><pre><code class='java'>
    z = sampled_z * std + mu
    return z

<a id="change">start_time = time.time()</a>
for epoch in range(opt.epoch, opt.n_epochs):
    for i, batch in enumerate(dataloader):

        &#47&#47 Set model input
        real_A = Variable(batch[&quotA&quot].type(Tensor))
        real_B = Variable(batch[&quotB&quot].type(Tensor))

        &#47&#47 -----------------------------
        &#47&#47  Train Generator and Encoder
        &#47&#47 -----------------------------

        optimizer_E.zero_grad()
        optimizer_G.zero_grad()

        &#47&#47 Produce output using encoding of B (cVAE-GAN)
        mu, logvar = encoder(real_B)
        encoded_z = reparameterization(mu, logvar)
        fake_B = generator(real_A, encoded_z)

        &#47&#47 Produce output using sampled z (cLR-GAN)
        sampled_z = Variable(Tensor(np.random.normal(0, 1, (mu.size(0), opt.latent_dim))))
        _fake_B = generator(real_A, sampled_z)

        &#47&#47 Pixelwise loss of translated image by VAE
        loss_pixel = pixelwise_loss(fake_B, real_B)

        &#47&#47 Kullback-Leibler divergence of encoded B
        loss_kl = torch.sum(0.5 * (mu**2 + torch.exp(logvar) - logvar - 1))

        &#47&#47 Discriminators evaluate generated samples
        VAE_validity1, VAE_validity2 = D_VAE(fake_B)
        LR_validity1, LR_validity2 = D_LR(_fake_B)

        &#47&#47 Adversarial losses
        loss_VAE_GAN =  (adversarial_loss(VAE_validity1, valid1) + \
                        adversarial_loss(VAE_validity2, valid2)) / 2
        loss_LR_GAN =   (adversarial_loss(LR_validity1, valid1) + \
                        adversarial_loss(LR_validity2, valid2)) / 2

        &#47&#47 Shared losses between encoder and generator
        loss_GE =   loss_VAE_GAN + \
                    loss_LR_GAN + \
                    lambda_pixel * loss_pixel + \
                    lambda_kl * loss_kl

        loss_GE.backward()
        optimizer_E.step()

        &#47&#47 Latent L1 loss
        _mu, _ = encoder(generator(real_A, sampled_z))
        loss_latent = lambda_latent * latent_loss(_mu, sampled_z)

        loss_latent.backward()
        optimizer_G.step()

        &#47&#47 --------------------------------
        &#47&#47  Train Discriminator (cVAE-GAN)
        &#47&#47 --------------------------------

        optimizer_D_VAE.zero_grad()

        &#47&#47 Real loss
        pred_real1, pred_real2 = D_VAE(real_B)
        loss_real = (adversarial_loss(pred_real1, valid1) + \
                    adversarial_loss(pred_real2, valid2)) / 2

        &#47&#47 Fake loss (D_LR evaluates samples produced by encoded B)
        pred_gen1, pred_gen2 = D_VAE(fake_B.detach())
        loss_fake = (adversarial_loss(pred_gen1, fake1) + \
                    adversarial_loss(pred_gen2, fake2)) / 2

        &#47&#47 Total loss
        loss_D_VAE = (loss_real + loss_fake) / 2

        loss_D_VAE.backward()
        optimizer_D_VAE.step()

        &#47&#47 -------------------------------
        &#47&#47  Train Discriminator (cLR-GAN)
        &#47&#47 -------------------------------

        optimizer_D_LR.zero_grad()

        &#47&#47 Real loss
        pred_real1, pred_real2 = D_LR(real_B)
        loss_real = (adversarial_loss(pred_real1, valid1) + \
                    adversarial_loss(pred_real2, valid2)) / 2

        &#47&#47 Fake loss (D_LR evaluates samples produced by sampled z)
        pred_gen1, pred_gen2 = D_LR(_fake_B.detach())
        loss_fake = (adversarial_loss(pred_gen1, fake1) + \
                    adversarial_loss(pred_gen2, fake2)) / 2

        &#47&#47 Total loss
        loss_D_LR = 0.5 * (loss_real + loss_fake)

        loss_D_LR.backward()
        optimizer_D_LR.step()

        &#47&#47 --------------
        &#47&#47  Log Progress
        &#47&#47 --------------

        &#47&#47 Determine approximate time left
        batches_done = epoch * len(dataloader) + i
        batches_left = opt.n_epochs * len(dataloader) - batches_done
        time_left = datetime.timedelta(seconds=batches_left * (time.time() - start_time)/ (batches_done + 1))

        &#47&#47 Print log
        <a id="change">sys.stdout.write("\r[Epoch %d/%d] [Batch %d/%d] [D VAE_loss: %f, LR_loss: %f] [G loss: %f, pixel: %f, latent: %f] ETA: %s" %
                                                        (epoch, opt.n_epochs,
                                                        i, len(dataloader),
                                                        loss_D_VAE.item(), loss_D_LR.item(),
                                                        loss_GE.item(), loss_pixel.item(),
                                                        loss_latent.item(), time_left))</a>

        if batches_done % opt.sample_interval == 0:
            sample_images(batches_done)
</code></pre><img src="129655282.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/eriklindernoren/PyTorch-GAN/commit/61228f3243eaee39cba31a9abd2afc6ead9612a8#diff-d3e1c4411b6f580293411b1726cd987c27fcb1ea04379afb16679af9a663983bL134' target='_blank'>Link</a></div><div id='project'> Project Name: eriklindernoren/PyTorch-GAN</div><div id='commit'> Commit Name: 61228f3243eaee39cba31a9abd2afc6ead9612a8</div><div id='time'> Time: 2018-05-04</div><div id='author'> Author: eriklindernoren@gmail.com</div><div id='file'> File Name: implementations/bicyclegan/bicyclegan.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: </div><BR><BR><div id='link'><a href='https://github.com/HyperGAN/HyperGAN/commit/5a69007e1ab2f4c0b4a549c0a2a8cd9701fd8929#diff-2522377705f625ab2ece649e2395450ebeb46e59c06b23b10a3061e1fd684fe1L138' target='_blank'>Link</a></div><div id='project'> Project Name: HyperGAN/HyperGAN</div><div id='commit'> Commit Name: 5a69007e1ab2f4c0b4a549c0a2a8cd9701fd8929</div><div id='time'> Time: 2017-06-28</div><div id='author'> Author: mikkel@255bits.com</div><div id='file'> File Name: examples/colorizer.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: search</div><BR><BR><div id='link'><a href='https://github.com/deepchem/deepchem/commit/c7c06f56e918cabf565d4e4454daa344137d1f0f#diff-872bc0d3ee13b759216bff07fb60ec569d144a55c297c6c9239f65c4ca5b0d31L152' target='_blank'>Link</a></div><div id='project'> Project Name: deepchem/deepchem</div><div id='commit'> Commit Name: c7c06f56e918cabf565d4e4454daa344137d1f0f</div><div id='time'> Time: 2017-05-25</div><div id='author'> Author: Karl</div><div id='file'> File Name: contrib/rl/tictactoe.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: main</div><BR>