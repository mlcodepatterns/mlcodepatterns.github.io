<html><h3>8be52c9dc6198fbbd5a0b3e8e80571a505a21b1d,art/attacks/carlini.py,CarliniL2Method,generate,#CarliniL2Method#Any#,184
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        for j, (ex, target) in enumerate(zip(x_adv, y)):        
            logger.debug(&quotProcessing sample %i out of %i&quot % (j, x_adv.shape[0]))
            image = <a id="change">ex.copy().astype(NUMPY_DTYPE)</a>

            &#47&#47 The optimization is performed in tanh space to keep the
            &#47&#47 adversarial images bounded from clip_min and clip_max. 
            image_tanh = self._original_to_tanh(image, clip_min, clip_max)</code></pre><h3>After Change</h3><pre><code class='java'>
                        while loss &lt;= prev_loss and doubling &lt; self.max_doubling:  
                            prev_loss = loss
                            lr *= 2     
                            <a id="change">logger.debug(&quotApply gradient with learning rate %f (doubling=%i)&quot, lr, doubling)</a>
                            doubling += 1
                            new_adv_image_tanh = adv_image_tanh + lr * perturbation_tanh
                            new_adv_image = self._tanh_to_original(new_adv_image_tanh, clip_min, clip_max)
                            _, l2dist, loss = self._loss(image, new_adv_image, target, c)                            </code></pre><img src="161340237.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 2</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/IBM/adversarial-robustness-toolbox/commit/8be52c9dc6198fbbd5a0b3e8e80571a505a21b1d#diff-c1ad1dccee8a742954884bfabae3e4b877eace13c3da1e2c11eec208489a5e5fL213' target='_blank'>Link</a></div><div id='project'> Project Name: IBM/adversarial-robustness-toolbox</div><div id='commit'> Commit Name: 8be52c9dc6198fbbd5a0b3e8e80571a505a21b1d</div><div id='time'> Time: 2018-10-31</div><div id='author'> Author: mathsinn@ie.ibm.com</div><div id='file'> File Name: art/attacks/carlini.py</div><div id='class'> Class Name: CarliniL2Method</div><div id='method'> Method Name: generate</div><BR><BR><div id='link'><a href='https://github.com/deeptools/HiCExplorer/commit/beb8b792a465a568561afc9d764049bbbc6c4a27#diff-94bcee89c8be34daa9d7499c1e91657bc28affbb8349948556cacdf22cd1de08L581' target='_blank'>Link</a></div><div id='project'> Project Name: deeptools/HiCExplorer</div><div id='commit'> Commit Name: beb8b792a465a568561afc9d764049bbbc6c4a27</div><div id='time'> Time: 2019-05-10</div><div id='author'> Author: wolffj@informatik.uni-freiburg.de</div><div id='file'> File Name: hicexplorer/hicCorrectMatrix.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: main</div><BR><BR><div id='link'><a href='https://github.com/sentinel-hub/eo-learn/commit/9574ca11461a7674e724d78b507852022fb2c59f#diff-e22402ed02eeb825e688bc8fa71ae63cf9032f2f43c600cf48a6038f26eec7ffL100' target='_blank'>Link</a></div><div id='project'> Project Name: sentinel-hub/eo-learn</div><div id='commit'> Commit Name: 9574ca11461a7674e724d78b507852022fb2c59f</div><div id='time'> Time: 2019-11-06</div><div id='author'> Author: jovan.visnjic@sinergise.com</div><div id='file'> File Name: io/eolearn/io/processing_api.py</div><div id='class'> Class Name: SentinelHubProcessingInput</div><div id='method'> Method Name: execute</div><BR>