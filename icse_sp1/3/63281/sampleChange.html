<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        y = tf.placeholder("int32",[None], name=&quoty&quot)
        y_oe = tf.one_hot(y, num_classes, name=&quottargets&quot)

        w = tf.Variable(<a id="change">tf.zeros([num_features, num_classes])</a>)
        b = tf.Variable(tf.zeros([num_classes]))

        <a id="change">y_ = tf.nn.softmax(tf.matmul(x, w) + b, name=&quotpredictions&quot)</a>

        &#47&#47 Define a cost function
        &#47&#47tf.losses.add_loss(tf.losses.softmax_cross_entropy(y_oe, y_))
        loss = tf.losses.softmax_cross_entropy(y_oe, y_)</code></pre><h3>After Change</h3><pre><code class='java'>
        c = conv2d_block(x, 32, 3, conv=dict(kernel_initializer=tf.contrib.layers.xavier_initializer()), max_pooling=dict(strides=4))
        f = flatten(c)
        f = tf.layers.dense(f, num_classes)
        y_ = <a id="change">tf.identity(f, name=&quotpredictions&quot)</a>

        &#47&#47 Define a cost function
        &#47&#47tf.losses.add_loss(tf.losses.softmax_cross_entropy(y_oe, y_))
        loss = tf.losses.softmax_cross_entropy(y_oe, y_)</code></pre>