<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        outs = []
        for i in range(X.size(0)):
            outs.append(output[i, seq_lengths[i] - 1,:])
        <a id="change">output = torch.stack(outs, dim=0)</a>
        return self.output_layer(self.dropout_layer(output))
    
    def initalize_hidden_state(self, batch_size):
        return (</code></pre><h3>After Change</h3><pre><code class='java'>

        seq_lengths, perm_idx = seq_lengths.sort(0, descending=True)
        X = X[perm_idx, :]
        inv_perm_idx = <a id="change">torch.tensor([i for i, _ in sorted(enumerate(perm_idx), key=lambda idx: idx[1])], dtype=torch.long)</a>

        encoded_X = self.embedding(X)
        encoded_X = pack_padded_sequence(encoded_X, seq_lengths, batch_first=True)
        _, (ht, _) = self.lstm(encoded_X, hidden_state)</code></pre>