<html><h3>754238ee0338c960ed6f3640f3ef6dd3b3fb7108,policy.py,PolicyNetwork,set_up_network,#PolicyNetwork#,51
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 Add epsilon to avoid taking the log of 0 in following step
        output = tf.nn.softmax(tf.reshape(h_conv_final, [-1, go.N ** 2]) + b_conv_final) + tf.constant(EPSILON)

        <a id="change">log_likelihood_cost = -tf.reduce_mean(tf.reduce_sum(tf.multiply(tf.log(output), y), reduction_indices=[1]))</a>

        &#47&#47 The step size was initialized to 0.003 and was halved every 80 million training steps
        _learning_rate = tf.train.exponential_decay(3e-3, global_step,
                                           8e7, 0.5)</code></pre><h3>After Change</h3><pre><code class='java'>

        logits = tf.reshape(h_conv_final, [-1, go.N ** 2]) + b_conv_final

        log_likelihood_cost = <a id="change">tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, y))</a>

        train_step = tf.train.AdamOptimizer(1e-4).minimize(log_likelihood_cost, global_step=global_step)
        was_correct = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))
        accuracy = tf.reduce_mean(tf.cast(was_correct, tf.float32))</code></pre><img src="184949062.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/brilee/MuGo/commit/754238ee0338c960ed6f3640f3ef6dd3b3fb7108#diff-3d9f5c51ee85fb2da79a74349657cb62bb9abc5a02fd3d0238ffc76251310e24L53' target='_blank'>Link</a></div><div id='project'> Project Name: brilee/MuGo</div><div id='commit'> Commit Name: 754238ee0338c960ed6f3640f3ef6dd3b3fb7108</div><div id='time'> Time: 2017-06-23</div><div id='author'> Author: brian.kihoon.lee@gmail.com</div><div id='file'> File Name: policy.py</div><div id='class'> Class Name: PolicyNetwork</div><div id='method'> Method Name: set_up_network</div><BR><BR><div id='link'><a href='https://github.com/MorvanZhou/tutorials/commit/780dcd9fd372afa8524a6515eec6a4c90b1494c9#diff-1c91ba16911d0498f1259a5655c2ecbf955025d4db42b2913d9a7d24d318d2f2L22' target='_blank'>Link</a></div><div id='project'> Project Name: MorvanZhou/tutorials</div><div id='commit'> Commit Name: 780dcd9fd372afa8524a6515eec6a4c90b1494c9</div><div id='time'> Time: 2017-03-09</div><div id='author'> Author: morvanzhou@gmail.com</div><div id='file'> File Name: Reinforcement_learning_TUT/8_Actor_Critic_Advantage/AC_CartPole.py</div><div id='class'> Class Name: Actor</div><div id='method'> Method Name: __init__</div><BR><BR><div id='link'><a href='https://github.com/tensorlayer/tensorlayer/commit/fe9ebeefe7593432d1df9cb2c8b7ffdc8ec1a38b#diff-87ad50e157eb29abedfcc00e3683663fc1feb68653dc988ba2ab7a475858ec66L33' target='_blank'>Link</a></div><div id='project'> Project Name: tensorlayer/tensorlayer</div><div id='commit'> Commit Name: fe9ebeefe7593432d1df9cb2c8b7ffdc8ec1a38b</div><div id='time'> Time: 2016-08-23</div><div id='author'> Author: dhsig552@163.com</div><div id='file'> File Name: tensorlayer/cost.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: cross_entropy</div><BR>