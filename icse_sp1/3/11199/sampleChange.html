<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        &#47&#47 now verify that all of the columns needed are there (that is, the defaults have filled out appropriately)
        require_dataframe_has_columns(
            <a id="change">self.name(type_name)</a>, known, self.selected_columns
        )

        for column, transform in self.transform_columns.items():</code></pre><h3>After Change</h3><pre><code class='java'>

        existing = set(self.selected_columns).intersection(data.columns)

        <a id="change">ids = data.index</a>

        &#47&#47 split the dataframe based on the columns we know about
        missing_columns = []

        def select_column(old_name):
            if old_name in data.columns:
                column = data[old_name].to_numpy()
            elif old_name in self.column_defaults:
                column = np.full(len(ids), self.column_defaults[old_name])
            else:
                nonlocal missing_columns
                missing_columns.append(old_name)
                return None

            transform = self.transform_columns.get(old_name)
            if transform is not None:
                column = transform(column)

            return column

        columns = {
            new_name: select_column(old_name)
            for old_name, new_name in self.selected_columns.items()
        }
        if missing_columns:
            raise ValueError(
                f"{self.name(type_name)}: expected {comma_sep(self.selected_columns)} columns, found: {comma_sep(data.columns)}"
            )

        other = data.drop(columns=existing)

        if self.allow_features:
            &#47&#47 to_numpy returns an unspecified order but it&quots Fortran in practice. Row-level bulk
            &#47&#47 operations are more common (e.g. slicing out a couple of row, when sampling a few
            &#47&#47 nodes) than column-level ones so having rows be contiguous (C order) is much more
            &#47&#47 efficient.
            features = np.ascontiguousarray(other.to_numpy(dtype=self.dtype))
        elif len(other.columns) == 0:
            features = None
        else:
            raise ValueError(
                f"{self.name(type_name)}: expected zero feature columns, found {comma_sep(other.columns)}"
            )

        <a id="change">return ids, columns, features</a>

    def _ids_columns_and_starts_from_singles(self, singles):
        rows_so_far = 0
        type_starts = []</code></pre>