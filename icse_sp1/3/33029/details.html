<html><h3>756e0cd08ee8c661e2c6d0adee360c4792b97ca0,ml/rl/training/dqn_trainer.py,DQNTrainer,train,#DQNTrainer#Any#Any#,153
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            )
            next_q_values = self.get_next_action_q_values(next_states, next_actions)

        filtered_next_q_vals = <a id="change">next_q_values.reshape(-1, 1)</a> * not_done_mask

        if self.use_reward_burnin and self.minibatch &lt; self.reward_burnin:
            target_q_values = rewards</code></pre><h3>After Change</h3><pre><code class='java'>
            next_actions = training_samples.next_actions
            next_q_values = self.get_next_action_q_values(next_states, next_actions)

        filtered_next_q_vals = <a id="change">next_q_values * not_done_mask</a>

        if self.use_reward_burnin and self.minibatch &lt; self.reward_burnin:
            target_q_values = rewards
        else:
            target_q_values = rewards + (discount_tensor * filtered_next_q_vals)

        &#47&#47 Get Q-value of action taken
        all_q_values = self.q_network(states)
        self.all_action_scores = deepcopy(all_q_values.detach())
        q_values = torch.sum(all_q_values * actions, 1, keepdim=True)

        logger.info(q_values.shape)
        <a id="change">logger.info(target_q_values.shape)</a>
        logger.info(rewards.shape)
        logger.info(next_q_values.shape)
        loss = self.q_network_loss(q_values, target_q_values)
        self.loss = loss.detach()</code></pre><img src="162295101.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/facebookresearch/Horizon/commit/756e0cd08ee8c661e2c6d0adee360c4792b97ca0#diff-1e05823efcf5119bf771fc16f182df9cf4b8aac20b722908d7557012b69896d4L206' target='_blank'>Link</a></div><div id='project'> Project Name: facebookresearch/Horizon</div><div id='commit'> Commit Name: 756e0cd08ee8c661e2c6d0adee360c4792b97ca0</div><div id='time'> Time: 2018-09-18</div><div id='author'> Author: jjg@fb.com</div><div id='file'> File Name: ml/rl/training/dqn_trainer.py</div><div id='class'> Class Name: DQNTrainer</div><div id='method'> Method Name: train</div><BR><BR><div id='link'><a href='https://github.com/ilastik/ilastik/commit/fe073644f6a8f37e9ce57df903bf12b560690fc3#diff-4fb4d106c653e8c615ba468d15377eb7d4e5c7b70097360c122e589a3edbf9bfL255' target='_blank'>Link</a></div><div id='project'> Project Name: ilastik/ilastik</div><div id='commit'> Commit Name: fe073644f6a8f37e9ce57df903bf12b560690fc3</div><div id='time'> Time: 2012-09-14</div><div id='author'> Author: christoph.straehle@iwr.uni-heidelberg.de</div><div id='file'> File Name: lazyflow/operators/obsolete/classifierOperators.py</div><div id='class'> Class Name: OpPredictRandomForest</div><div id='method'> Method Name: execute</div><BR><BR><div id='link'><a href='https://github.com/markovmodel/PyEMMA/commit/d1de2f98ec8f851228e28bf28a0f800e90bd9bcf#diff-5cec83556682502d7a4aaaa5a6357d15a78bb59590dd57b48fd84309c5d1273dL1712' target='_blank'>Link</a></div><div id='project'> Project Name: markovmodel/PyEMMA</div><div id='commit'> Commit Name: d1de2f98ec8f851228e28bf28a0f800e90bd9bcf</div><div id='time'> Time: 2017-12-21</div><div id='author'> Author: m.scherer@fu-berlin.de</div><div id='file'> File Name: pyemma/msm/estimators/maximum_likelihood_msm.py</div><div id='class'> Class Name: AugmentedMarkovModel</div><div id='method'> Method Name: _estimate</div><BR>