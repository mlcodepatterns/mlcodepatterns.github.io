<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
      X = pad_features(self.batch_size, X)
    if not self._restored_model:
      self.restore()
    <a id="change">with self.eval_graph.graph.as_default():
      &#47&#47 run eval data through the model
      n_tasks = self.n_tasks
      with self._get_shared_session(train=False).as_default():
        feed_dict = self.construct_feed_dict(X)
        data = self._get_shared_session(train=False).run(
            self.eval_graph.output, feed_dict=feed_dict)
        batch_outputs = np.asarray(data[:n_tasks], dtype=float)
        &#47&#47 reshape to batch_size x n_tasks x ...
        if batch_outputs.ndim == 3:
          batch_outputs = batch_outputs.transpose((1, 0, 2))
        elif batch_outputs.ndim == 2:
          batch_outputs = batch_outputs.transpose((1, 0))
        else:
          raise ValueError(
              &quotUnrecognized rank combination for output: %s &quot %
              (batch_outputs.shape,))

      &#47&#47 Note that softmax is already applied in construct_grpah
      outputs = batch_outputs

   </a> return np.copy(outputs)

class TensorflowRegressor(TensorflowGraphModel):
  Regression model.</code></pre><h3>After Change</h3><pre><code class='java'>

      return loss 

  def fit(self, dataset, nb_epoch=10, max_check<a id="change">points</a>_to_keep=5, 
	  log_every_N_batches=50, **kwargs):
    Fit the model.
</code></pre>