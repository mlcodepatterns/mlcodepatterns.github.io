<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>


def load_test_model(opt, dummy_opt):
    <a id="change">checkpoint = torch.load(opt.model,
                            map_location=lambda storage, loc: storage)</a>
    fields = onmt.io.load_fields_from_vocab(
        checkpoint[&quotvocab&quot], data_type=opt.data_type)

    model_opt = checkpoint[&quotopt&quot]
    for arg in dummy_opt:
        if arg not in model_opt:
            model_opt.__dict__[arg] = dummy_opt[arg]

    model = make_base_model(model_opt, fields,
                            use_gpu(opt), checkpoint)
    model.eval()
    <a id="change">model.generator.eval()</a>
    return fields, model, model_opt


def make_base_model(model_opt, fields, gpu, checkpoint=None):</code></pre><h3>After Change</h3><pre><code class='java'>
    
    Args:
        model_opt: the option loaded from checkpoint.
        fields: `Field` objects for<a id="change"> the model.
        </a>gpu(bool): whether to use gpu.
        checkpoint: the model gnerated by train phase, or a resumed snapshot
                    model from a stopped training.
    Returns:</code></pre>