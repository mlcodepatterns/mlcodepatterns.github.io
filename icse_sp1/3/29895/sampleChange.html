<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        num_time_steps = layer_input.shape[0]
        num_sequences = layer_input.shape[1]
        num_samples = self.network.num_noise_samples
        num_classes = <a id="change">self.network.vocabulary.num_classes()</a>

        &#47&#47 Sample k noise words from unigram distribution. These are shared
        &#47&#47 across mini-batch. We need to repeat the distribution as many times as
        &#47&#47 we want samples, because multinomial() does not yet use the size</code></pre><h3>After Change</h3><pre><code class='java'>
        num_time_steps = layer_input.shape[0]
        num_sequences = layer_input.shape[1]
        num_samples = self.network.num_noise_samples
        num_classes = numpy.int64(<a id="change">self.network.vocabulary.num_classes()</a>)
        random = self.network.random

        &#47&#47 Sample k noise words from unigram distribution. These are shared
        &#47&#47 across mini-batch. We need to repeat the distribution as many times as
        &#47&#47 we want samples, because multinomial() does not yet use the size
        &#47&#47 argument.
        if self.network.noise_probs is None:
            &#47&#47 The upper bound is exclusive, so this always creates samples that
            &#47&#47 are &lt; num_classes
            sample = <a id="change">random.uniform((num_samples,)) * num_classes</a>
            sample = sample.astype(&quotint64&quot)
        else:
            class_probs = self.network.noise_probs[None, :]
            class_probs = tensor.tile(class_probs, [num_samples, 1])</code></pre>