<html><h3>3c874575bf40e8b1fa2280371131a8f29ebb3e98,src/gluonnlp/models/roberta.py,RobertaModel,hybrid_forward,#RobertaModel#Any#Any#Any#,227
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                                   bias_initializer=bias_initializer)

    def hybrid_forward(self, F, tokens, valid_length):
        <a id="change">outputs = []</a>
        embedding = self.get_initial_embedding(F, tokens)

        contextual_embeddings, additional_outputs = self.encoder(embedding, valid_length)
        outputs.append(contextual_embeddings)
        if self._output_all_encodings:
            contextual_embeddings = contextual_embeddings[-1]

        if self.use_pooler:
            pooled_out = self.apply_pooling(contextual_embeddings)
            outputs.append(pooled_out)

        return <a id="change">tuple(outputs) if len(outputs) &gt; 1 else outputs[0]</a>

    def get_initial_embedding(self, F, inputs):
        Get the initial token embeddings that considers the token type and positional embeddings
</code></pre><h3>After Change</h3><pre><code class='java'>

    def hybrid_forward(self, F, tokens, valid_length):
        embedding = self.get_initial_embedding(F, tokens)
        <a id="change">if self._layout != self._compute_layout:
            contextual_embeddings, additional_outputs = self.encoder(F.np.swapaxes(embedding, 0, 1),
                                                                     valid_length)
            contextual_embeddings = F.np.swapaxes(contextual_embeddings, 0, 1)
        else:
            contextual_embeddings, additional_outputs = self.encoder(embedding, valid_length)
       </a> if self.use_pooler:
            if isinstance(contextual_embeddings, list):
                pooled_out = self.apply_pooling(contextual_embeddings[-1])
            else:</code></pre><img src="17046036.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 8</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/dmlc/gluon-nlp/commit/3c874575bf40e8b1fa2280371131a8f29ebb3e98#diff-f785f4b12e26803ddbf1fcadc9a9560c86ea5ed4b7a81bf267a46faa9545f5a4L227' target='_blank'>Link</a></div><div id='project'> Project Name: dmlc/gluon-nlp</div><div id='commit'> Commit Name: 3c874575bf40e8b1fa2280371131a8f29ebb3e98</div><div id='time'> Time: 2020-07-28</div><div id='author'> Author: xshiab@connect.ust.hk</div><div id='file'> File Name: src/gluonnlp/models/roberta.py</div><div id='class'> Class Name: RobertaModel</div><div id='method'> Method Name: hybrid_forward</div><BR><BR><div id='link'><a href='https://github.com/dmlc/gluon-nlp/commit/3c874575bf40e8b1fa2280371131a8f29ebb3e98#diff-734a5a4c8a46c2229a31b7a08a43bbb63bbeb3005dcf7157141440c6db83394aL513' target='_blank'>Link</a></div><div id='project'> Project Name: dmlc/gluon-nlp</div><div id='commit'> Commit Name: 3c874575bf40e8b1fa2280371131a8f29ebb3e98</div><div id='time'> Time: 2020-07-28</div><div id='author'> Author: xshiab@connect.ust.hk</div><div id='file'> File Name: src/gluonnlp/models/mobilebert.py</div><div id='class'> Class Name: MobileBertModel</div><div id='method'> Method Name: hybrid_forward</div><BR><BR><div id='link'><a href='https://github.com/Picovoice/porcupine/commit/c2cf686f1f8e8a7f81b89010b60911648a0b77b1#diff-f2ced2d0239578936e75ecc4fe2fb18d0c31e47efe862772918483112dd2fc89L20' target='_blank'>Link</a></div><div id='project'> Project Name: Picovoice/porcupine</div><div id='commit'> Commit Name: c2cf686f1f8e8a7f81b89010b60911648a0b77b1</div><div id='time'> Time: 2021-02-26</div><div id='author'> Author: 42750891+mrrostam@users.noreply.github.com</div><div id='file'> File Name: binding/python/util.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: _pv_linux_machine</div><BR>