<html><h3>aab3902d4a7d55f5a86058854adc36b8a12c873f,catalyst/dl/callbacks/base.py,OptimizerCallback,on_batch_end,#OptimizerCallback#Any#,202
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            return

        self._accumulation_counter += 1
        <a id="change">if not self.fp16:
            model = state.model
            optimizer = state.get_key(
                key="optimizer", inner_key=self.optimizer_key
            )
            loss.backward()

            if (self._accumulation_counter + 1) % self.accumulation_steps == 0:
                self.grad_step(
                    optimizer=optimizer,
                    optimizer_wd=self._optimizer_wd,
                    grad_clip_fn=self.grad_clip_fn
                )
                model.zero_grad()
                self._accumulation_counter = 0
        else:
            model = state.model
            model.zero_grad()
            optimizer = state.get_key(
                key="optimizer", inner_key=self.optimizer_key
            )
            loss = state.get_key(key="loss", inner_key=self.optimizer_key)
            scaled_loss = self.fp16_grad_scale * loss.float()
            scaled_loss.backward()

            master_params = list(optimizer.param_groups[0]["params"])
            model_params = list(
                filter(lambda p: p.requires_grad, model.parameters())
            )
            copy_grads(source=model_params, target=master_params)
            for param in master_params:
                param.grad.data.mul_(1. / self.fp16_grad_scale)
            self.grad_step(
                optimizer=optimizer,
                optimizer_wd=self._optimizer_wd,
                grad_clip_fn=self.grad_clip_fn
            )
            copy_params(source=master_params, target=model_params)
            torch.cuda.synchronize()

   </a> def on_epoch_end(self, state):
        optimizer = state.get_key(
            key="optimizer", inner_key=self.optimizer_key
        )</code></pre><h3>After Change</h3><pre><code class='java'>

    def on_batch_end(self, state):
        loss = state.get_key(key="loss", inner_key=self.loss_key)
        <a id="change">if isinstance(loss, dict):
            loss = list(loss.values())
       </a> if isinstance(loss, list):
            loss = torch.mean(torch.stack(loss))

        if self.prefix is not None:</code></pre><img src="25862027.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/catalyst-team/catalyst/commit/aab3902d4a7d55f5a86058854adc36b8a12c873f#diff-94f0b9669517bfb949ba9c8c8bd57cbd96ea0f16b7482a95010f509c6c577190L197' target='_blank'>Link</a></div><div id='project'> Project Name: catalyst-team/catalyst</div><div id='commit'> Commit Name: aab3902d4a7d55f5a86058854adc36b8a12c873f</div><div id='time'> Time: 2019-05-20</div><div id='author'> Author: ekhvedchenya@gmail.com</div><div id='file'> File Name: catalyst/dl/callbacks/base.py</div><div id='class'> Class Name: OptimizerCallback</div><div id='method'> Method Name: on_batch_end</div><BR><BR><div id='link'><a href='https://github.com/microsoft/nni/commit/acc311dd3e15135ca35f69b0183e5b0f9f4beadf#diff-dc3832ad6aef6b645f9b35818b5475036fb79f9381ec735900eb550887cd52c0L28' target='_blank'>Link</a></div><div id='project'> Project Name: microsoft/nni</div><div id='commit'> Commit Name: acc311dd3e15135ca35f69b0183e5b0f9f4beadf</div><div id='time'> Time: 2019-04-27</div><div id='author'> Author: 15094695770@163.com</div><div id='file'> File Name: tools/nni_gpu_tool/gpu_metrics_collector.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: check_ready_to_run</div><BR><BR><div id='link'><a href='https://github.com/GPflow/GPflow/commit/30120a183c81cc5d18af0a00ae35e3ec9e06063a#diff-431ca1ccc666853d9c1175e521472633714cf7c550f8487b84d62504503d1216L81' target='_blank'>Link</a></div><div id='project'> Project Name: GPflow/GPflow</div><div id='commit'> Commit Name: 30120a183c81cc5d18af0a00ae35e3ec9e06063a</div><div id='time'> Time: 2017-11-25</div><div id='author'> Author: art.art.v@gmail.com</div><div id='file'> File Name: gpflow/misc.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: initialize_variables</div><BR>