<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
@dispatch(DiagonalGaussian, kernels.Product, InducingPoints, kernels.Product, InducingPoints)
@quadrature_fallback
def _expectation(p, kern1, feat1, kern2, feat2):
    <a id="change">if feat1 != feat2:
        raise NotImplementedError("Different features are not supported")

   </a> if kern1 != kern2:
        raise NotImplementedError("Calculating the expectation over two different Product kernels is not supported")

    kern = kern1
    <a id="change">feat = feat1</a>

    if not kern.on_separate_dimensions:
        raise NotImplementedError("Product currently needs to be defined on separate dimensions.")  &#47&#47 pragma: no cover
    with tf.control_dependencies([</code></pre><h3>After Change</h3><pre><code class='java'>
    :return: NxDxQ
    
    with params_as_tensors_for(mean1), params_as_tensors_for(mean2):
        <a id="change">N = tf.shape(p.mu)[0]</a>
        e_xxt = p.cov + (p.mu[:, :, None] * p.mu[:, None, :])  &#47&#47 NxDxD
        e_xxt_A = tf.matmul(e_xxt, tf.tile(mean2.A[None, ...], (N, 1, 1)))  &#47&#47 NxDxQ
        e_x_bt = p.mu[:, :, None] * mean2.b[None, None, :]  &#47&#47 NxDxQ
</code></pre>