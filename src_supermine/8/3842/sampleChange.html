<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        
        _check_inputs_compatibility_for_scatter_gather(tensor, tensor_list)

        <a id="change">comm = self._get_nccl_collective_communicator()</a>
        <a id="change">stream = self._get_cuda_stream()</a>
        dtype = nccl_util.get_nccl_tensor_dtype(tensor_list[0])
        n_elems = nccl_util.get_tensor_n_elements(tensor_list[0])
        reduce_op = nccl_util.get_nccl_reduce_op(
            reducescatter_options.reduceOp)</code></pre><h3>After Change</h3><pre><code class='java'>
            collective_fn,
            postprocess_fn=postprocess_fn)

    def reducescatter(<a id="change">self</a>,
                      tensor,
                      tensor_list,
                      reducescatter_options=ReduceScatterOptions()):
        Reducescatter a list of tensors across the group.

        Args:
            tensor: the output tensor (could be unspecified).
            tensor_list: the list of tensor to be reduced then scattered.
            reducescatter_options: reducescatter options.

        Returns:
            None
        

        def collective_fn(input_tensor, output_tensor, comm, stream):
            comm.reduceScatter(
                nccl_util.get_tensor_ptr(input_tensor),
                nccl_util.get_tensor_ptr(output_tensor),
                nccl_util.get_tensor_n_elements(output_tensor),
                nccl_util.get_nccl_tensor_dtype(output_tensor),
                nccl_util.get_nccl_reduce_op(reducescatter_options.reduceOp),
                stream.ptr)

        _check_inputs_compatibility_for_scatter_gather(tensor, tensor_list)
        flattened_input_tensor = _flatten_for_scatter_gather(
            tensor_list, copy=False)

        def preprocess_fn(stream):
            for i, tensor in enumerate(tensor_list):
                nccl_util.copy_tensor(flattened_input_tensor[i], tensor)

        <a id="change">self._collective(
            flattened_input_tensor,
            tensor,
            collective_fn,
            preprocess_fn=preprocess_fn)</a>

    def send(self, tensor, dst_rank):
        Send tensor to a destination process in the group.
</code></pre>