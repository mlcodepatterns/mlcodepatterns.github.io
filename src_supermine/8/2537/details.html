<html><h3>4f2535df9cb702854ef892c0d2a92ef068636ce0,examples/reinforcement_learning/baselines/algorithms/td3/td3.py,,learn,#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#,271
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        td3_trainer.load_weights()

        <a id="change">while frame_idx &lt; test_frames:
            state = env.reset()
            state = state.astype(np.float32)
            episode_reward = 0
            if frame_idx &lt; 1:
                _ = td3_trainer.policy_net(
                    [state]
                )  &#47&#47 need an extra call to make inside functions be able to use forward
                _ = td3_trainer.target_policy_net([state])

            for step in range(max_steps):
                action = td3_trainer.policy_net.get_action(state, explore_noise_scale=1.0)
                next_state, reward, done, _ = env.step(action)
                next_state = next_state.astype(np.float32)
                env.render()
                done = 1 if done ==True else 0

                state = next_state
                episode_reward += reward
                frame_idx += 1

                &#47&#47 if frame_idx % 50 == 0:
                &#47&#47     plot(frame_idx, rewards)

                if done:
                    break
            episode = int(frame_idx / max_steps)
            all_episodes = int(test_frames / max_steps)
            print(&quotEpisode: {}/{}  | Episode Reward: {:.4f}  | Running Time: {:.4f}&quot\
            .format(episode, all_episodes, episode_reward, time.time()-t0 ) )
            rewards.append(episode_reward)</a>
</code></pre><h3>After Change</h3><pre><code class='java'>
        frame_idx = 0
        rewards = []
        t0 = time.time()
        <a id="change">for eps in range(train_episodes):
            state = env.reset()
            state = state.astype(np.float32)
            episode_reward = 0
            if frame_idx &lt; 1:
                _ = td3_trainer.policy_net(
                    [state]
                )  &#47&#47 need an extra call here to make inside functions be able to use model.forward
                _ = td3_trainer.target_policy_net([state])

            for step in range(max_steps):
                if frame_idx &gt; explore_steps:
                    action = td3_trainer.policy_net.get_action(state, explore_noise_scale=1.0)
                else:
                    action = td3_trainer.policy_net.sample_action()

                next_state, reward, done, _ = env.step(action)
                next_state = next_state.astype(np.float32)
                env.render()
                done = 1 if done ==True else 0

                replay_buffer.push(state, action, reward, next_state, done)

                state = next_state
                episode_reward += reward
                frame_idx += 1

                if len(replay_buffer) &gt; batch_size:
                    for i in range(update_itr):
                        td3_trainer.update(batch_size, eval_noise_scale=0.5, reward_scale=1.)

                if done:
                    break

            if eps % int(save_interval) == 0:
                plot(rewards, Algorithm_name=&quotTD3&quot, Env_name=env_id)
                td3_trainer.save_weights()

            print(&quotEpisode: {}/{}  | Episode Reward: {:.4f}  | Running Time: {:.4f}&quot\
            .format(eps, train_episodes, episode_reward, time.time()-t0 ))
            rewards.append(episode_reward)
       </a> td3_trainer.save_weights()

    if mode==&quottest&quot:
        frame_idx = 0</code></pre><img src="14032055.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/tensorlayer/tensorlayer/commit/4f2535df9cb702854ef892c0d2a92ef068636ce0#diff-a5880ffcf7ff10c8663b2934ed4c4fc6a24e3fda34c37fb4b0f55faf7b1ebe0aL294' target='_blank'>Link</a></div><div id='project'> Project Name: tensorlayer/tensorlayer</div><div id='commit'> Commit Name: 4f2535df9cb702854ef892c0d2a92ef068636ce0</div><div id='time'> Time: 2019-07-04</div><div id='author'> Author: 1402434478@qq.com</div><div id='file'> File Name: examples/reinforcement_learning/baselines/algorithms/td3/td3.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: learn</div><BR><BR><div id='link'><a href='https://github.com/hanxiao/bert-as-service/commit/f0d581c071f14682c46f7917e11592c189382f53#diff-44ace16cb718aadd24b1c32a628113844418f650ac5fcc606d7a88c3fdb393f1L82' target='_blank'>Link</a></div><div id='project'> Project Name: hanxiao/bert-as-service</div><div id='commit'> Commit Name: f0d581c071f14682c46f7917e11592c189382f53</div><div id='time'> Time: 2018-12-17</div><div id='author'> Author: hanhxiao@tencent.com</div><div id='file'> File Name: server/bert_serving/server/__init__.py</div><div id='class'> Class Name: BertServer</div><div id='method'> Method Name: _run</div><BR><BR><div id='link'><a href='https://github.com/chainer/chainercv/commit/93cfd8bd22d6b798b94aead3c8ea75ace2727265#diff-7b972eed9d034fa2e26eef0fc1dec8a9e08b7dba5c18e13f858af09e75b84146L135' target='_blank'>Link</a></div><div id='project'> Project Name: chainer/chainercv</div><div id='commit'> Commit Name: 93cfd8bd22d6b798b94aead3c8ea75ace2727265</div><div id='time'> Time: 2019-02-18</div><div id='author'> Author: shingogo@hotmail.co.jp</div><div id='file'> File Name: chainercv/functions/ps_roi_max_align_2d.py</div><div id='class'> Class Name: PSROIMaxAlign2D</div><div id='method'> Method Name: forward_cpu</div><BR><BR><div id='link'><a href='https://github.com/NVIDIA/OpenSeq2Seq/commit/42ad0f227fa39fe9b96bc3e08b2e5704dc157e74#diff-25748bd17accb5d25ebc25311278c998f70b7c8f28e587890a332b75d5dde2a1L77' target='_blank'>Link</a></div><div id='project'> Project Name: NVIDIA/OpenSeq2Seq</div><div id='commit'> Commit Name: 42ad0f227fa39fe9b96bc3e08b2e5704dc157e74</div><div id='time'> Time: 2018-06-26</div><div id='author'> Author: xravitejax@gmail.com</div><div id='file'> File Name: open_seq2seq/encoders/w2l_encoder.py</div><div id='class'> Class Name: Wave2LetterEncoder</div><div id='method'> Method Name: _encode</div><BR>