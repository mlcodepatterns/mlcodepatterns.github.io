<html><h3>bb9335bbc981c0541e37a875d79d0ef419008574,torchnlp/text_encoders/subword_encoder.py,SubwordEncoder,__init__,#SubwordEncoder#Any#Any#Any#Any#Any#,31
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                 max_occurrences=1e3):
        self.append_eos = append_eos

        <a id="change">if target_vocab_size is None:
            self.tokenizer = SubwordTextTokenizer()
            self.tokenizer.build_from_corpus(sample, min_count=min_occurrences)
        else:

            target_vocab_size -= len(RESERVED_ITOS)
            self.tokenizer = SubwordTextTokenizer.build_to_target_size_from_corpus(
                sample,
                target_size=target_vocab_size,
                min_val=min_occurrences,
                max_val=max_occurrences)

       </a> self.stoi = RESERVED_STOI.copy()
        self.itos = RESERVED_ITOS[:]
        for token in self.tokenizer.vocab:
            self.itos.append(token)</code></pre><h3>After Change</h3><pre><code class='java'>
        self.append_eos = append_eos

        if target_vocab_size is None:
            self.tokeniz<a id="change">er = SubwordTextTokenizer()
           </a> self.tokenizer.build_from_corpus(sample, min_count=min_occurrences)
        else:

            target_vocab_size -= len(reserved_tokens)</code></pre><img src="6235485.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/PetrochukM/PyTorch-NLP/commit/bb9335bbc981c0541e37a875d79d0ef419008574#diff-804fd2998f37efd35efbb467901833fbc95b5ed95e202dc76c1246dd33d61843L31' target='_blank'>Link</a></div><div id='project'> Project Name: PetrochukM/PyTorch-NLP</div><div id='commit'> Commit Name: bb9335bbc981c0541e37a875d79d0ef419008574</div><div id='time'> Time: 2018-03-25</div><div id='author'> Author: petrochukm@gmail.com</div><div id='file'> File Name: torchnlp/text_encoders/subword_encoder.py</div><div id='class'> Class Name: SubwordEncoder</div><div id='method'> Method Name: __init__</div><BR><BR><div id='link'><a href='https://github.com/uber/ludwig/commit/116e474be75cdcf4c1d53b1c6540097766671b18#diff-0430a392e9085e176481b29638139e95cc3aedd1f022c681ab601d7ad3840d61L82' target='_blank'>Link</a></div><div id='project'> Project Name: uber/ludwig</div><div id='commit'> Commit Name: 116e474be75cdcf4c1d53b1c6540097766671b18</div><div id='time'> Time: 2020-03-27</div><div id='author'> Author: jimthompson5802@aol.com</div><div id='file'> File Name: ludwig/models/model.py</div><div id='class'> Class Name: Model</div><div id='method'> Method Name: __init__</div><BR><BR><div id='link'><a href='https://github.com/dmlc/gluon-nlp/commit/f4275c0b80197e0f1bbd3a2a1a31cf07d85013b1#diff-9f211728739d8c530be209acfeaf63e70a4f30275188f5d5a4b458e61646b57eL177' target='_blank'>Link</a></div><div id='project'> Project Name: dmlc/gluon-nlp</div><div id='commit'> Commit Name: f4275c0b80197e0f1bbd3a2a1a31cf07d85013b1</div><div id='time'> Time: 2019-01-09</div><div id='author'> Author: leonard@lausen.nl</div><div id='file'> File Name: scripts/word_embeddings/evaluate_pretrained.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: </div><BR>