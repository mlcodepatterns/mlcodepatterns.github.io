<html><h3>4ce9a9d078d41af1a960f0e5bf16e373f69d5117,open_seq2seq/decoders/rnn_decoders.py,BeamSearchRNNDecoderWithAttention,_decode,#BeamSearchRNNDecoderWithAttention#Any#,345
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
      self._tgt_vocab_size, use_bias=False,
    )

    <a id="change">cell_params = copy.deepcopy(self.params)</a>
    <a id="change">cell_params["num_units"] = self.params[&quotdecoder_cell_units&quot]</a>

    if self._mode == "train":
      dp_input_keep_prob = self.params[&quotdecoder_dp_input_keep_prob&quot]
      dp_output_keep_prob = self.params[&quotdecoder_dp_output_keep_prob&quot]</code></pre><h3>After Change</h3><pre><code class='java'>
    &#47&#47)
    residual_connections = self.params[&quotdecoder_use_skip_connections&quot]
    &#47&#47 list of cells
    self._decoder_cells = <a id="change">[
      single_cell(cell_class=self.params[&quotcore_cell&quot],
                  cell_params=self.params.get(&quotcore_cell_params&quot, {}),
                  dp_input_keep_prob=dp_input_keep_prob,
                  dp_output_keep_prob=dp_output_keep_prob,
                  &#47&#47 residual connections are added a little differently for GNMT
                  residual_connections=False if self.params[
                    &quotattention_type&quot].startswith(
                    &quotgnmt&quot) else residual_connections,
                  ) for _ in range(self.params[&quotdecoder_layers&quot])]</a>

    tiled_enc_outputs = tf.contrib.seq2seq.tile_batch(
      encoder_outputs,
      multiplier=self._beam_width,
    )
    tiled_enc_src_lengths = tf.contrib.seq2seq.tile_batch(
      enc_src_lengths,
      multiplier=self._beam_width,
    )
    attention_mechanism = self._build_attention(
      tiled_enc_outputs,
      tiled_enc_src_lengths,
    )

    if self.params[&quotattention_type&quot].startswith(&quotgnmt&quot):
      attention_cell = self._decoder_cells.pop(0)
      attention_cell = AttentionWrapper(
        attention_cell,
        attention_mechanism=attention_mechanism,
        attention_layer_size=None,  &#47&#47 don&quott use attention layer.
        output_attention=False,
        name="gnmt_attention")
      attentive_decoder_cell = GNMTAttentionMultiCell(
        attention_cell, self._add_residual_wrapper(self._decoder_cells) if residual_connections else self._decoder_cells,
        use_new_attention=(self.params[&quotattention_type&quot] == &quotgnmt_v2&quot))
    else: &#47&#47 non-GNMT
      attentive_decoder_cell = AttentionWrapper(
        cell=<a id="change">tf.contrib.rnn.MultiRNNCell(self._decoder_cells)</a>,
        attention_mechanism=attention_mechanism,
      )
    batch_size_tensor = tf.constant(self._batch_size)</code></pre><img src="3592006.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 12</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/NVIDIA/OpenSeq2Seq/commit/4ce9a9d078d41af1a960f0e5bf16e373f69d5117#diff-b909f688fcde7b22bb97ac2678f3d71abf6efbfe6c2d13e464eed2174c676444L341' target='_blank'>Link</a></div><div id='project'> Project Name: NVIDIA/OpenSeq2Seq</div><div id='commit'> Commit Name: 4ce9a9d078d41af1a960f0e5bf16e373f69d5117</div><div id='time'> Time: 2018-06-13</div><div id='author'> Author: okuchaiev@nvidia.com</div><div id='file'> File Name: open_seq2seq/decoders/rnn_decoders.py</div><div id='class'> Class Name: BeamSearchRNNDecoderWithAttention</div><div id='method'> Method Name: _decode</div><BR><BR><div id='link'><a href='https://github.com/NVIDIA/OpenSeq2Seq/commit/4ce9a9d078d41af1a960f0e5bf16e373f69d5117#diff-f43a6fd98adddd64d7353a5996885e10af827df5be0f90e905399a91345bfd50L230' target='_blank'>Link</a></div><div id='project'> Project Name: NVIDIA/OpenSeq2Seq</div><div id='commit'> Commit Name: 4ce9a9d078d41af1a960f0e5bf16e373f69d5117</div><div id='time'> Time: 2018-06-13</div><div id='author'> Author: okuchaiev@nvidia.com</div><div id='file'> File Name: open_seq2seq/encoders/rnn_encoders.py</div><div id='class'> Class Name: BidirectionalRNNEncoderWithEmbedding</div><div id='method'> Method Name: _encode</div><BR><BR><div id='link'><a href='https://github.com/NVIDIA/OpenSeq2Seq/commit/4ce9a9d078d41af1a960f0e5bf16e373f69d5117#diff-b909f688fcde7b22bb97ac2678f3d71abf6efbfe6c2d13e464eed2174c676444L151' target='_blank'>Link</a></div><div id='project'> Project Name: NVIDIA/OpenSeq2Seq</div><div id='commit'> Commit Name: 4ce9a9d078d41af1a960f0e5bf16e373f69d5117</div><div id='time'> Time: 2018-06-13</div><div id='author'> Author: okuchaiev@nvidia.com</div><div id='file'> File Name: open_seq2seq/decoders/rnn_decoders.py</div><div id='class'> Class Name: RNNDecoderWithAttention</div><div id='method'> Method Name: _decode</div><BR>