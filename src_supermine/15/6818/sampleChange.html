<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
set_trainable(model.likelihood, False)

opt = gpflow.optimizers.Scipy()
<a id="change">opt.minimize(objective_closure,
             model.trainable_variables,
             options=dict(maxiter=ci_niter(1000)))</a>

&#47&#47 %% [markdown]
&#47&#47 We&quotve now fitted the VGP model to the data, but without optimizing over the hyperparameters. Plotting the data, we see that the fit is not terrible, but hasn&quott made use of our knowledge of the varying noise. 
</code></pre><h3>After Change</h3><pre><code class='java'>
def objective_closure():
    return - model.log_marginal_likelihood()

<a id="change">for _ in range(ci_niter(1000)):
    natgrad.minimize(objective_closure, [(model.q_mu, model.q_sqrt)])

&#47&#47 %% [markdown]
&#47&#47 We&quotve now fitted the VGP model to the data, but without optimizing over the hyperparameters. Plotting the data, we see that the fit is not terrible, but hasn&quott made use of our knowledge of the varying noise. 

&#47&#47 %%
&#47&#47 let&quots do some plotting!
</a>xx = np.linspace(-5, 5, 200)[:, None]

mu, var = model.predict_f(xx)
</code></pre>