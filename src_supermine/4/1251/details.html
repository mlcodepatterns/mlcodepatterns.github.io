<html><h3>f5ba97d8316e20f445eac8a47e1cdeae3d2f38ca,imgaug/augmenters/geometric.py,PerspectiveTransform,_draw_samples,#PerspectiveTransform#Any#Any#,2834
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 cv2 perspectiveTransform doesn&quott accept numpy arrays as cval
        cval_samples_cv2 = cval_samples.tolist()

        <a id="change">for i in sm.xrange(nb_images):
            h, w = shapes[i][0:2]

            points = self.jitter.draw_samples((4, 2), random_state=rngs[2+i])
            points = np.mod(np.abs(points), 1)

            &#47&#47 modify jitter to the four corner point coordinates
            &#47&#47 some x/y values have to be modified from `jitter` to `1-jtter`
            &#47&#47 for that

            &#47&#47 top left -- no changes needed, just use jitter
            &#47&#47 top right
            points[2, 0] = 1.0 - points[2, 0]  &#47&#47 h = 1.0 - jitter
            &#47&#47 bottom right
            points[1, 0] = 1.0 - points[1, 0]  &#47&#47 w = 1.0 - jitter
            points[1, 1] = 1.0 - points[1, 1]  &#47&#47 h = 1.0 - jitter
            &#47&#47 bottom left
            points[0, 1] = 1.0 - points[0, 1]  &#47&#47 h = 1.0 - jitter

            points[:, 0] = points[:, 0] * w
            points[:, 1] = points[:, 1] * h

            &#47&#47 obtain a consistent order of the points and unpack them
            &#47&#47 individually
            points = self._order_points(points)
            (tl, tr, br, bl) = points

            &#47&#47 TODO remove these loops
            &#47&#47 compute the width of the new image, which will be the
            &#47&#47 maximum distance between bottom-right and bottom-left
            &#47&#47 x-coordiates or the top-right and top-left x-coordinates
            min_width = None
            while min_width is None or min_width &lt; self.min_width:
                width_a = np.sqrt(((br[0]-bl[0])**2) + ((br[1]-bl[1])**2))
                width_b = np.sqrt(((tr[0]-tl[0])**2) + ((tr[1]-tl[1])**2))
                max_width = max(int(width_a), int(width_b))
                min_width = min(int(width_a), int(width_b))
                if min_width &lt; self.min_width:
                    tl[0] -= self.shift_step_size
                    tr[0] += self.shift_step_size
                    bl[0] -= self.shift_step_size
                    br[0] += self.shift_step_size

            &#47&#47 compute the height of the new image, which will be the
            &#47&#47 maximum distance between the top-right and bottom-right
            &#47&#47 y-coordinates or the top-left and bottom-left y-coordinates
            min_height = None
            while min_height is None or min_height &lt; self.min_height:
                height_a = np.sqrt(((tr[0]-br[0])**2) + ((tr[1]-br[1])**2))
                height_b = np.sqrt(((tl[0]-bl[0])**2) + ((tl[1]-bl[1])**2))
                max_height = max(int(height_a), int(height_b))
                min_height = min(int(height_a), int(height_b))
                if min_height &lt; self.min_height:
                    tl[1] -= self.shift_step_size
                    tr[1] -= self.shift_step_size
                    bl[1] += self.shift_step_size
                    br[1] += self.shift_step_size

            &#47&#47 now that we have the dimensions of the new image, construct
            &#47&#47 the set of destination points to obtain a "birds eye view",
            &#47&#47 (i.e. top-down view) of the image, again specifying points
            &#47&#47 in the top-left, top-right, bottom-right, and bottom-left
            &#47&#47 order
            dst = np.array([
                [0, 0],
                [max_width - 1, 0],
                [max_width - 1, max_height - 1],
                [0, max_height - 1]
            ], dtype="float32")

            &#47&#47 compute the perspective transform matrix and then apply it
            m = cv2.getPerspectiveTransform(points, dst)

            if self.fit_output:
                m, max_width, max_height = self._expand_transform(m, (h, w))

            matrices.append(m)
            max_heights.append(max_height)
            max_widths.append(max_width)

       </a> mode_samples = mode_samples.astype(np.int32)
        return _PerspectiveTransformSamplingResult(
            matrices, max_heights, max_widths, cval_samples_cv2,
            mode_samples)</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 cv2 perspectiveTransform doesn&quott accept numpy arrays as cval
        cval_samples_cv2 = cval_samples.tolist()

        for shape, rng in zip(shapes, <a id="change">rngs[2:]</a>):
            h, w = shape[0:2]

            points = self.jitter.draw_samples((4, 2), random_state=rng)</code></pre><img src="7173903.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/aleju/imgaug/commit/f5ba97d8316e20f445eac8a47e1cdeae3d2f38ca#diff-52655f854e5777e8c8477b4edeaf9edc204e433b24866740d25a2d5ddc4d5509L2838' target='_blank'>Link</a></div><div id='project'> Project Name: aleju/imgaug</div><div id='commit'> Commit Name: f5ba97d8316e20f445eac8a47e1cdeae3d2f38ca</div><div id='time'> Time: 2019-10-15</div><div id='author'> Author: kontakt@ajung.name</div><div id='file'> File Name: imgaug/augmenters/geometric.py</div><div id='class'> Class Name: PerspectiveTransform</div><div id='method'> Method Name: _draw_samples</div><BR><BR><div id='link'><a href='https://github.com/aleju/imgaug/commit/bc87005e5dce729044e1a10286f9124d652e34d6#diff-661616a8ca72acfea9cb9923d8d42bf6375a0b05d90cf5e943f2484e70e02646L260' target='_blank'>Link</a></div><div id='project'> Project Name: aleju/imgaug</div><div id='commit'> Commit Name: bc87005e5dce729044e1a10286f9124d652e34d6</div><div id='time'> Time: 2019-08-25</div><div id='author'> Author: kontakt@ajung.name</div><div id='file'> File Name: imgaug/augmentables/kps.py</div><div id='class'> Class Name: Keypoint</div><div id='method'> Method Name: generate_similar_points_manhattan</div><BR><BR><div id='link'><a href='https://github.com/aleju/imgaug/commit/6411c9079a834fd7549ab4593261a3619519eb02#diff-fe107f92728cf67dc12cf569142dae3e08872d8bc857ce303b98b49baec5a7c5L979' target='_blank'>Link</a></div><div id='project'> Project Name: aleju/imgaug</div><div id='commit'> Commit Name: 6411c9079a834fd7549ab4593261a3619519eb02</div><div id='time'> Time: 2019-09-04</div><div id='author'> Author: kontakt@ajung.name</div><div id='file'> File Name: imgaug/augmenters/size.py</div><div id='class'> Class Name: CropAndPad</div><div id='method'> Method Name: _augment_images</div><BR>