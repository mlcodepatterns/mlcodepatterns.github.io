<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

    &#47&#47 Message Passing
    data = tf.reshape(tf.nn.softmax(H1), [batch_size, -1, n_ch])
    Q1 = <a id="change">[None]</a> * len(permutohedrals)
    with tf.device(&quot/cpu:0&quot):
        for idx, permutohedral in enumerate(permutohedrals):
            Q1[idx] = tf.reshape(</code></pre><h3>After Change</h3><pre><code class='java'>
    n_voxels = np.prod(U.shape.as_list()[:-1])

    H1 = tf.reshape(tf.nn.softmax(H1), [batch_size, -1, n_ch])
    <a id="change">Q1 = 0</a>
    <a id="change">for idx, permutohedral in enumerate(permutohedrals):
        &#47&#47 Message Passing
        Q = _permutohedral_gen(permutohedral, H1, name + str(idx))
        Q.set_shape([n_voxels, n_ch])
        &#47&#47 Weighting Filtered Outputs
        Q1 = Q1 + Q * kernel_weights[idx]

    &#47&#47 Compatibility Transform, Adding Unary Potentials
    &#47&#47 output logits, not the softmax
   </a> return U - tf.reshape(<a id="change">tf.matmul(Q1, mu)</a>, U.shape.as_list())


def permutohedral_prepare(position_vectors):</code></pre>