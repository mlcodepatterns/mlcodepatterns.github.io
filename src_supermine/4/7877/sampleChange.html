<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                                             &quotWe load a LSTM model that is pre-trained on &quot
                                             &quotWikiText as our encoder.&quot)
group = parser.add_mutually_exclusive_group(required=True)
<a id="change">group.add_argument(&quot--use-sampling&quot, action=&quotstore_true&quot,
                   help=&quotUse sampling instead of beam search.&quot)</a>
group.add_argument(&quot--use-beam-search&quot, action=&quotstore_true&quot,
                   help=&quotUse beam search instead of random sampling.&quot)
parser.add_argument(&quot--lm_model&quot, type=str, default=&quotawd_lstm_lm_1150&quot,
                    help=&quottype of the pre-trained model to load, can be "standard_lstm_lm_200", &quot</code></pre><h3>After Change</h3><pre><code class='java'>
&#47&#47 beam search sampler options
subparsers = parser.add_subparsers(help=&quotSequence generation methods.&quot,
                                   dest=&quotcommand&quot)
<a id="change">subparsers.required = True</a>
beam_search_parser = subparsers.add_parser(&quotbeam-search&quot, help=&quotUse beam search for decoding.&quot)
beam_search_parser.add_argument(&quot--alpha&quot, type=float, default=0.0,
                                help=&quotAlpha in the length penalty term.&quot)
beam_search_parser.add_argument(&quot--k&quot, type=int, default=5, help=&quotK in the length penalty term.&quot)

&#47&#47 random sampler options
random_sample_parser = subparsers.add_parser(&quotrandom-sample&quot,
                                             help=&quotUse random sampling for decoding.&quot)
random_sample_parser.add_argument(&quot--temperature&quot, type=float, default=1.0,
                                  help=&quotSoftmax temperature used in sampling.&quot)
random_sample_parser.add_argument(&quot--use-top-k&quot, type=int, required=False,
                                  help=&quotSample only from the top-k candidates.&quot)

&#47&#47 shared options
<a id="change">for p in [beam_search_parser, random_sample_parser]:
    p.add_argument(&quot--gpu&quot, type=int, default=0,
                   help=&quotid of the gpu to use. Set it to empty means to use cpu.&quot)
    p.add_argument(&quot--lm-model&quot, type=str, default=&quotawd_lstm_lm_1150&quot,
                   help=&quottype of the pre-trained model to load, can be "standard_lstm_lm_200", &quot
                        &quot"standard_lstm_lm_650", "standard_lstm_lm_1500", &quot
                        &quot"awd_lstm_lm_1150", etc.&quot)
    p.add_argument(&quot--max-length&quot, type=int, default=20, help=&quotMaximum sentence length.&quot)
    p.add_argument(&quot--print-num&quot, type=int, default=3, help=&quotNumber of sentences to display.&quot)
    p.add_argument(&quot--bos&quot, type=str, default=&quotI think this works&quot)
    p.add_argument(&quot--beam-size&quot, type=int, default=5,
                   help=&quotBeam size in the beam search sampler.&quot)

</a>args = parser.parse_args()

print(args)
if args.gpu is not None and args.gpu &lt; mx.context.num_gpus():</code></pre>