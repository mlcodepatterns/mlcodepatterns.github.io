<html><h3>aeb516494daa207720b428072ab49eeea7bfff75,scripts/text_generation/sequence_sampling.py,,,#,33
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                                             &quotWe load a LSTM model that is pre-trained on &quot
                                             &quotWikiText as our encoder.&quot)
group = parser.add_mutually_exclusive_group(required=True)
<a id="change">group.add_argument(&quot--use-sampling&quot, action=&quotstore_true&quot,
                   help=&quotUse sampling instead of beam search.&quot)</a>
group.add_argument(&quot--use-beam-search&quot, action=&quotstore_true&quot,
                   help=&quotUse beam search instead of random sampling.&quot)
parser.add_argument(&quot--lm_model&quot, type=str, default=&quotawd_lstm_lm_1150&quot,
                    help=&quottype of the pre-trained model to load, can be "standard_lstm_lm_200", &quot</code></pre><h3>After Change</h3><pre><code class='java'>
&#47&#47 beam search sampler options
subparsers = parser.add_subparsers(help=&quotSequence generation methods.&quot,
                                   dest=&quotcommand&quot)
<a id="change">subparsers.required = True</a>
beam_search_parser = subparsers.add_parser(&quotbeam-search&quot, help=&quotUse beam search for decoding.&quot)
beam_search_parser.add_argument(&quot--alpha&quot, type=float, default=0.0,
                                help=&quotAlpha in the length penalty term.&quot)
beam_search_parser.add_argument(&quot--k&quot, type=int, default=5, help=&quotK in the length penalty term.&quot)

&#47&#47 random sampler options
random_sample_parser = subparsers.add_parser(&quotrandom-sample&quot,
                                             help=&quotUse random sampling for decoding.&quot)
random_sample_parser.add_argument(&quot--temperature&quot, type=float, default=1.0,
                                  help=&quotSoftmax temperature used in sampling.&quot)
random_sample_parser.add_argument(&quot--use-top-k&quot, type=int, required=False,
                                  help=&quotSample only from the top-k candidates.&quot)

&#47&#47 shared options
<a id="change">for p in [beam_search_parser, random_sample_parser]:
    p.add_argument(&quot--gpu&quot, type=int, default=0,
                   help=&quotid of the gpu to use. Set it to empty means to use cpu.&quot)
    p.add_argument(&quot--lm-model&quot, type=str, default=&quotawd_lstm_lm_1150&quot,
                   help=&quottype of the pre-trained model to load, can be "standard_lstm_lm_200", &quot
                        &quot"standard_lstm_lm_650", "standard_lstm_lm_1500", &quot
                        &quot"awd_lstm_lm_1150", etc.&quot)
    p.add_argument(&quot--max-length&quot, type=int, default=20, help=&quotMaximum sentence length.&quot)
    p.add_argument(&quot--print-num&quot, type=int, default=3, help=&quotNumber of sentences to display.&quot)
    p.add_argument(&quot--bos&quot, type=str, default=&quotI think this works&quot)
    p.add_argument(&quot--beam-size&quot, type=int, default=5,
                   help=&quotBeam size in the beam search sampler.&quot)

</a>args = parser.parse_args()

print(args)
if args.gpu is not None and args.gpu &lt; mx.context.num_gpus():</code></pre><img src="37388530.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/dmlc/gluon-nlp/commit/aeb516494daa207720b428072ab49eeea7bfff75#diff-d53419c44a8e0ed1f53b74495a8d5dd0397920c8bafed98fb865e54078a53634L33' target='_blank'>Link</a></div><div id='project'> Project Name: dmlc/gluon-nlp</div><div id='commit'> Commit Name: aeb516494daa207720b428072ab49eeea7bfff75</div><div id='time'> Time: 2019-06-13</div><div id='author'> Author: xshiab@ust.hk</div><div id='file'> File Name: scripts/text_generation/sequence_sampling.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: </div><BR><BR><div id='link'><a href='https://github.com/chainer/chainercv/commit/056ec6b546ba3f3120ff12398dec85ef69c4851a#diff-00357d913bb5e6b5eb096a31ff2e908765987f22e6b6bb2d7e96c590ef66814aL75' target='_blank'>Link</a></div><div id='project'> Project Name: chainer/chainercv</div><div id='commit'> Commit Name: 056ec6b546ba3f3120ff12398dec85ef69c4851a</div><div id='time'> Time: 2017-10-04</div><div id='author'> Author: yuyuniitani@gmail.com</div><div id='file'> File Name: examples/classification/train_imagenet_mn.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: main</div><BR><BR><div id='link'><a href='https://github.com/NervanaSystems/nlp-architect/commit/d50fdcc5aeb2d5ab80c3ac4ec26fef08358f598d#diff-f4935d9f5487211c333696d8d62d6c997b576c56d4502da29d4c28449adfec86L114' target='_blank'>Link</a></div><div id='project'> Project Name: NervanaSystems/nlp-architect</div><div id='commit'> Commit Name: d50fdcc5aeb2d5ab80c3ac4ec26fef08358f598d</div><div id='time'> Time: 2018-07-15</div><div id='author'> Author: jonathan.mamou@intel.com</div><div id='file'> File Name: solutions/set_expansion/set_expand.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: </div><BR>