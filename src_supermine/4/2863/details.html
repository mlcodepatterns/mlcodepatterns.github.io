<html><h3>b5a02391e003c33c8f8258a7e3d0736503c3c048,examples/babi_memnn.py,,,#,97
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
match = Sequential()
match.add(Merge([input_encoder_m, question_encoder],
                mode=&quotdot&quot,
                dot_axes=<a id="change">[2, 2]</a>))
match.add(Activation(&quotsoftmax&quot))
&#47&#47 output: (samples, story_maxlen, query_maxlen)
&#47&#47 embed the input into a single vector with size = story_maxlen:</code></pre><h3>After Change</h3><pre><code class='java'>
&#47&#47 compute a &quotmatch&quot between the first input vector sequence
&#47&#47 and the question vector sequence
match = dot([input_encoded_m, question_encoded], axes=(2, 2))  &#47&#47 (samples, story_maxlen, query_maxlen)
match = <a id="change">Activation(&quotsoftmax&quot)(match)</a>

&#47&#47 add the match matrix with the second input vector sequence
response = add([match, input_encoded_c])  &#47&#47 (samples, story_maxlen, query_maxlen)
response = Permute((2, 1))(response)  &#47&#47 (samples, query_maxlen, story_maxlen)

&#47&#47 concatenate the match matrix with the question vector sequence
answer = concatenate([response, question_encoded])

&#47&#47 the original paper uses a matrix multiplication for this reduction step.
&#47&#47 we choose to use a RNN instead.
answer = LSTM(32)(answer)  &#47&#47 (samples, 32)

&#47&#47 one regularization layer -- more would probably be needed.
<a id="change">answer = Dropout(0.3)(answer)</a>
answer = Dense(vocab_size)(answer)  &#47&#47 (samples, vocab_size)
&#47&#47 we output a probability distribution over the vocabulary
<a id="change">answer = Activation(&quotsoftmax&quot)(answer)</a>

&#47&#47 build the final model
model = Model([input_sequence, question], answer)
model.compile(optimizer=&quotrmsprop&quot, loss=&quotcategorical_crossentropy&quot,</code></pre><img src="15121638.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/keras-team/keras/commit/b5a02391e003c33c8f8258a7e3d0736503c3c048#diff-238b174768800b222e507d9a32e2756691a0c3720909da4504d6b08214f13e06L121' target='_blank'>Link</a></div><div id='project'> Project Name: keras-team/keras</div><div id='commit'> Commit Name: b5a02391e003c33c8f8258a7e3d0736503c3c048</div><div id='time'> Time: 2017-03-15</div><div id='author'> Author: farizrahman4u@gmail.com</div><div id='file'> File Name: examples/babi_memnn.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: </div><BR><BR><div id='link'><a href='https://github.com/keras-team/autokeras/commit/0a80b9769115d291f15c244429793eda4cb8ecad#diff-730650d5756109f62d6d7a23d1627d62612027da778e0ac3e1ab1c37d8bb6f2fL61' target='_blank'>Link</a></div><div id='project'> Project Name: keras-team/autokeras</div><div id='commit'> Commit Name: 0a80b9769115d291f15c244429793eda4cb8ecad</div><div id='time'> Time: 2017-12-28</div><div id='author'> Author: jhfjhfj1@gmail.com</div><div id='file'> File Name: tests/test_layer_transformer.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: test_conv_to_wider_layer</div><BR><BR><div id='link'><a href='https://github.com/raghakot/keras-vis/commit/2443550ee6915daf6e7ff6306f3dc2922752ea4b#diff-091b2c23e21fbaf5887eb01ca339efb20787a699b85f44b0a6345c2d10733f3dL70' target='_blank'>Link</a></div><div id='project'> Project Name: raghakot/keras-vis</div><div id='commit'> Commit Name: 2443550ee6915daf6e7ff6306f3dc2922752ea4b</div><div id='time'> Time: 2017-07-09</div><div id='author'> Author: ragha@outlook.com</div><div id='file'> File Name: vis/backend/tensorflow_backend.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: modify_model_backprop</div><BR>