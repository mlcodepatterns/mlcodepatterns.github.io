<html><h3>6f39f48519a3e4fdc3a1e44b86dba00b3fcbbae3,open_seq2seq/data/text2text/text2text.py,ParallelTextDataLayer,build_graph,#ParallelTextDataLayer#,149
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
      .map(lambda tokens: (tokens, tf.size(tokens)),
           num_parallel_calls=self._map_parallel_calls)

    _src_tgt_dataset = <a id="change">tf.data.Dataset.zip((_sources, _targets)).filter(
      lambda t1, t2: tf.logical_and(tf.less_equal(t1[1], self.max_len),
                                    tf.less_equal(t2[1], self.max_len))
    )</a>

    if self._num_workers &gt; 1:
      _src_tgt_dataset = _src_tgt_dataset\
        .shard(num_shards=self._num_workers, index=self._worker_id)


    if self.params[&quotshuffle&quot]:
      _src_tgt_dataset = _src_tgt_dataset\
        .shuffle(buffer_size=self.get_size_in_samples())
    else:
      _src_tgt_dataset = _src_tgt_dataset

    if self.params[&quotrepeat&quot]:
      _src_tgt_dataset = _src_tgt_dataset.repeat()

    <a id="change">self.batched_dataset</a> = _src_tgt_dataset.padded_batch(
      self._batch_size,
      padded_shapes=((tf.TensorShape([None]),
                      tf.TensorShape([])),
                     (tf.TensorShape([None]),
                      tf.TensorShape([]))),
      padding_values=(
      (SpecialTextTokens.PAD_ID.value,
       0),
      (SpecialTextTokens.PAD_ID.value,
       0))).prefetch(buffer_size=self._prefetch_buffer_size)

    <a id="change">self._iterator</a> = self.batched_dataset.make_initializable_iterator()

    if self.params[&quotmode&quot] == &quottrain&quot or self.params[&quotmode&quot] == &quoteval&quot:
      t1, t2 = self.iterator.get_next()</code></pre><h3>After Change</h3><pre><code class='java'>
      .map(lambda tokens: (tokens, tf.size(tokens)),
           num_parallel_calls=self._map_parallel_calls)

    _src_tgt_dataset = <a id="change">tf</a>.data.Dataset.zip((_sources, _targets)).filter(
      lambda t1, t2: tf.logical_and(tf.less_equal(t1[1], self.max_len),
                                    tf.less_equal(t2[1], self.max_len))
    ).cache()

    if self._num_workers &gt; 1:
      _src_tgt_dataset = _src_tgt_dataset\
        .shard(num_shards=self._num_workers, index=self._worker_id)


    if self.params[&quotshuffle&quot]:
      _src_tgt_dataset = _src_tgt_dataset\
        .shuffle(buffer_size=self.get_size_in_samples())
    else:
      _src_tgt_dataset = _src_tgt_dataset

    if self.params[&quotrepeat&quot]:
      _src_tgt_dataset = _src_tgt_dataset.repeat()

    <a id="change">self.batched_dataset</a> = _src_tgt_dataset.padded_batch(
      self._batch_size,
      padded_shapes=((tf.TensorShape([None]),
                      tf.TensorShape([])),
                     (tf.TensorShape([None]),
                      tf.TensorShape([]))),
      padding_values=(
      (SpecialTextTokens.PAD_ID.value,
       0),
      (SpecialTextTokens.PAD_ID.value,
       0))).prefetch(buffer_size=self._prefetch_buffer_size)

    <a id="change">self._iterator</a> = self.batched_dataset.make_initializable_iterator()

    if self.params[&quotmode&quot] == &quottrain&quot or self.params[&quotmode&quot] == &quoteval&quot:
      t1, t2 = self.iterator.get_next()</code></pre><img src="39827326.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/NVIDIA/OpenSeq2Seq/commit/6f39f48519a3e4fdc3a1e44b86dba00b3fcbbae3#diff-dac23c5164c415e549e4f199cd773c7c8cc1921e13d5a5b02e0c9846ccb49e61L182' target='_blank'>Link</a></div><div id='project'> Project Name: NVIDIA/OpenSeq2Seq</div><div id='commit'> Commit Name: 6f39f48519a3e4fdc3a1e44b86dba00b3fcbbae3</div><div id='time'> Time: 2018-05-22</div><div id='author'> Author: okuchaiev@nvidia.com</div><div id='file'> File Name: open_seq2seq/data/text2text/text2text.py</div><div id='class'> Class Name: ParallelTextDataLayer</div><div id='method'> Method Name: build_graph</div><BR><BR><div id='link'><a href='https://github.com/NVIDIA/OpenSeq2Seq/commit/36c22f3f6b96cd02d95f436c58186a7acfa4abf0#diff-dac23c5164c415e549e4f199cd773c7c8cc1921e13d5a5b02e0c9846ccb49e61L147' target='_blank'>Link</a></div><div id='project'> Project Name: NVIDIA/OpenSeq2Seq</div><div id='commit'> Commit Name: 36c22f3f6b96cd02d95f436c58186a7acfa4abf0</div><div id='time'> Time: 2018-05-17</div><div id='author'> Author: okuchaiev@nvidia.com</div><div id='file'> File Name: open_seq2seq/data/text2text/text2text.py</div><div id='class'> Class Name: ParallelTextDataLayer</div><div id='method'> Method Name: build_graph</div><BR><BR><div id='link'><a href='https://github.com/NVIDIA/OpenSeq2Seq/commit/ca06d634cbd61d7f3c4a38a56351de46e12a675f#diff-319c8ec1119aa1bfefc4fcf6fb516ebc2a4d732ccb1399bdf52ac9e1b4892f80L552' target='_blank'>Link</a></div><div id='project'> Project Name: NVIDIA/OpenSeq2Seq</div><div id='commit'> Commit Name: ca06d634cbd61d7f3c4a38a56351de46e12a675f</div><div id='time'> Time: 2018-05-08</div><div id='author'> Author: okuchaiev@nvidia.com</div><div id='file'> File Name: open_seq2seq/data/text2text.py</div><div id='class'> Class Name: ParallelTextDataLayer</div><div id='method'> Method Name: build_graph</div><BR><BR><div id='link'><a href='https://github.com/NifTK/NiftyNet/commit/4b2e09598a90ed402baace88a95e74b6440ecdce#diff-fead8e4619c57446e53a3ef1847e6cf6a065278a5abbb047030a1de586395719L102' target='_blank'>Link</a></div><div id='project'> Project Name: NifTK/NiftyNet</div><div id='commit'> Commit Name: 4b2e09598a90ed402baace88a95e74b6440ecdce</div><div id='time'> Time: 2017-08-22</div><div id='author'> Author: wenqi.li@ucl.ac.uk</div><div id='file'> File Name: niftynet/utilities/user_parameters_regex.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: </div><BR>