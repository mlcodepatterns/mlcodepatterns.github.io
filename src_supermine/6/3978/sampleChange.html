<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        &#47&#47 Concat. prev-action/reward if required.
        if self.model_config["lstm_use_prev_action_reward"]:
            <a id="change">wrapped_out = tf.concat(
                [
                    wrapped_out,
                    tf.reshape(
                        tf.cast(input_dict[SampleBatch.PREV_ACTIONS],
                                tf.float32), [-1, self.action_dim]),
                    tf.reshape(
                        tf.cast(input_dict[SampleBatch.PREV_REWARDS],
                                tf.float32), [-1, 1]),
                ],
                axis=1)</a>

        &#47&#47 Then through our LSTM.
        input_dict["obs_flat"] = wrapped_out
        return super().forward(input_dict, state, seq_lens)</code></pre><h3>After Change</h3><pre><code class='java'>
        wrapped_out, _ = self._wrapped_forward(input_dict, [], None)

        &#47&#47 Concat. prev-action/reward if required.
        <a id="change">prev_a_r = []</a>
        if self.model_config["lstm_use_prev_action"]:
            prev_a = input_dict[SampleBatch.PREV_ACTIONS]
            if isinstance(self.action_space, (Discrete, MultiDiscrete)):
                prev_a = one_hot(prev_a, self.action_space)</code></pre>