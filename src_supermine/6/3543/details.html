<html><h3>86edb86bfadfaea0f7925a09e4473258ae82f9f7,txtgen/modules/decoders/rnn_decoders.py,AttentionRNNDecoder,__init__,#AttentionRNNDecoder#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#,268
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47TODO(zhiting)
        att_params = hparams[&quotattention&quot]
        attention_class = hparams[&quotattention&quot][&quotclass&quot] &#47&#47LuongAttention
        attention_kwargs = <a id="change">hparams[&quotattention&quot][&quotparams&quot]</a>
        attention_kwargs[&quotnum_units&quot] = n_hidden
        attention_kwargs[&quotmemory_sequence_length&quot] = attention_values_length
        attention_kwargs[&quotmemory&quot] = attention_keys
        attention_modules = [&quottxtgen.custom&quot, &quottensorflow.contrib.seq2seq&quot]</code></pre><h3>After Change</h3><pre><code class='java'>
        attn_modules = [&quottxtgen.custom&quot, &quottensorflow.contrib.seq2seq&quot]
        &#47&#47 Use variable_scope to ensure all trainable variables created in
        &#47&#47 the attention mechanism  are collected
        <a id="change">with tf.variable_scope(self.variable_scope):
            attention_mechanism = get_instance(
                attn_hparams["type"], attn_kwargs, attn_modules)

       </a> atten_cell_kwargs = {
            "attention_layer_size": attn_hparams["attention_layer_size"],
            "alignment_history": attn_hparams["alignment_history"],
            "output_attention": attn_hparams["output_attention"],</code></pre><img src="17134324.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/asyml/texar/commit/86edb86bfadfaea0f7925a09e4473258ae82f9f7#diff-c3cb66aea366d5d40143134ee296dac807e5b65e745a6667771f251d0211daa6L269' target='_blank'>Link</a></div><div id='project'> Project Name: asyml/texar</div><div id='commit'> Commit Name: 86edb86bfadfaea0f7925a09e4473258ae82f9f7</div><div id='time'> Time: 2017-10-24</div><div id='author'> Author: zhitinghu@gmail.com</div><div id='file'> File Name: txtgen/modules/decoders/rnn_decoders.py</div><div id='class'> Class Name: AttentionRNNDecoder</div><div id='method'> Method Name: __init__</div><BR><BR><div id='link'><a href='https://github.com/catalyst-team/catalyst/commit/aab3902d4a7d55f5a86058854adc36b8a12c873f#diff-94f0b9669517bfb949ba9c8c8bd57cbd96ea0f16b7482a95010f509c6c577190L202' target='_blank'>Link</a></div><div id='project'> Project Name: catalyst-team/catalyst</div><div id='commit'> Commit Name: aab3902d4a7d55f5a86058854adc36b8a12c873f</div><div id='time'> Time: 2019-05-20</div><div id='author'> Author: ekhvedchenya@gmail.com</div><div id='file'> File Name: catalyst/dl/callbacks/base.py</div><div id='class'> Class Name: OptimizerCallback</div><div id='method'> Method Name: on_batch_end</div><BR><BR><div id='link'><a href='https://github.com/deepmipt/DeepPavlov/commit/8261994bf8f77251f0b22fb13fa490ffa0bd184b#diff-b82e57261a34d59549a7f0d9143b814a564d243ab755447fac8332604032309cL83' target='_blank'>Link</a></div><div id='project'> Project Name: deepmipt/DeepPavlov</div><div id='commit'> Commit Name: 8261994bf8f77251f0b22fb13fa490ffa0bd184b</div><div id='time'> Time: 2018-02-01</div><div id='author'> Author: yoptar@gmail.com</div><div id='file'> File Name: deeppavlov/core/data/utils.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: ungzip</div><BR>