<html><h3>f4275c0b80197e0f1bbd3a2a1a31cf07d85013b1,scripts/word_embeddings/evaluate_pretrained.py,,,#,173
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                allow_extend=True,
                unknown_autoextend=True)
        else:
            token_embedding_ = <a id="change">nlp.embedding.create(
                args_.embedding_name, source=args_.embedding_source)</a>
        name = &quot-&quot + args_.embedding_name + &quot-&quot + args_.embedding_source
    else:
        token_embedding_ = load_embedding_from_path(args_)
        name = &quot&quot

    enforce_max_size(token_embedding_, args_.max_vocab_size)
    known_tokens = set(token_embedding_.idx_to_token)
    &#47&#47 Auto-extend token_embedding with unknown extra eval tokens
    if token_embedding_.unknown_lookup is not None:
        eval_tokens = evaluation.get_tokens_in_evaluation_datasets(args_)
        &#47&#47 pylint: disable=pointless-statement
        token_embedding_[[
            t for t in eval_tokens - known_tokens
            if t in token_embedding_.unknown_lookup
        ]]

        if args_.max_vocab_size is not None and len(
                token_embedding_.idx_to_token) &gt; args_.max_vocab_size:
            logging.warning(&quotComputing embeddings for OOV words that occur &quot
                            &quotin the evaluation dataset lead to having &quot
                            &quotmore words than --max-vocab-size. &quot
                            &quotHave %s words (--max-vocab-size %s)&quot,
                            len(token_embedding_.idx_to_token),
                            args_.max_vocab_size)

    similarity_results = evaluation.evaluate_similarity(
        args_, token_embedding_, ctx, logfile=os.path.join(
            args_.logdir, &quotsimilarity{}.tsv&quot.format(name)))
    <a id="change">analogy_results</a> = evaluation.evaluate_analogy(
        args_, token_embedding_, ctx, logfile=os.path.join(
            args_.logdir, &quotanalogy{}.tsv&quot.format(name)))
</code></pre><h3>After Change</h3><pre><code class='java'>
    enforce_max_size(token_embedding_, args_.analogy_max_vocab_size)
    known_tokens = set(token_embedding_.idx_to_token)

    <a id="change">if args_.similarity_datasets:
        with utils.print_time(&quotfind relevant tokens for similarity&quot):
            tokens = evaluation.get_similarity_task_tokens(args_)
        vocab = nlp.Vocab(nlp.data.count_tokens(tokens))
        with utils.print_time(&quotset {} embeddings&quot.format(len(tokens))):
            vocab.set_embedding(token_embedding_)
        evaluation.evaluate_similarity(
            args_, vocab.embedding, ctx, logfile=os.path.join(
                args_.logdir, &quotsimilarity{}.tsv&quot.format(name)))
   </a> if args_.analogy_datasets:
        with utils.print_time(&quotextend open vocabulary with &quot
                              &quotOOV tokens for analogy&quot):
            tokens = evaluation.get_analogy_task_tokens(args_)</code></pre><img src="20608568.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/dmlc/gluon-nlp/commit/f4275c0b80197e0f1bbd3a2a1a31cf07d85013b1#diff-9f211728739d8c530be209acfeaf63e70a4f30275188f5d5a4b458e61646b57eL177' target='_blank'>Link</a></div><div id='project'> Project Name: dmlc/gluon-nlp</div><div id='commit'> Commit Name: f4275c0b80197e0f1bbd3a2a1a31cf07d85013b1</div><div id='time'> Time: 2019-01-09</div><div id='author'> Author: leonard@lausen.nl</div><div id='file'> File Name: scripts/word_embeddings/evaluate_pretrained.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: </div><BR><BR><div id='link'><a href='https://github.com/NifTK/NiftyNet/commit/44a908b07a2c6a32dbd868e59147dd777714775b#diff-023d37a8c76fa73084ec27927d67d215e2eba9f0bc6e99a32ee9d11a4d647fb2L21' target='_blank'>Link</a></div><div id='project'> Project Name: NifTK/NiftyNet</div><div id='commit'> Commit Name: 44a908b07a2c6a32dbd868e59147dd777714775b</div><div id='time'> Time: 2018-05-15</div><div id='author'> Author: d.shakir@ucl.ac.uk</div><div id='file'> File Name: niftynet/layer/loss_segmentation.py</div><div id='class'> Class Name: LossFunction</div><div id='method'> Method Name: __init__</div><BR><BR><div id='link'><a href='https://github.com/NifTK/NiftyNet/commit/44a908b07a2c6a32dbd868e59147dd777714775b#diff-292a34d666d5ca1c30ac10bacb54606e671bf38c2833028933e7bf97a781e6feL14' target='_blank'>Link</a></div><div id='project'> Project Name: NifTK/NiftyNet</div><div id='commit'> Commit Name: 44a908b07a2c6a32dbd868e59147dd777714775b</div><div id='time'> Time: 2018-05-15</div><div id='author'> Author: d.shakir@ucl.ac.uk</div><div id='file'> File Name: niftynet/layer/loss_regression.py</div><div id='class'> Class Name: LossFunction</div><div id='method'> Method Name: __init__</div><BR>