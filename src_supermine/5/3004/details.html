<html><h3>641a28fbf0daff0ad1ad0f43d2c4b545cb6f9656,examples/reinforcement_learning/tutorial_cartpole_ac.py,Actor,learn,#Actor#Any#Any#Any#,106
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47     self.train_op = tf.train.AdamOptimizer(lr).minimize(-self.exp_v)  &#47&#47 minimize(-exp_v) = maximize(exp_v)

    def learn(self, s, a, td):
        <a id="change">_, exp_v = self.sess.run([self.train_op, self.exp_v], {self.s: [s], self.a: [a], self.td_error: td[0]})</a>
        return exp_v

    def choose_action(self, s):
        probs = self.sess.run(self.acts_prob, {self.s: [s]})  &#47&#47 get probabilities of all actions</code></pre><h3>After Change</h3><pre><code class='java'>
            &#47&#47 _probs = tf.nn.softmax(_logits)
            _exp_v = tl.rein.cross_entropy_reward_loss(logits=_logits, actions=[a], rewards=td[0])
        grad = tape.gradient(_exp_v, self.model.weights)
        self.optimizer.apply_gradients(<a id="change">zip(grad, self.model.weights)</a>)
        return _exp_v

    def choose_action(self, s):</code></pre><img src="15620047.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/tensorlayer/tensorlayer/commit/641a28fbf0daff0ad1ad0f43d2c4b545cb6f9656#diff-1702490f9eb46e983be30c93f51fa12ca85f2bb222524f54c295abacb9691eb0L106' target='_blank'>Link</a></div><div id='project'> Project Name: tensorlayer/tensorlayer</div><div id='commit'> Commit Name: 641a28fbf0daff0ad1ad0f43d2c4b545cb6f9656</div><div id='time'> Time: 2019-02-16</div><div id='author'> Author: dhsig552@163.com</div><div id='file'> File Name: examples/reinforcement_learning/tutorial_cartpole_ac.py</div><div id='class'> Class Name: Actor</div><div id='method'> Method Name: learn</div><BR><BR><div id='link'><a href='https://github.com/tensorlayer/tensorlayer/commit/641a28fbf0daff0ad1ad0f43d2c4b545cb6f9656#diff-1702490f9eb46e983be30c93f51fa12ca85f2bb222524f54c295abacb9691eb0L142' target='_blank'>Link</a></div><div id='project'> Project Name: tensorlayer/tensorlayer</div><div id='commit'> Commit Name: 641a28fbf0daff0ad1ad0f43d2c4b545cb6f9656</div><div id='time'> Time: 2019-02-16</div><div id='author'> Author: dhsig552@163.com</div><div id='file'> File Name: examples/reinforcement_learning/tutorial_cartpole_ac.py</div><div id='class'> Class Name: Critic</div><div id='method'> Method Name: learn</div><BR><BR><div id='link'><a href='https://github.com/catalyst-team/catalyst/commit/b22f99034d3fbad4606037aedd5c314b166e590b#diff-4b90c41989dbb3729d3154fa639530e4b36f35208469c199d80bbe6b80ebc121L23' target='_blank'>Link</a></div><div id='project'> Project Name: catalyst-team/catalyst</div><div id='commit'> Commit Name: b22f99034d3fbad4606037aedd5c314b166e590b</div><div id='time'> Time: 2020-01-27</div><div id='author'> Author: scitator@gmail.com</div><div id='file'> File Name: catalyst/dl/runner/gan.py</div><div id='class'> Class Name: GanRunner</div><div id='method'> Method Name: _batch2device</div><BR>