<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 dropout
        val = np.random.random((100, 100))
        x_list = [k.variable(val) for k in BACKENDS]
        z_list = <a id="change">[]</a>
        for x, k in zip(x_list, BACKENDS):
            z_list.append(k.eval(k.dropout(x, level=0.2)))

        <a id="change">for i in range(len(z_list) - 1):
            assert z_list[i].shape == z_list[i + 1].shape
            &#47&#47 dropout patterns are different, only check mean
            assert np.abs(z_list[i].mean() - z_list[i + 1].mean()) &lt; 0.05

       </a> check_two_tensor_operation(&quotbinary_crossentropy&quot, (4, 2), (4, 2), BACKENDS, from_logits=True)
        &#47&#47 cross_entropy call require the label is a valid probability distribution,
        &#47&#47 otherwise it is garbage in garbage out...
        &#47&#47 due to the algo difference, we can&quott guarantee CNTK has the same result on the garbage input.</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 due to the algo difference, we can&quott guarantee CNTK has the same result on the garbage input.
        &#47&#47 so create a seperate test case for valid lable input
        check_two_tensor_operation(&quotcategorical_crossentropy&quot, (4, 2), (4, 2), [KTH, KTF], from_logits=True)
        <a id="change">xval = np.asarray([[0.26157712, 0.0432167], [-0.43380741, 0.30559841],
                           [0.20225059, -0.38956559], [-0.13805378, 0.08506755]], dtype=np.float32)</a>
        yval = np.asarray([[0.46221867, 0.53778133], [0.51228984, 0.48771016],
                           [0.64916514, 0.35083486], [0.47028078, 0.52971922]], dtype=np.float32)
        check_two_tensor_operation(&quotcategorical_crossentropy&quot, xval, yval,
                                   BACKENDS, cntk_two_dynamicity=True, from_logits=True)</code></pre>