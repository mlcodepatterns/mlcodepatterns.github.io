<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 unpack packed, if input is packed. packing and then unpacking will be slower than not
        &#47&#47 packing at all, but makes SRU usage compatible with nn.RNN usage
        orig_input = input
        <a id="change">if isinstance(orig_input, PackedSequence):
            input, batch_sizes, sorted_indices, unsorted_indices = input
            length = input.size(0)
            batch_size = input.size(1)
            mask_pad = torch.arange(batch_size,
                                    device=batch_sizes.device).expand(length, batch_size)
            mask_pad = (mask_pad &gt;= batch_sizes.view(length, 1)).contiguous()
        else:
            length = input.size(0)
            batch_size = input.size(1)
            batch_sizes = None
            sorted_indices = None
            unsorted_indices = None

        &#47&#47 The dimensions of `input` should be: `(sequence_length, batch_size, input_size)`.
       </a> if input.dim() != 3:
            raise ValueError("There must be 3 dimensions for (length, batch_size, input_size)")

        if c0 is None:</code></pre><h3>After Change</h3><pre><code class='java'>
            input, lengths = nn.utils.rnn.pad_packed_sequence(input)
            max_length = lengths.max().item()
            mask_pad = torch.ByteTensor([[0] * l + [1] * (max_length - l) for l in lengths.tolist()])
            mask_pad = <a id="change">mask_pad</a>.to(<a id="change">input.device</a>).transpose(0, 1).contiguous()

        &#47&#47 The dimensions of `input` should be: `(sequence_length, batch_size, input_size)`.
        if input.dim() != 3:</code></pre>