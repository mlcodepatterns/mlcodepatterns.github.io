<html><h3>faf3aa876462323f2fa721ebd633752d6489808f,sru/modules.py,SRU,forward,#SRU#Any#Any#Any#,536
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 unpack packed, if input is packed. packing and then unpacking will be slower than not
        &#47&#47 packing at all, but makes SRU usage compatible with nn.RNN usage
        orig_input = input
        <a id="change">if isinstance(orig_input, PackedSequence):
            input, batch_sizes, sorted_indices, unsorted_indices = input
            length = input.size(0)
            batch_size = input.size(1)
            mask_pad = torch.arange(batch_size,
                                    device=batch_sizes.device).expand(length, batch_size)
            mask_pad = (mask_pad &gt;= batch_sizes.view(length, 1)).contiguous()
        else:
            length = input.size(0)
            batch_size = input.size(1)
            batch_sizes = None
            sorted_indices = None
            unsorted_indices = None

        &#47&#47 The dimensions of `input` should be: `(sequence_length, batch_size, input_size)`.
       </a> if input.dim() != 3:
            raise ValueError("There must be 3 dimensions for (length, batch_size, input_size)")

        if c0 is None:</code></pre><h3>After Change</h3><pre><code class='java'>
            input, lengths = nn.utils.rnn.pad_packed_sequence(input)
            max_length = lengths.max().item()
            mask_pad = torch.ByteTensor([[0] * l + [1] * (max_length - l) for l in lengths.tolist()])
            mask_pad = <a id="change">mask_pad</a>.to(<a id="change">input.device</a>).transpose(0, 1).contiguous()

        &#47&#47 The dimensions of `input` should be: `(sequence_length, batch_size, input_size)`.
        if input.dim() != 3:</code></pre><img src="24789370.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/asappresearch/sru/commit/faf3aa876462323f2fa721ebd633752d6489808f#diff-fbdb17c4f9a1012308449ed128e27fceac2cd837fa198a5afc3ef73ed9cd6d0cL1' target='_blank'>Link</a></div><div id='project'> Project Name: asappresearch/sru</div><div id='commit'> Commit Name: faf3aa876462323f2fa721ebd633752d6489808f</div><div id='time'> Time: 2020-09-18</div><div id='author'> Author: taolei@csail.mit.edu</div><div id='file'> File Name: sru/modules.py</div><div id='class'> Class Name: SRU</div><div id='method'> Method Name: forward</div><BR><BR><div id='link'><a href='https://github.com/ray-project/ray/commit/d5604eaba321c11c1b9616c283262c4ddea55049#diff-37bd767fc050dc8429c31c11eec66900fda9b8efbf8810ddc5a7f94eca3b8752L70' target='_blank'>Link</a></div><div id='project'> Project Name: ray-project/ray</div><div id='commit'> Commit Name: d5604eaba321c11c1b9616c283262c4ddea55049</div><div id='time'> Time: 2020-12-21</div><div id='author'> Author: sven@anyscale.io</div><div id='file'> File Name: rllib/models/torch/modules/relative_multi_head_attention.py</div><div id='class'> Class Name: RelativeMultiHeadAttention</div><div id='method'> Method Name: forward</div><BR><BR><div id='link'><a href='https://github.com/keras-team/autokeras/commit/4fb281b7f9f5e549e29addd5641eac007c5ed385#diff-9a1c847417e8b1c9bba45ab69e8e1e62745317286491c5fdf9de2ba0fb46dbdbL335' target='_blank'>Link</a></div><div id='project'> Project Name: keras-team/autokeras</div><div id='commit'> Commit Name: 4fb281b7f9f5e549e29addd5641eac007c5ed385</div><div id='time'> Time: 2019-02-09</div><div id='author'> Author: jhfjhfj1@gmail.com</div><div id='file'> File Name: autokeras/pretrained/face_detector.py</div><div id='class'> Class Name: FaceDetector</div><div id='method'> Method Name: detect_pnet</div><BR>