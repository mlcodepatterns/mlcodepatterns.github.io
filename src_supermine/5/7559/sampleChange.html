<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            self._natgrad_step(loss_fn, q_mu, q_sqrt, xi_transform)

        with tf.name_scope(f"{self._name}/natural_gradient_steps"):
            <a id="change">list(map(natural_gradient_step, *zip(*parameters)))</a>

    def _natgrad_step(
        self, loss_fn: Callable, q_mu: Parameter, q_sqrt: Parameter, xi_transform: XiTransform
    ):</code></pre><h3>After Change</h3><pre><code class='java'>
            p.unconstrained_variable for params in (q_mus, q_sqrts) for p in params
        ]

        <a id="change">with tf.GradientTape(watch_accessed_variables=False) as tape:
            tape.watch(unconstrained_variables)
            loss = loss_fn()

       </a> q_mu_grads, q_sqrt_grads = tape.gradient(loss, [q_mus, q_sqrts])
        &#47&#47 NOTE that these are the gradients in *unconstrained* space

        with tf.name_scope(f"{self._name}/natural_gradient_steps"):</code></pre>