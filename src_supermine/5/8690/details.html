<html><h3>23dffb96ac95827a3af89f6ff027d254284ba93c,onmt/inputters/inputter.py,DatasetLazyIter,__iter__,#DatasetLazyIter#,528
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        for path in paths:
            cur_dataset = torch.load(path)
            logger.info(&quotLoading dataset from %s, number of examples: %d&quot %
                        <a id="change">(path, len(cur_dataset))</a>)
            cur_dataset.fields = self.fields
            cur_iter = OrderedIterator(
                dataset=cur_dataset,</code></pre><h3>After Change</h3><pre><code class='java'>
        paths = self._paths
        if self.is_train and self.repeat:
            &#47&#47 Cycle through the shards indefinitely.
            <a id="change">paths = cycle(paths)</a>
        for path in paths:
            for batch in self._iter_dataset(path):
                yield batch
                num_batches += 1
        if self.is_train and not self.repeat and \
           num_batches % self.num_batches_multiple != 0:
            &#47&#47 When the dataset is not repeated, we might need to ensure that
            &#47&#47 the number of returned batches is the multiple of a given value.
            &#47&#47 This is important for multi GPU training to ensure that all
            &#47&#47 workers have the same number of batches to process.
            <a id="change">for path in paths:
                for batch in self._iter_dataset(path):
                    yield batch
                    num_batches += 1
                    if num_batches % self.num_batches_multiple == 0:
                        return


</a>def max_tok_len(new, count, sofar):
    
    In token batching scheme, the number of sequences is limited
    such that the total number of src/tgt tokens (including padding)</code></pre><img src="40205894.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/OpenNMT/OpenNMT-py/commit/23dffb96ac95827a3af89f6ff027d254284ba93c#diff-c61bfe8788306098fb82b484c5a6438deecf5ebc239f9e0fd4aeeaca7333b023L528' target='_blank'>Link</a></div><div id='project'> Project Name: OpenNMT/OpenNMT-py</div><div id='commit'> Commit Name: 23dffb96ac95827a3af89f6ff027d254284ba93c</div><div id='time'> Time: 2019-02-08</div><div id='author'> Author: guillaumekln@users.noreply.github.com</div><div id='file'> File Name: onmt/inputters/inputter.py</div><div id='class'> Class Name: DatasetLazyIter</div><div id='method'> Method Name: __iter__</div><BR><BR><div id='link'><a href='https://github.com/streamlit/streamlit/commit/50c87bd8a64ced239cf0e3e12fa0d78de9895574#diff-f8edb24cb34258aa0411f4d4ea008b93facef7e87c8ce2c029d8f865b9e298bbL16' target='_blank'>Link</a></div><div id='project'> Project Name: streamlit/streamlit</div><div id='commit'> Commit Name: 50c87bd8a64ced239cf0e3e12fa0d78de9895574</div><div id='time'> Time: 2018-06-18</div><div id='author'> Author: armando@playground.global</div><div id='file'> File Name: lib/streamlit/Proxy/websocket.py</div><div id='class'> Class Name: ClientWebSocket</div><div id='method'> Method Name: open</div><BR><BR><div id='link'><a href='https://github.com/tensorlayer/tensorlayer/commit/f2073333b710a340403843763ba60eb1e6699916#diff-8dac8a79e475488e587e184ea47f922be854b7a4a25c252dcff227eec19cc6f3L64' target='_blank'>Link</a></div><div id='project'> Project Name: tensorlayer/tensorlayer</div><div id='commit'> Commit Name: f2073333b710a340403843763ba60eb1e6699916</div><div id='time'> Time: 2019-04-11</div><div id='author'> Author: rundi_wu@pku.edu.cn</div><div id='file'> File Name: examples/data_process/tutorial_tfrecord2.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: read_and_decode</div><BR>