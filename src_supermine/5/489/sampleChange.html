<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        x = array.reshape((-1,)).astype(&quotfloat32&quot, copy=False)
        return nd.dot(x, x)

    norm_arrays = [_norm(arr) <a id="change">for</a> arr in arrays]

    &#47&#47 group norm arrays by ctx
    def group_by_ctx(arr_list):</code></pre><h3>After Change</h3><pre><code class='java'>
        mx.autograd.backward(ls)

    def step(self, batch_size, max_norm=None):
        Makes o<a id="change">ne step of parameter updat</a>e. Should be called after
        `fp16_optimizer.backward()`, and outside of `record()` scope.

        Parameters
        --<a id="change">------</a>--
        batch_size : int
            Batch size of data processed. Gradient will be normalized by `1/batch_size`.
            Set this to 1 if you normalized loss manually with `loss = mean(loss)`.</code></pre>