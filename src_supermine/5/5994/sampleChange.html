<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            only_predictions
        )

        <a id="change">if &quotcombined&quot in output_stats and LOSS in output_stats[&quotcombined&quot]:
            regularization = session.run(
                [self.regularization_loss],
                feed_dict={self.regularization_lambda: regularization_lambda}
            )[0]
            output_stats[&quotcombined&quot][LOSS] += regularization

        &#47&#47 todo: tf2 debugging
       </a> fake_stats = OrderedDict(
            [(&quoty&quot, OrderedDict([(&quotloss&quot, [9489.847173455057]),
                                (&quotmean_squared_error&quot, [9489.847173455057]),
                                (&quotmean_absolute_error&quot, [76.44962405086903]),</code></pre><h3>After Change</h3><pre><code class='java'>

        &#47&#47 todo tf2: hardcoding for a single output feature - need to generalize
        of_name = self.hyperparameters[&quotoutput_features&quot][0][&quotname&quot]
        <a id="change">output_feature = self.output_features[of_name]</a>

        if is_on_master():
            progress_bar = tqdm(
                desc=&quotEvaluation&quot if name is None
                else &quotEvaluation {0: &lt;5.5}&quot.format(name),
                total=batcher.steps_per_epoch,
                file=sys.stdout,
                disable=is_progressbar_disabled()
            )

        while not batcher.last_batch():
            batch = batcher.next_batch()

            &#47&#47 todo: tf2 clean up  code
            &#47&#47 result = session.run(
            &#47&#47     output_nodes,
            &#47&#47     feed_dict=self.feed_dict(
            &#47&#47         batch,
            &#47&#47         regularization_lambda=regularization_lambda,
            &#47&#47         dropout_rate=0.0,
            &#47&#47         is_training=is_training
            &#47&#47     )
            &#47&#47 )

            &#47&#47 todo: tf2 need to rationalize to reduce redundant code
            &#47&#47 create array for predictors
            &#47&#47 todo: tf2 need to handle case of single predictor, e.g., image
            predictors = reduce(lambda x, y: np.vstack((x, y)),
                                [batch[f[&quotname&quot]] for f in
                                 self.hyperparameters[&quotinput_features&quot]]).T

            &#47&#47 create array for target
            &#47&#47 is there more than one target
            if len(self.hyperparameters[&quotoutput_features&quot]) &gt; 1:
                target = reduce(lambda x, y: np.vstack((x, y)),
                                [batch[f[&quotname&quot]] for f in
                                 self.hyperparameters[&quotoutput_features&quot]]).T
            else:
                of_name = self.hyperparameters[&quotoutput_features&quot][0][&quotname&quot]
                output_feature = self.output_features[of_name]
                target = batch[
                    self.hyperparameters[&quotoutput_features&quot][0][&quotname&quot]]

            result = self.evaluation_step(
                self.keras_model,
                output_feature,
                predictors,
                target
            )

            &#47&#47 output_stats, seq_set_size = self.update_output_stats_batch(
            &#47&#47     output_stats,
            &#47&#47     seq_set_size,
            &#47&#47     collect_predictions,
            &#47&#47     only_predictions,
            &#47&#47     result
            &#47&#47 )
            if is_on_master():
                progress_bar.update(1)

        if is_on_master():
            progress_bar.close()

        &#47&#47 if self.horovod:
        &#47&#47     output_stats, seq_set_size = self.merge_workers_outputs(
        &#47&#47         output_stats,
        &#47&#47         seq_set_size
        &#47&#47     )
        &#47&#47
        &#47&#47 output_stats = self.update_output_stats(
        &#47&#47     output_stats,
        &#47&#47     set_size,
        &#47&#47     seq_set_size,
        &#47&#47     collect_predictions,
        &#47&#47     only_predictions
        &#47&#47 )

        &#47&#47 if &quotcombined&quot in output_stats and LOSS in output_stats[&quotcombined&quot]:
        &#47&#47     regularization = session.run(
        &#47&#47         [self.regularization_loss],
        &#47&#47         feed_dict={self.regularization_lambda: regularization_lambda}
        &#47&#47     )[0]
        &#47&#47     output_stats[&quotcombined&quot][LOSS] += regularization

        &#47&#47 todo: tf2 debugging
        template = f&quotDataset {name}:&quot
        <a id="change">for measure, measure_fn in output_feature.measure_functions.items():
            if measure_fn is not None:  &#47&#47 todo tf2 test is needed only during development
                template += f&quot {measure}: {measure_fn.result()}&quot

       </a> print(template)

        fake_stats = OrderedDict(
            [(&quoty&quot, OrderedDict([(&quotloss&quot, [9489.847173455057]),</code></pre>