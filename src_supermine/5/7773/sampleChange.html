<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        if fp16:
            utils.assert_fp16_available()
            from apex import amp
            <a id="change">if fp16_opt_level not in {"O1", "O2", "O3"}:
                raise ValueError("fp16 mode must be one of O1, O2, O3")

           </a> model, optimizer = amp.initialize(
                model, optimizer, opt_level=fp16_opt_level)
        elif torch.cuda.device_count() &gt; 1:
            model = torch.nn.DataParallel(model)</code></pre><h3>After Change</h3><pre><code class='java'>
        optimizer_params = \
            self.stages_config[stage].get("optimizer_params", {})
        distributed_params = \
            <a id="change">self.stages_config[stage].get("distributed_params", {})</a>

        optimizer = self._get_optimizer(
            model_params=model_params, **optimizer_params)
</code></pre>