<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
  return {k: add_grad(left[k], right[k]) for k in left}


<a id="change">grad_adders = {
    (list, list): add_grad_list,
    (dict, dict): add_grad_dict,
    (numpy.ndarray, numpy.ndarray): add_grad_numpy,
    (numpy.ndarray, float): add_grad_numpy,
    (float, numpy.ndarray): add_grad_numpy,
    (numpy.ndarray, numpy.float64): add_grad_numpy,
    (numpy.float64, numpy.ndarray): add_grad_numpy,
    (numpy.ndarray, list): add_grad_numpy,
    (list, numpy.ndarray): add_grad_numpy,
    (bool, bool): lambda left, right: left or right,
}</a>


def register_add_grad(left_type, right_type, add_grad_function):
  Register a new gradient adder supporting the given types.</code></pre><h3>After Change</h3><pre><code class='java'>
&#47&#47 The values are tuples (initializer, allow_lazy_initializer). If
&#47&#47 supports_lazy_initializer is true, Tangent may substitude actual instances
&#47&#47 of the object for the ZeroGradient wrapper, which is a lazy creator.
<a id="change">grad_initializers = {
    &#47&#47 TODO: We may be able to use ZeroGradient for ndarrays, too.
    numpy.ndarray: (numpy.zeros_like, False),
    numpy.float32: (lambda obj: 0.0, False),
    numpy.float64: (lambda obj: 0.0, False),
    numpy.int32: (init_zero_int, False),
    numpy.int64: (init_zero_int, False),
    list: (lambda obj: [init_grad(el) for el in obj], False),
    tuple: (lambda obj: [init_grad(el) for el in obj], False),
    dict: (lambda obj: {k: init_grad(v) for k, v in six.iteritems(obj)}, False),
    Stack: (lambda obj: Stack(), False),
    float: (lambda obj: 0.0, False),
    int: (init_zero_int, False),
    bool: (init_zero_bool, False),
}</a>

if hasattr(types, &quotClassType&quot):
  grad_initializers[types.ClassType] = (init_common_object, False)
else:</code></pre>