<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    )
    if is_on_master():
        logging.info(&quotTraining set: {0}&quot.format(training_set.size))
        <a id="change">logging.info(&quotValidation set: {0}&quot.format(validation_set.size))</a>
        logging.info(&quotTest set: {0}&quot.format(test_set.size))

    &#47&#47 update model definition with metadata properties
    update_model_definition_with_metadata(model_definition, train_set_metadata)</code></pre><h3>After Change</h3><pre><code class='java'>
    )
    if is_on_master():
        logging.info(&quotTraining set: {0}&quot.format(training_set.size))
        <a id="change">if validation_set is not None:
            logging.info(&quotValidation set: {0}&quot.format(validation_set.size))
       </a> if test_set is not None:
            logging.info(&quotTest set: {0}&quot.format(test_set.size))

    &#47&#47 update model definition with metadata properties
    update_model_definition_with_metadata(model_definition, train_set_metadata)

    &#47&#47 run the experiment
    model, training_results = train(
        training_set=training_set,
        validation_set=validation_set,
        test_set=test_set,
        model_definition=model_definition,
        save_path=model_dir,
        model_load_path=model_load_path,
        resume=model_resume_path is not None,
        skip_save_progress_weights=skip_save_progress_weights,
        gpus=gpus,
        gpu_fraction=gpu_fraction,
        use_horovod=use_horovod,
        random_seed=random_seed,
        debug=debug
    )
    (
        train_trainset_stats,
        train_valisest_stats,
        train_testset_stats
    ) = training_results

    if is_on_master():
        &#47&#47 save train set metadata
        save_json(
            os.path.join(
                model_dir,
                TRAIN_SET_METADATA_FILE_NAME
            ),
            train_set_metadata
        )

    &#47&#47 grab the results of the model with highest validation test performance
    validation_field = model_definition[&quottraining&quot][&quotvalidation_field&quot]
    validation_measure = model_definition[&quottraining&quot][&quotvalidation_measure&quot]
    validation_field_result = train_valisest_stats[validation_field]

    best_function = get_best_function(validation_measure)

    &#47&#47 print the results of the model with highest validation test performance
    if is_on_master():
        <a id="change">if validation_set is not None:
            &#47&#47 max or min depending on the measure
            
            epoch_best_vali_measure, best_vali_measure = best_function(
                enumerate(validation_field_result[validation_measure]),
                key=lambda pair: pair[1]
            )
            logging.info(&quotBest validation model epoch: {0}&quot.format(
                epoch_best_vali_measure + 1)
            )
            logging.info(
                &quotBest validation model {0} on validation set {1}: {2}&quot.format(
                    validation_measure,
                    validation_field,
                    best_vali_measure)
            )
        
            if test_set is not None:
                best_vali_measure_epoch_test_measure = train_testset_stats[
                    validation_field
                ][validation_measure][epoch_best_vali_measure]
                logging.info(
                    &quotBest validation model {0} on test set {1}: {2}&quot.format(
                        validation_measure,
                        validation_field,
                        best_vali_measure_epoch_test_measure
                    )
                )

    &#47&#47 save training statistics
   </a> if is_on_master():
        save_json(
            training_stats_fn,
            {</code></pre>