<html><h3>76b060f625e037d479a2eb25462a3b3f70af5bb7,chainercv/links/model/vgg/vgg16.py,VGG16,__init__,#VGG16#Any#Any#Any#Any#Any#,100
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    def __init__(self,
                 n_class=None, pretrained_model=None, mean=None,
                 initialW=None, initial_bias=None):
        <a id="change">if n_class is None:
            if pretrained_model in self._models:
                n_class = self._models[pretrained_model][&quotn_class&quot]
            else:
                n_class = 1000

       </a> if mean is None:
            if pretrained_model in self._models:
                mean = self._models[pretrained_model][&quotmean&quot]
            else:
                mean = _imagenet_mean
        self.mean = mean

        if initialW is None:
            &#47&#47 Employ default initializers used in the original paper.
            initialW = normal.Normal(0.01)
        if pretrained_model:
            &#47&#47 As a sampling process is time-consuming,
            &#47&#47 we employ a zero initializer for faster computation.
            initialW = constant.Zero()
        kwargs = {&quotinitialW&quot: initialW, &quotinitial_bias&quot: initial_bias}

        super(VGG16, self).__init__()
        with self.init_scope():
            self.conv1_1 = Conv2DActiv(None, 64, 3, 1, 1, **kwargs)
            self.conv1_2 = Conv2DActiv(None, 64, 3, 1, 1, **kwargs)
            self.pool1 = _max_pooling_2d
            self.conv2_1 = Conv2DActiv(None, 128, 3, 1, 1, **kwargs)
            self.conv2_2 = Conv2DActiv(None, 128, 3, 1, 1, **kwargs)
            self.pool2 = _max_pooling_2d
            self.conv3_1 = Conv2DActiv(None, 256, 3, 1, 1, **kwargs)
            self.conv3_2 = Conv2DActiv(None, 256, 3, 1, 1, **kwargs)
            self.conv3_3 = Conv2DActiv(None, 256, 3, 1, 1, **kwargs)
            self.pool3 = _max_pooling_2d
            self.conv4_1 = Conv2DActiv(None, 512, 3, 1, 1, **kwargs)
            self.conv4_2 = Conv2DActiv(None, 512, 3, 1, 1, **kwargs)
            self.conv4_3 = Conv2DActiv(None, 512, 3, 1, 1, **kwargs)
            self.pool4 = _max_pooling_2d
            self.conv5_1 = Conv2DActiv(None, 512, 3, 1, 1, **kwargs)
            self.conv5_2 = Conv2DActiv(None, 512, 3, 1, 1, **kwargs)
            self.conv5_3 = Conv2DActiv(None, 512, 3, 1, 1, **kwargs)
            self.pool5 = _max_pooling_2d
            self.fc6 = Linear(None, 4096, **kwargs)
            self.fc6_relu = relu
            self.fc6_dropout = dropout
            self.fc7 = Linear(None, 4096, **kwargs)
            self.fc7_relu = relu
            self.fc7_dropout = dropout
            self.fc8 = Linear(None, n_class, **kwargs)
            self.prob = softmax

        <a id="change">if pretrained_model in self._models:
            path = download_model(self._models[pretrained_model][&quoturl&quot])
            chainer.serializers.load_npz(path, self)
        elif pretrained_model:
            chainer.serializers.load_npz(pretrained_model, self)


</a>def _max_pooling_2d(x):
    return max_pooling_2d(x, ksize=2)
</code></pre><h3>After Change</h3><pre><code class='java'>
    def __init__(self,
                 n_class=None, pretrained_model=None, mean=None,
                 initialW=None, initial_bias=None):
        <a id="change">n_class, path = prepare_link_initialization(
            n_class, pretrained_model, self._models, False,
            default_out_channels=1000)</a>

        if mean is None:
            if pretrained_model in self._models:
                mean = self._models[pretrained_model][&quotmean&quot]
            else:
                mean = _imagenet_mean
        self.mean = mean

        if initialW is None:
            &#47&#47 Employ default initializers used in the original paper.
            initialW = normal.Normal(0.01)
        if pretrained_model:
            &#47&#47 As a sampling process is time-consuming,
            &#47&#47 we employ a zero initializer for faster computation.
            initialW = constant.Zero()
        kwargs = {&quotinitialW&quot: initialW, &quotinitial_bias&quot: initial_bias}

        super(VGG16, self).__init__()
        with self.init_scope():
            self.conv1_1 = Conv2DActiv(None, 64, 3, 1, 1, **kwargs)
            self.conv1_2 = Conv2DActiv(None, 64, 3, 1, 1, **kwargs)
            self.pool1 = _max_pooling_2d
            self.conv2_1 = Conv2DActiv(None, 128, 3, 1, 1, **kwargs)
            self.conv2_2 = Conv2DActiv(None, 128, 3, 1, 1, **kwargs)
            self.pool2 = _max_pooling_2d
            self.conv3_1 = Conv2DActiv(None, 256, 3, 1, 1, **kwargs)
            self.conv3_2 = Conv2DActiv(None, 256, 3, 1, 1, **kwargs)
            self.conv3_3 = Conv2DActiv(None, 256, 3, 1, 1, **kwargs)
            self.pool3 = _max_pooling_2d
            self.conv4_1 = Conv2DActiv(None, 512, 3, 1, 1, **kwargs)
            self.conv4_2 = Conv2DActiv(None, 512, 3, 1, 1, **kwargs)
            self.conv4_3 = Conv2DActiv(None, 512, 3, 1, 1, **kwargs)
            self.pool4 = _max_pooling_2d
            self.conv5_1 = Conv2DActiv(None, 512, 3, 1, 1, **kwargs)
            self.conv5_2 = Conv2DActiv(None, 512, 3, 1, 1, **kwargs)
            self.conv5_3 = Conv2DActiv(None, 512, 3, 1, 1, **kwargs)
            self.pool5 = _max_pooling_2d
            self.fc6 = Linear(None, 4096, **kwargs)
            self.fc6_relu = relu
            self.fc6_dropout = dropout
            self.fc7 = Linear(None, 4096, **kwargs)
            self.fc7_relu = relu
            self.fc7_dropout = dropout
            self.fc8 = Linear(None, n_class, **kwargs)
            self.prob = softmax

        <a id="change">if path:
            chainer.serializers.load_npz(path, self)


</a>def _max_pooling_2d(x):
    return max_pooling_2d(x, ksize=2)
</code></pre><img src="39690260.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 21</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/chainer/chainercv/commit/76b060f625e037d479a2eb25462a3b3f70af5bb7#diff-bf7d79234d2c93f45b9614f63aa2897fdb74c66a38b384c95f78412bc17e369fL100' target='_blank'>Link</a></div><div id='project'> Project Name: chainer/chainercv</div><div id='commit'> Commit Name: 76b060f625e037d479a2eb25462a3b3f70af5bb7</div><div id='time'> Time: 2018-05-01</div><div id='author'> Author: yuyuniitani@gmail.com</div><div id='file'> File Name: chainercv/links/model/vgg/vgg16.py</div><div id='class'> Class Name: VGG16</div><div id='method'> Method Name: __init__</div><BR><BR><div id='link'><a href='https://github.com/chainer/chainercv/commit/76b060f625e037d479a2eb25462a3b3f70af5bb7#diff-48dff810e871b0d15035ccd1e03b945888115a8af7e2437243cdcc52c0300383L64' target='_blank'>Link</a></div><div id='project'> Project Name: chainer/chainercv</div><div id='commit'> Commit Name: 76b060f625e037d479a2eb25462a3b3f70af5bb7</div><div id='time'> Time: 2018-05-01</div><div id='author'> Author: yuyuniitani@gmail.com</div><div id='file'> File Name: chainercv/links/model/segnet/segnet_basic.py</div><div id='class'> Class Name: SegNetBasic</div><div id='method'> Method Name: __init__</div><BR><BR><div id='link'><a href='https://github.com/chainer/chainercv/commit/76b060f625e037d479a2eb25462a3b3f70af5bb7#diff-285fa2a680c67ed3355b20d7926b41e6bf64f8acc7c8023ffca2eecf5ddfc285L87' target='_blank'>Link</a></div><div id='project'> Project Name: chainer/chainercv</div><div id='commit'> Commit Name: 76b060f625e037d479a2eb25462a3b3f70af5bb7</div><div id='time'> Time: 2018-05-01</div><div id='author'> Author: yuyuniitani@gmail.com</div><div id='file'> File Name: chainercv/experimental/links/model/fcis/fcis_resnet101.py</div><div id='class'> Class Name: FCISResNet101</div><div id='method'> Method Name: __init__</div><BR>