<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        super(TimeDistributedDense, self).__init__(**kwargs)

    def build(self, input_shape):
        self.input_spec = <a id="change">[InputSpec(dtype=K.floatx(),
                                     shape=(None,) + input_shape[1:])]</a>
        input_dim = input_shape[2]

        self.W = self.add_weight((input_dim, self.output_dim),
                                 initializer=self.init,</code></pre><h3>After Change</h3><pre><code class='java'>

    This version performs the same function as Dropout, however it drops
    entire 2D feature maps instead of individual elements. If adjacent pixels
    within feature maps <a id="change">are strongly correlated (as is normally the case in
    early convolution layers) then regular dropout will not regularize the
    activations and will otherwise just result in an effective learning rate
    decrease. In this</a> case, SpatialDropout2D will help promote independence
    between feature maps and should be used instead.

    &#47&#47 Argument<a id="change">s
        rate: float between 0 and 1. Fraction of the input units to drop.
        data_format: &quotchannels_first&quot or &quotchannels_last&quot.
            In &quotchannels_first&quot mode, the channels dimension
            (the </a>depth) is at index 1,
            in &quotchannels_last&quot mode is it at index 3.
            It defaults to the `image_data_format` value found in your
            Keras config file at `~/.keras/keras.json`.</code></pre>