<html><h3>1ee31ee45cc3386cb94bc1f5014f2687da1f63f6,keras/models.py,,save_model,#Any#Any#Any#Any#,35
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        if not proceed:
            return

    <a id="change">with h5py.File(filepath, mode=&quotw&quot) as f:
        f.attrs[&quotkeras_version&quot] = str(keras_version).encode(&quotutf8&quot)
        f.attrs[&quotbackend&quot] = K.backend().encode(&quotutf8&quot)
        f.attrs[&quotmodel_config&quot] = json.dumps({
            &quotclass_name&quot: model.__class__.__name__,
            &quotconfig&quot: model.get_config()
        }, default=get_json_type).encode(&quotutf8&quot)

        model_weights_group = f.create_group(&quotmodel_weights&quot)
        if legacy_models.needs_legacy_support(model):
            model_layers = legacy_models.legacy_sequential_layers(model)
        else:
            model_layers = model.layers
        topology.save_weights_to_hdf5_group(model_weights_group, model_layers)

        if include_optimizer and hasattr(model, &quotoptimizer&quot):
            if isinstance(model.optimizer, optimizers.TFOptimizer):
                warnings.warn(
                    &quotTensorFlow optimizers do not &quot
                    &quotmake it possible to access &quot
                    &quotoptimizer attributes or optimizer state &quot
                    &quotafter instantiation. &quot
                    &quotAs a result, we cannot save the optimizer &quot
                    &quotas part of the model save file.&quot
                    &quotYou will have to compile your model again &quot
                    &quotafter loading it. &quot
                    &quotPrefer using a Keras optimizer instead &quot
                    &quot(see keras.io/optimizers).&quot)
            else:
                f.attrs[&quottraining_config&quot] = json.dumps({
                    &quotoptimizer_config&quot: {
                        &quotclass_name&quot: model.optimizer.__class__.__name__,
                        &quotconfig&quot: model.optimizer.get_config()
                    },
                    &quotloss&quot: model.loss,
                    &quotmetrics&quot: model.metrics,
                    &quotsample_weight_mode&quot: model.sample_weight_mode,
                    &quotloss_weights&quot: model.loss_weights,
                }, default=get_json_type).encode(&quotutf8&quot)

                &#47&#47 Save optimizer weights.
                symbolic_weights = getattr(model.optimizer, &quotweights&quot)
                if symbolic_weights:
                    optimizer_weights_group = f.create_group(&quotoptimizer_weights&quot)
                    weight_values = K.batch_get_value(symbolic_weights)
                    weight_names = []
                    for i, (w, val) in enumerate(zip(symbolic_weights,
                                                     weight_values)):
                        &#47&#47 Default values of symbolic_weights is /variable
                        &#47&#47 for Theano and CNTK
                        if K.backend() == &quottheano&quot or K.backend() == &quotcntk&quot:
                            if hasattr(w, &quotname&quot):
                                if w.name.split(&quot/&quot)[-1] == &quotvariable&quot:
                                    name = str(w.name) + &quot_&quot + str(i)
                                else:
                                    name = str(w.name)
                            else:
                                name = &quotparam_&quot + str(i)
                        else:
                            if hasattr(w, &quotname&quot) and w.name:
                                name = str(w.name)
                            else:
                                name = &quotparam_&quot + str(i)
                        weight_names.append(name.encode(&quotutf8&quot))
                    optimizer_weights_group.attrs[&quotweight_names&quot] = weight_names
                    for name, val in zip(weight_names, weight_values):
                        param_dset = optimizer_weights_group.create_dataset(
                            name,
                            val.shape,
                            dtype=val.dtype)
                        if not val.shape:
                            &#47&#47 scalar
                            param_dset[()] = val
                        else:
                            param_dset[:] = val
        f.flush()


</a>def load_model(filepath, custom_objects=None, compile=True):
    Loads a model saved via `save_model`.

    &#47&#47 Arguments</code></pre><h3>After Change</h3><pre><code class='java'>

    from . import __version__ as keras_version

    <a id="change">if not isinstance(filepath, h5py.File):
        &#47&#47 If file exists and should not be overwritten.
        if not overwrite and os.path.isfile(filepath):
            proceed = ask_to_proceed_with_overwrite(filepath)
            if not proceed:
                return

        f = h5py.File(filepath, mode=&quotw&quot)
        opened_new_file = True
    else:
        f = filepath
        opened_new_file = False

   </a> try:
        f.attrs[&quotkeras_version&quot] = str(keras_version).encode(&quotutf8&quot)
        f.attrs[&quotbackend&quot] = K.backend().encode(&quotutf8&quot)
        f.attrs[&quotmodel_config&quot] = json.dumps({</code></pre><img src="25847914.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/keras-team/keras/commit/1ee31ee45cc3386cb94bc1f5014f2687da1f63f6#diff-b36b9e0ef3d3d534810dc5cc50ad9f7ed1c5f17b9b3419157cd5ad8a14be9f2eL101' target='_blank'>Link</a></div><div id='project'> Project Name: keras-team/keras</div><div id='commit'> Commit Name: 1ee31ee45cc3386cb94bc1f5014f2687da1f63f6</div><div id='time'> Time: 2018-03-31</div><div id='author'> Author: predrag.gruevski@gmail.com</div><div id='file'> File Name: keras/models.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: save_model</div><BR><BR><div id='link'><a href='https://github.com/dmlc/gluon-nlp/commit/a947d66d28baaae1302363556a8a18b04fa6aa40#diff-8c38d8d7e6e2acb0239e4561bbe11789150dc07c3e01274ae1e4fd4348f36225L249' target='_blank'>Link</a></div><div id='project'> Project Name: dmlc/gluon-nlp</div><div id='commit'> Commit Name: a947d66d28baaae1302363556a8a18b04fa6aa40</div><div id='time'> Time: 2018-08-16</div><div id='author'> Author: leonard@lausen.nl</div><div id='file'> File Name: gluonnlp/embedding/evaluation.py</div><div id='class'> Class Name: ThreeCosMul</div><div id='method'> Method Name: __init__</div><BR><BR><div id='link'><a href='https://github.com/keras-team/keras/commit/1ee31ee45cc3386cb94bc1f5014f2687da1f63f6#diff-b36b9e0ef3d3d534810dc5cc50ad9f7ed1c5f17b9b3419157cd5ad8a14be9f2eL237' target='_blank'>Link</a></div><div id='project'> Project Name: keras-team/keras</div><div id='commit'> Commit Name: 1ee31ee45cc3386cb94bc1f5014f2687da1f63f6</div><div id='time'> Time: 2018-03-31</div><div id='author'> Author: predrag.gruevski@gmail.com</div><div id='file'> File Name: keras/models.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: load_model</div><BR>