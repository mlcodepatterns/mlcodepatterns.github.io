<html><h3>36bda8432b2ed23f623c8c3031b2cba148bec93b,rllib/examples/policy/episode_env_aware_policy.py,EpisodeEnvAwarePolicy,compute_actions_from_input_dict,#EpisodeEnvAwarePolicy#Any#Any#Any#,48
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        self.episode_id = input_dict[SampleBatch.EPS_ID][0]
        self.env_id = input_dict["env_id"][0]
        &#47&#47 Always return (episodeID, envID)
        <a id="change">return [
            np.array([self.episode_id, self.env_id]) for _ in input_dict["obs"]
        ], [], {}</a>

    @override(Policy)
    def postprocess_trajectory(self,
                               sample_batch,</code></pre><h3>After Change</h3><pre><code class='java'>
                                        explore=None,
                                        timestep=None,
                                        **kwargs):
        <a id="change">ts = input_dict["t"]</a>
        print(ts)
        &#47&#47 Always return [episodeID, envID] as actions.
        <a id="change">actions = np.array([[
            input_dict[SampleBatch.AGENT_INDEX][i],
            input_dict[SampleBatch.EPS_ID][i], input_dict["env_id"][i]
        ] for i, _ in enumerate(input_dict["obs"])])</a>
        <a id="change">states = [
            np.array([[ts[i]] for i in range(len(input_dict["obs"]))])
            for _ in range(2)
        ]</a>
        <a id="change">return actions, states, {}</a>

    @override(Policy)
    def postprocess_trajectory(self,
                               sample_batch,</code></pre><img src="17535304.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/ray-project/ray/commit/36bda8432b2ed23f623c8c3031b2cba148bec93b#diff-5de596895936b951561c4edc3a555595b84489dcef8f9367199c23f266b0141eL48' target='_blank'>Link</a></div><div id='project'> Project Name: ray-project/ray</div><div id='commit'> Commit Name: 36bda8432b2ed23f623c8c3031b2cba148bec93b</div><div id='time'> Time: 2020-10-01</div><div id='author'> Author: sven@anyscale.io</div><div id='file'> File Name: rllib/examples/policy/episode_env_aware_policy.py</div><div id='class'> Class Name: EpisodeEnvAwarePolicy</div><div id='method'> Method Name: compute_actions_from_input_dict</div><BR><BR><div id='link'><a href='https://github.com/d2l-ai/d2l-zh/commit/3a770cbc97085c2cd4eaa0a46b2bc037f35389c2#diff-09d0cbaf891d623ac245ccf84485a687b554217349ca55557c60b33234b969aeL78' target='_blank'>Link</a></div><div id='project'> Project Name: d2l-ai/d2l-zh</div><div id='commit'> Commit Name: 3a770cbc97085c2cd4eaa0a46b2bc037f35389c2</div><div id='time'> Time: 2017-10-25</div><div id='author'> Author: muli@cs.cmu.edu</div><div id='file'> File Name: utils.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: evaluate_accuracy</div><BR><BR><div id='link'><a href='https://github.com/NervanaSystems/coach/commit/19ad2d60a7022bb5125855c029f27d86aaa46d64#diff-fa66242c953f346b334335d151a4bc3b3b92bc2f9fb5620e855b06402d8b3af5L65' target='_blank'>Link</a></div><div id='project'> Project Name: NervanaSystems/coach</div><div id='commit'> Commit Name: 19ad2d60a7022bb5125855c029f27d86aaa46d64</div><div id='time'> Time: 2019-07-14</div><div id='author'> Author: gal.leibovich@intel.com</div><div id='file'> File Name: rl_coach/filters/reward/reward_normalization_filter.py</div><div id='class'> Class Name: RewardNormalizationFilter</div><div id='method'> Method Name: filter</div><BR>