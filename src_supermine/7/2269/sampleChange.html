<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
def make_features(batch, fields):
    &#47&#47 This is a bit hacky for now.
    feats = []
    <a id="change">for j in range(100):
        key = "src_feat_" + str(j)
        if key not in fields:
            break
        feats.append(batch.__dict__[key])
   </a> cat = [batch.src[0]] + feats
    cat = [c.unsqueeze(2) for c in cat]
    return torch.cat(cat, 2)
</code></pre><h3>After Change</h3><pre><code class='java'>
        _, src_lengths = batch.src
        src = onmt.IO.make_features(batch, self.fields)

        &#47&#47  (1) run the encod<a id="change">er on the src
        encStates, context</a> = self.model.encoder(src, l<a id="change">engths=src_lengths)
        en</a>cStates = self.model.init_decoder_state(context, encStates)

        useMasking = (self._type == "text")
        &#47&#47  This mask is applied to the attention model inside the decoder</code></pre>