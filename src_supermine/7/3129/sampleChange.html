<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        with self.name_scope():
            self.all_layers = nn.HybridSequential(prefix=&quotlayers_&quot)
            <a id="change">with self.all_layers.name_scope():
                for layer_idx in range(num_layers):
                    self.all_layers.add(
                      TransformerEncoderLayer(units=units,
                                              hidden_size=hidden_size,
                                              num_heads=num_heads,
                                              attention_dropout_prob=attention_dropout_prob,
                                              hidden_dropout_prob=hidden_dropout_prob,
                                              layer_norm_eps=layer_norm_eps,
                                              weight_initializer=weight_initializer,
                                              bias_initializer=bias_initializer,
                                              activation=activation,
                                              prefix=&quot{}_&quot.format(layer_idx)))

   </a> def hybrid_forward(self, F, data, valid_length):
        
        Generate the representation given the inputs.
</code></pre><h3>After Change</h3><pre><code class='java'>
        self.embed_layer_norm = nn.LayerNorm(epsilon=self.layer_norm_eps)
        self.embed_dropout = nn.Dropout(hidden_dropout_prob)
        &#47&#47 Construct token type embedding
        self<a id="change">.token_type_embed = nn.Embedding(input_dim=num_token_types,
                                             output_dim=units,
                                             weight_initializer=weight_initializer)
        self.token_pos_embed = PositionalEmbedding(units=units,
                                                   max_length=max_length,
                                                   dtype=self._dtype,
                                                   method=pos_embed_type)
        if self.use_pooler:
            &#47&#47 Construct pooler
            self.pooler = nn.Dense(units=units,
                     </a>              in_units=units,
                                   flatten=False,
                                   activation=&quottanh&quot,
                                   weight_initializer=weight_initializer,</code></pre>