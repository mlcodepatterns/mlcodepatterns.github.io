<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    ) -&gt; None:
        super().__init__(vocab, regularizer)

        <a id="change">if isinstance(bert_model, str):
            self.bert_model = BertModel.from_pretrained(bert_model)
        else:
            self.bert_model = bert_model

       </a> self.num_classes = self.vocab.get_vocab_size("labels")
        if srl_eval_path is not None:
            &#47&#47 For the span based evaluation, we don&quott want to consider labels
            &#47&#47 for verb, because the verb index is provided to the model.</code></pre><h3>After Change</h3><pre><code class='java'>
            `TextFieldEmbedder`. For this model, this must be a `SingleIdTokenIndexer` which
            indexes wordpieces from the BERT vocabulary.
        verb_indicator: torch.LongTensor, required.
            An integer `Sequenc<a id="change">eFeatureField` representation of the position of the verb
            in the sentence. This should have shape (batch_size, num_tokens) and importantly, can be
            all zeros, in t</a>he case that the sentence has no verbal predicate.
        tags : torch.LongTensor, optional (default = None)
            A torch tensor representing the sequence of integer gold class labels<a id="change">
            of shape `(batch_size, num_tokens)`
        metadata : `List[Dict[str, Any]]`, optional, (default = None)
            meta</a>data containg the original words in the sentence, the verb to compute the
            frame for, and start offsets for converting wordpieces back to a sequence of words,
            under &quotwords&quot, &quotverb&quot and &quotoffsets&quot keys, respectively.
</code></pre>