<html><h3>86cff17e7ef1b355e1ab4862ccd664ed4c856227,python/ray/util/sgd/torch/distributed_torch_runner.py,DistributedTorchRunner,_get_model_state_dicts,#DistributedTorchRunner#,140
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        
        cpu_state_dicts = []
        for model in self.models:
            <a id="change">state_dict = model.module.state_dict()</a>
            &#47&#47 This is so that we create a duplicate of weights into CPU rather
            &#47&#47 than move the model weights out of the GPU so that we can
            &#47&#47 resume training while saving intermediate checkpoints.
            <a id="change">cpu_state_dicts += [{k: v.cpu() for k, v in state_dict.items()}]</a>
        return cpu_state_dicts

    def _set_model_state_dicts(self, model_state_dicts):
        for model, model_state_dict in zip(self.models, model_state_dicts):</code></pre><h3>After Change</h3><pre><code class='java'>

        This is needed for PyTorch DistributedDataParallel models.
        
        return <a id="change">[model.module.state_dict() for model in self.models]</a>

    def _set_model_state_dicts(self, model_state_dicts):
        for model, model_state_dict in zip(self.models, model_state_dicts):
            model.module.load_state_dict(model_state_dict)</code></pre><img src="32526880.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/ray-project/ray/commit/86cff17e7ef1b355e1ab4862ccd664ed4c856227#diff-bcbbc871d3b955a0ea6b42e6dbc2213e0b847688efae523c35d5ab5b3ee175e9L145' target='_blank'>Link</a></div><div id='project'> Project Name: ray-project/ray</div><div id='commit'> Commit Name: 86cff17e7ef1b355e1ab4862ccd664ed4c856227</div><div id='time'> Time: 2020-03-30</div><div id='author'> Author: rliaw@berkeley.edu</div><div id='file'> File Name: python/ray/util/sgd/torch/distributed_torch_runner.py</div><div id='class'> Class Name: DistributedTorchRunner</div><div id='method'> Method Name: _get_model_state_dicts</div><BR><BR><div id='link'><a href='https://github.com/ray-project/ray/commit/86cff17e7ef1b355e1ab4862ccd664ed4c856227#diff-31d88f3d8a68242e96f2e27954833b60dfaa3bbb5a57fbb1c2dc483dbeb12131L229' target='_blank'>Link</a></div><div id='project'> Project Name: ray-project/ray</div><div id='commit'> Commit Name: 86cff17e7ef1b355e1ab4862ccd664ed4c856227</div><div id='time'> Time: 2020-03-30</div><div id='author'> Author: rliaw@berkeley.edu</div><div id='file'> File Name: python/ray/util/sgd/torch/torch_runner.py</div><div id='class'> Class Name: TorchRunner</div><div id='method'> Method Name: _get_model_state_dicts</div><BR><BR><div id='link'><a href='https://github.com/hanxiao/bert-as-service/commit/56e5ffcdef609e00fb3fab14d8f447c4edf22460#diff-38279be819ed053058699dc5ecd46739588b8ee812355a7147a779e87a6145d1L24' target='_blank'>Link</a></div><div id='project'> Project Name: hanxiao/bert-as-service</div><div id='commit'> Commit Name: 56e5ffcdef609e00fb3fab14d8f447c4edf22460</div><div id='time'> Time: 2018-11-27</div><div id='author'> Author: hanhxiao@tencent.com</div><div id='file'> File Name: example5.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: </div><BR>