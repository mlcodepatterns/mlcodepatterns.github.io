<html><h3>5ec08ed0e16d87c029bc5d9de46b95800d0bc470,texar/losses/mle_losses.py,,smoothing_cross_entropy,#Any#Any#Any#Any#Any#,169
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    &#47&#47 We subtract it just for readability, makes no difference on learning.
    normalizing = -(
        confidence * tf.log(confidence) + tf.to_float(vocab_size - 1) *
        low_confidence * <a id="change">tf.log(low_confidence + 1e-20)</a>)

    if gaussian and confidence &gt; 0.0:
      labels = tf.cast(labels, tf.float32)
      normal_dist = tf.distributions.Normal(loc=labels, scale=confidence)
      &#47&#47 Locations to evaluate the probability distributions.
      soft_targets = normal_dist.prob(
          tf.cast(tf.range(vocab_size), tf.float32)[:, None, None, None, None])
      &#47&#47 Reordering soft_targets from [vocab_size, batch_size, ?, ?, ?] to match
      &#47&#47 logits: [batch_size, ?, ?, ?, vocab_size]
      soft_targets = tf.transpose(soft_targets, perm=[1, 2, 3, 4, 0])
    else:
      soft_targets = tf.one_hot(
          tf.cast(labels, tf.int32),
          depth=vocab_size,
          on_value=confidence,
          off_value=low_confidence)
    xentropy = tf.nn.softmax_cross_entropy_with_logits(
        logits=logits, labels=soft_targets)
    <a id="change">return xentropy - normalizing</a>

</code></pre><h3>After Change</h3><pre><code class='java'>
        cross_entropy_fn = tf.nn.softmax_cross_entropy_with_logits_v2
    else:
        cross_entropy_fn = tf.nn.softmax_cross_entropy_with_logits
    <a id="change">return cross_entropy_fn(
        logits=logits, labels=soft_targets)</a>
</code></pre><img src="16567996.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/asyml/texar/commit/5ec08ed0e16d87c029bc5d9de46b95800d0bc470#diff-aa3b0abc971e6b4ee6deb4b56324c10c76b3d3b137cd0f83e55487a7843a0861L189' target='_blank'>Link</a></div><div id='project'> Project Name: asyml/texar</div><div id='commit'> Commit Name: 5ec08ed0e16d87c029bc5d9de46b95800d0bc470</div><div id='time'> Time: 2018-05-03</div><div id='author'> Author: shore@pku.edu.cn</div><div id='file'> File Name: texar/losses/mle_losses.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: smoothing_cross_entropy</div><BR><BR><div id='link'><a href='https://github.com/GPflow/GPflow/commit/456b9ed099cc5f7e99880371ac9d1924095769f3#diff-70037317547e40e30fcf6e22a42c988332d07d34b02af4245d4911377936fa02L139' target='_blank'>Link</a></div><div id='project'> Project Name: GPflow/GPflow</div><div id='commit'> Commit Name: 456b9ed099cc5f7e99880371ac9d1924095769f3</div><div id='time'> Time: 2017-05-26</div><div id='author'> Author: joachim.vanderherten@ugent.be</div><div id='file'> File Name: GPflow/transforms.py</div><div id='class'> Class Name: Log1pe</div><div id='method'> Method Name: backward</div><BR><BR><div id='link'><a href='https://github.com/GPflow/GPflow/commit/916458eba3f928893ed4f9bec5bb7e5a2aac94d7#diff-d9dbad6c34a8a14fab2d9799368ba8893f41395b54111cd09e10c707dbed2262L89' target='_blank'>Link</a></div><div id='project'> Project Name: GPflow/GPflow</div><div id='commit'> Commit Name: 916458eba3f928893ed4f9bec5bb7e5a2aac94d7</div><div id='time'> Time: 2018-06-13</div><div id='author'> Author: st--@users.noreply.github.com</div><div id='file'> File Name: gpflow/likelihoods.py</div><div id='class'> Class Name: Likelihood</div><div id='method'> Method Name: predict_density</div><BR>