<html><h3>f4275c0b80197e0f1bbd3a2a1a31cf07d85013b1,scripts/word_embeddings/evaluate_pretrained.py,,,#,173
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

    &#47&#47 Load pre-trained embeddings
    if not args_.embedding_path:
        if <a id="change">args_.embedding_name.lower()</a> == &quotfasttext&quot:
            token_embedding_ = nlp.embedding.create(
                args_.embedding_name,
                source=args_.embedding_source,</code></pre><h3>After Change</h3><pre><code class='java'>

    if args_.similarity_datasets:
        with utils.print_time(&quotfind relevant tokens for similarity&quot):
            <a id="change">tokens = evaluation.get_similarity_task_tokens(args_)</a>
        vocab = nlp.Vocab(nlp.data.count_tokens(tokens))
        with utils.print_time(&quotset {} embeddings&quot.format(len(tokens))):
            vocab.set_embedding(token_embedding_)
        evaluation.evaluate_similarity(
            args_, vocab.embedding, ctx, logfile=os.path.join(
                args_.logdir, &quotsimilarity{}.tsv&quot.format(name)))
    if args_.analogy_datasets:
        with utils.print_time(&quotextend open vocabulary with &quot
                              &quotOOV tokens for analogy&quot):
            tokens = evaluation.get_analogy_task_tokens(args_)
            if token_embedding_.unknown_token is not None:
                tokens.update(token_embedding_.idx_to_token[1:])
            else:
                tokens.update(token_embedding_.idx_to_token)
        vocab = nlp.Vocab(nlp.data.count_tokens(tokens))
        with utils.print_time(&quotset {} embeddings&quot.format(<a id="change">len(tokens)</a>)):
            vocab.set_embedding(token_embedding_)
        evaluation.evaluate_analogy(
            args_, vocab.embedding, ctx, logfile=os.path.join(</code></pre><img src="25047224.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/dmlc/gluon-nlp/commit/f4275c0b80197e0f1bbd3a2a1a31cf07d85013b1#diff-9f211728739d8c530be209acfeaf63e70a4f30275188f5d5a4b458e61646b57eL177' target='_blank'>Link</a></div><div id='project'> Project Name: dmlc/gluon-nlp</div><div id='commit'> Commit Name: f4275c0b80197e0f1bbd3a2a1a31cf07d85013b1</div><div id='time'> Time: 2019-01-09</div><div id='author'> Author: leonard@lausen.nl</div><div id='file'> File Name: scripts/word_embeddings/evaluate_pretrained.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: </div><BR><BR><div id='link'><a href='https://github.com/streamlit/streamlit/commit/3e96b208fe5bc38223eb453b68a03dae51a33544#diff-4734668dc6290a21edb0ef1579259622495453c3f4d0ba272626ac29b6e28db2L26' target='_blank'>Link</a></div><div id='project'> Project Name: streamlit/streamlit</div><div id='commit'> Commit Name: 3e96b208fe5bc38223eb453b68a03dae51a33544</div><div id='time'> Time: 2018-10-22</div><div id='author'> Author: thiagot@gmail.com</div><div id='file'> File Name: lib/streamlit/caseconverters.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: to_lower_camel_case</div><BR><BR><div id='link'><a href='https://github.com/deepmipt/DeepPavlov/commit/cb0c025ab87216d35b68a2b4b36d61621acd76ba#diff-4a928ee319c444f15b0c4c9492b95149c3ca73146feb4d6a7f5e95bd4ca17f0fL70' target='_blank'>Link</a></div><div id='project'> Project Name: deepmipt/DeepPavlov</div><div id='commit'> Commit Name: cb0c025ab87216d35b68a2b4b36d61621acd76ba</div><div id='time'> Time: 2018-01-31</div><div id='author'> Author: arkhipov@yahoo.com</div><div id='file'> File Name: deeppavlov/models/ner/slotfill.py</div><div id='class'> Class Name: DstcSlotFillingNetwork</div><div id='method'> Method Name: infer</div><BR>