<html><h3>42efaa53edce9b84a98fef1fce24502e6d2ba941,examples/transformer.py,,,#,11
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                writer.add_summary(mgd, global_step=step)
                for index, line in enumerate(zip(source, sourcetxt, target, targettxt)):
                    print(&quot{}:{} source:{} txt:{}&quot.format((step-1)*32+index, step, line[0], line[1]))
                    print(&quot{}:{} target:{} txt:{}&quot.format((step-1)*32+index, step, <a id="change">line[2]</a>, line[3]))
                for var in tf.trainable_variables():
                     print(&quotname:{}\tshape:{}\ttype:{}&quot.format(var.name, var.shape, var.dtype))
                if step % 1000 == 0:</code></pre><h3>After Change</h3><pre><code class='java'>
                        for line in source.tolist()]
                targettxt = [ &quot &quot.join([text_database.target_vocab._id_to_token_map_py[i] for i in line]) \
                        for line in target.tolist()]
                predicttxt = [ &quot &quot.join([text_database.target_vocab._id_to_token_map_py[i] <a id="change">for</a> i in line])\
                        for line in <a id="change">predict.tolist()</a>]
                writer.add_summary(mgd, global_step=step)
                &#47&#47for index, line in enumerate(zip(source, sourcetxt, target, targettxt, predict, predicttxt)):
                &#47&#47    print(&quot{}:{} source:{} txt:{}&quot.format((step-1)*32+index, step, line[0], line[1]))</code></pre><img src="15900402.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 5</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/asyml/texar/commit/42efaa53edce9b84a98fef1fce24502e6d2ba941#diff-43760dfb5c3bab72da19051bc8473cc4a86b5b12ccc0e699c256eb599eb3c42bL54' target='_blank'>Link</a></div><div id='project'> Project Name: asyml/texar</div><div id='commit'> Commit Name: 42efaa53edce9b84a98fef1fce24502e6d2ba941</div><div id='time'> Time: 2017-12-08</div><div id='author'> Author: shore@pku.edu.cn</div><div id='file'> File Name: examples/transformer.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: </div><BR><BR><div id='link'><a href='https://github.com/hanxiao/bert-as-service/commit/2bfe5bfcec7759ae022b1a479411aa7d1b8401f1#diff-1952d8eaead7f712e29f5645e63c4a4f431806db0ce05a06c187bbc81f72b592L26' target='_blank'>Link</a></div><div id='project'> Project Name: hanxiao/bert-as-service</div><div id='commit'> Commit Name: 2bfe5bfcec7759ae022b1a479411aa7d1b8401f1</div><div id='time'> Time: 2019-05-06</div><div id='author'> Author: zyn2122@gmail.com</div><div id='file'> File Name: example/example7.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: </div><BR><BR><div id='link'><a href='https://github.com/NVIDIA/OpenSeq2Seq/commit/a7b27761c6f02686135d9af83a300f23cb8d71ab#diff-bad5cf47a1e1c4e4fc80651a13828c81bcd9eaba3d69e6f5148a38d058938851L174' target='_blank'>Link</a></div><div id='project'> Project Name: NVIDIA/OpenSeq2Seq</div><div id='commit'> Commit Name: a7b27761c6f02686135d9af83a300f23cb8d71ab</div><div id='time'> Time: 2018-10-10</div><div id='author'> Author: vlavrukhin@nvidia.com</div><div id='file'> File Name: open_seq2seq/models/speech2text.py</div><div id='class'> Class Name: Speech2Text</div><div id='method'> Method Name: evaluate</div><BR><BR><div id='link'><a href='https://github.com/aleju/imgaug/commit/8147376c79287a1fe56f230e6f444c4f2d70f2fe#diff-52655f854e5777e8c8477b4edeaf9edc204e433b24866740d25a2d5ddc4d5509L2841' target='_blank'>Link</a></div><div id='project'> Project Name: aleju/imgaug</div><div id='commit'> Commit Name: 8147376c79287a1fe56f230e6f444c4f2d70f2fe</div><div id='time'> Time: 2019-10-15</div><div id='author'> Author: kontakt@ajung.name</div><div id='file'> File Name: imgaug/augmenters/geometric.py</div><div id='class'> Class Name: PerspectiveTransform</div><div id='method'> Method Name: _draw_samples</div><BR><BR><div id='link'><a href='https://github.com/NVIDIA/OpenSeq2Seq/commit/a7b27761c6f02686135d9af83a300f23cb8d71ab#diff-bad5cf47a1e1c4e4fc80651a13828c81bcd9eaba3d69e6f5148a38d058938851L124' target='_blank'>Link</a></div><div id='project'> Project Name: NVIDIA/OpenSeq2Seq</div><div id='commit'> Commit Name: a7b27761c6f02686135d9af83a300f23cb8d71ab</div><div id='time'> Time: 2018-10-10</div><div id='author'> Author: vlavrukhin@nvidia.com</div><div id='file'> File Name: open_seq2seq/models/speech2text.py</div><div id='class'> Class Name: Speech2Text</div><div id='method'> Method Name: maybe_print_logs</div><BR>