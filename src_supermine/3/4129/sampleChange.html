<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                TD_targets[i, batch.actions()[i]] -= self.alpha * advantage_learning_update

            &#47&#47 mixing monte carlo updates
            monte_carlo_target = <a id="change">batch</a>.total_returns()[i]
            TD_targets[i, batch.actions()[i]] = (1 - self.monte_carlo_mixing_rate) * TD_targets[i, batch.actions()[i]] \
                                        + self.monte_carlo_mixing_rate * monte_carlo_target
</code></pre><h3>After Change</h3><pre><code class='java'>

        &#47&#47 calculate TD error
        TD_targets = np.copy(q_st_online)
        <a id="change">total_returns = batch.n_step_discounted_rewards()</a>
        for i in range(self.ap.network_wrappers[&quotmain&quot].batch_size):
            TD_targets[i, batch.actions()[i]] = batch.rewards()[i] + \
                                        (1.0 - batch.game_overs()[i]) * self.ap.algorithm.discount * \
                                                     q_st_plus_1_target[i][selected_actions[i]]</code></pre>