<html><h3>e9aea97df1dc7878827ac193ba75cbea0b3ee351,ludwig/models/modules/sequence_decoders.py,SequenceGeneratorDecoder,__init__,#SequenceGeneratorDecoder#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#,32
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        else:
            self.vocab_size = self.num_classes

        <a id="change">self.embeddings_dec</a> = Embedding(num_classes, embedding_size)
        <a id="change">self.decoder_cell</a> = LSTMCell(state_size)

        if attention_mechanism:
            if attention_mechanism == &quotbahdanau&quot:
                pass
            elif attention_mechanism == &quotluong&quot:
                self.attention_mechanism = tfa.seq2seq.LuongAttention(
                    state_size,
                    None,  &#47&#47 todo tf2: confirm on need
                    memory_sequence_length=max_sequence_length  &#47&#47 todo tf2: confirm inputs or output seq length
                )
            else:
                raise ValueError(
                    "Attention specificaiton &quot{}&quot is invalid.  Valid values are "
                    "&quotbahdanau&quot or &quotluong&quot.".format(self.attention_mechanism))

            <a id="change">self.decoder_cell</a> = tfa.seq2seq.AttentionWrapper(
                self.decoder_cell,
                self.attention_mechanism
            )

        self.sampler = tfa.seq2seq.sampler.TrainingSampler()

        <a id="change">self.projection_layer = Dense(
            units=num_classes,
            use_bias=use_bias,
            kernel_initializer=weights_initializer,
            bias_initializer=bias_initializer,
            kernel_regularizer=weights_regularizer,
            bias_regularizer=bias_regularizer,
            activity_regularizer=activity_regularizer
        )</a>

        self.decoder = \
            tfa.seq2seq.basic_decoder.BasicDecoder(self.decoder_cell,
                                                    self.sampler,</code></pre><h3>After Change</h3><pre><code class='java'>
        self.decoder_embedding = tf.keras.layers.Embedding(
            input_dim=output_vocab_size,
            output_dim=embedding_dims)
        <a id="change">self.dense_layer</a> = tf.keras.layers.Dense(output_vocab_size)
        self.decoder_rnncell = tf.keras.layers.LSTMCell(rnn_units)

        &#47&#47 Sampler
        self.sampler = tfa.seq2seq.sampler.TrainingSampler()

        self.attention_mechanism = None
        self.rnn_units = rnn_units

        print(&quotsetting up attention for&quot, attention_mechanism)
        <a id="change">if attention_mechanism is not None:
            self.attention_mechanism = self.build_attention_mechanism(
                attention_mechanism,
                dense_units
            )
            self.decoder_rnncell = self.build_rnn_cell()

       </a> self.decoder = tfa.seq2seq.BasicDecoder(self.decoder_rnncell,
                                                sampler=self.sampler,
                                                output_layer=self.dense_layer)
</code></pre><img src="29772231.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 11</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/uber/ludwig/commit/e9aea97df1dc7878827ac193ba75cbea0b3ee351#diff-c9939725f3db666ea558a390c6beae039a2f53db3ecf738c5ca12c5ca1667094L1' target='_blank'>Link</a></div><div id='project'> Project Name: uber/ludwig</div><div id='commit'> Commit Name: e9aea97df1dc7878827ac193ba75cbea0b3ee351</div><div id='time'> Time: 2020-05-05</div><div id='author'> Author: jimthompson5802@gmail.com</div><div id='file'> File Name: ludwig/models/modules/sequence_decoders.py</div><div id='class'> Class Name: SequenceGeneratorDecoder</div><div id='method'> Method Name: __init__</div><BR><BR><div id='link'><a href='https://github.com/uber/ludwig/commit/e9aea97df1dc7878827ac193ba75cbea0b3ee351#diff-c9939725f3db666ea558a390c6beae039a2f53db3ecf738c5ca12c5ca1667094L32' target='_blank'>Link</a></div><div id='project'> Project Name: uber/ludwig</div><div id='commit'> Commit Name: e9aea97df1dc7878827ac193ba75cbea0b3ee351</div><div id='time'> Time: 2020-05-05</div><div id='author'> Author: jimthompson5802@gmail.com</div><div id='file'> File Name: ludwig/models/modules/sequence_decoders.py</div><div id='class'> Class Name: SequenceGeneratorDecoder</div><div id='method'> Method Name: __init__</div><BR><BR><div id='link'><a href='https://github.com/asyml/texar/commit/caca2348bd54ec25d71ee05fd2a58e12db39f2e4#diff-197e32a650b5585b4875dd4c5eaeeedc069033839bad0c138b1c1728493c2938L35' target='_blank'>Link</a></div><div id='project'> Project Name: asyml/texar</div><div id='commit'> Commit Name: caca2348bd54ec25d71ee05fd2a58e12db39f2e4</div><div id='time'> Time: 2018-03-24</div><div id='author'> Author: zhitinghu@gmail.com</div><div id='file'> File Name: texar/modules/decoders/rnn_decoder_base.py</div><div id='class'> Class Name: RNNDecoderBase</div><div id='method'> Method Name: __init__</div><BR><BR><div id='link'><a href='https://github.com/dmlc/gluon-nlp/commit/3c874575bf40e8b1fa2280371131a8f29ebb3e98#diff-eb9004e43facd91e0014967f61b5002cf65f851fc227180da1a0fe492056636aL179' target='_blank'>Link</a></div><div id='project'> Project Name: dmlc/gluon-nlp</div><div id='commit'> Commit Name: 3c874575bf40e8b1fa2280371131a8f29ebb3e98</div><div id='time'> Time: 2020-07-28</div><div id='author'> Author: xshiab@connect.ust.hk</div><div id='file'> File Name: src/gluonnlp/models/albert.py</div><div id='class'> Class Name: AlbertModel</div><div id='method'> Method Name: __init__</div><BR>