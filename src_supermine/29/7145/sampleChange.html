<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    return net

def block17(net, scale=1.0, activation=&quotrelu&quot):
    tower_conv = <a id="change">conv_2d(net, 192, 1, normalizer_fn=&quotbatch_normalization&quot, activation=&quotrelu&quot, name=&quotConv2d_1x1&quot)</a>
    tower_conv_1_0 = <a id="change">conv_2d(net, 128, 1, normalizer_fn=&quotbatch_normalization&quot, activation=&quotrelu&quot, name=&quotConv2d_0a_1x1&quot)</a>
    tower_conv_1_1 = <a id="change">conv_2d(tower_conv_1_0, 160,[1,7], normalizer_fn=&quotbatch_normalization&quot, activation=&quotrelu&quot,name=&quotConv2d_0b_1x7&quot)</a>
    tower_conv_1_2 = conv_2d(tower_conv_1_1, 192, [7,1], normalizer_fn=&quotbatch_normalization&quot, activation=&quotrelu&quot,name=&quotConv2d_0c_7x1&quot)
    tower_mixed = merge([tower_conv,tower_conv_1_2], mode=&quotconcat&quot, axis=3)
    tower_out = <a id="change">conv_2d(tower_mixed, net.get_shape()[3], 1, normalizer_fn=&quotbatch_normalization&quot, activation=None, name=&quotConv2d_1x1&quot)</a>
    net += scale * tower_out
    if activation:
        if isinstance(activation, str):
            net = activations.get(activation)(net)</code></pre><h3>After Change</h3><pre><code class='java'>
    return net

def block17(net, scale=1.0, activation="relu"):
    tower_conv = <a id="change">relu(batch_normalization(conv_2d(net, 192, 1, bias=False, activation=None, name=&quotConv2d_1x1&quot)))</a>
    tower_conv_1_0 = <a id="change">relu(batch_normalization(conv_2d(net, 128, 1, bias=False, activation=None, name=&quotConv2d_0a_1x1&quot)))</a>
    tower_conv_1_1 = <a id="change">relu(batch_normalization(conv_2d(tower_conv_1_0, 160,[1,7], bias=False, activation=None,name=&quotConv2d_0b_1x7&quot)))</a>
    tower_conv_1_2 = <a id="change">relu(batch_normalization(conv_2d(tower_conv_1_1, 192, [7,1], bias=False, activation=None,name=&quotConv2d_0c_7x1&quot)))</a>
    tower_mixed = merge([tower_conv,tower_conv_1_2], mode=&quotconcat&quot, axis=3)
    tower_out = <a id="change">relu(batch_normalization(conv_2d(tower_mixed, net.get_shape()[3], 1, bias=False, activation=None, name=&quotConv2d_1x1&quot)))</a>
    net += scale * tower_out
    if activation:
        if isinstance(activation, str):
            net = activations.get(activation)(net)</code></pre>