<html><h3>0d078991bf6a056be5579cda14dd1f305078eb7d,tensorflow_transform/beam/cached_impl_test.py,CachedImplTest,test_caching_vocab_for_integer_categorical,#CachedImplTest#,566
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    }, {
        &quotx_vocab&quot: -1,
    }]
    <a id="change">with beam_impl.Context(temp_dir=self.get_temp_dir()):
      with beam.Pipeline() as p:

        flat_data = p | &quotCreateInputData&quot &gt;&gt; beam.Create(
            list(itertools.chain(*input_data_dict.values())))

        cache_dict = {
            span_0_key: {
                b&quot__v0__VocabularyAccumulate[compute_and_apply_vocabulary/vocabulary]-\x05e\xfe4\x03H.P\xb5\xcb\xd22\xe3\x16\x15\xf8\xf5\xe38\xd9&quot:
                    p | &quotCreateB&quot &gt;&gt; beam.Create(
                        [b&quot[-2, 2]&quot, b&quot[-4, 1]&quot, b&quot[-1, 1]&quot, b&quot[4, 1]&quot]),
            },
            span_1_key: {},
        }

        transform_fn, cache_output = (
            (flat_data, input_data_dict, cache_dict, input_metadata)
            | &quotAnalyze&quot &gt;&gt;
            (beam_impl.AnalyzeDatasetWithCache(preprocessing_fn)))

        dot_string = nodes.get_dot_graph(
            [analysis_graph_builder._ANALYSIS_GRAPH]).to_string()
        self.WriteRenderedDotFile(dot_string)

        self.assertNotIn(span_0_key, cache_output)

        _ = cache_output | &quotWriteCache&quot &gt;&gt; analyzer_cache.WriteAnalysisCacheToFS(
            self._cache_dir)

        transformed_dataset = (((input_data_dict[span_1_key], input_metadata),
                                transform_fn)
                               | &quotTransform&quot &gt;&gt; beam_impl.TransformDataset())

        transformed_data, _ = transformed_dataset

        beam_test_util.assert_that(
            transformed_data,
            beam_test_util.equal_to(expected_transformed_data),
            label=&quotfirst&quot)

 </a> def test_non_frequency_vocabulary_merge(self):
    This test compares vocabularies produced with and without cache.

    mi_vocab_name = &quotmutual_information_vocab&quot</code></pre><h3>After Change</h3><pre><code class='java'>
    }, {
        &quotx_vocab&quot: -1,
    }]
    <a id="change">with _TestPipeline() as p:
      flat_data = p | &quotCreateInputData&quot &gt;&gt; beam.Create(
          list(itertools.chain(*input_data_dict.values())))

      cache_dict = {
          span_0_key: {
              b&quot__v0__VocabularyAccumulate[compute_and_apply_vocabulary/vocabulary]-\x05e\xfe4\x03H.P\xb5\xcb\xd22\xe3\x16\x15\xf8\xf5\xe38\xd9&quot:
                  p | &quotCreateB&quot &gt;&gt; beam.Create(
                      [b&quot[-2, 2]&quot, b&quot[-4, 1]&quot, b&quot[-1, 1]&quot, b&quot[4, 1]&quot]),
          },
          span_1_key: {},
      }

      transform_fn, cache_output = (
          (flat_data, input_data_dict, cache_dict, input_metadata)
          | &quotAnalyze&quot &gt;&gt;
          (beam_impl.AnalyzeDatasetWithCache(preprocessing_fn)))

      dot_string = nodes.get_dot_graph(
          [analysis_graph_builder._ANALYSIS_GRAPH]).to_string()
      self.WriteRenderedDotFile(dot_string)

      self.assertNotIn(span_0_key, cache_output)

      _ = cache_output | &quotWriteCache&quot &gt;&gt; analyzer_cache.WriteAnalysisCacheToFS(
          self._cache_dir)

      transformed_dataset = ((
          (input_data_dict[span_1_key], input_metadata), transform_fn)
                             | &quotTransform&quot &gt;&gt; beam_impl.TransformDataset())

      transformed_data, _ = transformed_dataset

      beam_test_util.assert_that(
          transformed_data,
          beam_test_util.equal_to(expected_transformed_data),
          label=&quotfirst&quot)

    &#47&#47 4 from analysis since 1 span was completely cached, and 4 from transform.
   </a> self.assertEqual(_get_counter_value(p.metrics, &quotnum_instances&quot), 8)
    self.assertEqual(_get_counter_value(p.metrics, &quotcache_entries_decoded&quot), 1)
    self.assertEqual(_get_counter_value(p.metrics, &quotcache_entries_encoded&quot), 1)
    self.assertEqual(_get_counter_value(p.metrics, &quotsaved_models_created&quot), 2)</code></pre><img src="9928706.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 9</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/tensorflow/transform/commit/0d078991bf6a056be5579cda14dd1f305078eb7d#diff-df685e6be9e468cade87a7e733b596daa19b1662e029aed238bd84cc6f916178L566' target='_blank'>Link</a></div><div id='project'> Project Name: tensorflow/transform</div><div id='commit'> Commit Name: 0d078991bf6a056be5579cda14dd1f305078eb7d</div><div id='time'> Time: 2019-04-29</div><div id='author'> Author: zoy@google.com</div><div id='file'> File Name: tensorflow_transform/beam/cached_impl_test.py</div><div id='class'> Class Name: CachedImplTest</div><div id='method'> Method Name: test_caching_vocab_for_integer_categorical</div><BR><BR><div id='link'><a href='https://github.com/tensorflow/transform/commit/0d078991bf6a056be5579cda14dd1f305078eb7d#diff-df685e6be9e468cade87a7e733b596daa19b1662e029aed238bd84cc6f916178L309' target='_blank'>Link</a></div><div id='project'> Project Name: tensorflow/transform</div><div id='commit'> Commit Name: 0d078991bf6a056be5579cda14dd1f305078eb7d</div><div id='time'> Time: 2019-04-29</div><div id='author'> Author: zoy@google.com</div><div id='file'> File Name: tensorflow_transform/beam/cached_impl_test.py</div><div id='class'> Class Name: CachedImplTest</div><div id='method'> Method Name: test_single_phase_mixed_analyzer_run_once</div><BR><BR><div id='link'><a href='https://github.com/tensorflow/transform/commit/0d078991bf6a056be5579cda14dd1f305078eb7d#diff-df685e6be9e468cade87a7e733b596daa19b1662e029aed238bd84cc6f916178L419' target='_blank'>Link</a></div><div id='project'> Project Name: tensorflow/transform</div><div id='commit'> Commit Name: 0d078991bf6a056be5579cda14dd1f305078eb7d</div><div id='time'> Time: 2019-04-29</div><div id='author'> Author: zoy@google.com</div><div id='file'> File Name: tensorflow_transform/beam/cached_impl_test.py</div><div id='class'> Class Name: CachedImplTest</div><div id='method'> Method Name: test_single_phase_run_twice</div><BR>