<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            self.eval_graph.output, feed_dict=feed_dict)
        batch_outputs = np.asarray(data[:n_tasks], dtype=float)
        &#47&#47 reshape to batch_size x n_tasks x ...
        <a id="change">if batch_outputs.ndim == 3:
          batch_outputs = batch_outputs.transpose((1, 0, 2))
        elif batch_outputs.ndim == 2:
          batch_outputs = batch_outputs.transpose((1, 0))
        else:
          raise ValueError(
              &quotUnrecognized rank combination for output: %s &quot %
              (batch_outputs.shape,))

      &#47&#47 Note that softmax is already applied in construct_grpah
     </a> outputs = batch_outputs

    return np.copy(outputs)
</code></pre><h3>After Change</h3><pre><code class='java'>

      return loss 

  def fit(self, dataset, nb_epoch=10, max_checkpoints_to_k<a id="change">eep=5, 
	  log_every_N_batches=50, **kwargs):
    Fit</a> the model.

    Parameters
    ---------- </code></pre>