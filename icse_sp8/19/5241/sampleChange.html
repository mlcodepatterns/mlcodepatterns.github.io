<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        super(WordClassifierBase, self).__init__()

    def make_input(self, batch_dict):
        <a id="change">x = batch_dict[&quotx&quot]</a>
        xch = batch_dict.get(&quotxch&quot)
        y = batch_dict.get(&quoty&quot)
        lengths = batch_dict.get(&quotlengths&quot)
        if self.gpu:
            <a id="change">x = x.cuda()</a>
            if xch is not None:
                xch = xch.cuda()
            if y is not None:
                y = y.cuda()

        <a id="change">return x, xch, lengths, y</a>

    def forward(self, input):
        &#47&#47 BxTxC
        x = input[0]</code></pre><h3>After Change</h3><pre><code class='java'>
        :param do_dropout: (``bool``) Should we do dropout.  Defaults to False
        :return:
        
        <a id="change">example_dict = dict({})</a>
        <a id="change">for key in self.embeddings.keys():
            example_dict[key] = torch.from_numpy(batch_dict[key])
            if self.gpu:
                example_dict[key] = example_dict[key].cuda()

        &#47&#47 Allow us to track a length, which is needed for BLSTMs
       </a> if self.lengths_key is not None:
            <a id="change">example_dict[&quotlengths&quot] = torch.from_numpy(batch_dict[self.lengths_key])</a>
            if self.gpu:
                example_dict[&quotlengths&quot] = example_dict[&quotlengths&quot].cuda()

        y = batch_dict.get(&quoty&quot)
        if y is not None:
            y = torch.from_numpy(y)
            if self.gpu is not None:
                y = y.cuda()
            example_dict[&quoty&quot] = y

        <a id="change">return example_dict</a>

    def forward(self, input):
        &#47&#47 BxTxC
        embeddings = self._embed(input)</code></pre>