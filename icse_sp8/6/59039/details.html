<html><h3>bc0ac45c0bf4f66d56df6c54f5230c6c4281daf1,onmt/Translator.py,Translator,translateBatch,#Translator#Any#Any#,78
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        decOut = self.model.make_init_decoder_output(context)

        padMask = <a id="change">srcBatch.data.eq(onmt.Constants.PAD).t() \
                                                      .unsqueeze(0) \
                                                      .repeat(beamSize, 1, 1)</a>

        batchIdx = list(range(batchSize))
        remainingSents = batchSize
        for i in range(self.opt.max_sent_length):

            self.model.decoder.apply(applyContextMask)

            &#47&#47 Prepare decoder input.
            input = torch.stack([b.getCurrentState() for b in beam
                                 if not b.done]).t().contiguous().view(1, -1)

            decOut, decStates, attn = self.model.decoder(
                Variable(input, volatile=True), decStates, context, decOut)
            &#47&#47 decOut: 1 x (beam*batch) x numWords
            decOut = decOut.squeeze(0)
            out = self.model.generator.forward(decOut)

            &#47&#47 batch x beam x numWords
            wordLk = out.view(beamSize, remainingSents, -1) \
                        .transpose(0, 1).contiguous()
            attn = attn.view(beamSize, remainingSents, -1) \
                       .transpose(0, 1).contiguous()

            active = []
            for b in range(batchSize):
                if beam[b].done:
                    continue

                idx = batchIdx[b]
                if not beam[b].advance(wordLk.data[idx], attn.data[idx]):
                    active += [b]

                for decState in decStates:  &#47&#47 iterate over h, c
                    &#47&#47 layers x beam*sent x dim
                    sentStates = decState.view(-1, beamSize,
                                               remainingSents,
                                               decState.size(2))[:, :, idx]
                    sentStates.data.copy_(
                        sentStates.data.index_select(
                            1, beam[b].getCurrentOrigin()))

            if not active:
                break

            &#47&#47 in this section, the sentences that are still active are
            &#47&#47 compacted so that the decoder is not run on completed sentences
            activeIdx = self.tt.LongTensor([batchIdx[k] for k in active])
            batchIdx = {beam: idx for idx, beam in enumerate(active)}

            def updateActive(t):
                &#47&#47 select only the remaining active sentences
                view = t.data.view(-1, remainingSents, rnnSize)
                newSize = list(t.size())
                newSize[-2] = newSize[-2] * len(activeIdx) // remainingSents
                return Variable(view.index_select(1, activeIdx)
                                .view(*newSize), volatile=True)

            decStates = (updateActive(decStates[0]),
                         updateActive(decStates[1]))
            decOut = updateActive(decOut)
            context = updateActive(context)
            <a id="change">padMask = padMask.index_select(1, activeIdx)</a>

            remainingSents = len(active)

        &#47&#47  (4) package everything up</code></pre><h3>After Change</h3><pre><code class='java'>
        if srcBatch[0].dim() == 2:
            batchSize = srcBatch[0].size(1)
        else:
            <a id="change">batchSize = srcBatch[0].size(0)</a>
        beamSize = self.opt.beam_size

        &#47&#47  (1) run the encoder on the src
        encStates, context = self.model.encoder(srcBatch)</code></pre><img src="273370219.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/OpenNMT/OpenNMT-py/commit/bc0ac45c0bf4f66d56df6c54f5230c6c4281daf1#diff-a6ee4fbb2b932113cbea6cbf0efb1fb763a70c3f68bacb21aac4ea4235123c36L78' target='_blank'>Link</a></div><div id='project'> Project Name: OpenNMT/OpenNMT-py</div><div id='commit'> Commit Name: bc0ac45c0bf4f66d56df6c54f5230c6c4281daf1</div><div id='time'> Time: 2017-05-31</div><div id='author'> Author: srush@sum1gpu02.rc.fas.harvard.edu</div><div id='file'> File Name: onmt/Translator.py</div><div id='class'> Class Name: Translator</div><div id='method'> Method Name: translateBatch</div><BR><BR><div id='link'><a href='https://github.com/jadore801120/attention-is-all-you-need-pytorch/commit/0b0eabbfd972c9e3f6323bff9d39ac5fc3ba9cc7#diff-13b50db4e17eecc27131342e1828da26b0d88a948a61d844a396e77d3377f01dL52' target='_blank'>Link</a></div><div id='project'> Project Name: jadore801120/attention-is-all-you-need-pytorch</div><div id='commit'> Commit Name: 0b0eabbfd972c9e3f6323bff9d39ac5fc3ba9cc7</div><div id='time'> Time: 2018-08-23</div><div id='author'> Author: yhhuang@nlg.csie.ntu.edu.tw</div><div id='file'> File Name: transformer/Translator.py</div><div id='class'> Class Name: Translator</div><div id='method'> Method Name: translate_batch</div><BR><BR><div id='link'><a href='https://github.com/osmr/imgclsmob/commit/7c3d0a5ea7405fe74cc31f5553f7c04d9804d42e#diff-d855ce643ed5d37472984b7cebe0ff69bae2baee0121cf5c768b5d715db2aa5cL22' target='_blank'>Link</a></div><div id='project'> Project Name: osmr/imgclsmob</div><div id='commit'> Commit Name: 7c3d0a5ea7405fe74cc31f5553f7c04d9804d42e</div><div id='time'> Time: 2019-03-02</div><div id='author'> Author: osemery@gmail.com</div><div id='file'> File Name: pytorch/pytorchcv/models/isqrtcovresnet.py</div><div id='class'> Class Name: Covpool</div><div id='method'> Method Name: forward</div><BR>