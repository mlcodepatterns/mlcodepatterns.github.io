<html><h3>caa5ccc42c3d7e0004688a91e9e4a5b42b1a8957,test/test_documentation.py,TestDocumentation,test_readme,#TestDocumentation#,158
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        agent = Agent.create(
            agent=&quottensorforce&quot,
            states=dict(type=&quotfloat&quot, shape=(10,)),
            actions=<a id="change">dict(type=&quotint&quot, num_values=5)</a>,
            max_episode_timesteps=100,
            memory=10000,
            update=dict(unit=&quottimesteps&quot, batch_size=64),
            optimizer=dict(type=&quotadam&quot, learning_rate=3e-4),
            policy=dict(network=&quotauto&quot),
            objective=&quotpolicy_gradient&quot,
            reward_estimation=dict(horizon=20)
        )

        &#47&#47 Retrieve the latest (observable) environment state
        state = get_current_state()  &#47&#47 (float array of shape [10])

        &#47&#47 Query the agent for its action decision
        <a id="change">action = agent.act(states=state)</a>  &#47&#47 (scalar between 0 and 4)

        &#47&#47 Execute the decision and retrieve the current performance score
        <a id="change">reward = execute_decision(action)</a>  &#47&#47 (any scalar float)

        &#47&#47 Pass feedback about performance (and termination) to the agent
        agent.observe(reward=reward, terminal=False)</code></pre><h3>After Change</h3><pre><code class='java'>

            while not terminal:
                &#47&#47 Episode timestep
                <a id="change">actions = agent.act(states=states)</a>
                <a id="change">states, terminal, reward = environment.execute(actions=actions)</a>
                agent.observe(terminal=terminal, reward=reward)

        agent.close()
        environment.close()</code></pre><img src="187858883.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/reinforceio/tensorforce/commit/caa5ccc42c3d7e0004688a91e9e4a5b42b1a8957#diff-3b683500e507267ea848c52b7ca3e5d995400f07cd26b294bf6ba977d557df93L161' target='_blank'>Link</a></div><div id='project'> Project Name: reinforceio/tensorforce</div><div id='commit'> Commit Name: caa5ccc42c3d7e0004688a91e9e4a5b42b1a8957</div><div id='time'> Time: 2020-02-11</div><div id='author'> Author: alexkuhnle@t-online.de</div><div id='file'> File Name: test/test_documentation.py</div><div id='class'> Class Name: TestDocumentation</div><div id='method'> Method Name: test_readme</div><BR><BR><div id='link'><a href='https://github.com/MolSSI/QCEngine/commit/76d930ec1fe1e18300c835ddf938afd943d4ad05#diff-c2513a32098e0b14751980a1524320abc60b8cc1a883aacd76399e69949ebb0aL65' target='_blank'>Link</a></div><div id='project'> Project Name: MolSSI/QCEngine</div><div id='commit'> Commit Name: 76d930ec1fe1e18300c835ddf938afd943d4ad05</div><div id='time'> Time: 2019-06-10</div><div id='author'> Author: lori.burns@gmail.com</div><div id='file'> File Name: qcengine/programs/dftd3.py</div><div id='class'> Class Name: DFTD3Harness</div><div id='method'> Method Name: compute</div><BR><BR><div id='link'><a href='https://github.com/MolSSI/QCEngine/commit/1895a1e954eb0ee668deffe0de9b2207b5c04c9c#diff-1e405636fdaf5ac05c94244e5b5b6f449f798d78bac83b5ffba6d9e059aeda0cL64' target='_blank'>Link</a></div><div id='project'> Project Name: MolSSI/QCEngine</div><div id='commit'> Commit Name: 1895a1e954eb0ee668deffe0de9b2207b5c04c9c</div><div id='time'> Time: 2019-06-07</div><div id='author'> Author: lori.burns@gmail.com</div><div id='file'> File Name: qcengine/programs/mp2d.py</div><div id='class'> Class Name: MP2DHarness</div><div id='method'> Method Name: compute</div><BR>