<html><h3>557622faca0328c0303b824006c5fe11cc87cca1,art/attacks/virtual_adversarial.py,VirtualAdversarialMethod,generate,#VirtualAdversarialMethod#Any#,33
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        for ind, val in enumerate(x_adv):
            d = np.random.randn(*dims)
            e = <a id="change">np.random.randn(*dims)</a>
            for _ in range(self.max_iter):
                d = self.finite_diff * self._normalize(d)
                <a id="change">e = self.finite_diff * self._normalize(e)</a>
                preds_new = self.classifier.predict(np.stack(<a id="change">(val + d, val + e)</a>))

                &#47&#47 Compute KL divergence between logits
                from scipy.stats import entropy</code></pre><h3>After Change</h3><pre><code class='java'>
                
                &#47&#47 TODO remove for loop
                d_new = d
                <a id="change">for i in range(*dims):
                    d[i] += self.finite_diff
                    preds_new = self.classifier.predict((val + d)[None,...], logits=False)
                    kl_div2 = entropy(preds[ind], preds_new[0])                    
                    d_new[i] = (kl_div2-kl_div1)/self.finite_diff
                    d[i] -= self.finite_diff
               </a> d = d_new

            &#47&#47 Apply perturbation and clip
            val = np.clip(val + self.eps * self._normalize(d), clip_min, clip_max)</code></pre><img src="204155003.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/IBM/adversarial-robustness-toolbox/commit/557622faca0328c0303b824006c5fe11cc87cca1#diff-c9a542d3fdf37ea34459460fcc7daf03f9071cdad1a07bb2d7af7d0e0e1b6416L33' target='_blank'>Link</a></div><div id='project'> Project Name: IBM/adversarial-robustness-toolbox</div><div id='commit'> Commit Name: 557622faca0328c0303b824006c5fe11cc87cca1</div><div id='time'> Time: 2018-05-09</div><div id='author'> Author: mathsinn@ie.ibm.com</div><div id='file'> File Name: art/attacks/virtual_adversarial.py</div><div id='class'> Class Name: VirtualAdversarialMethod</div><div id='method'> Method Name: generate</div><BR><BR><div id='link'><a href='https://github.com/pymanopt/pymanopt/commit/f40c063512e47b5f56d015e0836efc90a23af25f#diff-e617844a3778fb02fe44b9d30160424083c604ec47d4a6cf1b8183d2723048baL104' target='_blank'>Link</a></div><div id='project'> Project Name: pymanopt/pymanopt</div><div id='commit'> Commit Name: f40c063512e47b5f56d015e0836efc90a23af25f</div><div id='time'> Time: 2020-02-01</div><div id='author'> Author: niklas.koep@gmail.com</div><div id='file'> File Name: tests/test_backends/_backend_tests.py</div><div id='class'> Class Name: TestNaryParameterGrouping</div><div id='method'> Method Name: test_nary_parameter_grouping</div><BR><BR><div id='link'><a href='https://github.com/IBM/adversarial-robustness-toolbox/commit/9bc56cc177b7997d6b4a30d204a08ef95a03a343#diff-c9a542d3fdf37ea34459460fcc7daf03f9071cdad1a07bb2d7af7d0e0e1b6416L33' target='_blank'>Link</a></div><div id='project'> Project Name: IBM/adversarial-robustness-toolbox</div><div id='commit'> Commit Name: 9bc56cc177b7997d6b4a30d204a08ef95a03a343</div><div id='time'> Time: 2018-05-09</div><div id='author'> Author: Maria-Irina.Nicolae@ibm.com</div><div id='file'> File Name: art/attacks/virtual_adversarial.py</div><div id='class'> Class Name: VirtualAdversarialMethod</div><div id='method'> Method Name: generate</div><BR>