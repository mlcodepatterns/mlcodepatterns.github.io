<html><h3>8e4926a58d0ff919db9cb85ac9530053eda62190,models/VGGBinomialDropout.py,VGGBinomialDropout,_inference,#VGGBinomialDropout#Any#Any#Any#Any#Any#,20
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        with tf.variable_scope(self.__class__.__name__):
            with tf.variable_scope(&quot64&quot):
                with tf.variable_scope(&quotconv1&quot):
                    conv1 = <a id="change">tf.nn.relu(
                        utils.conv_layer(
                            images, [3, 3, 3, 64], 1, &quotSAME&quot, wd=l2_penalty))</a>
                    if train_phase:
                        conv1 = utils.binomial_dropout(conv1, 0.7)

                with tf.variable_scope(&quotconv2&quot):
                    conv2 = <a id="change">tf.nn.relu(
                        utils.conv_layer(
                            conv1, [3, 3, 64, 64], 1, &quotSAME&quot, wd=l2_penalty))</a>

                    if train_phase:
                        conv2 = utils.binomial_dropout(conv2, 0.6)

            with tf.variable_scope(&quotpool1&quot):
                pool1 = tf.nn.max_pool(
                    conv2,
                    ksize=[1, 2, 2, 1],
                    strides=[1, 2, 2, 1],
                    padding=&quotVALID&quot)

            with tf.variable_scope(&quot128&quot):
                with tf.variable_scope(&quotconv3&quot):
                    conv3 = <a id="change">tf.nn.relu(
                        utils.conv_layer(
                            pool1, [3, 3, 64, 128], 1, &quotSAME&quot, wd=l2_penalty))</a>

                    if train_phase:
                        conv3 = utils.binomial_dropout(conv3, 0.6)

                with tf.variable_scope(&quotconv4&quot):
                    conv4 = <a id="change">tf.nn.relu(
                        utils.conv_layer(
                            conv3, [3, 3, 128, 128], 1, &quotSAME&quot, wd=l2_penalty))</a>

                    if train_phase:
                        conv4 = utils.binomial_dropout(conv4, 0.6)

            with tf.variable_scope(&quotpool2&quot):
                pool2 = tf.nn.max_pool(
                    conv4,
                    ksize=[1, 2, 2, 1],
                    strides=[1, 2, 2, 1],
                    padding=&quotVALID&quot)

            with tf.variable_scope(&quot256&quot):
                with tf.variable_scope(&quotconv5&quot):
                    conv5 = tf.nn.relu(
                        utils.conv_layer(
                            pool2, [3, 3, 128, 256], 1, &quotSAME&quot, wd=l2_penalty))

                    if train_phase:
                        conv5 = utils.binomial_dropout(conv5, 0.6)

                with tf.variable_scope(&quotconv6&quot):
                    conv6 = tf.nn.relu(
                        utils.conv_layer(
                            conv5, [3, 3, 256, 256], 1, &quotSAME&quot, wd=l2_penalty))

                    if train_phase:
                        conv6 = utils.binomial_dropout(conv6, 0.6)

                with tf.variable_scope(&quotconv7&quot):
                    conv7 = tf.nn.relu(
                        utils.conv_layer(
                            conv6, [3, 3, 256, 256], 1, &quotSAME&quot, wd=l2_penalty))

                    if train_phase:
                        conv7 = utils.binomial_dropout(conv7, 0.6)

            with tf.variable_scope(&quotpool3&quot):
                pool3 = tf.nn.max_pool(
                    conv7,
                    ksize=[1, 2, 2, 1],
                    strides=[1, 2, 2, 1],
                    padding=&quotVALID&quot)

            with tf.variable_scope(&quot512&quot):
                with tf.variable_scope(&quotconv8&quot):
                    conv8 = <a id="change">tf.nn.relu(
                        utils.conv_layer(
                            pool3, [3, 3, 256, 512], 1, &quotSAME&quot, wd=l2_penalty))</a>

                    if train_phase:
                        conv8 = utils.binomial_dropout(conv8, 0.6)

                with tf.variable_scope(&quotconv9&quot):
                    conv9 = <a id="change">tf.nn.relu(
                        utils.conv_layer(
                            conv8, [3, 3, 512, 512], 1, &quotSAME&quot, wd=l2_penalty))</a>

                    if train_phase:
                        conv9 = utils.binomial_dropout(conv9, 0.6)

                with tf.variable_scope(&quotconv10&quot):
                    conv10 = <a id="change">tf.nn.relu(
                        utils.conv_layer(
                            conv9, [3, 3, 512, 512], 1, &quotSAME&quot, wd=l2_penalty))</a>

                    if train_phase:
                        conv10 = utils.binomial_dropout(conv10, 0.6)

            with tf.variable_scope(&quotpool4&quot):
                pool4 = tf.nn.max_pool(
                    conv10,
                    ksize=[1, 2, 2, 1],
                    strides=[1, 2, 2, 1],
                    padding=&quotVALID&quot)

            with tf.variable_scope(&quot512b2&quot):
                with tf.variable_scope(&quotconv11&quot):
                    conv11 = tf.nn.relu(
                        utils.conv_layer(
                            pool4, [3, 3, 512, 512], 1, &quotSAME&quot, wd=l2_penalty))

                    if train_phase:
                        conv11 = utils.binomial_dropout(conv11, 0.6)

                with tf.variable_scope(&quotconv12&quot):
                    conv12 = <a id="change">tf.nn.relu(
                        utils.conv_layer(
                            conv11, [3, 3, 512, 512], 1, &quotSAME&quot, wd=l2_penalty))</a>

                    if train_phase:
                        conv12 = utils.binomial_dropout(conv12, 0.6)

                with tf.variable_scope(&quotconv13&quot):
                    conv13 = <a id="change">tf.nn.relu(
                        utils.conv_layer(
                            conv12, [3, 3, 512, 512], 1, &quotSAME&quot, wd=l2_penalty))</a>

                    if train_phase:
                        conv13 = utils.binomial_dropout(conv13, 0.6)

            with tf.variable_scope(&quotpool5&quot):
                pool5 = tf.nn.max_pool(
                    conv13,
                    ksize=[1, 2, 2, 1],
                    strides=[1, 2, 2, 1],
                    padding=&quotVALID&quot)

                pool5 = tf.reshape(pool5, [-1, 512])

            with tf.variable_scope(&quotfc&quot):
                fc1 = <a id="change">tf.nn.relu(
                    utils.fc_layer(
                        pool5, [512, 512], wd=l2_penalty))</a>

                if train_phase:
                    fc1 = utils.binomial_dropout(fc1, 0.5)
</code></pre><h3>After Change</h3><pre><code class='java'>
        with tf.variable_scope(self.__class__.__name__):
            with tf.variable_scope(&quot64&quot):
                with tf.variable_scope(&quotconv1&quot):
                    conv1 = <a id="change">utils.conv_layer(
                        images, [3, 3, 3, 64],
                        1,
                        &quotSAME&quot,
                        activation=tf.nn.relu,
                        wd=l2_penalty)</a>
                    if train_phase:
                        conv1 = utils.binomial_dropout(conv1, 0.7)

                with tf.variable_scope(&quotconv2&quot):
                    conv2 = <a id="change">utils.conv_layer(
                        conv1, [3, 3, 64, 64],
                        1,
                        &quotSAME&quot,
                        activation=tf.nn.relu,
                        wd=l2_penalty)</a>

                    if train_phase:
                        conv2 = utils.binomial_dropout(conv2, 0.6)

            with tf.variable_scope(&quotpool1&quot):
                pool1 = tf.nn.max_pool(
                    conv2,
                    ksize=[1, 2, 2, 1],
                    strides=[1, 2, 2, 1],
                    padding=&quotVALID&quot)

            with tf.variable_scope(&quot128&quot):
                with tf.variable_scope(&quotconv3&quot):
                    conv3 = <a id="change">utils.conv_layer(
                        pool1, [3, 3, 64, 128],
                        1,
                        &quotSAME&quot,
                        activation=tf.nn.relu,
                        wd=l2_penalty)</a>

                    if train_phase:
                        conv3 = utils.binomial_dropout(conv3, 0.6)

                with tf.variable_scope(&quotconv4&quot):
                    conv4 = <a id="change">utils.conv_layer(
                        conv3, [3, 3, 128, 128],
                        1,
                        &quotSAME&quot,
                        activation=tf.nn.relu,
                        wd=l2_penalty)</a>

                    if train_phase:
                        conv4 = utils.binomial_dropout(conv4, 0.6)

            with tf.variable_scope(&quotpool2&quot):
                pool2 = tf.nn.max_pool(
                    conv4,
                    ksize=[1, 2, 2, 1],
                    strides=[1, 2, 2, 1],
                    padding=&quotVALID&quot)

            with tf.variable_scope(&quot256&quot):
                with tf.variable_scope(&quotconv5&quot):
                    conv5 = utils.conv_layer(
                        pool2, [3, 3, 128, 256],
                        1,
                        &quotSAME&quot,
                        activation=tf.nn.relu,
                        wd=l2_penalty)

                    if train_phase:
                        conv5 = utils.binomial_dropout(conv5, 0.6)

                with tf.variable_scope(&quotconv6&quot):
                    conv6 = utils.conv_layer(
                        conv5, [3, 3, 256, 256],
                        1,
                        &quotSAME&quot,
                        activation=tf.nn.relu,
                        wd=l2_penalty)

                    if train_phase:
                        conv6 = utils.binomial_dropout(conv6, 0.6)

                with tf.variable_scope(&quotconv7&quot):
                    conv7 = utils.conv_layer(
                        conv6, [3, 3, 256, 256],
                        1,
                        &quotSAME&quot,
                        activation=tf.nn.relu,
                        wd=l2_penalty)

                    if train_phase:
                        conv7 = utils.binomial_dropout(conv7, 0.6)

            with tf.variable_scope(&quotpool3&quot):
                pool3 = tf.nn.max_pool(
                    conv7,
                    ksize=[1, 2, 2, 1],
                    strides=[1, 2, 2, 1],
                    padding=&quotVALID&quot)

            with tf.variable_scope(&quot512&quot):
                with tf.variable_scope(&quotconv8&quot):
                    conv8 = <a id="change">utils.conv_layer(
                        pool3, [3, 3, 256, 512],
                        1,
                        &quotSAME&quot,
                        activation=tf.nn.relu,
                        wd=l2_penalty)</a>

                    if train_phase:
                        conv8 = utils.binomial_dropout(conv8, 0.6)

                with tf.variable_scope(&quotconv9&quot):
                    conv9 = <a id="change">utils.conv_layer(
                        conv8, [3, 3, 512, 512],
                        1,
                        &quotSAME&quot,
                        activation=tf.nn.relu,
                        wd=l2_penalty)</a>

                    if train_phase:
                        conv9 = utils.binomial_dropout(conv9, 0.6)

                with tf.variable_scope(&quotconv10&quot):
                    conv10 = <a id="change">utils.conv_layer(
                        conv9, [3, 3, 512, 512],
                        1,
                        &quotSAME&quot,
                        activation=tf.nn.relu,
                        wd=l2_penalty)</a>

                    if train_phase:
                        conv10 = utils.binomial_dropout(conv10, 0.6)

            with tf.variable_scope(&quotpool4&quot):
                pool4 = tf.nn.max_pool(
                    conv10,
                    ksize=[1, 2, 2, 1],
                    strides=[1, 2, 2, 1],
                    padding=&quotVALID&quot)

            with tf.variable_scope(&quot512b2&quot):
                with tf.variable_scope(&quotconv11&quot):
                    conv11 = utils.conv_layer(
                        pool4, [3, 3, 512, 512],
                        1,
                        &quotSAME&quot,
                        activation=tf.nn.relu,
                        wd=l2_penalty)

                    if train_phase:
                        conv11 = utils.binomial_dropout(conv11, 0.6)

                with tf.variable_scope(&quotconv12&quot):
                    conv12 = <a id="change">utils.conv_layer(
                        conv11, [3, 3, 512, 512],
                        1,
                        &quotSAME&quot,
                        activation=tf.nn.relu,
                        wd=l2_penalty)</a>

                    if train_phase:
                        conv12 = utils.binomial_dropout(conv12, 0.6)

                with tf.variable_scope(&quotconv13&quot):
                    conv13 = <a id="change">utils.conv_layer(
                        conv12, [3, 3, 512, 512],
                        1,
                        &quotSAME&quot,
                        activation=tf.nn.relu,
                        wd=l2_penalty)</a>

                    if train_phase:
                        conv13 = utils.binomial_dropout(conv13, 0.6)

            with tf.variable_scope(&quotpool5&quot):
                pool5 = tf.nn.max_pool(
                    conv13,
                    ksize=[1, 2, 2, 1],
                    strides=[1, 2, 2, 1],
                    padding=&quotVALID&quot)

                pool5 = tf.reshape(pool5, [-1, 512])

            with tf.variable_scope(&quotfc&quot):
                fc1 = <a id="change">utils.fc_layer(
                    pool5, [512, 512], activation=tf.nn.relu, wd=l2_penalty)</a>

                if train_phase:
                    fc1 = utils.binomial_dropout(fc1, 0.5)
</code></pre><img src="315427116.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 60</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/galeone/dynamic-training-bench/commit/8e4926a58d0ff919db9cb85ac9530053eda62190#diff-5ef71f7ddb66b1fe523623000415f4e75d813558ac889e239647b8d4ad97e5ebL42' target='_blank'>Link</a></div><div id='project'> Project Name: galeone/dynamic-training-bench</div><div id='commit'> Commit Name: 8e4926a58d0ff919db9cb85ac9530053eda62190</div><div id='time'> Time: 2016-12-09</div><div id='author'> Author: nessuno@nerdz.eu</div><div id='file'> File Name: models/VGGBinomialDropout.py</div><div id='class'> Class Name: VGGBinomialDropout</div><div id='method'> Method Name: _inference</div><BR><BR><div id='link'><a href='https://github.com/galeone/dynamic-training-bench/commit/8e4926a58d0ff919db9cb85ac9530053eda62190#diff-ae089ce9be52a10e3deb7a59bc316347268c96609c773b77f5dffdae648cc3daL43' target='_blank'>Link</a></div><div id='project'> Project Name: galeone/dynamic-training-bench</div><div id='commit'> Commit Name: 8e4926a58d0ff919db9cb85ac9530053eda62190</div><div id='time'> Time: 2016-12-09</div><div id='author'> Author: nessuno@nerdz.eu</div><div id='file'> File Name: models/VGGDropout.py</div><div id='class'> Class Name: VGGDropout</div><div id='method'> Method Name: _inference</div><BR><BR><div id='link'><a href='https://github.com/galeone/dynamic-training-bench/commit/8e4926a58d0ff919db9cb85ac9530053eda62190#diff-7be619caace282d4eac5e5e3ce8c678ad162943a5944953eded8766800e9cca5L58' target='_blank'>Link</a></div><div id='project'> Project Name: galeone/dynamic-training-bench</div><div id='commit'> Commit Name: 8e4926a58d0ff919db9cb85ac9530053eda62190</div><div id='time'> Time: 2016-12-09</div><div id='author'> Author: nessuno@nerdz.eu</div><div id='file'> File Name: models/VGGDirectDropout.py</div><div id='class'> Class Name: VGGDirectDropout</div><div id='method'> Method Name: _inference</div><BR>