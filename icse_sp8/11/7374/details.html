<html><h3>5a68c464caac68e4623f9a7b173bcf24aa719a5c,tensorflow_datasets/text/trivia_qa.py,TriviaQA,_generate_examples,#TriviaQA#Any#Any#Any#,230
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

    for filepath in files:
      logging.info("generating examples from = %s", filepath)
      <a id="change">with tf.io.gfile.GFile(filepath) as f:
        triviaqa = json.load(f)
        for article in triviaqa["Data"]:
          if "Answer" in article:
            answer = article["Answer"]
            answer_dict = {
                "aliases":
                    _strip(answer["Aliases"]),
                "normalized_aliases":
                    _strip(answer["NormalizedAliases"]),
                "matched_wiki_entity_name":
                    answer.get("MatchedWikiEntryName", "").strip(),
                "normalized_matched_wiki_entity_name":
                    answer.get("NormalizedMatchedWikiEntryName", "").strip(),
                "normalized_value":
                    answer["NormalizedValue"].strip(),
                "type":
                    answer["Type"].strip(),
                "value":
                    answer["Value"].strip(),
            }
          else:
            answer_dict = {
                "aliases":
                    [],
                "normalized_aliases":
                    [],
                "matched_wiki_entity_name":
                    "&lt;unk&gt;",
                "normalized_matched_wiki_entity_name":
                    "&lt;unk&gt;",
                "normalized_value":
                    "&lt;unk&gt;",
                "type":
                    "",
                "value":
                    "&lt;unk&gt;",
            }

          if self.builder_config.exclude_context:
            article["SearchResults"] = []
            article["EntityPages"] = []

          def _add_context(collection, context_field, file_dir):
            Adds context from file, or skips if file does not exist.
            new_items = []
            for item in collection:
              if "Filename" not in item:
                logging.info("Missing context &quotFilename&quot, skipping.")
                continue

              new_item = item.copy()
              fname = item["Filename"]
              try:
                with tf.io.gfile.GFile(os.path.join(file_dir, fname)) as f:
                  new_item[context_field] = f.read()
              except (IOError, tf.errors.NotFoundError):
                logging.info("File does not exist, skipping: %s", fname)
                continue
              new_items.append(new_item)
            return new_items

          def _strip_if_str(v):
            return v.strip() if isinstance(v, six.string_types) else v
          def _transpose_and_strip_dicts(dicts, field_names):
            return {
                tfds.core.naming.camelcase_to_snakecase(k):
                    [_strip_if_str(d[k]) for d in dicts]
                for k in field_names
            }

          search_results = _transpose_and_strip_dicts(
              _add_context(
                  article.get("SearchResults", []), "SearchContext", web_dir),
              ["Description", "Filename", "Rank", "Title", "Url",
               "SearchContext"])

          entity_pages = _transpose_and_strip_dicts(
              _add_context(
                  article.get("EntityPages", []), "WikiContext", wiki_dir),
              ["DocSource", "Filename", "Title", "WikiContext"])

          question = article["Question"].strip()
          question_id = article["QuestionId"]
          question_source = article["QuestionSource"].strip()

          yield "%s_%s" % (os.path.basename(filepath), question_id), {
              "entity_pages": entity_pages,
              "search_results": search_results,
              "question": question,
              "question_id": question_id,
              "question_source": question_source,
              "answer": answer_dict,
          }</a>
</code></pre><h3>After Change</h3><pre><code class='java'>

      with tf.io.gfile.GFile(filepath) as f:
        current_record = ""
        <a id="change">for line in f:
          if line == "        {\n":
            current_record = line
          elif line.startswith("        }"):  &#47&#47 Handles final record as well.
            article = json.loads(current_record + "}")
            current_record = ""
            example = parse_example(article)
            yield "%s_%s" % (fname, example["question_id"]), example
          else:
            current_record += line</a>
</code></pre><img src="45644472.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 8</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/tensorflow/datasets/commit/5a68c464caac68e4623f9a7b173bcf24aa719a5c#diff-22ce9f90357c0799e340f5c022d8805d4f0fa08d68e07d371d11a1e9475192d2L238' target='_blank'>Link</a></div><div id='project'> Project Name: tensorflow/datasets</div><div id='commit'> Commit Name: 5a68c464caac68e4623f9a7b173bcf24aa719a5c</div><div id='time'> Time: 2019-12-06</div><div id='author'> Author: adarob@google.com</div><div id='file'> File Name: tensorflow_datasets/text/trivia_qa.py</div><div id='class'> Class Name: TriviaQA</div><div id='method'> Method Name: _generate_examples</div><BR><BR><div id='link'><a href='https://github.com/tensorflow/datasets/commit/5a68c464caac68e4623f9a7b173bcf24aa719a5c#diff-22ce9f90357c0799e340f5c022d8805d4f0fa08d68e07d371d11a1e9475192d2L238' target='_blank'>Link</a></div><div id='project'> Project Name: tensorflow/datasets</div><div id='commit'> Commit Name: 5a68c464caac68e4623f9a7b173bcf24aa719a5c</div><div id='time'> Time: 2019-12-06</div><div id='author'> Author: adarob@google.com</div><div id='file'> File Name: tensorflow_datasets/text/trivia_qa.py</div><div id='class'> Class Name: TriviaQA</div><div id='method'> Method Name: _generate_examples</div><BR><BR><div id='link'><a href='https://github.com/pantsbuild/pants/commit/04629674f5f9e65bd35565b329f8c892a16865a4#diff-0b0970aa6211577db376dd669c2a4b810b457909c965b8d17b123848eed7df54L42' target='_blank'>Link</a></div><div id='project'> Project Name: pantsbuild/pants</div><div id='commit'> Commit Name: 04629674f5f9e65bd35565b329f8c892a16865a4</div><div id='time'> Time: 2012-07-07</div><div id='author'> Author: benjy@foursquare.com</div><div id='file'> File Name: src/python/twitter/pants/tasks/jvm_compiler_dependencies.py</div><div id='class'> Class Name: Dependencies</div><div id='method'> Method Name: findclasses</div><BR><BR><div id='link'><a href='https://github.com/allenai/allennlp/commit/3aa33139216ff3f597fe2630d44aa69afe4d97a7#diff-6950b2c2c3efae82af5fd1eff502c2b7ab881d2092df5508d3ae651e230831b9L201' target='_blank'>Link</a></div><div id='project'> Project Name: allenai/allennlp</div><div id='commit'> Commit Name: 3aa33139216ff3f597fe2630d44aa69afe4d97a7</div><div id='time'> Time: 2018-01-17</div><div id='author'> Author: markn@allenai.org</div><div id='file'> File Name: allennlp/data/dataset_readers/dataset_utils/ontonotes.py</div><div id='class'> Class Name: Ontonotes</div><div id='method'> Method Name: sentence_iterator</div><BR>