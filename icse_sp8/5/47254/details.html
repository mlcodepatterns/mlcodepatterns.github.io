<html><h3>c7028b68792e65bcf820d0e7e24954dff586c921,foolbox/ext/native/attacks/newtonfool.py,NewtonFoolAttack,__call__,#NewtonFoolAttack#Any#Any#Any#,29
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

            &#47&#47 (5) calculate & apply current perturbation
            x -= (
                <a id="change">atleast_kd(delta / gradients_l2_norm.square(), gradients.ndim)</a>
                * gradients
            )
            x = ep.clip(x, min_, max_)
</code></pre><h3>After Change</h3><pre><code class='java'>
            &#47&#47 (1) get the scores and gradients
            _, (scores, pred_scores), gradients = ep.value_aux_and_grad(loss_fun, x)

            <a id="change">pred = scores.argmax(-1)</a>
            num_classes = scores.shape[-1]

            &#47&#47 (2) calculate gradient norm
            gradients_l2_norm = flatten(gradients.square()).sum(1)

            &#47&#47 (3) calculate delta
            a = self.stepsize * x_l2_norm * gradients_l2_norm
            b = pred_scores - 1.0 / num_classes

            delta = ep.minimum(a, b)

            &#47&#47 (4) stop the attack if an adversarial example has been found
            &#47&#47 this is not described in the paper but otherwise once the prob. drops
            &#47&#47 below chance level the likelihood is not decreased but increased
            is_not_adversarial = (pred == classes).float32()
            delta *= is_not_adversarial

            &#47&#47 (5) calculate & apply current perturbation
            a = <a id="change">atleast_kd(delta / gradients_l2_norm.square(), gradients.ndim)</a>
            <a id="change">x -= a * gradients</a>

            x = ep.clip(x, min_, max_)

        return restore_type(x)</code></pre><img src="219841338.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/bethgelab/foolbox/commit/c7028b68792e65bcf820d0e7e24954dff586c921#diff-c64224f94f6329b87c5b792a109805ea69d92f436285bd7d550d97d50ad6e542L37' target='_blank'>Link</a></div><div id='project'> Project Name: bethgelab/foolbox</div><div id='commit'> Commit Name: c7028b68792e65bcf820d0e7e24954dff586c921</div><div id='time'> Time: 2020-02-06</div><div id='author'> Author: 5895436+zimmerrol@users.noreply.github.com</div><div id='file'> File Name: foolbox/ext/native/attacks/newtonfool.py</div><div id='class'> Class Name: NewtonFoolAttack</div><div id='method'> Method Name: __call__</div><BR><BR><div id='link'><a href='https://github.com/bethgelab/foolbox/commit/914ed63ebb68c250490b7e2863ea9e9f2aba1c7a#diff-49669dffddd42f7cf8c5313da86b97b6939771fcb91e4b45649126b99e1f582fL28' target='_blank'>Link</a></div><div id='project'> Project Name: bethgelab/foolbox</div><div id='commit'> Commit Name: 914ed63ebb68c250490b7e2863ea9e9f2aba1c7a</div><div id='time'> Time: 2020-01-10</div><div id='author'> Author: git@jonasrauber.de</div><div id='file'> File Name: foolbox/ext/native/attacks/carlini_wagner.py</div><div id='class'> Class Name: L2CarliniWagnerAttack</div><div id='method'> Method Name: __call__</div><BR><BR><div id='link'><a href='https://github.com/bethgelab/foolbox/commit/fa5137308a8eae6c24aca4f6c0146544d43581ed#diff-49669dffddd42f7cf8c5313da86b97b6939771fcb91e4b45649126b99e1f582fL28' target='_blank'>Link</a></div><div id='project'> Project Name: bethgelab/foolbox</div><div id='commit'> Commit Name: fa5137308a8eae6c24aca4f6c0146544d43581ed</div><div id='time'> Time: 2019-12-20</div><div id='author'> Author: git@jonasrauber.de</div><div id='file'> File Name: foolbox/ext/native/attacks/carlini_wagner.py</div><div id='class'> Class Name: L2CarliniWagnerAttack</div><div id='method'> Method Name: __call__</div><BR>