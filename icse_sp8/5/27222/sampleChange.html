<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &quot&quot&quot
        total_t = util.s_get(self, &quotaeb_space.clock&quot).get(&quottotal_t&quot)
        if (total_t &gt; self.training_min_timestep and total_t % self.training_frequency == 0):
            <a id="change">logger.debug3(f&quotTraining at total_t: {total_t}&quot)</a>
            total_loss = 0.0
            for _b in range(self.training_epoch):
                batch = self.sample()
                batch_loss = 0.0
                for _i in range(self.training_iters_per_batch):
                    with torch.no_grad():
                        q_targets = self.compute_q_target_values(batch)
                        y = q_targets
                    loss = self.net.training_step(batch[&quotstates&quot], y)
                    batch_loss += loss.item()
                batch_loss /= self.training_iters_per_batch
                total_loss += batch_loss
            total_loss /= self.training_epoch
            logger.debug(f&quottotal_loss {total_loss}&quot)
            return total_loss
        else:
            <a id="change">logger.debug3(&quotNOT training&quot)</a>
            return np.nan

    @lab_api
    def body_act(self, body, state):</code></pre><h3>After Change</h3><pre><code class='java'>
            self.body.entropies = []
            logger.debug(f&quotLoss: {loss}&quot)
            self.last_loss = loss.item()
        <a id="change">return self.last_loss</a>

    @lab_api
    def update(self):
        &quot&quot&quotUpdate the agent after training&quot&quot&quot</code></pre>