<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

    def __call__(self, input, target_is_real):
        target_tensor = self.get_target_tensor(input, target_is_real)
        <a id="change">return self.loss(input, target_tensor)</a>


&#47&#47 Defines the generator that consists of Resnet blocks between a few
&#47&#47 downsampling/upsampling operations.</code></pre><h3>After Change</h3><pre><code class='java'>
        
        if self.gan_mode in [&quotlsgan&quot, &quotvanilla&quot]:
            target_tensor = self.get_target_tensor(prediction, target_is_real)
            <a id="change">loss = self.loss(prediction, target_tensor)</a>
        elif self.gan_mode == &quotwgangp&quot:
            if target_is_real:
                loss = -prediction.mean()
            else:
                loss = prediction.mean()
        <a id="change">return loss</a>


def cal_gradient_penalty(netD, real_data, fake_data, device, type=&quotmixed&quot, constant=1.0, lambda_gp=10.0):
    calculate the gradient penalty loss, used in WGAN-GP paper https://arxiv.org/abs/1704.00028</code></pre>