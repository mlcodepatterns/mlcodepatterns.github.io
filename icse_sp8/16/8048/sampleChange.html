<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

    &#47&#47 pad cols with zeros if ndims returned is less than ndims
    if x_reduced[0].shape[1] &lt; ndims:
        <a id="change">for idx, x_r in enumerate(x_reduced):
            x_reduced[idx] = np.hstack([x_r, np.zeros((x_r.shape[0], ndims-x_reduced[0].shape[1]))])

   </a> if align == True:
        &#47&#47 Import is here to avoid circular imports with reduce.py
        from .align import align as aligner
        x_reduced = aligner(x_reduced)</code></pre><h3>After Change</h3><pre><code class='java'>
            return [x_r[0]]

    &#47&#47 dictionary of models
    <a id="change">models = {
        &quotPCA&quot : PCA,
        &quotFastICA&quot : FastICA,
        &quotTSNE&quot : TSNE,
        &quotIsomap&quot : Isomap,
        &quotSpectralEmbedding&quot : SpectralEmbedding,
        &quotLocallyLinearEmbedding&quot : LocallyLinearEmbedding
    }</a>

    &#47&#47 main
    x = format_data(x)

    assert all([i.shape[1]&gt;ndims for i in x]), "In order to reduce the data, ndims must be less than the number of dimensions"

    &#47&#47 if there are any nans in any of the lists, use ppca
    if np.isnan(np.vstack(x)).any():
        warnings.warn(&quotMissing data: Inexact solution computed with PPCA (see https://github.com/allentran/pca-magic for details)&quot)
        x = fill_missing(x)

    &#47&#47 normalize
    if normalize:
        x = normalizer(x, normalize=normalize)

    &#47&#47 build model params dict
    if model_params=={}:
        model_params = <a id="change">{
            &quotn_components&quot : ndims
        }</a>
    elif &quotn_components&quot in model_params:
        pass
    else:
        model_params[&quotn_components&quot]=ndims</code></pre>