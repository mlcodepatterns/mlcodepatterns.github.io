<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    def test_synchronization(self):
        self.start_tests(name=&quotsynchronization&quot)

        <a id="change">self.unittest(
            policy=dict(network=dict(type=&quotauto&quot, size=8, depth=1, rnn=2)),
            optimizer=&quotsynchronization&quot,
            baseline=dict(network=dict(type=&quotauto&quot, size=8, depth=1, rnn=1)),
            baseline_optimizer=&quotadam&quot, baseline_objective=&quotpolicy_gradient&quot
        )</a>

    def test_tf_optimizer(self):
        self.start_tests(name=&quottf-optimizer&quot)
</code></pre><h3>After Change</h3><pre><code class='java'>
        actions = dict(
            bool_action=dict(type=&quotbool&quot, shape=(1,)),
            int_action=dict(type=&quotint&quot, shape=(2,), num_values=4),
            gaussian_action1=<a id="change">dict(type=&quotfloat&quot, shape=(1, 2), min_value=1.0, max_value=2.0)</a>,
            gaussian_action2=dict(type=&quotfloat&quot, shape=(), min_value=-2.0, max_value=1.0)
        )
        baseline = dict(network=dict(type=&quotauto&quot, size=8, depth=1, rnn=1), distributions=dict(
            gaussian_action2=dict(type=&quotgaussian&quot, global_stddev=True)
        ))
        <a id="change">self.unittest(
            &#47&#47 Requires same size, but can still vary RNN horizon
            actions=actions, baseline=baseline, baseline_optimizer=&quotsynchronization&quot,
            &#47&#47 Using policy_gradient here, since action_value is covered by DQN
            baseline_objective=&quotpolicy_gradient&quot
        )</a>

    def test_tf_optimizer(self):
        self.start_tests(name=&quottf-optimizer&quot)
</code></pre>