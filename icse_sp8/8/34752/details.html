<html><h3>3bd4db86630b75bbbfb6c5c0a1a85603097bf9b2,torchaudio/transforms.py,F2M,__call__,#F2M#Any#,248
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

    def __call__(self, spec_f):

        <a id="change">spec_f, is_variable = _check_is_variable(spec_f)</a>
        n_fft = spec_f.size(2)

        m_min = 0. if self.f_min == 0 else 2595 * np.log10(1. + (self.f_min / 700))
        m_max = 2595 * np.log10(1. + (self.f_max / 700))

        m_pts = torch.linspace(m_min, m_max, self.n_mels + 2)
        f_pts = (700 * (10**(m_pts / 2595) - 1))

        bins = torch.floor(((n_fft - 1) * 2) * f_pts / self.sr).long()

        fb = torch.zeros(n_fft, self.n_mels)
        for m in range(1, self.n_mels + 1):
            f_m_minus = bins[m - 1].item()
            f_m = bins[m].item()
            f_m_plus = bins[m + 1].item()

            if f_m_minus != f_m:
                fb[f_m_minus:f_m, m - 1] = (torch.arange(f_m_minus, f_m) - f_m_minus) / (f_m - f_m_minus)
            if f_m != f_m_plus:
                fb[f_m:f_m_plus, m - 1] = (f_m_plus - torch.arange(f_m, f_m_plus)) / (f_m_plus - f_m)

        fb = Variable(fb)
        spec_m = torch.matmul(spec_f, fb)  &#47&#47 (c, l, n_fft) dot (n_fft, n_mels) -&gt; (c, l, n_mels)
        return <a id="change">spec_m if is_variable else spec_m.data</a>


class SPEC2DB(object):
    Turns a spectrogram from the power/amplitude scale to the decibel scale.</code></pre><h3>After Change</h3><pre><code class='java'>
                fb[f_m:f_m_plus, m - 1] = (f_m_plus - torch.arange(f_m, f_m_plus)) / (f_m_plus - f_m)

        spec_m = torch.matmul(spec_f, fb)  &#47&#47 (c, l, n_fft) dot (n_fft, n_mels) -&gt; (c, l, n_mels)
        <a id="change">return spec_m</a>


class SPEC2DB(object):
    Turns a spectrogram from the power/amplitude scale to the decibel scale.</code></pre><img src="170731917.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/pytorch/audio/commit/3bd4db86630b75bbbfb6c5c0a1a85603097bf9b2#diff-e835241144a5115b9931dd00984a88a73f9d4530de1ef1b3456be83804260a1cL248' target='_blank'>Link</a></div><div id='project'> Project Name: pytorch/audio</div><div id='commit'> Commit Name: 3bd4db86630b75bbbfb6c5c0a1a85603097bf9b2</div><div id='time'> Time: 2019-01-04</div><div id='author'> Author: david@da3.net</div><div id='file'> File Name: torchaudio/transforms.py</div><div id='class'> Class Name: F2M</div><div id='method'> Method Name: __call__</div><BR><BR><div id='link'><a href='https://github.com/pytorch/audio/commit/3bd4db86630b75bbbfb6c5c0a1a85603097bf9b2#diff-e835241144a5115b9931dd00984a88a73f9d4530de1ef1b3456be83804260a1cL291' target='_blank'>Link</a></div><div id='project'> Project Name: pytorch/audio</div><div id='commit'> Commit Name: 3bd4db86630b75bbbfb6c5c0a1a85603097bf9b2</div><div id='time'> Time: 2019-01-04</div><div id='author'> Author: david@da3.net</div><div id='file'> File Name: torchaudio/transforms.py</div><div id='class'> Class Name: SPEC2DB</div><div id='method'> Method Name: __call__</div><BR><BR><div id='link'><a href='https://github.com/pytorch/audio/commit/3bd4db86630b75bbbfb6c5c0a1a85603097bf9b2#diff-e835241144a5115b9931dd00984a88a73f9d4530de1ef1b3456be83804260a1cL339' target='_blank'>Link</a></div><div id='project'> Project Name: pytorch/audio</div><div id='commit'> Commit Name: 3bd4db86630b75bbbfb6c5c0a1a85603097bf9b2</div><div id='time'> Time: 2019-01-04</div><div id='author'> Author: david@da3.net</div><div id='file'> File Name: torchaudio/transforms.py</div><div id='class'> Class Name: MEL2</div><div id='method'> Method Name: __call__</div><BR>