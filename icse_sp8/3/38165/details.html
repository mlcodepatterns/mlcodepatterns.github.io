<html><h3>f33446be0e9e8deb631477db30f20ac436491f24,ch16/01_cartpole_es.py,,,#,84
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    writer = SummaryWriter(comment="-cartpole-es")
    env = gym.make("CartPole-v0")
    print(env)
    obs = <a id="change">env.reset()</a>
    print(obs)

    net = Net(env.observation_space.shape[0], env.action_space.n)
    print(net)</code></pre><h3>After Change</h3><pre><code class='java'>

    step_idx = 0
    while True:
        t_start = <a id="change">time.time()</a>
        batch_noise = []
        batch_reward = []
        batch_steps = 0
        for _ in range(MAX_BATCH_EPISODES):
            noise = sample_noise(net)
            batch_noise.append(noise)
            reward, steps = eval_with_noise(env, net, noise)
            batch_reward.append(reward)
            batch_steps += steps
            if batch_steps &gt; MAX_BATCH_STEPS:
                break

        step_idx += 1
        m_reward = np.mean(batch_reward)
        if m_reward &gt; 199:
            print("Solved in %d steps" % step_idx)
            print(batch_reward)
            break

        train_step(net, batch_noise, batch_reward, writer, step_idx)
        writer.add_scalar("reward_mean", m_reward, step_idx)
        writer.add_scalar("reward_std", np.std(batch_reward), step_idx)
        writer.add_scalar("reward_max", np.max(batch_reward), step_idx)
        writer.add_scalar("batch_episodes", len(batch_reward), step_idx)
        writer.add_scalar("batch_steps", batch_steps, step_idx)
        <a id="change">speed = batch_steps / (time.time() - t_start)</a>
        writer.add_scalar("speed", speed, step_idx)
        print("%d: reward=%.2f, speed=%.2f f/s" % (step_idx, m_reward, speed))

    pass</code></pre><img src="185189016.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/PacktPublishing/Deep-Reinforcement-Learning-Hands-On/commit/f33446be0e9e8deb631477db30f20ac436491f24#diff-e9d4b5961dd97356fd5848a5e4c82c945d873dfd9979d05ec858c859e512ff19L86' target='_blank'>Link</a></div><div id='project'> Project Name: PacktPublishing/Deep-Reinforcement-Learning-Hands-On</div><div id='commit'> Commit Name: f33446be0e9e8deb631477db30f20ac436491f24</div><div id='time'> Time: 2018-02-17</div><div id='author'> Author: max.lapan@gmail.com</div><div id='file'> File Name: ch16/01_cartpole_es.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: </div><BR><BR><div id='link'><a href='https://github.com/openai/baselines/commit/b875fb7b5e4feb85b9f1f1bf4e78f64c75595664#diff-e9acb6a4403aa225036049c6be067a6ddbfd5a4603e3eb4c0cbee22311442d17L10' target='_blank'>Link</a></div><div id='project'> Project Name: openai/baselines</div><div id='commit'> Commit Name: b875fb7b5e4feb85b9f1f1bf4e78f64c75595664</div><div id='time'> Time: 2019-02-27</div><div id='author'> Author: peterzhokhoff@gmail.com</div><div id='file'> File Name: baselines/common/tests/envs/mnist_env.py</div><div id='class'> Class Name: MnistEnv</div><div id='method'> Method Name: __init__</div><BR><BR><div id='link'><a href='https://github.com/OpenNMT/OpenNMT-tf/commit/d7db4b1b9a6c9577ca3a09c4241cdd9db58b31bc#diff-fd3ec181173ca09f203ada8548167bf7897932889e98ae24d12dfffcf6a0048cL45' target='_blank'>Link</a></div><div id='project'> Project Name: OpenNMT/OpenNMT-tf</div><div id='commit'> Commit Name: d7db4b1b9a6c9577ca3a09c4241cdd9db58b31bc</div><div id='time'> Time: 2020-01-16</div><div id='author'> Author: guillaumekln@users.noreply.github.com</div><div id='file'> File Name: opennmt/training.py</div><div id='class'> Class Name: Trainer</div><div id='method'> Method Name: __call__</div><BR>