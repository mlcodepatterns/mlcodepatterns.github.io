<html><h3>6fe998295efee06541295a086d57dc2a10f230b7,opennmt/utils/transformer.py,,multi_head_attention,#Any#Any#Any#Any#Any#Any#Any#Any#,67
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
  input_dim = keys.get_shape().as_list()[-1]
  head_dim = input_dim / num_heads

  <a id="change">with tf.variable_scope("multi_head"):
    for i in range(num_heads):
      with tf.variable_scope("head_" + str(i)):
        &#47&#47 Project queries, keys and values to different and smaller subspaces.
        queries_proj = tf.layers.dense(
          queries,
          head_dim,
          use_bias=False)
        keys_proj = tf.layers.dense(
          keys,
          head_dim,
          use_bias=False)
        values_proj = tf.layers.dense(
          values,
          head_dim,
          use_bias=False)

        head_i = scaled_dot_attention(
          queries_proj,
          keys_proj,
          values_proj,
          mode,
          values_length=values_length,
          mask_future=mask_future,
          dropout=dropout)

        heads.append(head_i)

    &#47&#47 Concatenate all heads output.
    return tf.concat(heads, axis=2)

</a>def feed_forward(x, inner_dim):
  Implements the Transformer&quots "Feed Forward" layer.

  ffn(x) = max(0, x*W_1 + b_1)*W_2 + b_2</code></pre><h3>After Change</h3><pre><code class='java'>
  input_dim = keys.get_shape().as_list()[-1]
  head_dim = input_dim / num_heads

  <a id="change">for i in range(num_heads):
    with tf.variable_scope("head_" + str(i)):
      &#47&#47 Project queries, keys and values to different and smaller subspaces.
      queries_proj = tf.layers.dense(
        queries,
        head_dim,
        use_bias=False)
      keys_proj = tf.layers.dense(
        keys,
        head_dim,
        use_bias=False)
      values_proj = tf.layers.dense(
        values,
        head_dim,
        use_bias=False)

      head_i = scaled_dot_attention(
        queries_proj,
        keys_proj,
        values_proj,
        mode,
        values_length=values_length,
        mask_future=mask_future,
        dropout=dropout)

      heads.append(head_i)

  &#47&#47 Concatenate all heads output.
 </a> return tf.concat(heads, axis=2)

def feed_forward(x, inner_dim):
  Implements the Transformer&quots "Feed Forward" layer.</code></pre><img src="133475061.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/OpenNMT/OpenNMT-tf/commit/6fe998295efee06541295a086d57dc2a10f230b7#diff-435b278136ea3d3655731485c220f304ad1c047bcee3d147d25757181a2551beL96' target='_blank'>Link</a></div><div id='project'> Project Name: OpenNMT/OpenNMT-tf</div><div id='commit'> Commit Name: 6fe998295efee06541295a086d57dc2a10f230b7</div><div id='time'> Time: 2017-08-16</div><div id='author'> Author: guillaume.klein@systrangroup.com</div><div id='file'> File Name: opennmt/utils/transformer.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: multi_head_attention</div><BR><BR><div id='link'><a href='https://github.com/asyml/texar/commit/49107396aaa0339f1b2dbf43490b9df0417e4675#diff-e07d9904b334598a524b49ab6ce2dcef7f8bc61532ba4a43133585d542f3dbe0L331' target='_blank'>Link</a></div><div id='project'> Project Name: asyml/texar</div><div id='commit'> Commit Name: 49107396aaa0339f1b2dbf43490b9df0417e4675</div><div id='time'> Time: 2018-08-22</div><div id='author'> Author: zhitinghu@gmail.com</div><div id='file'> File Name: texar/modules/memory/memory_network.py</div><div id='class'> Class Name: MemNetRNNLike</div><div id='method'> Method Name: _build</div><BR><BR><div id='link'><a href='https://github.com/dpressel/mead-baseline/commit/bfd0068e7a0922c06cdeff346a6c6339f98ae256#diff-56c739f93913ef817fc351cc95027a6046bf8b75e154ee69b54ef8c7c2c3cb21L809' target='_blank'>Link</a></div><div id='project'> Project Name: dpressel/mead-baseline</div><div id='commit'> Commit Name: bfd0068e7a0922c06cdeff346a6c6339f98ae256</div><div id='time'> Time: 2019-11-19</div><div id='author'> Author: blester125@gmail.com</div><div id='file'> File Name: python/eight_mile/tf/layers.py</div><div id='class'> Class Name: BiLSTMEncoder1</div><div id='method'> Method Name: call</div><BR><BR><div id='link'><a href='https://github.com/rlworkgroup/garage/commit/5c42053fcd6821eb39eded56526cfe5f2070418a#diff-b6fc5554809617369d7c7c5dba6b0034f0f2fe447d3f58b5d98827b3e467cffeL44' target='_blank'>Link</a></div><div id='project'> Project Name: rlworkgroup/garage</div><div id='commit'> Commit Name: 5c42053fcd6821eb39eded56526cfe5f2070418a</div><div id='time'> Time: 2018-05-25</div><div id='author'> Author: 35857569+gonzaiva@users.noreply.github.com</div><div id='file'> File Name: sandbox/rocky/tf/optimizers/penalty_lbfgs_optimizer.py</div><div id='class'> Class Name: PenaltyLbfgsOptimizer</div><div id='method'> Method Name: update_opt</div><BR>