<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
  if has_moving_average_decay:
    ema = tf.train.ExponentialMovingAverage(
        decay=params[&quotmoving_average_decay&quot], num_updates=global_step)
    <a id="change">ema_vars = tf.trainable_variables() + tf.get_collection(&quotmoving_vars&quot)</a>
    <a id="change">for v in tf.global_variables():
      &#47&#47 We maintain mva for batch norm moving mean and variance as well.
      if &quotmoving_mean&quot in v.name or &quotmoving_variance&quot in v.name:
        ema_vars.append(v)
   </a> ema_vars = <a id="change">list(set(ema_vars))</a>

  host_call = None
  if is_training:
    &#47&#47 Compute the current epoch and associated learning rate from global_step.</code></pre><h3>After Change</h3><pre><code class='java'>
  if has_moving_average_decay:
    ema = tf.train.ExponentialMovingAverage(
        decay=params[&quotmoving_average_decay&quot], num_updates=global_step)
    ema_vars = <a id="change">mnasnet_utils.get_ema_vars()</a>

  host_call = None
  if is_training:
    &#47&#47 Compute the current epoch and associated learning rate from global_step.</code></pre>