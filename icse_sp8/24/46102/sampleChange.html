<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            layout = &quotcna&quot if b_norm else &quotca&quot
            layout_transpose = &quottna&quot if b_norm else &quotta&quot

            <a id="change">net = conv_block(dim, net, 32, 3, layout_transpose, &quotoutput_conv_1&quot, 2, **kwargs)</a>
            <a id="change">net = conv_block(dim, net, 32, 3, layout, &quotoutput_conv_2&quot, **kwargs)</a>
            <a id="change">net = conv_block(dim, net, n_classes, 2, &quott&quot, &quotoutput_conv_3&quot, 2, **kwargs)</a>

        logits = tf.identity(net, &quotpredictions&quot)
        tf.nn.softmax(logits, name=&quotpredicted_prob&quot)
</code></pre><h3>After Change</h3><pre><code class='java'>

        n_classes = self.num_channels(&quotmasks&quot)
        data_format = self.data_format(&quotimages&quot)
        <a id="change">dim</a> = self.spatial_dim(&quotimages&quot)
        enable_batch_norm = self.get_from_config(&quotbatch_norm&quot, True)
        n_filters = self.get_from_config(&quotn_filters&quot, 64)
        n_blocks = self.get_from_config(&quotn_blocks&quot, 4)

        conv = {&quotdata_format&quot: data_format}
        batch_norm = {&quotmomentum&quot: 0.1,
                      &quottraining&quot: self.is_training}

        kwargs = {&quotconv&quot: conv, &quotbatch_norm&quot: batch_norm}

        with tf.variable_scope(&quotLinkNet&quot):
            layout = &quotcpna&quot if enable_batch_norm else &quotcpa&quot
            linknet_filters = 2 ** np.arange(n_blocks) * n_filters

            net = conv_block(dim, inputs[&quotimages&quot], n_filters, 7, layout, &quotinput_conv&quot, strides=2, pool_size=3, **kwargs)

            encoder_output = []

            for i, filters in enumerate(linknet_filters):
                net = self.downsampling_block(dim, net, filters, &quotdownsampling-&quot+str(i), enable_batch_norm, **kwargs)
                encoder_output.append(net)

            for i, filters in enumerate(linknet_filters[::-1][1:]):
                net = self.upsampling_block(dim, net, filters, &quotupsampling-&quot+str(i), enable_batch_norm, **kwargs)
                net = tf.add(net, encoder_output[-2-i])

            net = self.upsampling_block(dim, net, n_filters, &quotupsampling-3&quot, enable_batch_norm, **kwargs)

            layout = &quottnacnat&quot if enable_batch_norm else &quottacat&quot

            <a id="change">net = conv_block(dim, net, [32, 32, n_classes], [3, 3, 2], layout, &quotoutput-conv&quot, 
                             strides=[2, 1, 2], **kwargs)</a>

        logits = tf.identity(net, &quotpredictions&quot)
        tf.nn.softmax(logits, name=&quotpredicted_prob&quot)
</code></pre>