<html><h3>cefe625f707d3fd0241f4ad682d2d991233db200,tmtoolkit/lda_utils/evaluation_sklearn.py,MultiprocEvaluationWorkerSklearn,fit_model_using_params,#MultiprocEvaluationWorkerSklearn#Any#,23
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            else:
                results = lda_instance.perplexity(data)

            <a id="change">logger.info(&quot&gt; evaluation result with metric "%s": %f&quot % (self.eval_metric, results))</a>

        self.send_results(params, results)

</code></pre><h3>After Change</h3><pre><code class='java'>
            lda_instance.fit(data)

            results = {}
            <a id="change">for metric in self.eval_metric:
                if metric == &quotcross_validation&quot: continue

                metric_opt = self.eval_metric_options.get(metric, {})

                if metric == &quotcao_juan_2009&quot:
                    topic_word_distrib = lda_instance.components_ / lda_instance.components_.sum(axis=1)[:, np.newaxis]
                    res = metric_cao_juan_2009(topic_word_distrib)
                elif metric == &quotarun_2010&quot:
                    topic_word_distrib = lda_instance.components_ / lda_instance.components_.sum(axis=1)[:, np.newaxis]
                    res = metric_arun_2010(topic_word_distrib, lda_instance.transform(data), data.sum(axis=1))
                else:  &#47&#47 default: perplexity
                    res = lda_instance.perplexity(data)

                logger.info(&quot&gt; evaluation result with metric "%s": %f&quot % (metric, res))
                results[metric] = res

       </a> self.send_results(params, results)


def evaluate_topic_models(varying_parameters, constant_parameters, data, metric=None, n_workers=None, n_folds=0,</code></pre><img src="212333486.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/WZBSocialScienceCenter/tmtoolkit/commit/cefe625f707d3fd0241f4ad682d2d991233db200#diff-4c954b6fbc5bc69f90b6a51d840fc8015306d52fafafb14753d2bada79154f32L23' target='_blank'>Link</a></div><div id='project'> Project Name: WZBSocialScienceCenter/tmtoolkit</div><div id='commit'> Commit Name: cefe625f707d3fd0241f4ad682d2d991233db200</div><div id='time'> Time: 2017-10-12</div><div id='author'> Author: markus.konrad@wzb.eu</div><div id='file'> File Name: tmtoolkit/lda_utils/evaluation_sklearn.py</div><div id='class'> Class Name: MultiprocEvaluationWorkerSklearn</div><div id='method'> Method Name: fit_model_using_params</div><BR><BR><div id='link'><a href='https://github.com/WZBSocialScienceCenter/tmtoolkit/commit/cefe625f707d3fd0241f4ad682d2d991233db200#diff-ccef7db30187f4b9c40b60c981f0e396b6c1bf256564eea4ba1e8a49ccb077c9L35' target='_blank'>Link</a></div><div id='project'> Project Name: WZBSocialScienceCenter/tmtoolkit</div><div id='commit'> Commit Name: cefe625f707d3fd0241f4ad682d2d991233db200</div><div id='time'> Time: 2017-10-12</div><div id='author'> Author: markus.konrad@wzb.eu</div><div id='file'> File Name: tmtoolkit/lda_utils/evaluation_gensim.py</div><div id='class'> Class Name: MultiprocEvaluationWorkerGensim</div><div id='method'> Method Name: fit_model_using_params</div><BR><BR><div id='link'><a href='https://github.com/OpenNMT/OpenNMT-tf/commit/ab6f9e4c489beea3bec518d60629c0f8af0b6123#diff-f1cf444e49dc05b3a2d1175e135b051acd00cbae2b7bc8775f71fe6e35045199L277' target='_blank'>Link</a></div><div id='project'> Project Name: OpenNMT/OpenNMT-tf</div><div id='commit'> Commit Name: ab6f9e4c489beea3bec518d60629c0f8af0b6123</div><div id='time'> Time: 2019-06-21</div><div id='author'> Author: guillaume.klein@systrangroup.com</div><div id='file'> File Name: opennmt/runner.py</div><div id='class'> Class Name: Runner</div><div id='method'> Method Name: train</div><BR>