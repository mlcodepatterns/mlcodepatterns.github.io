<html><h3>e1861863b2248e4d7d73c12a152e8c035301095d,pytext/torchscript/module.py,ScriptPyTextTwoTowerEmbeddingModule,make_batch,#ScriptPyTextTwoTowerEmbeddingModule#Any#Any#,752
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        &#47&#47 The next lines performs the following function, which is not supported by TorchScript
        &#47&#47 sorted_mega_batch = sorted(mega_batch,key=lambda element : len(element[argno]))
        mega_batch_class_list = <a id="change">[
            PytextTwoTowerEmbeddingModuleBatchSort(x, argno) for x in mega_batch
        ]</a>
        sorted_mega_batch_class_list = sorted(mega_batch_class_list)
        <a id="change">sorted_mega_batch = [x.be() for x in sorted_mega_batch_class_list]</a>

        &#47&#47 TBD: allow model server to specify batch size in goals dictionary
        max_bs: int = 10
        len_mb = len(mega_batch)</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 The next lines sort all cross-request batch elements by the token length of right_.
        &#47&#47 Note that cross-request batch element can in turn be a client batch.
        mega_batch_key_list = [
            (max_tokens(<a id="change">self.right_tensorizer.tokenize(x[0], x[2])</a>), n)
            for (n, x) in enumerate(mega_batch)
        ]
        sorted_mega_batch_key_list = sorted(mega_batch_key_list)
        sorted_mega_batch = [<a id="change">mega_batch[n]</a> <a id="change">for</a> (key, n) in sorted_mega_batch_key_list]

        &#47&#47 TBD: allow model server to specify batch size in goals dictionary
        max_bs: int = 10</code></pre><img src="327531589.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/facebookresearch/pytext/commit/e1861863b2248e4d7d73c12a152e8c035301095d#diff-6fe03fade3ffeb2f7c18ea27c310bc31b8781d5afb82ea7e2d510cc5274a9e5bL751' target='_blank'>Link</a></div><div id='project'> Project Name: facebookresearch/pytext</div><div id='commit'> Commit Name: e1861863b2248e4d7d73c12a152e8c035301095d</div><div id='time'> Time: 2020-10-30</div><div id='author'> Author: mikekg@fb.com</div><div id='file'> File Name: pytext/torchscript/module.py</div><div id='class'> Class Name: ScriptPyTextTwoTowerEmbeddingModule</div><div id='method'> Method Name: make_batch</div><BR><BR><div id='link'><a href='https://github.com/facebookresearch/pytext/commit/e1861863b2248e4d7d73c12a152e8c035301095d#diff-6fe03fade3ffeb2f7c18ea27c310bc31b8781d5afb82ea7e2d510cc5274a9e5bL333' target='_blank'>Link</a></div><div id='project'> Project Name: facebookresearch/pytext</div><div id='commit'> Commit Name: e1861863b2248e4d7d73c12a152e8c035301095d</div><div id='time'> Time: 2020-10-30</div><div id='author'> Author: mikekg@fb.com</div><div id='file'> File Name: pytext/torchscript/module.py</div><div id='class'> Class Name: ScriptPyTextEmbeddingModule</div><div id='method'> Method Name: make_batch</div><BR><BR><div id='link'><a href='https://github.com/hellohaptik/chatbot_ner/commit/2e801652a510dea463b43cb718b87b54bf4acab3#diff-163a0c6b51022438351c8155f0381bf6eb3c25a76e89bd406f1751065e10d4eeL51' target='_blank'>Link</a></div><div id='project'> Project Name: hellohaptik/chatbot_ner</div><div id='commit'> Commit Name: 2e801652a510dea463b43cb718b87b54bf4acab3</div><div id='time'> Time: 2018-09-09</div><div id='author'> Author: pratik.jayarao@haptik.co</div><div id='file'> File Name: models/crf_v2/crf_preprocess_data.py</div><div id='class'> Class Name: CrfPreprocessData</div><div id='method'> Method Name: pre_process_text_</div><BR>