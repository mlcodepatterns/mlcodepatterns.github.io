<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    env = ptan.common.wrappers.wrap_dqn(env)

    writer = SummaryWriter(comment="-" + params[&quotrun_name&quot] + "-%d-step" % args.n)
    net = <a id="change">dqn_model.DQN(env.observation_space.shape, env.action_space.n)</a>
    <a id="change">if args.cuda:
        net.cuda()

   </a> tgt_net = ptan.agent.TargetNet(net)
    selector = ptan.actions.EpsilonGreedyActionSelector(epsilon=params[&quotepsilon_start&quot])
    epsilon_tracker = common.EpsilonTracker(selector, params)
    agent = ptan.agent.DQNAgent(net, selector, cuda=args.cuda)</code></pre><h3>After Change</h3><pre><code class='java'>
    parser.add_argument("--cuda", default=False, action="store_true", help="Enable cuda")
    parser.add_argument("-n", default=REWARD_STEPS_DEFAULT, type=int, help="Count of steps to unroll Bellman")
    args = parser.parse_args()
    <a id="change">device = torch.device("cuda" if args.cuda else "cpu")</a>

    env = gym.make(params[&quotenv_name&quot])
    env = ptan.common.wrappers.wrap_dqn(env)

    writer = SummaryWriter(comment="-" + params[&quotrun_name&quot] + "-%d-step" % args.n)
    net = <a id="change">dqn_model.DQN(env.observation_space.shape, env.action_space.n).to(device)</a>

    tgt_net = ptan.agent.TargetNet(net)
    selector = ptan.actions.EpsilonGreedyActionSelector(epsilon=params[&quotepsilon_start&quot])
    epsilon_tracker = common.EpsilonTracker(selector, params)</code></pre>