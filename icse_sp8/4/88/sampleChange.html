<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        &#47&#47 Encoder
        x = self.add_forward_preprocessing_ops()  &#47&#47 (N, D)
        self.sum_log_det_jacobians = np.zeros_like(<a id="change">(x.shape[0],)</a>)  &#47&#47 (N,)
        forward_out = x
        for layer in self.layers:
            forward_out, log_det_jacobian = layer.forward_and_jacobian(</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 None dimension in the shape. The result of this is just zero
        &#47&#47 tensor with shape (None, ), i.e. (N,), where N is the batch_size
        self.sum_log_det_jacobians = tf.reduce_sum(
            tf.zeros_like(x), axis=<a id="change">tuple(range(1, len(x.shape)))</a>)  &#47&#47 (N,)
        forward_out = x
        for layer in self.layers:
            forward_out, log_det_jacobian = layer.forward_and_jacobian(</code></pre>