<html><h3>193c2dffbf492f832d2914d16b12f7ba8afc3979,models/official/mnasnet/mnasnet_main.py,,build_model_fn,#Any#Any#Any#Any#,263
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
      &#47&#47 expects [batch_size, ...] Tensors, thus reshape to introduce a batch
      &#47&#47 dimension. These Tensors are implicitly concatenated to
      &#47&#47 [params[&quotbatch_size&quot]].
      gs_t = <a id="change">tf.reshape(global_step, [1])</a>
      loss_t = tf.reshape(loss, [1])
      lr_t = tf.reshape(learning_rate, [1])
      ce_t = tf.reshape(current_epoch, [1])

      <a id="change">host_call = (host_call_fn, [gs_t, loss_t, lr_t, ce_t])</a>

  else:
    train_op = None
</code></pre><h3>After Change</h3><pre><code class='java'>
      if params[&quotadd_summaries&quot]:
        summary_writer = tf2.summary.create_file_writer(
            FLAGS.model_dir, max_queue=params[&quotiterations_per_loop&quot])
        <a id="change">with summary_writer.as_default():
          should_record = tf.equal(global_step % params[&quotiterations_per_loop&quot],
                                   0)
          with tf2.summary.record_if(should_record):
            tf2.summary.scalar(&quotloss&quot, loss, step=global_step)
            tf2.summary.scalar(&quotlearning_rate&quot, learning_rate, step=global_step)
            tf2.summary.scalar(&quotcurrent_epoch&quot, current_epoch, step=global_step)

    &#47&#47 Batch normalization requires UPDATE_OPS to be added as a dependency to
    &#47&#47 the train operation.
   </a> update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)

    with tf.control_dependencies(update_ops + tf.summary.all_v2_summary_ops()):
      train_op = optimizer.minimize(loss, global_step)</code></pre><img src="12455535.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/tensorflow/tpu/commit/193c2dffbf492f832d2914d16b12f7ba8afc3979#diff-1b2556446c21831afa3b5930d46633ee5f20b58b95a971cb3ac402d6705a3b00L412' target='_blank'>Link</a></div><div id='project'> Project Name: tensorflow/tpu</div><div id='commit'> Commit Name: 193c2dffbf492f832d2914d16b12f7ba8afc3979</div><div id='time'> Time: 2019-12-03</div><div id='author'> Author: gardener@tensorflow.org</div><div id='file'> File Name: models/official/mnasnet/mnasnet_main.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: build_model_fn</div><BR><BR><div id='link'><a href='https://github.com/ilastik/ilastik/commit/5a0373b2cdb1222e7c9816c0fc88e22fda743647#diff-535ded9df43e92aaa6f9ee9190e3b6db76e4c9d5212d5885d99d86fef6b2fbddL78' target='_blank'>Link</a></div><div id='project'> Project Name: ilastik/ilastik</div><div id='commit'> Commit Name: 5a0373b2cdb1222e7c9816c0fc88e22fda743647</div><div id='time'> Time: 2014-08-13</div><div id='author'> Author: bergs@janelia.hhmi.org</div><div id='file'> File Name: lazyflow/operators/opBlockedArrayCache.py</div><div id='class'> Class Name: OpBlockedArrayCache</div><div id='method'> Method Name: setupOutputs</div><BR><BR><div id='link'><a href='https://github.com/sony/nnabla-examples/commit/4f031d76c9a5b1e61080a4be62eee6f1ccd584fa#diff-e6c835736a51f88306835c78a0e2fa379c57aeadacba1724562d83c1f9fc9568L40' target='_blank'>Link</a></div><div id='project'> Project Name: sony/nnabla-examples</div><div id='commit'> Commit Name: 4f031d76c9a5b1e61080a4be62eee6f1ccd584fa</div><div id='time'> Time: 2019-05-14</div><div id='author'> Author: Akio.Hayakawa@sony.com</div><div id='file'> File Name: speech-synthesis/WaveNet/train.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: train</div><BR>