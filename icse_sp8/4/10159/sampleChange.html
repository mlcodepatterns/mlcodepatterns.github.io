<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        for epoch in range(args.fixbase_epoch):
            start_train_time = time.time()
            <a id="change">train(epoch, model, criterion, optimizer_tmp, trainloader, use_gpu, freeze_bn=True)</a>
            train_time += round(time.time() - start_train_time)

        del optimizer_tmp
        print("Now open all layers for training")</code></pre><h3>After Change</h3><pre><code class='java'>
    optimizer = init_optimizer(model.parameters(), **optimizer_kwargs(args))
    scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=args.stepsize, gamma=args.gamma)

    <a id="change">if args.fixbase_epoch &gt; 0:
        if hasattr(model, &quotclassifier&quot) and isinstance(model.classifier, nn.Module):
            optimizer_tmp = init_optimizer(model.classifier.parameters(), **optimizer_kwargs(args))
        else:
            print("Warn: model has no attribute &quotclassifier&quot and fixbase_epoch is reset to 0")
            args.fixbase_epoch = 0
        raise NotImplementedError

   </a> if args.load_weights and check_isfile(args.load_weights):
        &#47&#47 load pretrained weights but ignore layers that don&quott match in size
        checkpoint = torch.load(args.load_weights)
        pretrain_dict = checkpoint[&quotstate_dict&quot]</code></pre>