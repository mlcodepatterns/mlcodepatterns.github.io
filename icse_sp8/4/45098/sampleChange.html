<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                     if self._minibatch_size else len(rewards_flat))
        for epoch in range(self._max_optimization_epochs):
            shuffled_ids = np.random.permutation(len(rewards_flat))
            <a id="change">for start in range(0, len(rewards_flat), step_size):
                ids = shuffled_ids[start:start + step_size]
                loss = self._train(obs_flat[ids], actions_flat[ids],
                                   rewards_flat[ids], advantages_flat[ids])
           </a> logger.log(&quotMini epoch: {} | Loss: {}&quot.format(epoch, loss))

        self._value_function.fit(paths)
</code></pre><h3>After Change</h3><pre><code class='java'>
            tabular.record(&quot/Entropy&quot, policy_entropy.mean().item())

        with tabular.prefix(self._value_function.name):
            <a id="change">tabular.record(&quot/LossBefore&quot, vf_loss_before.item())</a>
            tabular.record(&quot/LossAfter&quot, vf_loss_after.item())
            tabular.record(&quot/dLoss&quot,
                           vf_loss_before.item() - vf_loss_after.item())
</code></pre>