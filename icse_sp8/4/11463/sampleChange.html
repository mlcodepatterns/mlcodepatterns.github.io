<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    loss, per_example_loss, logits, probabilities, model = create_model(bert_config, is_training, input_ids, input_mask,
                                                            segment_ids, label_ids, num_labels,use_one_hot_embeddings)
    &#47&#47 define train operation
    num_train_steps = <a id="change">int(float(num_examples) / float(FLAGS.batch_size * FLAGS.num_epochs))</a>;use_tpu=False
    num_warmup_steps = int(num_train_steps * 0.1)
    train_op = optimization.create_optimizer(loss, FLAGS.learning_rate, num_train_steps, num_warmup_steps, use_tpu)
</code></pre><h3>After Change</h3><pre><code class='java'>
    &#47&#47 define train operation
    &#47&#47num_train_steps = int(float(num_examples) / float(FLAGS.batch_size * FLAGS.num_epochs)); use_tpu=False; num_warmup_steps = int(num_train_steps * 0.1)
    &#47&#47train_op = optimization.create_optimizer(loss, FLAGS.learning_rate, num_train_steps, num_warmup_steps, use_tpu)
    global_step = <a id="change">tf.Variable(0, trainable=False, name="Global_Step")</a>
    train_op = tf.contrib.layers.optimize_loss(loss, global_step=global_step, learning_rate=FLAGS.learning_rate,optimizer="Adam", clip_gradients=3.0)

    is_training_eval=False
    loss_eval, per_example_loss_eval, logits_eval, probabilities_eval, model_eval = create_model(bert_config, is_training_eval, input_ids, input_mask,</code></pre>