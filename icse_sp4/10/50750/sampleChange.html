<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    &#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47
    iteration = infos[&quotiter&quot]
    epoch = infos[&quotepoch&quot]
    <a id="change">loader.iterators = infos.get(&quotiterators&quot, loader.iterators)</a>
    loader.split_ix = infos.get(&quotsplit_ix&quot, loader.split_ix)
    if opt.load_best_score == 1:
        best_val_score = infos.get(&quotbest_val_score&quot, None)
    if opt.noamopt:
        optimizer._step = iteration
    &#47&#47 flag indicating finish of an epoch
    &#47&#47 Always set to True at the beginning to initialize the lr or etc.
    epoch_done = True
    &#47&#47 Assure in training mode
    dp_lw_model.train()

    &#47&#47 Start training
    try:
        while True:
            if epoch_done:
                if not opt.noamopt and not opt.reduce_on_plateau:
                    &#47&#47 Assign the learning rate
                    if epoch &gt; opt.learning_rate_decay_start and opt.learning_rate_decay_start &gt;= 0:
                        frac = (epoch - opt.learning_rate_decay_start) // opt.learning_rate_decay_every
                        decay_factor = opt.learning_rate_decay_rate  ** frac
                        opt.current_lr = opt.learning_rate * decay_factor
                    else:
                        opt.current_lr = opt.learning_rate
                    utils.set_lr(optimizer, opt.current_lr) &#47&#47 set the decayed rate
                &#47&#47 Assign the scheduled sampling prob
                if epoch &gt; opt.scheduled_sampling_start and opt.scheduled_sampling_start &gt;= 0:
                    frac = (epoch - opt.scheduled_sampling_start) // opt.scheduled_sampling_increase_every
                    opt.ss_prob = min(opt.scheduled_sampling_increase_prob  * frac, opt.scheduled_sampling_max_prob)
                    model.ss_prob = opt.ss_prob

                &#47&#47 If start self critical training
                if opt.self_critical_after != -1 and epoch &gt;= opt.self_critical_after:
                    sc_flag = True
                    init_scorer(opt.cached_tokens)
                else:
                    sc_flag = False
                
                &#47&#47 If start structure loss training
                if opt.structure_after != -1 and epoch &gt;= opt.structure_after:
                    struc_flag = True
                    init_scorer(opt.cached_tokens)
                else:
                    struc_flag = False

                epoch_done = False
                    
            start = time.time()
            &#47&#47 Load data from train split (0)
            data = loader.get_batch(&quottrain&quot)
            print(&quotRead data:&quot, time.time() - start)

            torch.cuda.synchronize()
            start = time.time()

            tmp = [data[&quotfc_feats&quot], data[&quotatt_feats&quot], data[&quotlabels&quot], data[&quotmasks&quot], data[&quotatt_masks&quot]]
            tmp = [_ if _ is None else _.cuda() for _ in tmp]
            fc_feats, att_feats, labels, masks, att_masks = tmp
            
            optimizer.zero_grad()
            model_out = dp_lw_model(fc_feats, att_feats, labels, masks, att_masks, data[&quotgts&quot], torch.arange(0, len(data[&quotgts&quot])), sc_flag, struc_flag)

            loss = model_out[&quotloss&quot].mean()

            loss.backward()
            utils.clip_gradient(optimizer, opt.grad_clip)
            optimizer.step()
            train_loss = loss.item()
            torch.cuda.synchronize()
            end = time.time()
            if struc_flag:
                print("iter {} (epoch {}), train_loss = {:.3f}, lm_loss = {:.3f}, struc_loss = {:.3f}, time/batch = {:.3f}" \
                    .format(iteration, epoch, train_loss, model_out[&quotlm_loss&quot].mean().item(), model_out[&quotstruc_loss&quot].mean().item(), end - start))
            elif not sc_flag:
                print("iter {} (epoch {}), train_loss = {:.3f}, time/batch = {:.3f}" \
                    .format(iteration, epoch, train_loss, end - start))
            else:
                print("iter {} (epoch {}), avg_reward = {:.3f}, time/batch = {:.3f}" \
                    .format(iteration, epoch, model_out[&quotreward&quot].mean(), end - start))

            &#47&#47 Update the iteration and epoch
            iteration += 1
            if data[&quotbounds&quot][&quotwrapped&quot]:
                epoch += 1
                epoch_done = True

            &#47&#47 Write the training loss summary
            if (iteration % opt.losses_log_every == 0):
                tb_summary_writer.add_scalar(&quottrain_loss&quot, train_loss, iteration)
                if opt.noamopt:
                    opt.current_lr = optimizer.rate()
                elif opt.reduce_on_plateau:
                    opt.current_lr = optimizer.current_lr
                tb_summary_writer.add_scalar(&quotlearning_rate&quot, opt.current_lr, iteration)
                tb_summary_writer.add_scalar(&quotscheduled_sampling_prob&quot, model.ss_prob, iteration)
                if sc_flag:
                    tb_summary_writer.add_scalar(&quotavg_reward&quot, model_out[&quotreward&quot].mean(), iteration)
                elif struc_flag:
                    tb_summary_writer.add_scalar(&quotlm_loss&quot, model_out[&quotlm_loss&quot].mean().item(), iteration)
                    tb_summary_writer.add_scalar(&quotstruc_loss&quot, model_out[&quotstruc_loss&quot].mean().item(), iteration)
                    tb_summary_writer.add_scalar(&quotreward&quot, model_out[&quotreward&quot].mean().item(), iteration)

                histories[&quotloss_history&quot][iteration] = train_loss if not sc_flag else model_out[&quotreward&quot].mean()
                histories[&quotlr_history&quot][iteration] = opt.current_lr
                histories[&quotss_prob_history&quot][iteration] = model.ss_prob

            &#47&#47 update infos
            infos[&quotiter&quot] = iteration
            infos[&quotepoch&quot] = epoch
            infos[&quotiterators&quot] = <a id="change">loader.iterators</a>
            infos[&quotsplit_ix&quot] = loader.split_ix
            
            &#47&#47 make evaluation on validation set, and save model
            if (iteration % opt.save_checkpoint_every == 0):</code></pre><h3>After Change</h3><pre><code class='java'>
    epoch = infos[&quotepoch&quot]
    &#47&#47 For back compatibility
    if &quotiterators&quot in infos:
        <a id="change">infos[&quotloader_state_dict&quot] = {split: {&quotindex_list&quot: infos[&quotsplit_ix&quot][split], &quotiter_counter&quot: infos[&quotiterators&quot][split]} for split in [&quottrain&quot, &quotval&quot, &quottest&quot]}</a>
    loader.load_state_dict(infos[&quotloader_state_dict&quot])
    if opt.load_best_score == 1:
        best_val_score = infos.get(&quotbest_val_score&quot, None)
    if opt.noamopt:</code></pre>