<html><h3>e7a02b6293100e21ef15870fd0f9069beaae5290,train.py,,,#,21
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        g_update_first = True
        batch_size = data.size(0)
        running_batch_sizes += batch_size
        real_label = Variable(<a id="change">torch.ones(batch_size)</a>)
        fake_label = Variable(torch.zeros(batch_size))

        &#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47
        &#47&#47 (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))
        &#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47
        real_img = Variable(target)
        if torch.cuda.is_available():
            real_img = real_img.cuda()
            real_label = real_label.cuda()

        &#47&#47 compute loss of real_img
        real_out = netD(real_img)
        d_loss_real = discriminator_criterion(real_out, real_label)
        real_scores = real_out.data.sum()
        running_real_scores += real_scores

        &#47&#47 compute loss of fake_img
        z = Variable(data)
        if torch.cuda.is_available():
            z = z.cuda()
            fake_label = fake_label.cuda()
        fake_img = netG(z)
        fake_out = netD(fake_img)
        d_loss_fake = discriminator_criterion(fake_out, fake_label)
        fake_scores = fake_out.data.sum()

        d_loss = d_loss_real + d_loss_fake

        &#47&#47 bp and optimize
        optimizerD.zero_grad()
        d_loss.backward(retain_graph=True)
        optimizerD.step()

        &#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47
        &#47&#47 (2) Update G network: maximize log(D(G(z)))
        &#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47
        index = 1
        while ((fabs((real_scores - fake_scores) / batch_size) &gt; G_THRESHOLD) or g_update_first) and (
                    index &lt;= G_STOP_THRESHOLD):
            &#47&#47 compute loss of fake_img
            g_loss = generator_criterion(fake_out, real_label, fake_img, real_img)
            &#47&#47 bp and optimize
            optimizerG.zero_grad()
            g_loss.backward()
            optimizerG.step()
            fake_img = netG(z)
            fake_out = netD(fake_img)
            fake_scores = fake_out.data.sum()
            g_update_first = False
            index += 1

        g_loss = generator_criterion(fake_out, real_label, fake_img, real_img)
        running_g_loss += g_loss.data[0] * batch_size
        d_loss_fake = discriminator_criterion(fake_out, fake_label)
        d_loss = <a id="change">d_loss_real + d_loss_fake</a>
        running_d_loss += d_loss.data[0] * batch_size
        running_fake_scores += fake_scores

        train_bar.set_description(desc=&quot[%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f&quot</code></pre><h3>After Change</h3><pre><code class='java'>

        g_loss = generator_criterion(fake_out, fake_img, real_img)
        running_g_loss += g_loss.data[0] * batch_size
        <a id="change">d_loss = - torch.mean(torch.log(real_out) + torch.log(1 - fake_out))</a>
        running_d_loss += d_loss.data[0] * batch_size
        running_fake_scores += fake_scores

        train_bar.set_description(desc=&quot[%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f&quot</code></pre><img src="66747099.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/leftthomas/SRGAN/commit/e7a02b6293100e21ef15870fd0f9069beaae5290#diff-ed183d67207df065a11e1289f19d34cc2abbc5448dea952683cfe9728c342b95L71' target='_blank'>Link</a></div><div id='project'> Project Name: leftthomas/SRGAN</div><div id='commit'> Commit Name: e7a02b6293100e21ef15870fd0f9069beaae5290</div><div id='time'> Time: 2017-12-02</div><div id='author'> Author: leftthomas@qq.com</div><div id='file'> File Name: train.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: </div><BR><BR><div id='link'><a href='https://github.com/rusty1s/pytorch_geometric/commit/45a03ac258234ba49c0a43d46ae022493190591e#diff-fbf4de79d438a7d2145817bbf5d1c21ceaff59c0b0b65827ea3fb9a976267207L220' target='_blank'>Link</a></div><div id='project'> Project Name: rusty1s/pytorch_geometric</div><div id='commit'> Commit Name: 45a03ac258234ba49c0a43d46ae022493190591e</div><div id='time'> Time: 2019-03-26</div><div id='author'> Author: matthias.fey@tu-dortmund.de</div><div id='file'> File Name: torch_geometric/nn/models/autoencoder.py</div><div id='class'> Class Name: ARGA</div><div id='method'> Method Name: discriminator_loss</div><BR><BR><div id='link'><a href='https://github.com/nipy/dipy/commit/33cdc0ba9dcad9db132205012ac9c6b015c50436#diff-e96c1ddab3264f7caeef18525b95415a5789ff87ca05f6bee5ad6721013b7230L131' target='_blank'>Link</a></div><div id='project'> Project Name: nipy/dipy</div><div id='commit'> Commit Name: 33cdc0ba9dcad9db132205012ac9c6b015c50436</div><div id='time'> Time: 2017-06-20</div><div id='author'> Author: arokem@gmail.com</div><div id='file'> File Name: dipy/denoise/tests/test_lpca.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: test_lpca_rmse</div><BR>