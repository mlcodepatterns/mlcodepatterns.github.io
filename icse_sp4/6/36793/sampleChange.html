<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    metric_utils.log_metrics(metrics)
    for metric in metrics:
      tf.summary.scalar(
          metric.name, <a id="change">metric.result()</a>, step=step_metric.result())
    checkpoint_manager.save()
    saver.save(os.path.join(root_dir, &quotpolicy_%d&quot % step_metric.result()))
</code></pre><h3>After Change</h3><pre><code class='java'>
      tf_metrics.AverageEpisodeLengthMetric(batch_size=environment.batch_size)
  ] + list(additional_metrics)

  <a id="change">if isinstance(environment.reward_spec(), dict):
    metrics += [tf_metrics.AverageReturnMultiMetric(
        reward_spec=environment.reward_spec(),
        batch_size=environment.batch_size)]
  else:
    metrics += [
        tf_metrics.AverageReturnMetric(batch_size=environment.batch_size)]

 </a> if training_data_spec_transformation_fn is not None:
    add_batch_fn = lambda data: replay_buffer.add_batch(  &#47&#47 pylint: disable=g-long-lambda
        training_data_spec_transformation_fn(data))
  else:</code></pre>