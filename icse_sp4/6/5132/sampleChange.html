<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    dirnames = [dirname] + extra_test_dirs

    pref_filed, pref_filename = tempfile.mkstemp(&quotbrian_prefs&quot, text=True)
    <a id="change">pref_file = os.fdopen(pref_filed, &quotw&quot)</a>

    print(&quotRunning tests in %s &quot % (&quot, &quot.join(dirnames)), end=&quot&quot)
    if codegen_targets:
        print(&quotfor targets %s&quot % (&quot, &quot.join(codegen_targets)), end=&quot&quot)
    ex_in = &quotincluding&quot if long_tests else &quotexcluding&quot
    print(&quot (%s long tests)&quot % ex_in)

    print("Running Brian version {} "
          "from &quot{}&quot".format(brian2.__version__,
                               os.path.dirname(brian2.__file__)))

    all_targets = set(codegen_targets)

    if test_standalone:
        if not isinstance(test_standalone, basestring):
            raise ValueError(&quottest_standalone argument has to be the name of a &quot
                             &quotstandalone device (e.g. "cpp_standalone")&quot)
        if test_standalone not in all_devices:
            raise ValueError(&quottest_standalone argument "%s" is not a known &quot
                             &quotdevice. Known devices are: &quot
                             &quot%s&quot % (test_standalone,
                                     &quot, &quot.join(repr(d) for d in all_devices)))
        print(&quotTesting standalone&quot)
        all_targets.add(test_standalone)
    if test_codegen_independent:
        print(&quotTesting codegen-independent code&quot)
        all_targets.add(&quotcodegen_independent&quot)

    parallel_tests = all_targets.intersection(set(test_in_parallel))
    if parallel_tests:
        try:
            import xdist
            print(&quotTesting with multiple processes for %s&quot % &quot, &quot.join(
                parallel_tests))
        except ImportError:
            test_in_parallel = []

    if reset_preferences:
        print(&quotResetting to default preferences&quot)

    if reset_preferences:
        stored_prefs = prefs.as_file
        prefs.read_preference_file(StringIO(prefs.defaults_as_file))


    &#47&#47 Avoid failures in the tests for user-registered units
    import copy
    import brian2.units.fundamentalunits as fundamentalunits
    old_unit_registry = copy.copy(fundamentalunits.user_unit_register)
    fundamentalunits.user_unit_register = fundamentalunits.UnitRegistry()

    if float_dtype is not None:
        print(&quotSetting dtype for floating point variables to: &quot
                         &quot{}&quot.format(float_dtype.__name__))

        prefs[&quotcore.default_float_dtype&quot] = float_dtype

    print()

    &#47&#47 Suppress INFO log messages during testing
    from brian2.utils.logger import BrianLogger, LOG_LEVELS
    log_level = BrianLogger.console_handler.level
    BrianLogger.console_handler.setLevel(LOG_LEVELS[&quotWARNING&quot])

    &#47&#47 Switch off code optimization to get faster compilation times
    prefs[&quotcodegen.cpp.extra_compile_args_gcc&quot].extend([&quot-w&quot, &quot-O0&quot])
    prefs[&quotcodegen.cpp.extra_compile_args_msvc&quot].extend([&quot-w&quot, &quot-O0&quot])

    &#47&#47 if fail_for_not_implemented:
    &#47&#47     not_implemented_plugin = NotImplementedPlugin
    &#47&#47 else:
    &#47&#47     not_implemented_plugin = NotImplementedNoFailurePlugin
    &#47&#47 &#47&#47 This hack is needed to get the NotImplementedPlugin working for multiprocessing
    &#47&#47 import nose.plugins.multiprocess as multiprocess
    &#47&#47 multiprocess._instantiate_plugins = [not_implemented_plugin]
    &#47&#47
    &#47&#47 plugins = [not_implemented_plugin()]

    from brian2.devices import set_device
    set_device(&quotruntime&quot)
    pref_plugin = PreferencePlugin(prefs)
    try:
        success = []
        if test_codegen_independent:
            print(&quotRunning tests that do not use code generation&quot)
            &#47&#47 Some doctests do actually use code generation, use numpy for that
            prefs[&quotcodegen.target&quot] = &quotnumpy&quot
            &#47&#47 Print output changed in numpy 1.14, stick with the old format to
            &#47&#47 avoid doctest failures
            import numpy as np
            try:
                np.set_printoptions(legacy=&quot1.13&quot)
            except TypeError:
                pass  &#47&#47 using a numpy version &lt; 1.14
            argv = make_argv(dirnames, "codegen_independent")
            if &quotcodegen_independent&quot in test_in_parallel:
                argv.extend(multiprocess_arguments)
            &#47&#47     multiprocess._instantiate_plugins.append(OurDoctestPlugin)
            print(&quotexecuting with&quot, argv)
            pref_file.truncate(0)
            <a id="change">pref_file.write(prefs.as_file)</a>
            pref_file.flush()
            success.append(pytest.main(argv, plugins=[pref_plugin]) == 0)
            &#47&#47 if &quotcodegen_independent&quot in test_in_parallel:
            &#47&#47     multiprocess._instantiate_plugins.remove(OurDoctestPlugin)</code></pre><h3>After Change</h3><pre><code class='java'>
            &#47&#47 Some doctests do actually use code generation, use numpy for that
            prefs[&quotcodegen.target&quot] = &quotnumpy&quot
            argv = make_argv(dirnames, doctests=True)
            <a id="change">if &quotcodegen_independent&quot in test_in_parallel:
                argv.extend(multiprocess_arguments)
           </a> success.append(pytest.main(argv, plugins=[pref_plugin]) == 0)

            print(&quotRunning tests that do not use code generation&quot)
            argv = make_argv(dirnames, "codegen_independent")</code></pre>