<html><h3>edc5cf0c0e22b02d52de1b2e3ab89daceaa70c97,tensorlayer/layers.py,BiRNNLayer,__init__,#BiRNNLayer#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#Any#,3509
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            raise Exception("RNN : Input dimension should be rank 3 : [batch_size, n_steps, n_features]")

        with tf.variable_scope(name, initializer=initializer) as vs:
            <a id="change">self.fw_cell</a> = <a id="change">cell_fn(num_units=n_hidden, **cell_init_args)</a>
            <a id="change">self.bw_cell</a> = <a id="change">cell_fn(num_units=n_hidden, **cell_init_args)</a>
            &#47&#47 Apply dropout
            if dropout:
                if type(dropout) in [tuple, list]:
                    in_keep_prob = dropout[0]
                    out_keep_prob = dropout[1]
                elif isinstance(dropout, float):
                    in_keep_prob, out_keep_prob = dropout, dropout
                else:
                    raise Exception("Invalid dropout type (must be a 2-D tuple of "
                                    "float)")
                try: &#47&#47 TF 1.0
                    DropoutWrapper_fn = tf.contrib.rnn.DropoutWrapper
                except:
                    DropoutWrapper_fn = tf.nn.rnn_cell.DropoutWrapper
                <a id="change">self.fw_cell = DropoutWrapper_fn(
                          self.fw_cell,
                          input_keep_prob=in_keep_prob,
                          output_keep_prob=out_keep_prob)</a>
                <a id="change">self.bw_cell = DropoutWrapper_fn(
                          self.bw_cell,
                          input_keep_prob=in_keep_prob,
                          output_keep_prob=out_keep_prob)</a>
            &#47&#47 Apply multiple layers
            if n_layer &gt; 1:
                try: &#47&#47 TF1.0
                    MultiRNNCell_fn = tf.contrib.rnn.MultiRNNCell
                except:
                    MultiRNNCell_fn = tf.nn.rnn_cell.MultiRNNCell

                try:
                    self.fw_cell = MultiRNNCell_fn(<a id="change">[self.fw_cell] * n_layer</a>,
                                                          state_is_tuple=True)
                    <a id="change">self.bw_cell = MultiRNNCell_fn([self.bw_cell] * n_layer,
                                                          state_is_tuple=True)</a>
                except:
                    self.fw_cell = MultiRNNCell_fn([self.fw_cell] * n_layer)
                    self.bw_cell = MultiRNNCell_fn([self.bw_cell] * n_layer)

            &#47&#47 Initial state of RNN
            if fw_initial_state is None:
                self.fw_initial_state = self.fw_cell.zero_state(self.batch_size, dtype=tf.float32)
            else:
                self.fw_initial_state = fw_initial_state
            if bw_initial_state is None:
                <a id="change">self.bw_initial_state</a> = self.bw_cell.zero_state(self.batch_size, dtype=tf.float32)
            else:
                self.bw_initial_state = bw_initial_state
            &#47&#47 exit()</code></pre><h3>After Change</h3><pre><code class='java'>
            else:
                cell_creator = rnn_creator
            self.fw_cell = cell_creator()
            <a id="change">self.bw_cell = cell_creator()</a>

            &#47&#47 Apply multiple layers
            if n_layer &gt; 1:
                try: &#47&#47 TF1.0
                    MultiRNNCell_fn = tf.contrib.rnn.MultiRNNCell
                except:
                    MultiRNNCell_fn = tf.nn.rnn_cell.MultiRNNCell

                try:
                    self.fw_cell = MultiRNNCell_fn([cell_creator() for _ in range(n_layer)], state_is_tuple=True)
                    <a id="change">self.bw_cell = MultiRNNCell_fn([cell_creator() for _ in range(n_layer)], state_is_tuple=True)</a>
                except:
                    self.fw_cell = MultiRNNCell_fn([cell_creator() for _ in range(n_layer)])
                    self.bw_cell = <a id="change">MultiRNNCell_fn([cell_creator() for _ in range(n_layer)])</a>

            &#47&#47 Initial state of RNN
            if fw_initial_state is None:
                self.fw_initial_state = self.fw_cell.zero_state(self.batch_size, dtype=tf.float32)
            else:
                self.fw_initial_state = fw_initial_state
            if bw_initial_state is None:
                <a id="change">self.bw_initial_state</a> = self.bw_cell.zero_state(self.batch_size, dtype=tf.float32)
            else:
                self.bw_initial_state = bw_initial_state
            &#47&#47 exit()</code></pre><img src="109559431.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 39</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/tensorlayer/srgan/commit/edc5cf0c0e22b02d52de1b2e3ab89daceaa70c97#diff-4ae88bc9e7591485a5eb7a2f6592a370c907bee8518c1e2210e18586f5b75f96L3510' target='_blank'>Link</a></div><div id='project'> Project Name: tensorlayer/srgan</div><div id='commit'> Commit Name: edc5cf0c0e22b02d52de1b2e3ab89daceaa70c97</div><div id='time'> Time: 2017-06-06</div><div id='author'> Author: dhsig552@163.com</div><div id='file'> File Name: tensorlayer/layers.py</div><div id='class'> Class Name: BiRNNLayer</div><div id='method'> Method Name: __init__</div><BR><BR><div id='link'><a href='https://github.com/tensorlayer/srgan/commit/edc5cf0c0e22b02d52de1b2e3ab89daceaa70c97#diff-4ae88bc9e7591485a5eb7a2f6592a370c907bee8518c1e2210e18586f5b75f96L4126' target='_blank'>Link</a></div><div id='project'> Project Name: tensorlayer/srgan</div><div id='commit'> Commit Name: edc5cf0c0e22b02d52de1b2e3ab89daceaa70c97</div><div id='time'> Time: 2017-06-06</div><div id='author'> Author: dhsig552@163.com</div><div id='file'> File Name: tensorlayer/layers.py</div><div id='class'> Class Name: BiDynamicRNNLayer</div><div id='method'> Method Name: __init__</div><BR><BR><div id='link'><a href='https://github.com/tensorlayer/tensorlayer/commit/dcef47168e1d630fe02634f6a542df0c3571228d#diff-4ae88bc9e7591485a5eb7a2f6592a370c907bee8518c1e2210e18586f5b75f96L3517' target='_blank'>Link</a></div><div id='project'> Project Name: tensorlayer/tensorlayer</div><div id='commit'> Commit Name: dcef47168e1d630fe02634f6a542df0c3571228d</div><div id='time'> Time: 2017-05-15</div><div id='author'> Author: chentao904@163.com</div><div id='file'> File Name: tensorlayer/layers.py</div><div id='class'> Class Name: BiRNNLayer</div><div id='method'> Method Name: __init__</div><BR><BR><div id='link'><a href='https://github.com/tensorlayer/srgan/commit/edc5cf0c0e22b02d52de1b2e3ab89daceaa70c97#diff-4ae88bc9e7591485a5eb7a2f6592a370c907bee8518c1e2210e18586f5b75f96L3510' target='_blank'>Link</a></div><div id='project'> Project Name: tensorlayer/srgan</div><div id='commit'> Commit Name: edc5cf0c0e22b02d52de1b2e3ab89daceaa70c97</div><div id='time'> Time: 2017-06-06</div><div id='author'> Author: dhsig552@163.com</div><div id='file'> File Name: tensorlayer/layers.py</div><div id='class'> Class Name: BiRNNLayer</div><div id='method'> Method Name: __init__</div><BR><BR><div id='link'><a href='https://github.com/tensorlayer/tensorlayer/commit/dcef47168e1d630fe02634f6a542df0c3571228d#diff-4ae88bc9e7591485a5eb7a2f6592a370c907bee8518c1e2210e18586f5b75f96L4133' target='_blank'>Link</a></div><div id='project'> Project Name: tensorlayer/tensorlayer</div><div id='commit'> Commit Name: dcef47168e1d630fe02634f6a542df0c3571228d</div><div id='time'> Time: 2017-05-15</div><div id='author'> Author: chentao904@163.com</div><div id='file'> File Name: tensorlayer/layers.py</div><div id='class'> Class Name: BiDynamicRNNLayer</div><div id='method'> Method Name: __init__</div><BR>