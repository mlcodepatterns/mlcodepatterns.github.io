<html><h3>db09dc1fb503ab8f7de69fa23e8d38742bda8e90,ch07/02_dqn_n_steps.py,,,#,12
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    env = ptan.common.wrappers.wrap_dqn(env)

    writer = SummaryWriter(comment="-" + params[&quotrun_name&quot] + "-%d-step" % args.n)
    net = <a id="change">dqn_model.DQN(env.observation_space.shape, env.action_space.n)</a>
    <a id="change">if args.cuda:
        net.cuda()

   </a> tgt_net = ptan.agent.TargetNet(net)
    selector = ptan.actions.EpsilonGreedyActionSelector(epsilon=params[&quotepsilon_start&quot])
    epsilon_tracker = common.EpsilonTracker(selector, params)
    agent = ptan.agent.DQNAgent(net, selector, cuda=args.cuda)</code></pre><h3>After Change</h3><pre><code class='java'>
    parser.add_argument("--cuda", default=False, action="store_true", help="Enable cuda")
    parser.add_argument("-n", default=REWARD_STEPS_DEFAULT, type=int, help="Count of steps to unroll Bellman")
    args = parser.parse_args()
    <a id="change">device = torch.device("cuda" if args.cuda else "cpu")</a>

    env = gym.make(params[&quotenv_name&quot])
    env = ptan.common.wrappers.wrap_dqn(env)

    writer = SummaryWriter(comment="-" + params[&quotrun_name&quot] + "-%d-step" % args.n)
    net = <a id="change">dqn_model.DQN(env.observation_space.shape, env.action_space.n).to(device)</a>

    tgt_net = ptan.agent.TargetNet(net)
    selector = ptan.actions.EpsilonGreedyActionSelector(epsilon=params[&quotepsilon_start&quot])
    epsilon_tracker = common.EpsilonTracker(selector, params)</code></pre><img src="128603834.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/PacktPublishing/Deep-Reinforcement-Learning-Hands-On/commit/db09dc1fb503ab8f7de69fa23e8d38742bda8e90#diff-bc7110902b3580406be7ee1b83c7294bc776f4d219a35e31f226bb2d0110d77dL20' target='_blank'>Link</a></div><div id='project'> Project Name: PacktPublishing/Deep-Reinforcement-Learning-Hands-On</div><div id='commit'> Commit Name: db09dc1fb503ab8f7de69fa23e8d38742bda8e90</div><div id='time'> Time: 2018-04-27</div><div id='author'> Author: max.lapan@gmail.com</div><div id='file'> File Name: ch07/02_dqn_n_steps.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: </div><BR><BR><div id='link'><a href='https://github.com/PacktPublishing/Deep-Reinforcement-Learning-Hands-On/commit/db09dc1fb503ab8f7de69fa23e8d38742bda8e90#diff-d04d281efcf168611c35672ea3dc2fea2267fe65fbdcb734db1bd5e18f339fcbL18' target='_blank'>Link</a></div><div id='project'> Project Name: PacktPublishing/Deep-Reinforcement-Learning-Hands-On</div><div id='commit'> Commit Name: db09dc1fb503ab8f7de69fa23e8d38742bda8e90</div><div id='time'> Time: 2018-04-27</div><div id='author'> Author: max.lapan@gmail.com</div><div id='file'> File Name: ch07/01_dqn_basic.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: </div><BR><BR><div id='link'><a href='https://github.com/PacktPublishing/Deep-Reinforcement-Learning-Hands-On/commit/db09dc1fb503ab8f7de69fa23e8d38742bda8e90#diff-03bb8411193f16cfff67f183b35d5ec767f69bc66631a91d06d37ba76de5c703L61' target='_blank'>Link</a></div><div id='project'> Project Name: PacktPublishing/Deep-Reinforcement-Learning-Hands-On</div><div id='commit'> Commit Name: db09dc1fb503ab8f7de69fa23e8d38742bda8e90</div><div id='time'> Time: 2018-04-27</div><div id='author'> Author: max.lapan@gmail.com</div><div id='file'> File Name: ch07/03_dqn_double.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: </div><BR>