<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    )

    if self._summarize_grads_and_vars:
      <a id="change">with tf.name_scope(&quotVariables/&quot):
        for var in self._actor_network.trainable_weights:
          tf.compat.v2.summary.histogram(
              name=var.name.replace(&quot:&quot, &quot_&quot),
              data=var,
              step=self.train_step_counter)

   </a> return loss_info

  @eager_utils.future_in_eager_mode
  def _loss(self, time_steps, actions, returns, weights):</code></pre><h3>After Change</h3><pre><code class='java'>
                            experience.observation)

    variables_to_train = self._actor_network.variables
    <a id="change">with tf.GradientTape() as tape:
      loss_info = self._loss(time_step,
                             experience.action,
                             tf.stop_gradient(returns),
                             weights=weights)
      tf.debugging.check_numerics(loss_info.loss, &quotLoss is inf or nan&quot)
   </a> grads = tape.gradient(loss_info.loss, variables_to_train)

    grads_and_vars = zip(grads, variables_to_train)
    if self._gradient_clipping:</code></pre>