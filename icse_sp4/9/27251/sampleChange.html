<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

  def _get_initial_state(self, batch_size, dtype, initial_state=None):
    &#47&#47 TODO: make this decoder eager-friendly.
    <a id="change">if tf.executing_eagerly():
      raise RuntimeError("Attention-based RNN decoder are currently not compatible "
                         "with eager execution")
   </a> <a id="change">initial_cell_state = super(AttentionalRNNDecoder, self)._get_initial_state(
        batch_size, dtype, initial_state=initial_state)</a>
    <a id="change">attention_mechanism = self.attention_mechanism_class(
        self.cell.output_size,
        self.memory,
        memory_sequence_length=self.memory_sequence_length,
        dtype=self.memory.dtype)</a>
    if self.first_layer_attention:
      self.cell.cells[0] = tfa.seq2seq.AttentionWrapper(
          self.cell.cells[0],
          attention_mechanism,</code></pre><h3>After Change</h3><pre><code class='java'>
    if initial_state is not None:
      if self.first_layer_attention:
        cell_state = list(decoder_state)
        cell_state[0] = <a id="change">decoder_state</a>[<a id="change">0</a>].cell_state
        cell_state = self.bridge(initial_state, cell_state)
        cell_state[0] = decoder_state[0].clone(cell_state=cell_state[0])
        decoder_state = tuple(cell_state)</code></pre>