<html><h3>ff0d04f231cc8cd912a99982269dca0c41a68316,thinc/neural/_classes/batchnorm.py,BatchNorm,begin_update,#BatchNorm#Any#Any#,43
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        diff = X - self.m
        incr = (1-alpha) * diff
        self.m += incr.mean(axis=0)
        self.v += <a id="change">(diff * incr).mean(axis=0)</a>
        self.v *= alpha

        Xhat = _forward(self.ops, X, mu, var)

        &#47&#47 Batch "renormalization"
        if self.nr_upd &gt;= 7500:
            <a id="change">Xhat *= var / (self.v+1e-08)</a>
            Xhat += (mu - self.m) / (self.v+1e-08)

        y, backprop_rescale = self._begin_update_scale_shift(Xhat)
</code></pre><h3>After Change</h3><pre><code class='java'>
        return y

    def begin_update(self, X, drop=0.):
        <a id="change">if drop is None:
            return self.predict(X), None
       </a> assert X.dtype == &quotfloat32&quot
        X, backprop_child = self.child.begin_update(X, drop=0.)
        N, mu, var = _get_moments(self.ops, X)
        var += self.eps
        self.r = min(self.rmax, max(1. / self.rmax, var / self.v))
        self.d = min(self.dmax, max(-self.dmax, (mu-self.m) / self.v))
        self.nr_upd += 1

        &#47&#47 I&quotm not sure this is the best thing to do --
        &#47&#47 Should we consider a sample be the instance, or the batch?
        &#47&#47 If we want the variance of the inputs it should be like:
        &quot&quot&quot
        diff = X - self.m
        incr = (1-alpha) * diff
        self.m += incr.mean(axis=0)
        self.v += (diff * incr).mean(axis=0)
        self.v *= alpha
        &quot&quot&quot
        <a id="change">self.m += self.alpha * (mu - self.m)</a>
        self.v += self.alpha * (var - self.v)
        Xhat = _forward(self.ops, X, mu, var)
        Xhat *= self.r
        Xhat += self.d</code></pre><img src="296699567.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/explosion/thinc/commit/ff0d04f231cc8cd912a99982269dca0c41a68316#diff-109786c0d7b3ddfaa47501c055f28058edf07707406dd5b965311a49967021baL43' target='_blank'>Link</a></div><div id='project'> Project Name: explosion/thinc</div><div id='commit'> Commit Name: ff0d04f231cc8cd912a99982269dca0c41a68316</div><div id='time'> Time: 2018-03-14</div><div id='author'> Author: honnibal+gh@gmail.com</div><div id='file'> File Name: thinc/neural/_classes/batchnorm.py</div><div id='class'> Class Name: BatchNorm</div><div id='method'> Method Name: begin_update</div><BR><BR><div id='link'><a href='https://github.com/explosion/thinc/commit/3611452afac53b53f3e41ee83d7fc7bd811ffb81#diff-109786c0d7b3ddfaa47501c055f28058edf07707406dd5b965311a49967021baL43' target='_blank'>Link</a></div><div id='project'> Project Name: explosion/thinc</div><div id='commit'> Commit Name: 3611452afac53b53f3e41ee83d7fc7bd811ffb81</div><div id='time'> Time: 2018-03-14</div><div id='author'> Author: honnibal+gh@gmail.com</div><div id='file'> File Name: thinc/neural/_classes/batchnorm.py</div><div id='class'> Class Name: BatchNorm</div><div id='method'> Method Name: begin_update</div><BR><BR><div id='link'><a href='https://github.com/stellargraph/stellargraph/commit/0aa1073c28edff2434b9a4d0fb0657084441a694#diff-d7808b795d267cd5105e681870a2aab28e4cbf8fc235ec1b744d080803326dedL386' target='_blank'>Link</a></div><div id='project'> Project Name: stellargraph/stellargraph</div><div id='commit'> Commit Name: 0aa1073c28edff2434b9a4d0fb0657084441a694</div><div id='time'> Time: 2019-01-09</div><div id='author'> Author: andrew.docherty@data61.csiro.au</div><div id='file'> File Name: stellargraph/layer/graphsage.py</div><div id='class'> Class Name: MeanPoolingAggregator</div><div id='method'> Method Name: call</div><BR>