<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

  &#47&#47 NumPy has an np.argparition() method, however log(1000) is so small that
  &#47&#47 sorting the whole array is simpler and fast enough.
  <a id="change">top_indicies = np.argsort(predicted_scores_by_user, axis=1)[:, -_TOP_K:]</a>
  top_indicies = np.flip(top_indicies, axis=1)

  &#47&#47 Both HR and NDCG vectorized computation takes advantage of the fact that if
  &#47&#47 the positive example for a user is not in the top k, that index does not
  &#47&#47 appear. That is to say:   hit_ind.shape[0] &lt;= num_users
  hit_ind = np.argwhere(np.equal(top_indicies, 0))
  hr = hit_ind.shape[0] / ncf_dataset.num_users
  <a id="change">ndcg = np.sum(np.log(2) / np.log(hit_ind[:, 1] + 2)) / ncf_dataset.num_users</a>

  global_step = estimator.get_variable_value(tf.GraphKeys.GLOBAL_STEP)
  eval_results = {
      _HR_KEY: hr,</code></pre><h3>After Change</h3><pre><code class='java'>
  &#47&#47 Get predictions
  predictions = estimator.predict(input_fn=pred_input_fn,
                                  yield_single_examples=False)
  <a id="change">predictions = list(predictions)</a>

  prediction_batches = [p[movielens.RATING_COLUMN] for p in predictions]
  <a id="change">item_batches = [p[movielens.ITEM_COLUMN] for p in predictions]</a>

  &#47&#47 Reshape the predicted scores and items. Each user takes one row.
  prediction_with_padding = np.concatenate(prediction_batches, axis=0)
  predicted_scores_by_user = prediction_with_padding[
      :ncf_dataset.num_users * (1 + rconst.NUM_EVAL_NEGATIVES)]\
      .reshape(ncf_dataset.num_users, -1)
  <a id="change">item_with_padding = np.concatenate(item_batches, axis=0)</a>
  items_by_user = item_with_padding[
      :ncf_dataset.num_users * (1 + rconst.NUM_EVAL_NEGATIVES)]\
      .reshape(ncf_dataset.num_users, -1)
</code></pre>