<html><h3>718677ebb044e27aaf1a30640c2f7ab6b8fa8509,fairseq/criterions/masked_lm.py,MaskedLmLoss,forward,#MaskedLmLoss#Any#Any#Any#,25
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            ignore_index=self.padding_idx,
        )

        <a id="change">sample_size = targets.ne(self.padding_idx).int().sum().item()</a>

        logging_output = {
            &quotloss&quot: utils.item(loss.data) if reduce else loss.data,
            &quotnll_loss&quot: utils.item(loss.data) if reduce else loss.data,</code></pre><h3>After Change</h3><pre><code class='java'>
        3) logging outputs to display while training
        
        &#47&#47 compute MLM loss
        <a id="change">masked_tokens = sample[&quottarget&quot].ne(self.padding_idx)</a>
        logits = model(**sample[&quotnet_input&quot], masked_tokens=masked_tokens)[0]
        targets = model.get_targets(sample, [logits])
        targets = targets[masked_tokens]

        loss = F.nll_loss(
            F.log_softmax(
                logits.view(-1, logits.size(-1)),
                dim=-1,
                dtype=torch.float32,
            ),
            targets.view(-1),
            reduction=&quotsum&quot,
            ignore_index=self.padding_idx,
        )

        <a id="change">sample_size = masked_tokens.int().sum().item()</a>

        logging_output = {
            &quotloss&quot: utils.item(loss.data) if reduce else loss.data,
            &quotnll_loss&quot: utils.item(loss.data) if reduce else loss.data,</code></pre><img src="295975772.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 8</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/pytorch/fairseq/commit/718677ebb044e27aaf1a30640c2f7ab6b8fa8509#diff-7d953f4b0fa135da1ac3c7dad3a9de2313a9c57ea301723b9c0d8b4c4e2a6417L33' target='_blank'>Link</a></div><div id='project'> Project Name: pytorch/fairseq</div><div id='commit'> Commit Name: 718677ebb044e27aaf1a30640c2f7ab6b8fa8509</div><div id='time'> Time: 2019-09-18</div><div id='author'> Author: namangoyal@learnfair0893.h2.fair</div><div id='file'> File Name: fairseq/criterions/masked_lm.py</div><div id='class'> Class Name: MaskedLmLoss</div><div id='method'> Method Name: forward</div><BR><BR><div id='link'><a href='https://github.com/jadore801120/attention-is-all-you-need-pytorch/commit/24357bb63d8338158ddb7fefaf35ca4bd7064f31#diff-ed183d67207df065a11e1289f19d34cc2abbc5448dea952683cfe9728c342b95L31' target='_blank'>Link</a></div><div id='project'> Project Name: jadore801120/attention-is-all-you-need-pytorch</div><div id='commit'> Commit Name: 24357bb63d8338158ddb7fefaf35ca4bd7064f31</div><div id='time'> Time: 2018-08-22</div><div id='author'> Author: yhhuang@nlg.csie.ntu.edu.tw</div><div id='file'> File Name: train.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: get_performance</div><BR>