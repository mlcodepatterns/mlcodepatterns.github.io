<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        s[data_vec].parallel(parallel_axis)
        data_vec = data_vec.op.input_tensors[0]

    <a id="change">if autotvm.GLOBAL_SCOPE.in_tuning:
        &#47&#47 only in autotuning, input data of conv2d_NCHWc will be 4-D.
        &#47&#47 skip this part during tuning to make records accurate.
        &#47&#47 this part will be folded during Relay fold_constant pass.
        s[data_vec].pragma(s[data_vec].op.axis[0], "debug_skip_region")
        s[kernel_vec].pragma(s[kernel_vec].op.axis[0], "debug_skip_region")
    elif isinstance(kernel_vec.op, tvm.te.ComputeOp) and \
            kernel_vec.name == &quotkernel_vec&quot:
        &#47&#47 data and kernel are not pre-computed, schedule layout transform here.
        &#47&#47 this should only be used by x86 conv2d_nchw, which is for
        &#47&#47 testing purpose.
        batch, ic_chunk, ih, ic_block, iw = s[data_vec].op.axis
        parallel_axis = s[data_vec].fuse(batch, ic_chunk, ih)
        s[data_vec].parallel(parallel_axis)

        oc_chunk, ic_chunk, oh, ow, ic_block, oc_block = s[kernel_vec].op.axis
        s[kernel_vec].reorder(oc_chunk, oh, ic_chunk, ow, ic_block, oc_block)
        oc_bn = cfg["tile_oc"].size[-1]
        if oc_bn &gt; 1:
            s[kernel_vec].vectorize(oc_block)
        parallel_axis = s[kernel_vec].fuse(oc_chunk, oh)
        s[kernel_vec].parallel(parallel_axis)

   </a> C, O = conv_out, last
    CC = s.cache_write(C, &quotglobal&quot)

    batch, oc_chunk, oh, ow, oc_block = s[C].op.axis</code></pre><h3>After Change</h3><pre><code class='java'>
    if isinstance(s[data_vec].op, tvm.te.ComputeOp) \
            and "pad" in data_vec.op.tag:
        batch, ic_chunk, ih, iw, ic_block = s[data_vec].op.axis
        <a id="change">s[data_vec].vectorize(ic_block)</a>
        parallel_axis = s[data_vec].fuse(batch, ic_chunk, ih)
        s[data_vec].parallel(parallel_axis)
        data_vec = data_vec.op.input_tensors[0]
</code></pre>