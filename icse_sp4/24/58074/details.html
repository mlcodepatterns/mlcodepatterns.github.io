<html><h3>e8ee5ce8baba0330f5b64e36c34b12f52a5ad29e,pyannote/audio/embedding/models.py,ClopiNet,__call__,#ClopiNet#Any#,289
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 stack (bidirectional) LSTM layers
        for i, output_dim in enumerate(self.lstm):

            <a id="change">if i:
                lstm = LSTM(output_dim,
                            name=&quotlstm_{i:d}&quot.format(i=i),
                            return_sequences=True,
                            activation=&quottanh&quot)
            else:
                &#47&#47 we need to provide input_shape to first LSTM
                lstm = LSTM(output_dim,
                            input_shape=input_shape,
                            name=&quotlstm_{i:d}&quot.format(i=i),
                            return_sequences=True,
                            activation=&quottanh&quot)

            &#47&#47 bi-directional LSTM
           </a> if self.bidirectional:
                lstm = Bidirectional(lstm, merge_mode=self.bidirectional)

            &#47&#47 (actually) stack LSTM</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 stack (bidirectional) LSTM layers
        for i, output_dim in enumerate(self.lstm):

            <a id="change">params = {
                &quotname&quot: &quotlstm_{i:d}&quot.format(i=i),
                &quotreturn_sequences&quot: True,
                &#47&#47 &quotgo_backwards&quot: False,
                &#47&#47 &quotstateful&quot: False,
                &#47&#47 &quotunroll&quot: False,
                &#47&#47 &quotimplementation&quot: 0,
                &quotactivation&quot: &quottanh&quot,
                &#47&#47 &quotrecurrent_activation&quot: &quothard_sigmoid&quot,
                &#47&#47 &quotuse_bias&quot: True,
                &#47&#47 &quotkernel_initializer&quot: &quotglorot_uniform&quot,
                &#47&#47 &quotrecurrent_initializer&quot: &quotorthogonal&quot,
                &#47&#47 &quotbias_initializer&quot: &quotzeros&quot,
                &#47&#47 &quotunit_forget_bias&quot: True,
                &#47&#47 &quotkernel_regularizer&quot: None,
                &#47&#47 &quotrecurrent_regularizer&quot: None,
                &#47&#47 &quotbias_regularizer&quot: None,
                &#47&#47 &quotactivity_regularizer&quot: None,
                &#47&#47 &quotkernel_constraint&quot: None,
                &#47&#47 &quotrecurrent_constraint&quot: None,
                &#47&#47 &quotbias_constraint&quot: None,
                &#47&#47 &quotdropout&quot: 0.0,
                &#47&#47 &quotrecurrent_dropout&quot: 0.0,
            }</a>

            &#47&#47 first LSTM needs to be given the input shape
            <a id="change">if i == 0:
                params[&quotinput_shape&quot] = input_shape

           </a> <a id="change">lstm = LSTM(output_dim, **params)</a>

            &#47&#47 bi-directional LSTM
            if self.bidirectional:
                lstm = Bidirectional(lstm, merge_mode=self.bidirectional)</code></pre><img src="269355396.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 12</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/pyannote/pyannote-audio/commit/e8ee5ce8baba0330f5b64e36c34b12f52a5ad29e#diff-cadcde2a7efbfc28165845cd52dc1d4720b008380e6c96ce68b4f2e0ed871b42L311' target='_blank'>Link</a></div><div id='project'> Project Name: pyannote/pyannote-audio</div><div id='commit'> Commit Name: e8ee5ce8baba0330f5b64e36c34b12f52a5ad29e</div><div id='time'> Time: 2017-04-24</div><div id='author'> Author: bredin@limsi.fr</div><div id='file'> File Name: pyannote/audio/embedding/models.py</div><div id='class'> Class Name: ClopiNet</div><div id='method'> Method Name: __call__</div><BR><BR><div id='link'><a href='https://github.com/pyannote/pyannote-audio/commit/e8ee5ce8baba0330f5b64e36c34b12f52a5ad29e#diff-cadcde2a7efbfc28165845cd52dc1d4720b008380e6c96ce68b4f2e0ed871b42L124' target='_blank'>Link</a></div><div id='project'> Project Name: pyannote/pyannote-audio</div><div id='commit'> Commit Name: e8ee5ce8baba0330f5b64e36c34b12f52a5ad29e</div><div id='time'> Time: 2017-04-24</div><div id='author'> Author: bredin@limsi.fr</div><div id='file'> File Name: pyannote/audio/embedding/models.py</div><div id='class'> Class Name: TristouNet</div><div id='method'> Method Name: __call__</div><BR><BR><div id='link'><a href='https://github.com/pyannote/pyannote-audio/commit/e8ee5ce8baba0330f5b64e36c34b12f52a5ad29e#diff-cadcde2a7efbfc28165845cd52dc1d4720b008380e6c96ce68b4f2e0ed871b42L219' target='_blank'>Link</a></div><div id='project'> Project Name: pyannote/pyannote-audio</div><div id='commit'> Commit Name: e8ee5ce8baba0330f5b64e36c34b12f52a5ad29e</div><div id='time'> Time: 2017-04-24</div><div id='author'> Author: bredin@limsi.fr</div><div id='file'> File Name: pyannote/audio/embedding/models.py</div><div id='class'> Class Name: TrottiNet</div><div id='method'> Method Name: __call__</div><BR>