<html><h3>a55f9be217b2320cec7c7dc44a8245496f851af5,softlearning/algorithms/sac.py,SAC,_get_Q_target,#SAC#,175
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    def _get_Q_target(self):
        next_actions = self._policy.actions([self._next_observations_ph])
        next_log_pis = self._policy.log_pis(
            <a id="change">[self._next_observations_ph]</a>, next_actions)

        next_Qs_values = tuple(
            Q([self._next_observations_ph, next_actions])
            for Q in self._Q_targets)

        min_next_Q = tf.reduce_min(next_Qs_values, axis=0)
        next_value = min_next_Q - self._alpha * next_log_pis

        Q_target = td_target(
            reward=self._reward_scale * self._rewards_ph,
            discount=self._discount,
            next_value=(1 - self._terminals_ph) * next_value)

        <a id="change">return Q_target</a>

    def _init_critic_update(self):
        Create minimization operation for critic Q-function.
</code></pre><h3>After Change</h3><pre><code class='java'>
            discount=self._discount,
            next_value=(1 - terminals) * next_values)

        <a id="change">return tf.stop_gradient(Q_target)</a>

    def _init_critic_update(self):
        Create minimization operation for critic Q-function.
</code></pre><img src="899653.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/rail-berkeley/softlearning/commit/a55f9be217b2320cec7c7dc44a8245496f851af5#diff-c427dfbb58b5337d68da626b8e4cbd3324fb1836da0ca03e40cb9be61520c9ddL159' target='_blank'>Link</a></div><div id='project'> Project Name: rail-berkeley/softlearning</div><div id='commit'> Commit Name: a55f9be217b2320cec7c7dc44a8245496f851af5</div><div id='time'> Time: 2019-06-01</div><div id='author'> Author: hartikainen@berkeley.edu</div><div id='file'> File Name: softlearning/algorithms/sac.py</div><div id='class'> Class Name: SAC</div><div id='method'> Method Name: _get_Q_target</div><BR><BR><div id='link'><a href='https://github.com/rail-berkeley/softlearning/commit/459441e166ebcd176698041e260d4f467652e7ac#diff-cbb1f8079a190e0b795dc0a5866f21740149e766d88ab90cebca35d5a1f6a92dL25' target='_blank'>Link</a></div><div id='project'> Project Name: rail-berkeley/softlearning</div><div id='commit'> Commit Name: 459441e166ebcd176698041e260d4f467652e7ac</div><div id='time'> Time: 2018-07-21</div><div id='author'> Author: kristian.hartikainen@gmail.com</div><div id='file'> File Name: softlearning/policies/uniform_policy.py</div><div id='class'> Class Name: UniformPolicy</div><div id='method'> Method Name: get_action</div><BR><BR><div id='link'><a href='https://github.com/rail-berkeley/softlearning/commit/90409b97bf72a44b6f99dc3285d0a3c11c6cc355#diff-f43d4789de441b93392e882e689b02b95b62163f33610256d53269a8f6ddcedfL85' target='_blank'>Link</a></div><div id='project'> Project Name: rail-berkeley/softlearning</div><div id='commit'> Commit Name: 90409b97bf72a44b6f99dc3285d0a3c11c6cc355</div><div id='time'> Time: 2018-10-16</div><div id='author'> Author: hartikainen@berkeley.edu</div><div id='file'> File Name: softlearning/replay_pools/flexible_replay_pool.py</div><div id='class'> Class Name: FlexibleReplayPool</div><div id='method'> Method Name: random_indices</div><BR>