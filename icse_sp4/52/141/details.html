<html><h3>85aea8b77a57afbb8d81a1235382b73bff6552be,examples/mujoco_all_sql_remote.py,,run_experiment,#Any#,103
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>


def run_experiment(variant):
    <a id="change">if variant[&quotenv_name&quot] == &quothumanoid-rllab&quot:
        env = normalize(HumanoidEnv())
    elif variant[&quotenv_name&quot] == &quotswimmer-rllab&quot:
        env = normalize(SwimmerEnv())
    else:
        env = normalize(GymEnv(variant[&quotenv_name&quot]))

   </a> env = DelayedEnv(env, delay=0.01)

    pool = SimpleReplayPool(
        env_spec=<a id="change">env.spec</a>, max_size=variant[&quotmax_pool_size&quot])

    sampler = RemoteSampler(
        max_path_length=variant[&quotmax_path_length&quot],
        min_pool_size=variant[&quotmax_path_length&quot],
        batch_size=variant[&quotbatch_size&quot])

    base_kwargs = dict(
        epoch_length=variant[&quotepoch_length&quot],
        n_epochs=variant[&quotn_epochs&quot],
        n_train_repeat=variant[&quotn_train_repeat&quot],
        eval_render=False,
        eval_n_episodes=1,
        sampler=sampler)

    M = variant[&quotlayer_size&quot]
    qf = NNQFunction(env_spec=<a id="change">env.spec</a>, hidden_layer_sizes=(M, M))

    policy = StochasticNNPolicy(env_spec=<a id="change">env.spec</a>, hidden_layer_sizes=(M, M))

    algorithm = SQL(
        base_kwargs=base_kwargs,</code></pre><h3>After Change</h3><pre><code class='java'>


def run_experiment(variant):
    <a id="change">universe = variant[&quotuniverse&quot]</a>

    assert universe in [&quotrllab&quot, &quotgym&quot], universe

    <a id="change">task = variant[&quottask&quot]</a>
    <a id="change">domain = variant[&quotdomain&quot]</a>

    <a id="change">env = get_environment(universe, domain, task, env_params={})</a>
    env = DelayedEnv(env, delay=0.01)

    pool = SimpleReplayPool(
        observation_shape=<a id="change">env.observation_space.shape</a>,
        action_shape=<a id="change">env.action_space.shape</a>,
        max_size=variant[&quotmax_pool_size&quot])

    sampler = RemoteSampler(
        max_path_length=variant[&quotmax_path_length&quot],
        min_pool_size=variant[&quotmax_path_length&quot],
        batch_size=variant[&quotbatch_size&quot])

    base_kwargs = dict(
        epoch_length=variant[&quotepoch_length&quot],
        n_epochs=variant[&quotn_epochs&quot],
        n_train_repeat=variant[&quotn_train_repeat&quot],
        eval_render=False,
        eval_n_episodes=1,
        sampler=sampler)

    M = variant[&quotlayer_size&quot]
    qf = NNQFunction(
        observation_shape=<a id="change">env.observation_space.shape</a>,
        action_shape=<a id="change">env.action_space.shape</a>,
        hidden_layer_sizes=(M, M))

    policy = StochasticNNPolicy(
        observation_shape=<a id="change">env.observation_space.shape</a>,
        action_shape=<a id="change">env.action_space.shape</a>,
        hidden_layer_sizes=(M, M))

    algorithm = SQL(</code></pre><img src="1852316.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 40</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/rail-berkeley/softlearning/commit/85aea8b77a57afbb8d81a1235382b73bff6552be#diff-c41aa6748495adf63ca083af0754bd8286859a3f947080ff560e18054b47b2c8L89' target='_blank'>Link</a></div><div id='project'> Project Name: rail-berkeley/softlearning</div><div id='commit'> Commit Name: 85aea8b77a57afbb8d81a1235382b73bff6552be</div><div id='time'> Time: 2018-07-27</div><div id='author'> Author: kristian.hartikainen@gmail.com</div><div id='file'> File Name: examples/mujoco_all_sql_remote.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: run_experiment</div><BR><BR><div id='link'><a href='https://github.com/rail-berkeley/softlearning/commit/85aea8b77a57afbb8d81a1235382b73bff6552be#diff-0897881dc4cf5ec2327051a46cb9b06fc52e0301582200004aa667400109dd3cL96' target='_blank'>Link</a></div><div id='project'> Project Name: rail-berkeley/softlearning</div><div id='commit'> Commit Name: 85aea8b77a57afbb8d81a1235382b73bff6552be</div><div id='time'> Time: 2018-07-27</div><div id='author'> Author: kristian.hartikainen@gmail.com</div><div id='file'> File Name: examples/mujoco_all_sac_remote.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: run_experiment</div><BR><BR><div id='link'><a href='https://github.com/rail-berkeley/softlearning/commit/85aea8b77a57afbb8d81a1235382b73bff6552be#diff-844b0907573be0aa48fee64575ba0f25289f2849a90a5362cc9fa4b2df3e1b11L108' target='_blank'>Link</a></div><div id='project'> Project Name: rail-berkeley/softlearning</div><div id='commit'> Commit Name: 85aea8b77a57afbb8d81a1235382b73bff6552be</div><div id='time'> Time: 2018-07-27</div><div id='author'> Author: kristian.hartikainen@gmail.com</div><div id='file'> File Name: examples/mujoco_all_sql.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: run_experiment</div><BR><BR><div id='link'><a href='https://github.com/rail-berkeley/softlearning/commit/85aea8b77a57afbb8d81a1235382b73bff6552be#diff-c41aa6748495adf63ca083af0754bd8286859a3f947080ff560e18054b47b2c8L103' target='_blank'>Link</a></div><div id='project'> Project Name: rail-berkeley/softlearning</div><div id='commit'> Commit Name: 85aea8b77a57afbb8d81a1235382b73bff6552be</div><div id='time'> Time: 2018-07-27</div><div id='author'> Author: kristian.hartikainen@gmail.com</div><div id='file'> File Name: examples/mujoco_all_sql_remote.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: run_experiment</div><BR>