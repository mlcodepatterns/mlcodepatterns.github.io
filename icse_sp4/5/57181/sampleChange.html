<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
  &#47&#47 Cloud ML requires dynamic batch sizes, so set shape to [None].
  input_jpeg_str = tf.placeholder(tf.string, shape=[None])
  &#47&#47 For each instance in batch, calculate the bottleneck.
  <a id="change">bottleneck_tensor = tf.map_fn(
      ml_utils.get_bottleneck_tensor,
      input_jpeg_str,
      back_prop=False,
      dtype=tf.float32)</a>
  &#47&#47 Reduce dimension in bottleneck - we want to feed a BATCH_SIZE x 2048 tensor
  &#47&#47 to dense layer, to produce a BATCH_SIZE x NUMBER_OF_CLASSES tensor.
  bottleneck_tensor = tf.squeeze(bottleneck_tensor, [1])
  _, normalized_tensor, prediction_index = _create_dense_and_softmax_layers(</code></pre><h3>After Change</h3><pre><code class='java'>
    score is the score for the predicted label.
  

  <a id="change">img_bytes</a>, bottleneck_tensor = ml_utils.create_fixed_weight_input_graph()
  _, normalized_tensor, prediction_index = _create_dense_and_softmax_layers(
      bottleneck_tensor, class_count)
  &#47&#47 Get the prediction (label) for a given tensor index.</code></pre>