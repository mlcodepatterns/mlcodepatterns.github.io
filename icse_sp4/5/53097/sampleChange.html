<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        &#47&#47 setup GPU device if available, move model into configured device
        n_gpu_use = config[&quotn_gpu&quot]
        <a id="change">n_gpu = torch.cuda.device_count()</a>
        if n_gpu_use &gt; 0 and n_gpu == 0:
            self.logger.warning("Warning: There\&quots no GPU available on this machine, training will be performed on CPU.")
            n_gpu_use = 0
        if n_gpu_use &gt; n_gpu:
            msg = "Warning: The number of GPU\&quots configured to use is {}, but only {} are available on this machine.".format(n_gpu_use, n_gpu)
            self.logger.warning(msg)
            n_gpu_use = n_gpu
        self.device = torch.device(&quotcuda:0&quot if n_gpu_use &gt; 0 else &quotcpu&quot)
        self.model = model.to(self.device)
        if n_gpu_use &gt; 1:
            <a id="change">self.model</a> = torch.nn.DataParallel(model, device_ids=list(range(n_gpu_use)))

        self.loss = loss
        self.metrics = metrics</code></pre><h3>After Change</h3><pre><code class='java'>
        self.logger = logging.getLogger(self.__class__.__name__)

        &#47&#47 setup GPU device if available, move model into configured device
        <a id="change">self</a>.device, device_ids = self._prepare_device(config[&quotn_gpu&quot])
        self.model = model.to(self.device)
        if len(device_ids) &gt; 1:
            self.model = torch.nn.DataParallel(model, device_ids=device_ids)</code></pre>