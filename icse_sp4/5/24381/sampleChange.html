<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
      features = tf.parse_example(serialized_tf_example, feature_spec)
      return tf.estimator.export.ServingInputReceiver(features, receiver_tensors)

    <a id="change">estimator.export_savedmodel(args.export_dir, serving_input_receiver_fn)</a>


if __name__ == &quot__main__&quot:
  import argparse</code></pre><h3>After Change</h3><pre><code class='java'>
    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)

  else:  &#47&#47 mode == &quotinference&quot
    <a id="change">if args.input_mode == &quotspark&quot:
      tf_feed = TFNode.DataFeed(ctx.mgr)

      def rdd_generator():
        while not tf_feed.should_stop():
          batch = tf_feed.next_batch(1)
          if len(batch) &gt; 0:
            record = batch[0]
            image = numpy.array(record[0]).astype(numpy.float32) / 255.0
            label = numpy.array(record[1]).astype(numpy.float32)
            yield (image, label)

      def predict_input_fn():
        ds = tf.data.Dataset.from_generator(rdd_generator,
                                            (tf.float32, tf.float32),
                                            (tf.TensorShape([IMAGE_PIXELS * IMAGE_PIXELS]), tf.TensorShape([10])))
        ds = ds.batch(args.batch_size)
        return ds

      predictions = estimator.predict(predict_input_fn)
      for result in predictions:
        tf_feed.batch_results([result])


</a>if __name__ == &quot__main__&quot:
  import argparse
  from pyspark.context import SparkContext
  from pyspark.conf import SparkConf</code></pre>