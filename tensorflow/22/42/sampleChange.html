<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        kernel_shape=self.KERNEL_SHAPE,
        use_bias=use_bias,
        stride=stride,
        initializers=<a id="change">create_constant_initializers(1.0, 1.0, use_bias)</a>)
    x = tf.constant(np.random.random(self.INPUT_SHAPE).astype(np.float32))
    <a id="change">self.helperDataFormats(func, x)</a>

  @parameterized.named_parameters(
      ("WithBias_Stride1", True, 1), ("WithoutBias_Stride1", False, 1),
      ("WithBias_Stride2", True, 2), ("WithoutBias_Stride2", False, 2))</code></pre><h3>After Change</h3><pre><code class='java'>
        initializers=create_initializers(use_bias))

    conv1 = func(name="NHWC", data_format="NHWC")
    <a id="change">x</a> = tf.constant(np.random.random(self.INPUT_SHAPE).astype(np.float32))
    <a id="change">o1 = conv1(x)</a>

    &#47&#47 We will force both modules to share the same weights by creating
    &#47&#47 a custom getter that returns the weights from the first conv module when
    &#47&#47 tf.get_variable is called.
    custom_getter = {"w": create_custom_field_getter(conv1, "w"),
                     "b": create_custom_field_getter(conv1, "b")}
    conv2 = func(name="NCHW", data_format="NCHW", custom_getter=custom_getter)
    <a id="change">x_transpose = tf.transpose(x, perm=(0, 3, 1, 2))</a>
    <a id="change">o2 = tf.transpose(conv2(x_transpose), perm=(0, 2, 3, 1))</a>

    <a id="change">self.checkEquality(o1, o2)</a>

  @parameterized.named_parameters(("WithBias", True), ("WithoutBias", False))
  def testConv2DDataFormatsBatchNorm(self, use_bias):
    Similar to `testConv2DDataFormats`, but this checks BatchNorm support.</code></pre>